{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be21346a",
   "metadata": {},
   "source": [
    "# 04-4 Agent Implementation\n",
    "\n",
    "- LangGraph + Pydantic v2（仕様準拠、既存ロジック変更なし）\n",
    "- 入力: `artifacts/{RUN_ID}/handoff/04-3_llm_tools_setup.pkl`\n",
    "- 出力: `artifacts/{RUN_ID}/handoff/04-4_agent_implementation.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcc5711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN_ID] 2025-10-22_074213\n",
      "[IN]  artifacts/2025-10-22_074213/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
      "[OUT] artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Dynamic RUN_ID Bootstrap (aligned with 04-3) ===\n",
    "import os, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def bootstrap_run_id(force_new: bool=False) -> str:\n",
    "    ROOT = Path(\".\").resolve()\n",
    "    ARTIFACTS = ROOT / \"artifacts\"\n",
    "    ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "    env_id = os.environ.get(\"RUN_ID\", \"\").strip()\n",
    "    if env_id and not force_new:\n",
    "        run_id = env_id\n",
    "    else:\n",
    "        latest_file = ARTIFACTS / \"LATEST_RUN_ID.txt\"\n",
    "        if latest_file.exists() and not force_new:\n",
    "            run_id = latest_file.read_text().strip()\n",
    "        else:\n",
    "            pat = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}_\\d{6}$\")\n",
    "            dirs = [p.name for p in ARTIFACTS.iterdir() if p.is_dir() and pat.match(p.name)]\n",
    "            run_id = sorted(dirs, reverse=True)[0] if (dirs and not force_new) else datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    (ARTIFACTS / \"LATEST_RUN_ID.txt\").write_text(run_id)\n",
    "    os.environ[\"RUN_ID\"] = run_id\n",
    "    return run_id\n",
    "\n",
    "RUN_ID = bootstrap_run_id(False)\n",
    "\n",
    "ARTIFACTS   = Path(\"artifacts\") / RUN_ID\n",
    "HANDOFF_DIR = ARTIFACTS / \"handoff\"\n",
    "RESULTS_DIR = ARTIFACTS / \"results\"\n",
    "HANDOFF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_HANDOFF_PKL  = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "OUT_HANDOFF_PKL = HANDOFF_DIR / \"04-4_agent_implementation.pkl\"\n",
    "\n",
    "print(f\"[RUN_ID] {RUN_ID}\")\n",
    "print(f\"[IN]  {IN_HANDOFF_PKL}\")\n",
    "print(f\"[OUT] {OUT_HANDOFF_PKL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af41a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-4] handoff file exists: artifacts/2025-10-22_074213/handoff/04-3_llm_tools_setup_with_tools.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2a: Preflight handoff presence ===\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path(IN_HANDOFF_PKL).is_file():\n",
    "    raise FileNotFoundError(f\"[04-4] handoff file not found: {IN_HANDOFF_PKL}\\n\"\n",
    "                            \"→ 04-3 を実行して 04-3_llm_tools_setup.pkl を生成してください。\")\n",
    "print(f\"[04-4] handoff file exists: {IN_HANDOFF_PKL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af33d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-4] handoff keys: {'cfg': 'OK', 'tools': 'OK', 'llm': 'OK'}\n",
      "[04-4] extra/stat keys detected: ['brand_keywords', 'cert_full_info_map']\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3: Load handoff payload (STRICT) ===\n",
    "import pickle\n",
    "\n",
    "with open(IN_HANDOFF_PKL, \"rb\") as f:\n",
    "    payload = pickle.load(f) or {}\n",
    "\n",
    "required = [\"cfg\", \"tools\", \"llm\"]\n",
    "missing  = [k for k in required if k not in payload or payload[k] is None]\n",
    "print(\"[04-4] handoff keys:\", {k: (\"OK\" if k not in missing else \"MISSING\") for k in required})\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(f\"[04-4] handoff missing required keys: {missing}\"\n",
    "                       f\"@ {IN_HANDOFF_PKL}\"\n",
    "                       \"→ 04-3 を修正／再実行して必要キーを含めてください。\")\n",
    "\n",
    "# Bind globals (no logic change)\n",
    "cfg   = payload[\"cfg\"]\n",
    "tools = payload[\"tools\"]\n",
    "llm   = payload[\"llm\"]\n",
    "\n",
    "# Read-only report of extra/stat keys if present\n",
    "stats_like = {k: v for k, v in payload.items() if \"stat\" in k.lower() or \"brand\" in k.lower() or \"cert\" in k.lower()}\n",
    "print(\"[04-4] extra/stat keys detected:\", list(stats_like.keys())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745ecf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5.5: Structured Output Schema Definition (Pydantic v2) ===\n",
    "# Purpose: Define Pydantic models to structure ALL agent I/O (LLM outputs & tool returns)\n",
    "#          with type-safety and rich validation. This cell is intentionally standalone.\n",
    "#\n",
    "# Notes:\n",
    "# - Field descriptions are in English for better LLM alignment; Japanese comments are for maintainers.\n",
    "# - Backward compatibility: each model exposes `.to_dict()` (alias of `model_dump()`).\n",
    "# - Pydantic v2 API (`field_validator`, `model_validator`) only; v1 is not required in this repo/runtime.\n",
    "#\n",
    "# Ref: https://docs.pydantic.dev/latest/ (v2)\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional, List, Dict, Any, Literal\n",
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator, model_validator, ValidationInfo\n",
    "\n",
    "# -------- Shared literals / limits --------\n",
    "RiskLevelLiteral = Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "ActionLiteral    = Literal[\"block\", \"warn\", \"allow\", \"review\"]\n",
    "StepLiteral      = Literal[\"initial\", \"brand_check\", \"cert_check\", \"domain_check\", \"decision\", \"complete\"]\n",
    "\n",
    "_MAX_REASON_LEN = 4096\n",
    "_MAX_STR_LEN    = 256\n",
    "_MAX_LIST_EVIDENCE = 32\n",
    "_MAX_LIST_PATTERNS = 64\n",
    "\n",
    "def _coerce_float_01(x: Any, default: float = 0.0) -> float:\n",
    "    \"\"\"Coerce to float in [0,1]. If out of range or invalid, clamp to [0,1].\"\"\"\n",
    "    try:\n",
    "        f = float(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "    if f < 0.0:\n",
    "        return 0.0\n",
    "    if f > 1.0:\n",
    "        return 1.0\n",
    "    return f\n",
    "\n",
    "class _ModelMixin:\n",
    "    \"\"\"Backward-compat mixin to expose dict-like outputs expected by legacy code.\"\"\"\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return self.model_dump()\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any]):\n",
    "        return cls(**data)\n",
    "\n",
    "# -------- 1) BrandAnalysisResult --------\n",
    "class BrandAnalysisResult(_ModelMixin, BaseModel):\n",
    "    \"\"\"Structured result of brand impersonation analysis.\"\"\"\n",
    "    is_impersonation: bool = Field(..., description=\"True if the domain likely impersonates a known brand.\")\n",
    "    detected_brand: Optional[str] = Field(\n",
    "        None, description=\"Canonical name of the impersonated brand if detected (normalized), else null.\",\n",
    "        max_length=_MAX_STR_LEN\n",
    "    )\n",
    "    confidence: float = Field(0.0, description=\"Confidence score in [0.0, 1.0] for the impersonation judgment.\")\n",
    "    evidence: List[str] = Field(default_factory=list, description=\"List of short evidence snippets supporting the judgment.\")\n",
    "    risk_level: RiskLevelLiteral = Field(\"low\", description=\"Risk level based on brand context and patterns.\")\n",
    "\n",
    "    # Validators\n",
    "    @field_validator(\"confidence\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_confidence(cls, v):\n",
    "        return _coerce_float_01(v, default=0.0)\n",
    "\n",
    "    @field_validator(\"evidence\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_evidence_len(cls, v):\n",
    "        v = v or []\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            v = list(v)[:_MAX_LIST_EVIDENCE]\n",
    "        else:\n",
    "            v = [str(v)][:1]\n",
    "        return [str(x)[:_MAX_STR_LEN] for x in v]\n",
    "\n",
    "# -------- 2) CertificateAnalysisResult --------\n",
    "class CertificateAnalysisResult(_ModelMixin, BaseModel):\n",
    "    \"\"\"Security-focused summary of the target's TLS certificate properties.\"\"\"\n",
    "    has_certificate: bool = Field(..., description=\"True if any valid certificate was found for the domain.\")\n",
    "    is_valid: bool = Field(False, description=\"True if the certificate is currently valid (date range, parsing succeeded).\")\n",
    "    age_days: int = Field(-1, description=\"Certificate age in days (from NotBefore to now); -1 if unknown/unavailable.\")\n",
    "    issuer: Optional[str] = Field(None, description=\"Certificate issuer organization (normalized), if available.\", max_length=_MAX_STR_LEN)\n",
    "    is_free_ca: bool = Field(False, description=\"True if a free CA (e.g., Let's Encrypt) issued the certificate.\")\n",
    "    is_wildcard: bool = Field(False, description=\"True if a wildcard certificate (*.example.com).\")\n",
    "    san_count: int = Field(0, description=\"Number of SAN entries on the certificate.\")\n",
    "    risk_factors: List[str] = Field(default_factory=list, description=\"List of risk factors derived from certificate fields.\")\n",
    "    confidence: float = Field(0.0, description=\"Confidence score in [0.0, 1.0] for the certificate-related assessment.\")\n",
    "\n",
    "    @field_validator(\"san_count\", \"age_days\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_non_negative_or_minus1(cls, v, info: ValidationInfo):\n",
    "        # san_count: >=0 ; age_days: -1 or >=0\n",
    "        try:\n",
    "            iv = int(v)\n",
    "        except Exception:\n",
    "            iv = -1 if info.field_name == \"age_days\" else 0\n",
    "        if info.field_name == \"age_days\":\n",
    "            return iv if iv >= -1 else -1\n",
    "        return max(0, iv)\n",
    "\n",
    "    @field_validator(\"confidence\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_confidence(cls, v):\n",
    "        return _coerce_float_01(v, default=0.0)\n",
    "\n",
    "    @field_validator(\"risk_factors\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_risk_factors(cls, v):\n",
    "        v = v or []\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            v = list(v)[:_MAX_LIST_EVIDENCE]\n",
    "        else:\n",
    "            v = [str(v)][:1]\n",
    "        return [str(x)[:_MAX_STR_LEN] for x in v]\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _v_is_valid_consistency(self):\n",
    "        # has_certificate=False => is_valid must be False, san_count=0\n",
    "        if not self.has_certificate:\n",
    "            self.is_valid = False\n",
    "            self.san_count = 0\n",
    "        return self\n",
    "\n",
    "# -------- 3) DomainAnalysisResult --------\n",
    "class DomainAnalysisResult(_ModelMixin, BaseModel):\n",
    "    \"\"\"Structured summary of domain structure risks and lexical signals.\"\"\"\n",
    "    is_suspicious: bool = Field(..., description=\"True if domain structure suggests phishing or abuse.\")\n",
    "    domain_length: int = Field(0, description=\"Length of the full domain string (host only, no scheme).\")\n",
    "    has_suspicious_tld: bool = Field(False, description=\"True if the TLD is in a known dangerous list.\")\n",
    "    tld: str = Field(..., description=\"Top-level domain (without leading dot), e.g., 'com', 'co.jp'.\")\n",
    "    typosquatting_candidate: Optional[str] = Field(None, description=\"Closest brand or domain candidate (if any).\", max_length=_MAX_STR_LEN)\n",
    "    levenshtein_distance: Optional[int] = Field(None, description=\"Edit distance to the candidate when relevant (non-negative).\")\n",
    "    risk_factors: List[str] = Field(default_factory=list, description=\"List of risk factor codes or short explanations.\")\n",
    "    confidence: float = Field(0.0, description=\"Confidence score in [0.0, 1.0] for the domain structural assessment.\")\n",
    "\n",
    "    @field_validator(\"domain_length\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_len(cls, v):\n",
    "        try:\n",
    "            iv = int(v)\n",
    "        except Exception:\n",
    "            iv = 0\n",
    "        return max(0, iv)\n",
    "\n",
    "    @field_validator(\"tld\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_tld(cls, v):\n",
    "        v = (v or \"\").strip()\n",
    "        if v.startswith(\".\"):\n",
    "            v = v[1:]\n",
    "        return v[:_MAX_STR_LEN]\n",
    "\n",
    "    @field_validator(\"levenshtein_distance\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_lev(cls, v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        try:\n",
    "            iv = int(v)\n",
    "        except Exception:\n",
    "            iv = 0\n",
    "        return max(0, iv)\n",
    "\n",
    "    @field_validator(\"risk_factors\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_rf(cls, v):\n",
    "        v = v or []\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            v = list(v)[:_MAX_LIST_EVIDENCE]\n",
    "        else:\n",
    "            v = [str(v)][:1]\n",
    "        return [str(x)[:_MAX_STR_LEN] for x in v]\n",
    "\n",
    "    @field_validator(\"confidence\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_confidence(cls, v):\n",
    "        return _coerce_float_01(v, default=0.0)\n",
    "\n",
    "# -------- 4) PhishingDetectionResult (main output) --------\n",
    "class PhishingDetectionResult(_ModelMixin, BaseModel):\n",
    "    \"\"\"Final phishing verdict with integrated signals from ML, certificate, domain & brand checks.\"\"\"\n",
    "    domain: str = Field(..., description=\"Target domain under evaluation (host only).\", min_length=1, max_length=_MAX_STR_LEN)\n",
    "    is_phishing: bool = Field(..., description=\"True if the final decision is phishing.\")\n",
    "    confidence: float = Field(..., description=\"Overall confidence in [0.0, 1.0] for the final decision.\")\n",
    "    risk_level: RiskLevelLiteral = Field(..., description=\"Normalized risk level summarizing overall severity.\")\n",
    "    ml_probability: float = Field(..., description=\"Raw ML model probability (0.0 to 1.0).\")\n",
    "    brand_analysis: Optional[BrandAnalysisResult] = Field(None, description=\"Nested result of brand impersonation analysis.\")\n",
    "    certificate_analysis: Optional[CertificateAnalysisResult] = Field(None, description=\"Nested result of certificate analysis.\")\n",
    "    domain_analysis: Optional[DomainAnalysisResult] = Field(None, description=\"Nested result of domain structure analysis.\")\n",
    "    reasoning: str = Field(..., description=\"Concise explanation describing why the decision was made.\", max_length=_MAX_REASON_LEN)\n",
    "    detected_patterns: List[str] = Field(default_factory=list, description=\"Patterns detected during analysis (codes or short strings).\")\n",
    "    recommended_action: ActionLiteral = Field(\"review\", description=\"Recommended action for downstream systems or analysts.\")\n",
    "\n",
    "    @field_validator(\"confidence\", \"ml_probability\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_range_01(cls, v):\n",
    "        return _coerce_float_01(v, default=0.0)\n",
    "\n",
    "    @field_validator(\"detected_patterns\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_patterns(cls, v):\n",
    "        v = v or []\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            v = list(v)[:_MAX_LIST_PATTERNS]\n",
    "        else:\n",
    "            v = [str(v)][:1]\n",
    "        return [str(x)[:_MAX_STR_LEN] for x in v]\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _v_action_coherence(self):\n",
    "        # If risk is high/critical, never return 'allow'\n",
    "        if self.risk_level in (\"high\", \"critical\") and self.recommended_action == \"allow\":\n",
    "            self.recommended_action = \"warn\"\n",
    "        return self\n",
    "\n",
    "# -------- 5) AgentState (LangGraph state) --------\n",
    "class AgentState(_ModelMixin, BaseModel):\n",
    "    \"\"\"Internal state for LangGraph-based agent orchestration.\"\"\"\n",
    "    current_step: StepLiteral = Field(\"initial\", description=\"Current step in the agent pipeline.\")\n",
    "    domain: Optional[str] = Field(None, description=\"Domain being processed, if any.\", max_length=_MAX_STR_LEN)\n",
    "    ml_probability: Optional[float] = Field(None, description=\"ML probability available at state time; [0.0, 1.0].\")\n",
    "    intermediate_results: Dict[str, Any] = Field(default_factory=dict, description=\"Arbitrary map to store tool and node results.\")\n",
    "    final_result: Optional[PhishingDetectionResult] = Field(None, description=\"Finalized detection result if complete.\")\n",
    "    error: Optional[str] = Field(None, description=\"Latest error message, if any.\", max_length=1024)\n",
    "    retry_count: int = Field(0, description=\"How many times the agent retried recoverable failures.\")\n",
    "\n",
    "    @field_validator(\"retry_count\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_retry_non_negative(cls, v):\n",
    "        try:\n",
    "            iv = int(v)\n",
    "        except Exception:\n",
    "            iv = 0\n",
    "        return max(0, iv)\n",
    "\n",
    "    @field_validator(\"ml_probability\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _v_mlprob_range(cls, v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        return _coerce_float_01(v, default=0.0)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _v_consistency(self):\n",
    "        # When complete, final_result should exist; if not, write error\n",
    "        if self.current_step == \"complete\" and self.final_result is None:\n",
    "            self.error = self.error or \"State is 'complete' but final_result is None.\"\n",
    "        return self\n",
    "\n",
    "# ---- Public exports ----\n",
    "__all__ = [\n",
    "    \"BrandAnalysisResult\",\n",
    "    \"CertificateAnalysisResult\",\n",
    "    \"DomainAnalysisResult\",\n",
    "    \"PhishingDetectionResult\",\n",
    "    \"AgentState\",\n",
    "    \"RiskLevelLiteral\",\n",
    "    \"ActionLiteral\",\n",
    "    \"StepLiteral\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Usage examples (commented)\n",
    "# -------------------------\n",
    "# result = PhishingDetectionResult(\n",
    "#     domain=\"example.com\",\n",
    "#     is_phishing=True,\n",
    "#     confidence=0.85,\n",
    "#     risk_level=\"high\",\n",
    "#     ml_probability=0.30,\n",
    "#     reasoning=\"High similarity to brand login + dangerous TLD + very new cert.\"\n",
    "# )\n",
    "#\n",
    "# # LLM structured output (LangChain-style):\n",
    "# #   llm_with_structured_output = llm.with_structured_output(PhishingDetectionResult)\n",
    "# #   response = llm_with_structured_output.invoke(\"Please analyze this domain: example.com\")\n",
    "# #\n",
    "# # Backward compatibility:\n",
    "# #   payload = result.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e129498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> [Cell6] bootstrapping LangGraph-based agent…\n",
      "✅ LangGraph-based PhishingDetectionAgent defined; evaluate_domain bound. (fallback mode: sequential)\n"
     ]
    }
   ],
   "source": [
    "# === セル6（LangGraph-based Phishing Detection Agent）===\n",
    "# 目的: 既存の PhishingDetectionAgent / evaluate_domain を定義し、LangGraph でのワークフローを提供。\n",
    "# 互換: 既存 evaluate_domain を維持。_call_tool / _structured / _to_dict を提供。\n",
    "# 失敗時: langgraph 等の import に失敗した場合は、直列実行のフォールバックで evaluate() を提供。\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, time, traceback, builtins\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "print(\">> [Cell6] bootstrapping LangGraph-based agent…\")\n",
    "\n",
    "# --- Helpers & model adapters -------------------------------------------------\n",
    "\n",
    "def _now_ms() -> int:\n",
    "    import time as _t\n",
    "    return int(_t.time() * 1000)\n",
    "\n",
    "def _to_dict(obj: Any) -> Dict[str, Any]:\n",
    "    if isinstance(obj, dict):\n",
    "        return obj\n",
    "    for attr in (\"model_dump\", \"dict\"):\n",
    "        if hasattr(obj, attr):\n",
    "            try:\n",
    "                return getattr(obj, attr)()\n",
    "            except Exception:\n",
    "                pass\n",
    "    try:\n",
    "        return json.loads(getattr(obj, \"json\")())\n",
    "    except Exception:\n",
    "        return {\"value\": repr(obj)}\n",
    "\n",
    "def _structured(kind: str, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    Model = globals().get(kind, None)\n",
    "    if Model is None:\n",
    "        return dict(data)\n",
    "    try:\n",
    "        if hasattr(Model, \"__call__\"):\n",
    "            inst = Model(**data)\n",
    "            if hasattr(inst, \"model_dump\"):\n",
    "                try:\n",
    "                    return inst.model_dump()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if hasattr(inst, \"__dict__\"):\n",
    "                return dict(inst.__dict__)\n",
    "        return dict(data)\n",
    "    except Exception:\n",
    "        return dict(data)\n",
    "\n",
    "def _risk_to_score(level: str) -> int:\n",
    "    m = {\"low\": 20, \"medium\": 50, \"medium-high\": 70, \"high\": 85, \"critical\": 95}\n",
    "    return m.get(str(level).lower(), 0)\n",
    "\n",
    "def _ensure_cfg(base: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    cfg0: Dict[str, Any] = {}\n",
    "    if isinstance(base, dict):\n",
    "        cfg0.update(base)\n",
    "    g = globals()\n",
    "    if isinstance(g.get(\"cfg\"), dict):\n",
    "        tmp = g[\"cfg\"].copy()\n",
    "        tmp.update(cfg0)\n",
    "        cfg0 = tmp\n",
    "    try:\n",
    "        from _compat import config as _cfgm\n",
    "        if hasattr(_cfgm, \"load_configuration\"):\n",
    "            c2 = _cfgm.load_configuration(cfg_override=cfg0)\n",
    "            if isinstance(c2, dict):\n",
    "                return c2\n",
    "    except Exception:\n",
    "        pass\n",
    "    return cfg0\n",
    "\n",
    "# Provide a proper global `_call_tool` used by wrappers & graph nodes\n",
    "def _call_tool(tool_name: str, **kwargs) -> Dict[str, Any]:\n",
    "    g = globals()\n",
    "    fn = g.get(tool_name)\n",
    "    if fn is None:\n",
    "        return {\"success\": False, \"error\": f\"Tool `{tool_name}` not available\"}\n",
    "    try:\n",
    "        res = fn(**kwargs)\n",
    "        out = _to_dict(res)\n",
    "        if isinstance(out, dict) and \"success\" not in out:\n",
    "            out[\"success\"] = True\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": f\"{tool_name} failed: {type(e).__name__}: {e}\", \"traceback\": traceback.format_exc()}\n",
    "\n",
    "globals()['_call_tool'] = _call_tool\n",
    "\n",
    "# --- Optional LangGraph import ------------------------------------------------\n",
    "HAVE_LG = True\n",
    "try:\n",
    "    from lib.langgraph import graph as _lg  # project vendored alias if present\n",
    "    StateGraph, END, START = _lg.StateGraph, _lg.END, _lg.START\n",
    "except Exception:\n",
    "    try:\n",
    "        from langgraph import StateGraph, END, START\n",
    "    except Exception as e:\n",
    "        HAVE_LG = False\n",
    "        _LG_IMPORT_ERROR = e\n",
    "\n",
    "# --- Agent definition ---------------------------------------------------------\n",
    "\n",
    "class PhishingDetectionAgent:\n",
    "    \"\"\"LangGraph-based (with graceful fallback) phishing detection orchestrator.\n",
    "    Exposes:\n",
    "      - evaluate(domain, ml_probability, trace=None) -> PhishingDetectionResult (dict)\n",
    "      - batch_evaluate(domains, probs) -> List[PhishingDetectionResult]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: Optional[Dict[str, Any]] = None):\n",
    "        self.cfg: Dict[str, Any] = _ensure_cfg(cfg)\n",
    "        self.graph = None\n",
    "        if HAVE_LG:\n",
    "            try:\n",
    "                self.graph = self._build_graph()\n",
    "            except Exception:\n",
    "                print(\"!! [Cell6] LangGraph build failed, falling back to sequential:\", _LG_IMPORT_ERROR)\n",
    "                self.graph = None\n",
    "        else:\n",
    "            print(\"!! [Cell6] langgraph not available → using sequential fallback\")\n",
    "\n",
    "    def _build_graph(self):\n",
    "        def brand_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            domain = state.get(\"domain\"); mlp = float(state.get(\"ml_probability\") or 0.0)\n",
    "            try:\n",
    "                tool = \"brand_impersonation_check\"\n",
    "                if \"wordlist_detector\" in globals():\n",
    "                    tool = \"wordlist_detector\"\n",
    "                out = _call_tool(tool, domain=domain, ml_probability=mlp, cfg=self._ctx())\n",
    "                res = {\n",
    "                    \"is_impersonation\": bool(out.get(\"is_impersonation\") or out.get(\"is_suspicious\")),\n",
    "                    \"confidence\": float(out.get(\"confidence\", 0.0) or 0.0),\n",
    "                    \"risk_level\": out.get(\"risk_level\", \"low\"),\n",
    "                    \"detected_brands\": out.get(\"detected_brands\") or out.get(\"brands\") or [],\n",
    "                    \"risk_factors\": out.get(\"risk_factors\", {}),\n",
    "                    \"reasons\": out.get(\"reasons\", []),\n",
    "                    \"success\": out.get(\"success\", True),\n",
    "                    \"error\": out.get(\"error\"),\n",
    "                }\n",
    "                st = dict(state)\n",
    "                st.setdefault(\"intermediate_results\", {})\n",
    "                st[\"intermediate_results\"][\"brand\"] = _structured(\"BrandAnalysisResult\", res)\n",
    "                st[\"current_step\"] = \"certificate_check\" if (res[\"is_impersonation\"] or _risk_to_score(res[\"risk_level\"])>=70) else \"domain_check\"\n",
    "                return st\n",
    "            except Exception as e:\n",
    "                st = dict(state); st.setdefault(\"intermediate_results\", {})\n",
    "                st[\"intermediate_results\"][\"brand\"] = _structured(\"BrandAnalysisResult\", {\n",
    "                    \"is_impersonation\": False, \"confidence\": 0.0, \"risk_level\":\"low\",\n",
    "                    \"risk_factors\": {\"error\": str(e)}, \"reasons\": [\"brand node error\"], \"success\": False\n",
    "                })\n",
    "                st[\"current_step\"] = \"certificate_check\"\n",
    "                return st\n",
    "\n",
    "        def cert_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            domain = state.get(\"domain\"); mlp = float(state.get(\"ml_probability\") or 0.0)\n",
    "            out = _call_tool(\"certificate_analysis\", domain=domain, ml_probability=mlp, cfg=self._ctx())\n",
    "            res = {\n",
    "                \"confidence\": float(out.get(\"confidence\", 0.0) or 0.0),\n",
    "                \"risk_level\": out.get(\"risk_level\", \"low\"),\n",
    "                \"risk_factors\": out.get(\"risk_factors\", {}),\n",
    "                \"reasons\": out.get(\"reasons\", []),\n",
    "                \"success\": out.get(\"success\", True),\n",
    "                \"error\": out.get(\"error\"),\n",
    "            }\n",
    "            st = dict(state); st.setdefault(\"intermediate_results\", {})\n",
    "            st[\"intermediate_results\"][\"cert\"] = _structured(\"CertificateAnalysisResult\", res)\n",
    "            st[\"current_state\"] = \"domain_check\"\n",
    "            return st\n",
    "\n",
    "        def domain_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            domain = state.get(\"domain\"); mlp = float(state.get(\"ml_probability\") or 0.0)\n",
    "            out = _call_tool(\"short_domain_analysis\", domain=domain, ml_probability=mlp, cfg=self._ctx())\n",
    "            res = {\n",
    "                \"is_suspicious\": bool(out.get(\"is_suspicious\", False)),\n",
    "                \"confidence\": float(out.get(\"confidence\", 0.0) or 0.0),\n",
    "                \"risk_level\": out.get(\"risk_level\", \"low\"),\n",
    "                \"risk_factors\": out.get(\"risk_factors\", {}),\n",
    "                \"reasons\": out.get(\"reasons\", []),\n",
    "                \"success\": out.get(\"success\", True),\n",
    "                \"error\": out.get(\"error\"),\n",
    "            }\n",
    "            st = dict(state); st.setdefault(\"intermediate_results\", {})\n",
    "            st[\"intermediate_results\"][\"domain\"] = _structured(\"DomainAnalysisResult\", res)\n",
    "            st[\"current_state\"] = \"decision\"\n",
    "            return st\n",
    "\n",
    "        def decide_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            brand = state.get(\"intermediate_results\", {}).get(\"brand\", {}) or {}\n",
    "            cert  = state.get(\"intermediate_results\", {}).get(\"cert\", {}) or {}\n",
    "            dom   = state.get(\"intermediate_results\", {}).get(\"domain\", {}) or {}\n",
    "            mlp   = float(state.get(\"ml_probability\") or 0.0)\n",
    "\n",
    "            conf = max(float(brand.get(\"confidence\",0.0) or 0.0),\n",
    "                       float(dom.get(\"confidence\",0.0) or 0.0),\n",
    "                       float(cert.get(\"confidence\",0.0) or 0.0))\n",
    "            risk_score = max(\n",
    "                int(conf * 100),\n",
    "                _risk_to_score(brand.get(\"risk_level\")),\n",
    "                _risk_to_score(dom.get(\"risk_level\")),\n",
    "                _risk_to_score(cert.get(\"risk_level\"))\n",
    "            )\n",
    "            is_phish = bool(brand.get(\"is_impersonation\")) or bool(dom.get(\"is_suspicious\")) or (risk_score >= 50)\n",
    "\n",
    "            lvl = \"low\"\n",
    "            if   risk_score >= 85: lvl = \"critical\"\n",
    "            elif risk_score >= 70: lvl = \"high\"\n",
    "            elif risk_score >= 50: lvl = \"medium-high\"\n",
    "            elif risk_score >= 30: lvl = \"medium\"\n",
    "\n",
    "            result = {\n",
    "                \"domain\": state.get(\"name\") or state.get(\"domain\"),\n",
    "                \"ml_probability\": mlp,\n",
    "                \"is_phishing\": bool(is_phish),\n",
    "                \"confidence\": float(max(0.0, min(1.0, conf))),\n",
    "                \"risk_level\": lvl,\n",
    "                \"detected_brands\": brand.get(\"lures\", []) or brand.get(\"detected_brands\", []),\n",
    "                \"risk_factors\": {\n",
    "                    \"brand\":       brand.get(\"risk_factors\", {}),\n",
    "                    \"domain\":      dom.get(\"risk_factors\", {}),\n",
    "                    \"certificate\": cert.get(\"risk_factors\", {}),\n",
    "                },\n",
    "                \"reasons\": (brand.get(\"reasons\", []) or []) + (dom.get(\"reasons\", []) or []) + (cert.get(\"reasons\", []) or []),\n",
    "                \"success\": bool(brand.get(\"success\", True) and dom.get(\"success\", True) and cert.get(\"success\", True)),\n",
    "            }\n",
    "            st = dict(state); st[\"result\"] = _structured(\"PhishingDetectionResult\", result); st[\"current_state\"] = \"done\"\n",
    "            return st\n",
    "\n",
    "        g = StateGraph(dict)\n",
    "        g.add_node(\"brand_check\",       lambda s: brand_node(s))\n",
    "        g.add_node(\"certificate_check\", lambda s: cert_node(s))\n",
    "        g.add_node(\"domain_check\",      lambda s: domain_node(s))\n",
    "        g.add_node(\"decision\",          lambda s: decide_node(s))\n",
    "        g.set_entry_point(\"brand_check\")\n",
    "        g.add_conditional_edges(\"brand_check\", lambda s: s.get(\"current_state\",\"domain_check\"),\n",
    "                                {\"certificate_check\":\"certificate_check\",\"domain_check\":\"domain_check\"})\n",
    "        g.add_edge(\"certificate_check\", \"domain_check\")\n",
    "        g.add_conditional_edges(\"domain_check\", lambda s: \"decision\", {\"decision\":\"decision\"})\n",
    "        g.add_edge(\"decision\", END)\n",
    "        return g\n",
    "\n",
    "    def _ctx(self) -> Dict[str, Any]:\n",
    "        ctx = {\"cfg\": self.cfg}\n",
    "        return ctx\n",
    "\n",
    "    def evaluate(self, domain: str, ml_probability: float, trace: Optional[Any] = None) -> Dict[str, Any]:\n",
    "        state0 = {\n",
    "            \"name\": str(domain),\n",
    "            \"domain\": str(domain),\n",
    "            \"ml_probability\": float(ml_probability or 0.0),\n",
    "            \"intermediate_results\": {},\n",
    "            \"current_state\": \"brand_check\",\n",
    "        }\n",
    "        if self.graph is not None:\n",
    "            try:\n",
    "                runtime = self.graph.compile()\n",
    "                out = runtime.invoke(state0)\n",
    "                res = out.get(\"result\")\n",
    "                if res:\n",
    "                    return _to_dict(res)\n",
    "            except Exception as e:\n",
    "                print(\"!! [Cell6] graph run failed → fallback to sequential:\", e)\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "        b = _call_tool(\"brand_impersonation_check\", domain=domain, ml_probability=ml_probability, cfg=self._ctx())\n",
    "        c = _call_tool(\"certificate_analysis\",      domain=domain, ml_probability=ml_probability, cfg=self._ctx())\n",
    "        d = _call_tool(\"short_domain_analysis\",     domain=domain, ml_probability=ml_probability, cfg=self._ctx())\n",
    "\n",
    "        conf = max(float(b.get(\"confidence\",0.0) or 0.0),\n",
    "                   float(c.get(\"confidence\",0.0) or 0.0),\n",
    "                   float(d.get(\"confidence\",0.0) or 0.0))\n",
    "        risk_score = max(\n",
    "            int(conf*100),\n",
    "            _risk_to_score(b.get(\"risk_level\")),\n",
    "            _risk_to_score(c.get(\"risk_level\")),\n",
    "            _risk_to_score(d.get(\"risk_level\"))\n",
    "        )\n",
    "        is_phish = bool(b.get(\"is_phishing\") or b.get(\"is_impersonation\")) or bool(d.get(\"is_suspicious\")) or (risk_score >= 50)\n",
    "\n",
    "        lvl = \"low\"\n",
    "        if   risk_score >= 85: lvl = \"critical\"\n",
    "        elif risk_score >= 70: lvl = \"high\"\n",
    "        elif risk_score >= 50: lvl = \"medium-high\"\n",
    "        elif risk_score >= 30: lvl = \"medium\"\n",
    "\n",
    "        result = {\n",
    "            \"domain\": str(domain),\n",
    "            \"ml_probability\": float(ml_probability or 0.0),\n",
    "            \"is_phishing\": bool(is_phish),\n",
    "            \"confidence\": float(conf),\n",
    "            \"risk_level\": lvl,\n",
    "            \"detected_brands\": b.get(\"detected_brands\", []),\n",
    "            \"risk_factors\": {\n",
    "                \"brand\":       b.get(\"risk_factors\", {}),\n",
    "                \"domain\":      d.get(\"risk_factors\", {}),\n",
    "                \"certificate\": c.get(\"risk_factors\", {}),\n",
    "            },\n",
    "            \"reasons\": (b.get(\"reasons\", []) or []) + (d.get(\"reasons\", []) or []) + (c.get(\"reasons\", []) or []),\n",
    "            \"success\": bool(b.get(\"success\", True) and c.get(\"success\", True) and d.get(\"success\", True)),\n",
    "        }\n",
    "        return _structured(\"PhishingDetectionResult\", result)\n",
    "\n",
    "    def batch_evaluate(self, domains, probs):\n",
    "        out = []\n",
    "        for dd, pp in zip(list(domains), list(probs)):\n",
    "            try:\n",
    "                out.append(self.evaluate(dd, pp))\n",
    "            except Exception as e:\n",
    "                out.append({\"domain\": dd, \"ml_probability\": float(pp or 0.0),\n",
    "                            \"is_phishing\": False, \"confidence\": 0.0, \"risk_level\":\"low\",\n",
    "                            \"success\": False, \"error\": str(e)})\n",
    "        return out\n",
    "\n",
    "# Backward-compatible alias\n",
    "def evaluate_domain(domain: str, ml_probability: float, **kwargs) -> Any:\n",
    "    agent = PhishingDetectionAgent(cfg=globals().get(\"cfg\"))\n",
    "    return agent.evaluate(domain, ml_probability, **kwargs)\n",
    "\n",
    "print(\"✅ LangGraph-based PhishingDetectionAgent defined; evaluate_domain bound.\",\n",
    "      \"(graph available)\" if HAVE_LG else \"(fallback mode: sequential)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbaf4349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local tool defined: certificate_analysis (P1-3b)\n"
     ]
    }
   ],
   "source": [
    "# === P1-3b: Local tool wrapper `certificate_analysis` (for 04-4 globals) ===\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "_FREE_CA_HINTS = (\n",
    "\"let's encrypt\",\"zerossl\",\"buypass\",\"trustasia\",\"gandi\",\"cloudflare\",\"google internet authority\",\"isrg\",\"actalis\")\n",
    "\n",
    "def _p1_3b_norm_apostrophes(s: str) -> str:\n",
    "    return (s or '').lower().replace('’', \"'\").replace('‘', \"'\").replace('`', \"'\")\n",
    "\n",
    "def _p1_3b_risk_level(score: float) -> str:\n",
    "    if score >= 80: return \"critical\"\n",
    "    if score >= 60: return \"high\"\n",
    "    if score >= 45: return \"medium-high\"\n",
    "    if score >= 25: return \"medium\"\n",
    "    return \"low\"\n",
    "\n",
    "def _p1_3b_norm_dt(s: Any) -> Optional[datetime]:\n",
    "    if not s: return None\n",
    "    if isinstance(s, datetime): return s\n",
    "    if isinstance(s, (int, float)):\n",
    "        try: return datetime.utcfromtimestamp(float(s))\n",
    "        except Exception: return None\n",
    "    s = str(s).strip().replace(\"Z\", \"\")\n",
    "    for fmt in (\"%Y-%m-%dT%H:%M:%S\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d\"):\n",
    "        try: return datetime.strptime(s, fmt)\n",
    "        except Exception: pass\n",
    "    try: return datetime.fromisoformat(s)\n",
    "    except Exception: return None\n",
    "\n",
    "def _p1_3b_days_between(a: Any, b: Any) -> Optional[int]:\n",
    "    da, db = _p1_3b_norm_dt(a), _p1_3b_norm_dt(b)\n",
    "    if da and db:\n",
    "        try: return abs((db - da).days)\n",
    "        except Exception: return None\n",
    "    return None\n",
    "\n",
    "def _p1_3b_pick_cert_record(payload_or_globals: Dict[str, Any], domain: str) -> Dict[str, Any]:\n",
    "    cfmap = None\n",
    "    if isinstance(payload_or_globals, dict):\n",
    "        cfmap = payload_or_globals.get(\"cert_full_info_map\") or payload_or_globals.get(\"CERT_FULL_INFO_MAP\")\n",
    "    if not isinstance(cfmap, dict):\n",
    "        cfmap = globals().get(\"CERT_FULL_INFO_MAP\") or globals().get(\"cert_full_info_map\") or {}\n",
    "    if not isinstance(cfmap, dict):\n",
    "        cfmap = {}\n",
    "    # direct and simple variants\n",
    "    rec = cfmap.get(domain) or cfmap.get(domain.lower())\n",
    "    if not isinstance(rec, dict):\n",
    "        # try www/no-www\n",
    "        if domain.startswith(\"www.\"):\n",
    "            rec = cfmap.get(domain[4:], {})\n",
    "        else:\n",
    "            rec = cfmap.get(\"www.\"+domain, {})\n",
    "    if not isinstance(rec, dict):\n",
    "        # try eTLD+1 fallback (naive split)\n",
    "        parts = domain.split(\".\")\n",
    "        if len(parts) >= 2:\n",
    "            rec = cfmap.get(\".\".join(parts[-2:]), {})\n",
    "    return rec if isinstance(rec, dict) else {}\n",
    "\n",
    "def certificate_analysis(domain: str, ml_probability: float = 0.0, cfg: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    d = (domain or \"\").strip().lower()\n",
    "    try:\n",
    "        p = float(ml_probability or 0.0)\n",
    "    except Exception:\n",
    "        p = 0.0\n",
    "\n",
    "    payload = globals().get(\"payload\") or {}\n",
    "    rec = _p1_3b_pick_cert_record(payload, d)\n",
    "    if (not isinstance(rec, dict) or not rec) and isinstance(cfg, dict):\n",
    "        if cfg.get('cert_full_info_map') or cfg.get('CERT_FULL_INFO_MAP'):\n",
    "            rec = _p1_3b_pick_cert_record({'cert_full_info_map': cfg.get('cert_full_info_map') or cfg.get('CERT_FULL_INFO_MAP')}, d)\n",
    "\n",
    "    issuer = (str(rec.get(\"issuer\") or rec.get(\"issuer_cn\") or rec.get(\"ca\") or \"\")).strip()\n",
    "    org    = (str(rec.get(\"organization\") or rec.get(\"org\") or \"\")).strip()\n",
    "    valid_days = rec.get(\"valid_days\")\n",
    "    if valid_days is None:\n",
    "        valid_days = _p1_3b_days_between(rec.get(\"valid_from\") or rec.get(\"not_before\"),\n",
    "                                         rec.get(\"valid_to\")   or rec.get(\"not_after\"))\n",
    "    try:\n",
    "        valid_days = int(valid_days) if valid_days is not None else None\n",
    "    except Exception:\n",
    "        valid_days = None\n",
    "\n",
    "    san_count = rec.get(\"san_count\")\n",
    "    if san_count is None:\n",
    "        sans = rec.get(\"subject_alt_names\") or rec.get(\"dns_names\") or rec.get(\"san\") or []\n",
    "        try: san_count = len(sans)\n",
    "        except Exception: san_count = None\n",
    "\n",
    "    self_signed = bool(rec.get(\"self_signed\") or rec.get(\"is_self_signed\", False))\n",
    "    wildcard    = bool(rec.get(\"wildcard\") or rec.get(\"is_wildcard\", False))\n",
    "\n",
    "    issuer_lc = issuer.lower()\n",
    "    free_ca = any(h in issuer_lc for h in _FREE_CA_HINTS) if issuer else False\n",
    "    very_new = (valid_days is not None and valid_days <= 120)\n",
    "\n",
    "    score = 0.0\n",
    "    if self_signed: score += 35\n",
    "    if not org:     score += 15\n",
    "    if free_ca:     score += 10\n",
    "    if very_new:    score += 10\n",
    "    if wildcard:    score += 5\n",
    "    if isinstance(san_count, int) and san_count <= 1: score += 5\n",
    "    score += 8.0 * float(p or 0.0)\n",
    "    score = max(0.0, min(score, 99.0))\n",
    "\n",
    "    level = _p1_3b_risk_level(score)\n",
    "    conf  = round(min(1.0, max(0.0, (score / 100.0) + 0.10 * float(p or 0.0))), 3)\n",
    "\n",
    "    reasons: List[str] = []\n",
    "    if self_signed: reasons.append(\"self-signed certificate\")\n",
    "    if not org:     reasons.append(\"organization field missing (DV)\")\n",
    "    if free_ca:     reasons.append(\"issued by widely-used free CA\")\n",
    "    if very_new:    reasons.append(f\"short validity ({valid_days} days)\" if valid_days is not None else \"short validity period\")\n",
    "    if wildcard:    reasons.append(\"wildcard certificate detected\")\n",
    "    if isinstance(san_count, int) and san_count <= 1: reasons.append(\"SAN count is small\")\n",
    "    if not reasons:\n",
    "        reasons.append(\"no strong anomalies found in certificate metadata\")\n",
    "\n",
    "    # Provide both risk_factors.* and top-level compatibility flags (used by 04-4 node)\n",
    "    result = {\n",
    "        \"confidence\": conf,\n",
    "        \"risk_level\": level,\n",
    "        \"risk_factors\": {\n",
    "            \"issuer\": issuer or None,\n",
    "            \"organization_present\": bool(org),\n",
    "            \"valid_days\": valid_days,\n",
    "            \"san_count\": san_count,\n",
    "            \"self_signed\": self_signed,\n",
    "            \"wildcard\": wildcard,\n",
    "            \"free_ca\": free_ca,\n",
    "            \"very_new_cert\": very_new,\n",
    "            \"ml_probability\": p,\n",
    "        },\n",
    "        \"is_free_ca\": free_ca,\n",
    "        \"very_new\": very_new,\n",
    "        \"is_wildcard\": wildcard,\n",
    "        \"reasons\": reasons,\n",
    "        \"success\": True,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "print(\"✅ Local tool defined: certificate_analysis (P1-3b)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a3c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1-3b test result: {'confidence': 0.461, 'risk_level': 'medium', 'risk_factors': {'issuer': \"Let's Encrypt\", 'organization_present': False, 'valid_days': 90, 'san_count': 1, 'self_signed': False, 'wildcard': False, 'free_ca': True, 'very_new_cert': True, 'ml_probability': 0.34}, 'is_free_ca': True, 'very_new': True, 'is_wildcard': False, 'reasons': ['organization field missing (DV)', 'issued by widely-used free CA', 'short validity (90 days)', 'SAN count is small'], 'success': True}\n",
      "P1-3b smoketest: OK\n"
     ]
    }
   ],
   "source": [
    "# === P1-3b TEST (local, no external I/O) ===\n",
    "if \"payload\" not in globals() or not isinstance(payload, dict):\n",
    "    payload = {}\n",
    "# Unconditionally set a minimal cert record for the test domain\n",
    "payload[\"cert_full_info_map\"] = {\n",
    "    \"paypal-secure-login.info\": {\n",
    "        \"issuer\": \"Let's Encrypt\",\n",
    "        \"organization\": \"\",\n",
    "        \"valid_days\": 90,\n",
    "        \"san_count\": 1,\n",
    "        \"self_signed\": False,\n",
    "        \"wildcard\": False,\n",
    "    }\n",
    "}\n",
    "_t = certificate_analysis(\"paypal-secure-login.info\", 0.34, cfg=globals().get(\"cfg\"))\n",
    "print(\"P1-3b test result:\", _t)\n",
    "assert isinstance(_t, dict) and \"confidence\" in _t and \"risk_level\" in _t and \"risk_factors\" in _t and \"success\" in _t\n",
    "assert _t[\"risk_factors\"].get(\"free_ca\") is True\n",
    "print(\"P1-3b smoketest: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10282be",
   "metadata": {
    "title": "Cell NEW: Restore `_execute_tool_with_trace` (compat wrapper)"
   },
   "outputs": [],
   "source": [
    "# === Cell NEW: Restore compatibility wrapper `_execute_tool_with_trace` ===\n",
    "# Purpose: Provide a thin wrapper around `_call_tool` that records per-tool traces.\n",
    "# Rationale: The original 03_ai_agent_analysis.ipynb exposed `_execute_tool_with_trace(self, tool_name, inputs, trace)`\n",
    "# as a method on the agent. The refactored split notebooks switched to a module-level `_call_tool`.\n",
    "# This wrapper preserves the legacy semantics (return shape + optional tracing) with minimal surface change.\n",
    "from typing import Any, Dict, Optional\n",
    "import time\n",
    "\n",
    "def _execute_tool_with_trace(tool_name: str, inputs: Dict[str, Any], trace: Optional[Any] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    トレース付きツール実行（互換ラッパ）\n",
    "    - calls: `_call_tool(tool_name, **inputs)`\n",
    "    - ensures: result shape is {\"success\": True, \"result\": {...}} when the tool returns a non-error payload\n",
    "    - if `trace` has `add_tool_trace(...)`, record execution metadata.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # Ensure dict\n",
    "    inputs = inputs or {}\n",
    "    # Execute via the unified tool dispatcher\n",
    "    out = _call_tool(tool_name, **inputs)\n",
    "    # Normalize shape to keep legacy-compatible contract\n",
    "    if not isinstance(out, dict):\n",
    "        out = {\"success\": True, \"result\": {\"value\": repr(out)}}\n",
    "    else:\n",
    "        if \"success\" not in out:\n",
    "            out = {\"success\": True, \"result\": out}\n",
    "    # Trace\n",
    "    if trace is not None and hasattr(trace, \"add_tool_trace\"):\n",
    "        try:\n",
    "            trace.add_tool_trace(tool_name=tool_name, inputs=inputs, output=out, duration=time.time()-start)\n",
    "        except Exception:\n",
    "            # Tracing is best-effort; do not disrupt main flow\n",
    "            pass\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9522a64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local tool defined: brand_impersonation_check (P1-2b fixed)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === P1-2b: Local tool wrapper `brand_impersonation_check` (for 04-4 globals) ===\n",
    "from typing import Dict, Any, Iterable, List, Tuple, Optional\n",
    "import re\n",
    "\n",
    "_P1_2B_RISK_WORDS = {'secure','login','verify','update','account','wallet','support','confirm','bank','invoice','payment'}\n",
    "\n",
    "def _p1_2b_risk_level(conf: float) -> str:\n",
    "    if conf >= 0.85: return \"critical\"\n",
    "    if conf >= 0.70: return \"high\"\n",
    "    if conf >= 0.50: return \"medium-high\"\n",
    "    if conf >= 0.30: return \"medium\"\n",
    "    return \"low\"\n",
    "\n",
    "def _p1_2b_iter_keywords(bk: Any):\n",
    "    if bk is None:\n",
    "        return []\n",
    "    if isinstance(bk, dict):\n",
    "        for k, v in bk.items():\n",
    "            if isinstance(k, str) and k: yield k.lower()\n",
    "            if isinstance(v, (list, tuple, set)):\n",
    "                for x in v:\n",
    "                    if isinstance(x, str) and x: yield x.lower()\n",
    "            elif isinstance(v, str) and v: yield v.lower()\n",
    "        return\n",
    "    if isinstance(bk, (list, tuple, set)):\n",
    "        for x in bk:\n",
    "            if isinstance(x, str) and x: yield x.lower()\n",
    "        return\n",
    "    try:\n",
    "        for x in list(bk):\n",
    "            if isinstance(x, str) and x: yield x.lower()\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def _p1_2b_tokenize_domain(d: str) -> List[str]:\n",
    "    try:\n",
    "        d = d.encode('idna').decode('ascii')\n",
    "    except Exception:\n",
    "        pass\n",
    "    return [t for t in re.split(r'[^a-z0-9]+', (d or '').lower()) if t]\n",
    "\n",
    "def _p1_2b_one_edit(a: str, b: str) -> bool:\n",
    "    la, lb = len(a), len(b)\n",
    "    if abs(la - lb) > 1: return False\n",
    "    if la > lb: a, b, la, lb = b, a, lb, la\n",
    "    i = j = edits = 0\n",
    "    while i < la and j < lb:\n",
    "        if a[i] == b[j]:\n",
    "            i += 1; j += 1\n",
    "        else:\n",
    "            edits += 1\n",
    "            if edits > 1: return False\n",
    "            if la == lb: i += 1; j += 1\n",
    "            else: j += 1\n",
    "    edits += (lb - j) + (la - i)\n",
    "    return edits <= 1\n",
    "\n",
    "def brand_impersonation_check(domain: str, ml_probability: float = 0.0, cfg: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    d = (domain or \"\").strip().lower()\n",
    "    try:\n",
    "        p = float(ml_probability or 0.0)\n",
    "    except Exception:\n",
    "        p = 0.0\n",
    "\n",
    "    g = globals()\n",
    "    bk = g.get(\"BRAND_KEYWORDS\", g.get(\"brand_keywords\", None))\n",
    "    if bk is None and \"payload\" in g and isinstance(g[\"payload\"], dict):\n",
    "        bk = g[\"payload\"].get(\"brand_keywords\")\n",
    "\n",
    "    brands = sorted(set(_p1_2b_iter_keywords(bk)))\n",
    "    tokens = _p1_2b_tokenize_domain(d)\n",
    "\n",
    "    substr_hits = [b for b in brands if b and b in d]\n",
    "    token_hits  = [b for b in brands if b in tokens]\n",
    "\n",
    "    typo_hits: List[Tuple[str, str]] = []\n",
    "    cand = [t for t in tokens if len(t) >= 3]\n",
    "    for b in brands:\n",
    "        if not b or len(b) < 4: \n",
    "            continue\n",
    "        if b in substr_hits or b in token_hits:\n",
    "            continue\n",
    "        for t in cand:\n",
    "            if _p1_2b_one_edit(b, t):\n",
    "                typo_hits.append((b, t))\n",
    "                break\n",
    "\n",
    "    risk_kw = [kw for kw in _P1_2B_RISK_WORDS if kw in d]\n",
    "\n",
    "    score = 0.0\n",
    "    if substr_hits or token_hits: score += 0.60\n",
    "    if typo_hits: score += 0.25\n",
    "    if risk_kw: score += 0.10 + 0.02 * min(len(risk_kw), 5)\n",
    "    score += 0.30 * p\n",
    "    score = max(0.0, min(score, 0.99))\n",
    "\n",
    "    result = {\n",
    "        \"is_impersonation\": bool(substr_hits or token_hits or typo_hits),\n",
    "        \"confidence\": score,\n",
    "        \"risk_level\": _p1_2b_risk_level(score),\n",
    "        \"detected_brands\": sorted(set(substr_hits + token_hits)),\n",
    "        \"risk_factors\": {\n",
    "            \"typosquatting_matches\": typo_hits,\n",
    "            \"risk_keywords\": risk_kw,\n",
    "            \"ml_probability\": p,\n",
    "            \"tokens\": tokens[:8],\n",
    "        },\n",
    "        \"reasons\": [\n",
    "            \"brand keyword present\" if (substr_hits or token_hits) else \"no direct brand keyword found\",\n",
    "            \"typosquatting candidate detected\" if typo_hits else \"no typo candidate\",\n",
    "            f\"ml_probability contribution={round(0.30*p,3)}\"\n",
    "        ],\n",
    "        \"success\": True,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "print(\"✅ Local tool defined: brand_impersonation_check (P1-2b fixed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44380309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1-2b test result: {'is_impersonation': True, 'confidence': 0.842, 'risk_level': 'high', 'detected_brands': ['paypal'], 'risk_factors': {'typosquatting_matches': [], 'risk_keywords': ['login', 'secure'], 'ml_probability': 0.34, 'tokens': ['paypal', 'secure', 'login', 'info']}, 'reasons': ['brand keyword present', 'no typo candidate', 'ml_probability contribution=0.102'], 'success': True}\n",
      "P1-2b smoketest: OK\n"
     ]
    }
   ],
   "source": [
    "# === P1-2b TEST (local, no external I/O) ===\n",
    "try:\n",
    "    _bk = (globals().get(\"payload\") or {}).get(\"brand_keywords\")\n",
    "    if not _bk: BRAND_KEYWORDS = [\"paypal\",\"mercari\",\"ledger\"]\n",
    "except Exception:\n",
    "    BRAND_KEYWORDS = [\"paypal\",\"mercari\",\"ledger\"]\n",
    "_t = brand_impersonation_check(\"paypal-secure-login.info\", 0.34, cfg=globals().get(\"cfg\"))\n",
    "print(\"P1-2b test result:\", _t)\n",
    "assert isinstance(_t, dict) and \"confidence\" in _t and \"risk_level\" in _t and \"success\" in _t\n",
    "if \"paypal\" in [k.lower() for k in globals().get(\"BRAND_KEYWORDS\", [])]:\n",
    "    assert _t.get(\"is_impersonation\") is True\n",
    "print(\"P1-2b smoketest: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e58742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1-2b test result: {'is_impersonation': True, 'confidence': 0.842, 'risk_level': 'high', 'detected_brands': ['paypal'], 'risk_factors': {'typosquatting_matches': [], 'risk_keywords': ['login', 'secure'], 'ml_probability': 0.34, 'tokens': ['paypal', 'secure', 'login', 'info']}, 'reasons': ['brand keyword present', 'no typo candidate', 'ml_probability contribution=0.102'], 'success': True}\n",
      "P1-2b smoketest: OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === P1-2b TEST (local tool; no external I/O) ===\n",
    "try:\n",
    "    if \"BRAND_KEYWORDS\" not in globals():\n",
    "        BRAND_KEYWORDS = [\"paypal\", \"mercari\", \"ledger\"]\n",
    "    _out = brand_impersonation_check(\"paypal-secure-login.info\", 0.34)\n",
    "    print(\"P1-2b test result:\", _out)\n",
    "    assert isinstance(_out, dict) and all(k in _out for k in [\"is_impersonation\",\"confidence\",\"risk_level\",\"risk_factors\",\"success\"])\n",
    "    print(\"P1-2b smoketest: OK\")\n",
    "except Exception as e:\n",
    "    print(\"P1-2b test failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88b748b",
   "metadata": {
    "title": "Cell NEW.TEST: `_execute_tool_with_trace` smoke test"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNIT] result: {'sum': 10, 'diff': 4, 'inputs': {'x': 7, 'y': 3}, 'success': True}\n",
      "[UNIT] trace-count: 1\n",
      "[UNIT] trace-sample: {'tool_name': 'demo_tool', 'inputs': {'x': 7, 'y': 3}, 'output': {'sum': 10, 'diff': 4, 'inputs': {'x': 7, 'y': 3}, 'success': True}, 'duration': 6.4373016357421875e-06}\n",
      "[HANDOFF] wrote smoke artifact -> artifacts/2025-10-22_074213/handoff/04-4_smoketest_tool_trace.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Cell NEW.TEST: Unit & handoff smoke test for `_execute_tool_with_trace` (hardened) ===\n",
    "from typing import Any, Dict\n",
    "from pathlib import Path\n",
    "import json, pickle\n",
    "\n",
    "# --- Fallback stub: define _call_tool if upstream cell wasn't executed ---\n",
    "if \"_call_tool\" not in globals():\n",
    "    def _call_tool(tool_name: str, **kwargs) -> Dict[str, Any]:\n",
    "        fn = globals().get(tool_name)\n",
    "        if fn is None:\n",
    "            return {\"error\": f\"Tool `{tool_name}` not available\"}\n",
    "        try:\n",
    "            res = fn(**kwargs)\n",
    "            return res if isinstance(res, dict) else {\"value\": res}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"{tool_name} failed: {type(e).__name__}: {e}\"}\n",
    "\n",
    "class _SimpleTrace:\n",
    "    def __init__(self):\n",
    "        self.records = []\n",
    "    def add_tool_trace(self, **kwargs):\n",
    "        self.records.append(kwargs)\n",
    "\n",
    "# A tiny demo tool discoverable by `_call_tool` (globals lookup)\n",
    "def demo_tool(x: int, y: int) -> Dict[str, Any]:\n",
    "    return {\"sum\": x + y, \"diff\": x - y, \"inputs\": {\"x\": x, \"y\": y}}\n",
    "\n",
    "# ---- run ----\n",
    "_tr = _SimpleTrace()\n",
    "_res = _execute_tool_with_trace(\"demo_tool\", {\"x\": 7, \"y\": 3}, trace=_tr)\n",
    "\n",
    "print(\"[UNIT] result:\", _res)\n",
    "print(\"[UNIT] trace-count:\", len(_tr.records))\n",
    "print(\"[UNIT] trace-sample:\", _tr.records[0] if _tr.records else {})\n",
    "\n",
    "# --- Optional handoff smoke (non-invasive, guarded) ---\n",
    "smoke_dir = globals().get(\"HANDOFF_DIR\", None)\n",
    "if smoke_dir:\n",
    "    smoke_path = Path(smoke_dir) / \"04-4_smoketest_tool_trace.pkl\"\n",
    "    try:\n",
    "        with open(smoke_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"function\": \"_execute_tool_with_trace\",\n",
    "                \"trace_count\": len(_tr.records),\n",
    "                \"sample_output\": _res\n",
    "            }, f)\n",
    "        print(f\"[HANDOFF] wrote smoke artifact -> {smoke_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[HANDOFF] skip (write error): {e}\")\n",
    "else:\n",
    "    print(\"[HANDOFF] skip: HANDOFF_DIR undefined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b4debf-f7ee-4e7e-bf83-5f8cf7fa92e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== preflight probe ==\n",
      "has AgentState models?: True\n",
      "has PhishingDetectionAgent?: True\n",
      "has evaluate_domain?: True\n",
      "has evaluate_domain_fixed?: False\n",
      "※ セル6実行ログに '✅ LangGraph-based PhishingDetectionAgent is defined' が出ているか確認してください。\n"
     ]
    }
   ],
   "source": [
    "print(\"== preflight probe ==\")\n",
    "print(\"has AgentState models?:\", 'PhishingDetectionResult' in globals())\n",
    "print(\"has PhishingDetectionAgent?:\", 'PhishingDetectionAgent' in globals())\n",
    "print(\"has evaluate_domain?:\", 'evaluate_domain' in globals())\n",
    "print(\"has evaluate_domain_fixed?:\", 'evaluate_domain_fixed' in globals())\n",
    "\n",
    "# セル6の終端で出るはずのメッセージが出ているか（実行ログを目視確認）\n",
    "print(\"※ セル6実行ログに '✅ LangGraph-based PhishingDetectionAgent is defined' が出ているか確認してください。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90a7edb-ff67-4005-b274-7bb6a6333e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[probe] has PhishingDetectionAgent: True\n",
      "[probe] has evaluate_domain: True\n",
      "[probe] has evaluate_domain_fixed: False\n"
     ]
    }
   ],
   "source": [
    "print(\"[probe] has PhishingDetectionAgent:\", 'PhishingDetectionAgent' in globals())\n",
    "print(\"[probe] has evaluate_domain:\", 'evaluate_domain' in globals())\n",
    "print(\"[probe] has evaluate_domain_fixed:\", 'evaluate_domain_fixed' in globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cebc484-75d3-4dd4-8c4f-dd9a6eb67221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🎯 関数統一設定（安全版）\n",
      "======================================================================\n",
      "  ✅ evaluate_domain → 既存版を使用\n",
      "  ⚠️ process_domains_batch が未定義のため、簡易フォールバックを定義\n",
      "  ⚠️ AI_AGENT が未定義（evaluate_domain に依存動作するため続行可能）\n",
      "📋 定義状況チェック:\n",
      "  • evaluate_domain: 定義あり\n",
      "  • evaluate_domain_fixed: （未定義）\n",
      "  • process_domains_batch: 定義あり\n",
      "  • process_domains_batch_fixed: （未定義）\n",
      "  • AI_AGENT: （未定義）\n",
      "  • FIXED_AI_AGENT: （未定義）\n",
      "✅ 安全な関数統一が完了しました。\n"
     ]
    }
   ],
   "source": [
    "# === Cell 06-D-ALIAS: Safe unification (fixed が無ければフォールバック) ===\n",
    "print(\"=\" * 70)\n",
    "print(\"🎯 関数統一設定（安全版）\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# evaluate_domain: *_fixed があれば採用、無ければ既存を使う\n",
    "if 'evaluate_domain_fixed' in globals():\n",
    "    evaluate_domain = evaluate_domain_fixed\n",
    "    print(\"  ✅ evaluate_domain → evaluate_domain_fixed を使用\")\n",
    "elif 'evaluate_domain' in globals():\n",
    "    print(\"  ✅ evaluate_domain → 既存版を使用\")\n",
    "else:\n",
    "    raise RuntimeError(\"evaluate_domain / evaluate_domain_fixed が見つかりません。定義セルを先に実行してください。\")\n",
    "\n",
    "# process_domains_batch: *_fixed があれば採用、無ければ既存を使う\n",
    "if 'process_domains_batch_fixed' in globals():\n",
    "    process_domains_batch = process_domains_batch_fixed\n",
    "    print(\"  ✅ process_domains_batch → process_domains_batch_fixed を使用\")\n",
    "elif 'process_domains_batch' in globals():\n",
    "    print(\"  ✅ process_domains_batch → 既存版を使用\")\n",
    "else:\n",
    "    # どちらも無ければ evaluate_domain にフォールバックで1本ずつ処理する簡易版を定義\n",
    "    print(\"  ⚠️ process_domains_batch が未定義のため、簡易フォールバックを定義\")\n",
    "    def process_domains_batch(domains, probs=None, cfg=None, max_concurrent=10):\n",
    "        probs = probs or [0.0] * len(domains)\n",
    "        return [evaluate_domain(d, float(p), cfg=cfg or {}) for d, p in zip(domains, probs)]\n",
    "\n",
    "# AI_AGENT の互換ハンドリング（存在するものを採用）\n",
    "if 'FIXED_AI_AGENT' in globals():\n",
    "    AI_AGENT = FIXED_AI_AGENT\n",
    "    print(\"  ✅ AI_AGENT → FIXED_AI_AGENT を使用\")\n",
    "elif 'AI_AGENT' in globals():\n",
    "    print(\"  ✅ AI_AGENT → 既存版を使用\")\n",
    "else:\n",
    "    print(\"  ⚠️ AI_AGENT が未定義（evaluate_domain に依存動作するため続行可能）\")\n",
    "\n",
    "print(\"📋 定義状況チェック:\")\n",
    "for func in ['evaluate_domain', 'evaluate_domain_fixed',\n",
    "             'process_domains_batch', 'process_domains_batch_fixed',\n",
    "             'AI_AGENT', 'FIXED_AI_AGENT']:\n",
    "    if func in globals():\n",
    "        print(f\"  • {func}: 定義あり\")\n",
    "    else:\n",
    "        print(f\"  • {func}: （未定義）\")\n",
    "\n",
    "print(\"✅ 安全な関数統一が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7196ac1-2f3b-4032-8e5f-5304374e4908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-4] saved handoff -> artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl\n",
      "[04-4] exported keys: ['RUN_ID', 'cfg', 'evaluate_domain__ref', 'meta']\n",
      "[04-4] saved handoff -> artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl\n",
      "[04-4] exported keys: ['RUN_ID', 'cfg', 'evaluate_domain__ref', 'meta']\n",
      "[04-4] saved handoff -> artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl\n",
      "[04-4] exported keys: ['RUN_ID', 'cfg', 'evaluate_domain__ref', 'meta']\n",
      "[04-4] saved handoff -> artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl\n",
      "[04-4] exported keys: ['RUN_ID', 'cfg', 'evaluate_domain__ref', 'meta']\n"
     ]
    }
   ],
   "source": [
    "# === Cell 07: Save output handoff (SAFE, pickle-friendly) ===\n",
    "import os, pickle, json, warnings, datetime, types, inspect, pickle\n",
    "\n",
    "# 必要に応じて既存変数（RUN_ID/HANDOFF_DIR/IN_HANDOFF_PKL など）が上セルで定義済みである前提\n",
    "# OUT_HANDOFF_PKL はこのセルで定義します（上流と同じ命名を踏襲）\n",
    "HANDOFF_DIR = HANDOFF_DIR if 'HANDOFF_DIR' in globals() else os.path.join(\"artifacts\", RUN_ID, \"handoff\")\n",
    "os.makedirs(HANDOFF_DIR, exist_ok=True)\n",
    "OUT_HANDOFF_PKL = os.path.join(HANDOFF_DIR, \"04-4_agent_implementation.pkl\")\n",
    "\n",
    "def _is_pickleable(obj) -> bool:\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _ref_info(obj):\n",
    "    \"\"\"関数/クラス/グラフなど非ピクル化オブジェクトの軽量参照情報に変換\"\"\"\n",
    "    info = {\n",
    "        \"_nonserializable\": True,\n",
    "        \"type\": type(obj).__name__,\n",
    "        \"repr\": repr(obj)[:240],\n",
    "    }\n",
    "    # import可能なcallableなら __module__/__name__ を残す\n",
    "    if callable(obj):\n",
    "        info[\"callable\"] = True\n",
    "        info[\"module\"] = getattr(obj, \"__module__\", None)\n",
    "        info[\"name\"] = getattr(obj, \"__name__\", None)\n",
    "    # LangGraph の compiled graph っぽいものは型名だけ強調\n",
    "    if type(obj).__name__.lower().find(\"compiledstategraph\") >= 0:\n",
    "        info[\"kind\"] = \"langgraph_compiled_graph\"\n",
    "    return info\n",
    "\n",
    "# ---- 1) allowlist: 素のデータだけそのまま保存（ここに基本的に必要なキーを列挙） ----\n",
    "exports = {}\n",
    "allowlist_names = [\n",
    "    \"cfg\",                 # dict (config)\n",
    "    \"brand_keywords\",      # list or dict\n",
    "    \"cert_full_info_map\",  # dict\n",
    "    \"RUN_ID\",              # str\n",
    "]\n",
    "for name in allowlist_names:\n",
    "    if name in globals():\n",
    "        val = globals()[name]\n",
    "        # 念のためpickle可能性チェック\n",
    "        if _is_pickleable(val):\n",
    "            exports[name] = val\n",
    "        else:\n",
    "            exports[name] = _ref_info(val)\n",
    "\n",
    "# ---- 2) 参照メタ：関数やグラフオブジェクトの“所在”だけを書く（本体は保存しない） ----\n",
    "# 04-3 側の成果（tools 等）を参照したい場合はファイル名などのメタを残す\n",
    "# 例）IN_HANDOFF_PKL_043 等が上流セルにあれば利用。無ければ None。\n",
    "exports[\"meta\"] = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"module\": \"04-4_agent_implementation\",\n",
    "    \"note\": \"Functions/graphs are not pickled. Use runtime imports.\",\n",
    "    \"with_tools\": False,                # ツール関数はpickleしない方針\n",
    "    \"tools_from\": globals().get(\"IN_HANDOFF_PKL_043\", None),  # 04-3のpklがあるなら参照メタだけ\n",
    "    \"primary_type\": \"dict\",\n",
    "}\n",
    "\n",
    "# ---- 3) 任意：存在すれば評価エイリアス名だけ（中身は保存しない） ----\n",
    "#   evaluate_domain / evaluate_domain_fixed / AI_AGENT / PHISHING_DETECTION_GRAPH 等はpickleしない\n",
    "name_refs = [\"evaluate_domain_fixed\", \"evaluate_domain\", \"AI_AGENT\", \"PHISHING_DETECTION_GRAPH\"]\n",
    "for name in name_refs:\n",
    "    if name in globals():\n",
    "        exports[f\"{name}__ref\"] = _ref_info(globals()[name])\n",
    "\n",
    "# ---- 4) 念のため：その他 “保存したい変数” を追加したいときはここに個別追記（必ず _is_pickleable で防御） ----\n",
    "# 例）統計値や小さめの DataFrame など\n",
    "# if \"stats\" in globals() and _is_pickleable(stats): exports[\"stats\"] = stats\n",
    "\n",
    "# ---- 5) 最後に pickle 保存（ここで失敗しない構成になっている） ----\n",
    "with open(OUT_HANDOFF_PKL, \"wb\") as f:\n",
    "    pickle.dump(exports, f)\n",
    "\n",
    "print(f\"[04-4] saved handoff -> {OUT_HANDOFF_PKL}\")\n",
    "print(\"[04-4] exported keys:\", sorted(exports.keys()))\n",
    "# === Cell 07: Save output handoff (SAFE, pickle-friendly) ===\n",
    "import os, pickle, json, warnings, datetime, types, inspect, pickle\n",
    "\n",
    "# 必要に応じて既存変数（RUN_ID/HANDOFF_DIR/IN_HANDOFF_PKL など）が上セルで定義済みである前提\n",
    "# OUT_HANDOFF_PKL はこのセルで定義します（上流と同じ命名を踏襲）\n",
    "HANDOFF_DIR = HANDOFF_DIR if 'HANDOFF_DIR' in globals() else os.path.join(\"artifacts\", RUN_ID, \"handoff\")\n",
    "os.makedirs(HANDOFF_DIR, exist_ok=True)\n",
    "OUT_HANDOFF_PKL = os.path.join(HANDOFF_DIR, \"04-4_agent_implementation.pkl\")\n",
    "\n",
    "def _is_pickleable(obj) -> bool:\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _ref_info(obj):\n",
    "    \"\"\"関数/クラス/グラフなど非ピクル化オブジェクトの軽量参照情報に変換\"\"\"\n",
    "    info = {\n",
    "        \"_nonserializable\": True,\n",
    "        \"type\": type(obj).__name__,\n",
    "        \"repr\": repr(obj)[:240],\n",
    "    }\n",
    "    # import可能なcallableなら __module__/__name__ を残す\n",
    "    if callable(obj):\n",
    "        info[\"callable\"] = True\n",
    "        info[\"module\"] = getattr(obj, \"__module__\", None)\n",
    "        info[\"name\"] = getattr(obj, \"__name__\", None)\n",
    "    # LangGraph の compiled graph っぽいものは型名だけ強調\n",
    "    if type(obj).__name__.lower().find(\"compiledstategraph\") >= 0:\n",
    "        info[\"kind\"] = \"langgraph_compiled_graph\"\n",
    "    return info\n",
    "\n",
    "# ---- 1) allowlist: 素のデータだけそのまま保存（ここに基本的に必要なキーを列挙） ----\n",
    "exports = {}\n",
    "allowlist_names = [\n",
    "    \"cfg\",                 # dict (config)\n",
    "    \"brand_keywords\",      # list or dict\n",
    "    \"cert_full_info_map\",  # dict\n",
    "    \"RUN_ID\",              # str\n",
    "]\n",
    "for name in allowlist_names:\n",
    "    if name in globals():\n",
    "        val = globals()[name]\n",
    "        # 念のためpickle可能性チェック\n",
    "        if _is_pickleable(val):\n",
    "            exports[name] = val\n",
    "        else:\n",
    "            exports[name] = _ref_info(val)\n",
    "\n",
    "# ---- 2) 参照メタ：関数やグラフオブジェクトの“所在”だけを書く（本体は保存しない） ----\n",
    "# 04-3 側の成果（tools 等）を参照したい場合はファイル名などのメタを残す\n",
    "# 例）IN_HANDOFF_PKL_043 等が上流セルにあれば利用。無ければ None。\n",
    "exports[\"meta\"] = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"module\": \"04-4_agent_implementation\",\n",
    "    \"note\": \"Functions/graphs are not pickled. Use runtime imports.\",\n",
    "    \"with_tools\": False,                # ツール関数はpickleしない方針\n",
    "    \"tools_from\": globals().get(\"IN_HANDOFF_PKL_043\", None),  # 04-3のpklがあるなら参照メタだけ\n",
    "    \"primary_type\": \"dict\",\n",
    "}\n",
    "\n",
    "# ---- 3) 任意：存在すれば評価エイリアス名だけ（中身は保存しない） ----\n",
    "#   evaluate_domain / evaluate_domain_fixed / AI_AGENT / PHISHING_DETECTION_GRAPH 等はpickleしない\n",
    "name_refs = [\"evaluate_domain_fixed\", \"evaluate_domain\", \"AI_AGENT\", \"PHISHING_DETECTION_GRAPH\"]\n",
    "for name in name_refs:\n",
    "    if name in globals():\n",
    "        exports[f\"{name}__ref\"] = _ref_info(globals()[name])\n",
    "\n",
    "# ---- 4) 念のため：その他 “保存したい変数” を追加したいときはここに個別追記（必ず _is_pickleable で防御） ----\n",
    "# 例）統計値や小さめの DataFrame など\n",
    "# if \"stats\" in globals() and _is_pickleable(stats): exports[\"stats\"] = stats\n",
    "\n",
    "# ---- 5) 最後に pickle 保存（ここで失敗しない構成になっている） ----\n",
    "with open(OUT_HANDOFF_PKL, \"wb\") as f:\n",
    "    pickle.dump(exports, f)\n",
    "\n",
    "print(f\"[04-4] saved handoff -> {OUT_HANDOFF_PKL}\")\n",
    "print(\"[04-4] exported keys:\", sorted(exports.keys()))\n",
    "# === Cell 07: Save output handoff (SAFE, pickle-friendly) ===\n",
    "import os, pickle, json, warnings, datetime, types, inspect, pickle\n",
    "\n",
    "# 必要に応じて既存変数（RUN_ID/HANDOFF_DIR/IN_HANDOFF_PKL など）が上セルで定義済みである前提\n",
    "# OUT_HANDOFF_PKL はこのセルで定義します（上流と同じ命名を踏襲）\n",
    "HANDOFF_DIR = HANDOFF_DIR if 'HANDOFF_DIR' in globals() else os.path.join(\"artifacts\", RUN_ID, \"handoff\")\n",
    "os.makedirs(HANDOFF_DIR, exist_ok=True)\n",
    "OUT_HANDOFF_PKL = os.path.join(HANDOFF_DIR, \"04-4_agent_implementation.pkl\")\n",
    "\n",
    "def _is_pickleable(obj) -> bool:\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _ref_info(obj):\n",
    "    \"\"\"関数/クラス/グラフなど非ピクル化オブジェクトの軽量参照情報に変換\"\"\"\n",
    "    info = {\n",
    "        \"_nonserializable\": True,\n",
    "        \"type\": type(obj).__name__,\n",
    "        \"repr\": repr(obj)[:240],\n",
    "    }\n",
    "    # import可能なcallableなら __module__/__name__ を残す\n",
    "    if callable(obj):\n",
    "        info[\"callable\"] = True\n",
    "        info[\"module\"] = getattr(obj, \"__module__\", None)\n",
    "        info[\"name\"] = getattr(obj, \"__name__\", None)\n",
    "    # LangGraph の compiled graph っぽいものは型名だけ強調\n",
    "    if type(obj).__name__.lower().find(\"compiledstategraph\") >= 0:\n",
    "        info[\"kind\"] = \"langgraph_compiled_graph\"\n",
    "    return info\n",
    "\n",
    "# ---- 1) allowlist: 素のデータだけそのまま保存（ここに基本的に必要なキーを列挙） ----\n",
    "exports = {}\n",
    "allowlist_names = [\n",
    "    \"cfg\",                 # dict (config)\n",
    "    \"brand_keywords\",      # list or dict\n",
    "    \"cert_full_info_map\",  # dict\n",
    "    \"RUN_ID\",              # str\n",
    "]\n",
    "for name in allowlist_names:\n",
    "    if name in globals():\n",
    "        val = globals()[name]\n",
    "        # 念のためpickle可能性チェック\n",
    "        if _is_pickleable(val):\n",
    "            exports[name] = val\n",
    "        else:\n",
    "            exports[name] = _ref_info(val)\n",
    "\n",
    "# ---- 2) 参照メタ：関数やグラフオブジェクトの“所在”だけを書く（本体は保存しない） ----\n",
    "# 04-3 側の成果（tools 等）を参照したい場合はファイル名などのメタを残す\n",
    "# 例）IN_HANDOFF_PKL_043 等が上流セルにあれば利用。無ければ None。\n",
    "exports[\"meta\"] = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"module\": \"04-4_agent_implementation\",\n",
    "    \"note\": \"Functions/graphs are not pickled. Use runtime imports.\",\n",
    "    \"with_tools\": False,                # ツール関数はpickleしない方針\n",
    "    \"tools_from\": globals().get(\"IN_HANDOFF_PKL_043\", None),  # 04-3のpklがあるなら参照メタだけ\n",
    "    \"primary_type\": \"dict\",\n",
    "}\n",
    "\n",
    "# ---- 3) 任意：存在すれば評価エイリアス名だけ（中身は保存しない） ----\n",
    "#   evaluate_domain / evaluate_domain_fixed / AI_AGENT / PHISHING_DETECTION_GRAPH 等はpickleしない\n",
    "name_refs = [\"evaluate_domain_fixed\", \"evaluate_domain\", \"AI_AGENT\", \"PHISHING_DETECTION_GRAPH\"]\n",
    "for name in name_refs:\n",
    "    if name in globals():\n",
    "        exports[f\"{name}__ref\"] = _ref_info(globals()[name])\n",
    "\n",
    "# ---- 4) 念のため：その他 “保存したい変数” を追加したいときはここに個別追記（必ず _is_pickleable で防御） ----\n",
    "# 例）統計値や小さめの DataFrame など\n",
    "# if \"stats\" in globals() and _is_pickleable(stats): exports[\"stats\"] = stats\n",
    "\n",
    "# ---- 5) 最後に pickle 保存（ここで失敗しない構成になっている） ----\n",
    "with open(OUT_HANDOFF_PKL, \"wb\") as f:\n",
    "    pickle.dump(exports, f)\n",
    "\n",
    "print(f\"[04-4] saved handoff -> {OUT_HANDOFF_PKL}\")\n",
    "print(\"[04-4] exported keys:\", sorted(exports.keys()))\n",
    "import os, pickle, json, warnings, datetime, types, inspect, pickle\n",
    "\n",
    "# 必要に応じて既存変数（RUN_ID/HANDOFF_DIR/IN_HANDOFF_PKL など）が上セルで定義済みである前提\n",
    "# OUT_HANDOFF_PKL はこのセルで定義します（上流と同じ命名を踏襲）\n",
    "HANDOFF_DIR = HANDOFF_DIR if 'HANDOFF_DIR' in globals() else os.path.join(\"artifacts\", RUN_ID, \"handoff\")\n",
    "os.makedirs(HANDOFF_DIR, exist_ok=True)\n",
    "OUT_HANDOFF_PKL = os.path.join(HANDOFF_DIR, \"04-4_agent_implementation.pkl\")\n",
    "\n",
    "def _is_pickleable(obj) -> bool:\n",
    "    try:\n",
    "        pickle.dumps(obj)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _ref_info(obj):\n",
    "    \"\"\"関数/クラス/グラフなど非ピクル化オブジェクトの軽量参照情報に変換\"\"\"\n",
    "    info = {\n",
    "        \"_nonserializable\": True,\n",
    "        \"type\": type(obj).__name__,\n",
    "        \"repr\": repr(obj)[:240],\n",
    "    }\n",
    "    # import可能なcallableなら __module__/__name__ を残す\n",
    "    if callable(obj):\n",
    "        info[\"callable\"] = True\n",
    "        info[\"module\"] = getattr(obj, \"__module__\", None)\n",
    "        info[\"name\"] = getattr(obj, \"__name__\", None)\n",
    "    # LangGraph の compiled graph っぽいものは型名だけ強調\n",
    "    if type(obj).__name__.lower().find(\"compiledstategraph\") >= 0:\n",
    "        info[\"kind\"] = \"langgraph_compiled_graph\"\n",
    "    return info\n",
    "\n",
    "# ---- 1) allowlist: 素のデータだけそのまま保存（ここに基本的に必要なキーを列挙） ----\n",
    "exports = {}\n",
    "allowlist_names = [\n",
    "    \"cfg\",                 # dict (config)\n",
    "    \"brand_keywords\",      # list or dict\n",
    "    \"cert_full_info_map\",  # dict\n",
    "    \"RUN_ID\",              # str\n",
    "]\n",
    "for name in allowlist_names:\n",
    "    if name in globals():\n",
    "        val = globals()[name]\n",
    "        # 念のためpickle可能性チェック\n",
    "        if _is_pickleable(val):\n",
    "            exports[name] = val\n",
    "        else:\n",
    "            exports[name] = _ref_info(val)\n",
    "\n",
    "# ---- 2) 参照メタ：関数やグラフオブジェクトの“所在”だけを書く（本体は保存しない） ----\n",
    "# 04-3 側の成果（tools 等）を参照したい場合はファイル名などのメタを残す\n",
    "# 例）IN_HANDOFF_PKL_043 等が上流セルにあれば利用。無ければ None。\n",
    "exports[\"meta\"] = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"module\": \"04-4_agent_implementation\",\n",
    "    \"note\": \"Functions/graphs are not pickled. Use runtime imports.\",\n",
    "    \"with_tools\": False,                # ツール関数はpickleしない方針\n",
    "    \"tools_from\": globals().get(\"IN_HANDOFF_PKL_043\", None),  # 04-3のpklがあるなら参照メタだけ\n",
    "    \"primary_type\": \"dict\",\n",
    "}\n",
    "\n",
    "# ---- 3) 任意：存在すれば評価エイリアス名だけ（中身は保存しない） ----\n",
    "#   evaluate_domain / evaluate_domain_fixed / AI_AGENT / PHISHING_DETECTION_GRAPH 等はpickleしない\n",
    "name_refs = [\"evaluate_domain_fixed\", \"evaluate_domain\", \"AI_AGENT\", \"PHISHING_DETECTION_GRAPH\"]\n",
    "for name in name_refs:\n",
    "    if name in globals():\n",
    "        exports[f\"{name}__ref\"] = _ref_info(globals()[name])\n",
    "\n",
    "# ---- 4) 念のため：その他 “保存したい変数” を追加したいときはここに個別追記（必ず _is_pickleable で防御） ----\n",
    "# 例）統計値や小さめの DataFrame など\n",
    "# if \"stats\" in globals() and _is_pickleable(stats): exports[\"stats\"] = stats\n",
    "\n",
    "# ---- 5) 最後に pickle 保存（ここで失敗しない構成になっている） ----\n",
    "with open(OUT_HANDOFF_PKL, \"wb\") as f:\n",
    "    pickle.dump(exports, f)\n",
    "\n",
    "print(f\"[04-4] saved handoff -> {OUT_HANDOFF_PKL}\")\n",
    "print(\"[04-4] exported keys:\", sorted(exports.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5db5d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_domain: OK\n",
      "process_domains_batch: OK\n",
      "PHISHING_DETECTION_GRAPH: MISSING\n",
      "PhishingDetectionAgent: OK\n"
     ]
    }
   ],
   "source": [
    "# === Cell 08: Quick self-check (no logic change) ===\n",
    "print(\"evaluate_domain:\", \"OK\" if \"evaluate_domain\" in globals() else \"MISSING\")\n",
    "print(\"process_domains_batch:\", \"OK\" if \"process_domains_batch\" in globals() else \"MISSING\")\n",
    "print(\"PHISHING_DETECTION_GRAPH:\", \"OK\" if \"PHISHING_DETECTION_GRAPH\" in globals() else \"MISSING\")\n",
    "print(\"PhishingDetectionAgent:\", \"OK\" if \"PhishingDetectionAgent\" in globals() else \"MISSING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5713c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P1-1: process_domains_batch_fixed (restored minimal, fault-tolerant) ===\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time, traceback, os, pickle\n",
    "\n",
    "SUSPICIOUS_KEYWORDS = {'secure','login','verify','update','account','wallet','support','confirm','bank','invoice','payment'}\n",
    "\n",
    "def _risk_level_from_confidence(conf: float) -> str:\n",
    "    if conf >= 0.85: return \"critical\"\n",
    "    if conf >= 0.70: return \"high\"\n",
    "    if conf >= 0.50: return \"medium-high\"\n",
    "    if conf >= 0.30: return \"medium\"\n",
    "    return \"low\"\n",
    "\n",
    "def _normalize_result(domain, prob, res):\n",
    "    # Normalize various possible return types into unified dict\n",
    "    if hasattr(res, \"to_dict\"):\n",
    "        try:\n",
    "            res = res.to_dict()\n",
    "        except Exception:\n",
    "            pass\n",
    "    elif hasattr(res, \"model_dump\"):\n",
    "        try:\n",
    "            res = res.model_dump()\n",
    "        except Exception:\n",
    "            pass\n",
    "    elif hasattr(res, \"dict\"):\n",
    "        try:\n",
    "            res = res.dict()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not isinstance(res, dict):\n",
    "        res = {}\n",
    "    out = {\n",
    "        \"domain\": domain,\n",
    "        \"ml_probability\": float(prob) if prob is not None else None,\n",
    "        \"is_phishing\": bool(res.get(\"is_phishing\", False)),\n",
    "        \"confidence\": float(res.get(\"confidence\", res.get(\"ai_confidence\", 0.0) or 0.0)),\n",
    "        \"risk_level\": res.get(\"risk_level\", None),\n",
    "        \"risk_factors\": res.get(\"risk_factors\", {}),\n",
    "        \"reasoning\": res.get(\"reasoning\", \"\"),\n",
    "        \"success\": bool(res.get(\"success\", True)),\n",
    "    }\n",
    "    if not out[\"risk_level\"]:\n",
    "        out[\"risk_level\"] = _risk_level_from_confidence(out[\"confidence\"])\n",
    "    if isinstance(res, dict) and res.get(\"mock\"):\n",
    "        out.setdefault(\"risk_factors\", {})[\"mock\"] = True\n",
    "    return out\n",
    "\n",
    "def process_domains_batch_fixed(\n",
    "    domains: List[str],\n",
    "    probs: Optional[List[float]] = None,\n",
    "    cfg: Optional[Dict[str, Any]] = None,\n",
    "    max_concurrent: int = 8,\n",
    "    agent: Any = None,\n",
    "    mock: bool = False,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fault-tolerant batch processor for domain analysis.\n",
    "\n",
    "    Args:\n",
    "        domains: list of domain strings\n",
    "        probs: list of ML probabilities (0-1). If None, zeros are used.\n",
    "        cfg: optional config dict (kept for compatibility)\n",
    "        max_concurrent: degree of concurrency\n",
    "        agent: optional object with .evaluate(domain, prob)\n",
    "        mock: True -> deterministic, I/O-free evaluation (for tests)\n",
    "    Returns:\n",
    "        List[dict]: unified results per domain\n",
    "    \"\"\"\n",
    "    if probs is None:\n",
    "        probs = [0.0] * len(domains)\n",
    "\n",
    "    n = min(len(domains), len(probs))\n",
    "    domains = list(domains)[:n]\n",
    "    probs = list(probs)[:n]\n",
    "\n",
    "    g = globals()\n",
    "    evaluator = None\n",
    "    if \"evaluate_domain_fixed\" in g and callable(g[\"evaluate_domain_fixed\"]):\n",
    "        evaluator = g[\"evaluate_domain_fixed\"]\n",
    "    elif \"evaluate_domain\" in g and callable(g[\"evaluate_domain\"]):\n",
    "        evaluator = g[\"evaluate_domain\"]\n",
    "    elif agent is not None and hasattr(agent, \"evaluate\") and callable(agent.evaluate):\n",
    "        evaluator = lambda d, p: agent.evaluate(d, p)  # noqa\n",
    "    else:\n",
    "        evaluator = None\n",
    "\n",
    "    def _mock_eval(domain, prob):\n",
    "        lower = (domain or \"\").lower()\n",
    "        score = 0.0\n",
    "        kw = [k for k in SUSPICIOUS_KEYWORDS if k in lower]\n",
    "        if kw:\n",
    "            score += 0.4 + 0.05 * min(len(kw), 3)\n",
    "        if \"-\" in lower:\n",
    "            score += 0.1\n",
    "        if any(ch.isdigit() for ch in lower):\n",
    "            score += 0.05\n",
    "        score += float(prob or 0.0) * 0.3\n",
    "        score = max(0.0, min(score, 0.99))\n",
    "        return {\n",
    "            \"is_phishing\": score >= 0.5,\n",
    "            \"confidence\": score,\n",
    "            \"risk_factors\": {\"keywords\": kw, \"ml_probability\": float(prob or 0.0)},\n",
    "            \"reasoning\": \"Mock evaluation (no external I/O).\",\n",
    "            \"success\": True,\n",
    "            \"mock\": True,\n",
    "        }\n",
    "\n",
    "    def _safe_eval(domain, prob):\n",
    "        try:\n",
    "            if mock or evaluator is None:\n",
    "                res = _mock_eval(domain, prob)\n",
    "            else:\n",
    "                # Support both evaluator(domain, prob) and evaluator(domain=..., ml_probability=...)\n",
    "                try:\n",
    "                    res = evaluator(domain=domain, ml_probability=prob)\n",
    "                except TypeError:\n",
    "                    res = evaluator(domain, prob)\n",
    "            out = _normalize_result(domain, prob, res)\n",
    "            if out.get(\"success\") is None:\n",
    "                out[\"success\"] = True\n",
    "            return out\n",
    "        except Exception as e:  # pragma: no cover\n",
    "            tb = traceback.format_exc(limit=1)\n",
    "            return {\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": float(prob or 0.0),\n",
    "                \"is_phishing\": False,\n",
    "                \"confidence\": 0.0,\n",
    "                \"risk_level\": \"low\",\n",
    "                \"risk_factors\": {\"error\": str(e), \"where\": \"process_domains_batch_fixed\", \"trace\": tb},\n",
    "                \"reasoning\": \"Exception during evaluation; returning safe default.\",\n",
    "                \"success\": False,\n",
    "            }\n",
    "\n",
    "    results = [None] * n\n",
    "    with ThreadPoolExecutor(max_workers=max(1, int(max_concurrent or 1))) as ex:\n",
    "        futs = {ex.submit(_safe_eval, d, p): i for i, (d, p) in enumerate(zip(domains, probs))}\n",
    "        for fut in as_completed(futs):\n",
    "            i = futs[fut]\n",
    "            results[i] = fut.result()\n",
    "\n",
    "    # Optional handoff artifacts (if globals exist)\n",
    "    try:\n",
    "        run_id = g.get(\"RUN_ID\", None)\n",
    "        handoff_dir = g.get(\"HANDOFF_DIR\", None)\n",
    "        if run_id and handoff_dir:\n",
    "            os.makedirs(handoff_dir, exist_ok=True)\n",
    "            with open(os.path.join(handoff_dir, \"04-4_smoketest_process_domains_batch_fixed.pkl\"), \"wb\") as f:\n",
    "                pickle.dump({\"n\": n, \"ts\": time.time()}, f)\n",
    "            with open(os.path.join(handoff_dir, \"04-4_smoketest_process_domains_batch_fixed_results.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(results, f)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58e07901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1-1 test results: [{'domain': 'paypal-secure-login.info', 'ml_probability': 0.34, 'is_phishing': True, 'confidence': 0.702, 'risk_level': 'high', 'risk_factors': {'keywords': ['login', 'secure'], 'ml_probability': 0.34, 'mock': True}, 'reasoning': 'Mock evaluation (no external I/O).', 'success': True}, {'domain': 'example.com', 'ml_probability': 0.05, 'is_phishing': False, 'confidence': 0.015, 'risk_level': 'low', 'risk_factors': {'keywords': [], 'ml_probability': 0.05, 'mock': True}, 'reasoning': 'Mock evaluation (no external I/O).', 'success': True}]\n",
      "P1-1 smoketest: OK\n"
     ]
    }
   ],
   "source": [
    "# === P1-1 TEST (mock, no external I/O) ===\n",
    "_test_domains = [\"paypal-secure-login.info\", \"example.com\"]\n",
    "_test_probs   = [0.34, 0.05]\n",
    "_test_res = process_domains_batch_fixed(_test_domains, _test_probs, mock=True, max_concurrent=2)\n",
    "print(\"P1-1 test results:\", _test_res)\n",
    "assert len(_test_res) == 2 and all(\"domain\" in r for r in _test_res), \"Unexpected test output shape\"\n",
    "print(\"P1-1 smoketest: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7675b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P1-1 ALIAS (keep public name stable) ===\n",
    "try:\n",
    "    process_domains_batch = process_domains_batch_fixed\n",
    "except Exception as _e:\n",
    "    print(\"Alias setup failed:\", _e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68ad50c",
   "metadata": {
    "tags": [
     "C-02",
     "restore",
     "FixedPhishingDetectionAgent"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C-02] FixedPhishingDetectionAgent is ready.\n"
     ]
    }
   ],
   "source": [
    "# === C-02 FixedPhishingDetectionAgent (04-4) ===\n",
    "# NOTE: Appended by automation. Minimal-diff restoration from original 03 notebook design.\n",
    "# - Reads artifacts/{RUN_ID}/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
    "# - Provides FixedPhishingDetectionAgent with analyze(), _execute_tool(), and helpers\n",
    "# - Guarantees Structured Output keys: is_phishing, confidence, risk_factors, reasoning\n",
    "# - Safe fallbacks when tools aren't present yet (explicitly mocked)\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "import os, json, pickle, time, math, re, datetime as _dt\n",
    "\n",
    "# ---------- handoff loader (from 04-3) ----------\n",
    "def _load_llm_setup(run_id: Optional[str]=None) -> Dict[str, Any]:\n",
    "    run_id = run_id or os.getenv(\"RUN_ID\") or _dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    pkl_path = os.path.join(\"/mnt/data\", \"artifacts\", run_id, \"handoff\", \"04-3_llm_tools_setup_with_tools.pkl\")\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            state = pickle.load(f) or {}\n",
    "        return state\n",
    "    # fallback: empty skeleton\n",
    "    return {\n",
    "        \"provider\": None, \"base_url\": None, \"model\": None, \"llm\": {},\n",
    "        \"brand_keywords\": [], \"brand_keywords_cfg\": {},\n",
    "        \"paths\": {}, \"run_id\": run_id, \"timestamp\": _dt.datetime.now().isoformat(),\n",
    "        \"required_stats\": [], \"required_top\": [], \"present_stats\": [], \"present_top\": [],\n",
    "        \"missing_stats\": [], \"missing_top\": [], \"stats_keys\": [], \"top_level_keys\": []\n",
    "    }\n",
    "\n",
    "# ---------- tiny utility: entropy ----------\n",
    "def _entropy(text: str) -> float:\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    probs = [text.count(c)/len(text) for c in set(text)]\n",
    "    return -sum(p*math.log(p, 2) for p in probs if p > 0)\n",
    "\n",
    "# ---------- Agent Implementation ----------\n",
    "@dataclass\n",
    "class FixedPhishingDetectionAgent:\n",
    "    provider: Optional[str] = None\n",
    "    base_url: Optional[str] = None\n",
    "    model: Optional[str] = None\n",
    "    brand_keywords: List[str] = field(default_factory=list)\n",
    "    high_risk_words: List[str] = field(default_factory=lambda: [\n",
    "        \"secure\",\"verify\",\"update\",\"confirm\",\"account\",\"login\",\"signin\",\"validation\",\"verification\",\"official\"\n",
    "    ])\n",
    "    trace_enabled: bool = False\n",
    "\n",
    "    @classmethod\n",
    "    def from_handoff(cls, run_id: Optional[str]=None) -> \"FixedPhishingDetectionAgent\":\n",
    "        s = _load_llm_setup(run_id)\n",
    "        # if brand list empty, seed with paper examples (paypal, mercari, ledger) as a conservative default\n",
    "        seed_brands = [\"paypal\",\"mercari\",\"ledger\"]\n",
    "        bk = s.get(\"brand_keywords\") or seed_brands\n",
    "        return cls(\n",
    "            provider=s.get(\"provider\"), base_url=s.get(\"base_url\"), model=s.get(\"model\"),\n",
    "            brand_keywords=bk\n",
    "        )\n",
    "\n",
    "    # ---- internal helpers ----\n",
    "    def _check_obvious_phishing(self, domain: str) -> Tuple[bool, List[str], float]:\n",
    "        domain_lower = domain.lower()\n",
    "        detected = []\n",
    "        boost = 0.0\n",
    "        # brand hit\n",
    "        for b in self.brand_keywords:\n",
    "            try:\n",
    "                bl = b.lower()\n",
    "            except Exception:\n",
    "                continue\n",
    "            if bl and bl in domain_lower:\n",
    "                detected.append(b)\n",
    "                boost = max(boost, 0.15)\n",
    "        # high-risk words\n",
    "        for w in self.high_risk_words:\n",
    "            if w in domain_lower:\n",
    "                boost = max(boost, 0.10)\n",
    "        # obvious heuristic\n",
    "        is_obvious = (len(detected) > 0) and any(w in domain_lower for w in [\"secure\",\"login\",\"update\",\"verify\"])\n",
    "        if is_obvious:\n",
    "            boost = max(boost, 0.35)\n",
    "        return is_obvious, detected, boost\n",
    "\n",
    "    def _create_aggressive_prompt(self, domain: str, ml_probability: float, is_obvious: bool) -> str:\n",
    "        return (\n",
    "            \"You are a security analyst. Determine if the domain is a phishing site. \"\n",
    "            f\"Domain: {domain}\\n\"\n",
    "            f\"ML Probability: {ml_probability:.3f}\\n\"\n",
    "            f\"Obvious-Flag: {is_obvious}\\n\"\n",
    "            \"Return structured JSON with fields: is_phishing (bool), confidence (0..1), \"\n",
    "            \"risk_factors (object), reasoning (short).\"\n",
    "        )\n",
    "\n",
    "    def _parse_response_aggressive(self, response: str) -> Dict[str, Any]:\n",
    "        # Placeholder parser: expect JSON-like substrings; fallback to conservative result\n",
    "        try:\n",
    "            import json\n",
    "            data = json.loads(response)\n",
    "            # ensure keys\n",
    "            return {\n",
    "                \"is_phishing\": bool(data.get(\"is_phishing\", False)),\n",
    "                \"confidence\": max(0.0, min(1.0, float(data.get(\"confidence\", 0.5)))),\n",
    "                \"risk_factors\": dict(data.get(\"risk_factors\", {})),\n",
    "                \"reasoning\": str(data.get(\"reasoning\", \"\"))[:2000],\n",
    "            }\n",
    "        except Exception:\n",
    "            return {\"is_phishing\": False, \"confidence\": 0.5, \"risk_factors\": {}, \"reasoning\": \"parse-fallback\"}\n",
    "\n",
    "    # tool dispatcher with graceful fallback\n",
    "    def _execute_tool(self, tool_name: str, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        t0 = time.time()\n",
    "        out = {\"tool\": tool_name, \"ok\": True, \"inputs\": inputs, \"output\": None, \"latency_ms\": None}\n",
    "        try:\n",
    "            if tool_name == \"short_domain_analysis\":\n",
    "                # try global implementation\n",
    "                if \"short_domain_analysis\" in globals():\n",
    "                    out[\"output\"] = globals()[\"short_domain_analysis\"](inputs[\"domain\"], inputs.get(\"ml_probability\", 0.0))\n",
    "                else:\n",
    "                    # fallback quick heuristic\n",
    "                    domain = inputs[\"domain\"]\n",
    "                    parts = domain.split(\".\")\n",
    "                    without_tld = \".\".join(parts[:-1]) if len(parts) > 1 else domain\n",
    "                    ent = _entropy(without_tld)\n",
    "                    hyphens = domain.count(\"-\")\n",
    "                    digit_ratio = sum(c.isdigit() for c in without_tld) / max(1, len(without_tld))\n",
    "                    factors = {}\n",
    "                    reasons = []\n",
    "                    conf = 0.0\n",
    "                    if len(without_tld) <= 10: \n",
    "                        factors[\"short_name\"] = True; conf = max(conf, 0.30); reasons.append(\"短いドメイン名\")\n",
    "                    if ent > 4.0: \n",
    "                        factors[\"high_entropy\"] = True; conf = max(conf, 0.55); reasons.append(f\"高エントロピー {ent:.2f}\")\n",
    "                    if hyphens > 2: \n",
    "                        factors[\"many_hyphens\"] = True; conf = max(conf, 0.45); reasons.append(f\"ハイフン多 {hyphens}\")\n",
    "                    if digit_ratio > 0.3:\n",
    "                        factors[\"digit_ratio_high\"] = True; conf = max(conf, 0.40); reasons.append(f\"数字割合 {digit_ratio:.2f}\")\n",
    "                    out[\"output\"] = {\n",
    "                        \"is_phishing\": conf >= 0.5,\n",
    "                        \"confidence\": conf,\n",
    "                        \"risk_factors\": factors,\n",
    "                        \"reasoning\": \"; \".join(reasons) or \"no-issues\"\n",
    "                    }\n",
    "            elif tool_name == \"brand_check\":\n",
    "                domain = inputs[\"domain\"].lower()\n",
    "                hits = [b for b in self.brand_keywords if isinstance(b, str) and b.lower() in domain]\n",
    "                out[\"output\"] = {\n",
    "                    \"is_phishing\": len(hits) > 0,\n",
    "                    \"confidence\": 0.65 if len(hits) > 0 else 0.3,\n",
    "                    \"risk_factors\": {\"brand_hits\": hits},\n",
    "                    \"reasoning\": \"brand keywords matched\" if hits else \"no brand match\"\n",
    "                }\n",
    "            elif tool_name == \"cert_analysis\":\n",
    "                # placeholder; real impl will be connected later\n",
    "                out[\"output\"] = {\n",
    "                    \"is_phishing\": False,\n",
    "                    \"confidence\": 0.35,\n",
    "                    \"risk_factors\": {\"cert_org_missing\": True},\n",
    "                    \"reasoning\": \"mock: org field missing (placeholder)\"\n",
    "                }\n",
    "            elif tool_name == \"context_risk_assessment\":\n",
    "                # aggregate signals from previous results (pass via inputs)\n",
    "                signals = inputs.get(\"signals\", {})\n",
    "                conf = max([v.get(\"confidence\", 0.0) for v in signals.values()] + [0.0])\n",
    "                is_ph = any(v.get(\"is_phishing\", False) for v in signals.values())\n",
    "                out[\"output\"] = {\n",
    "                    \"is_phishing\": is_ph,\n",
    "                    \"confidence\": conf,\n",
    "                    \"risk_factors\": {\"combined\": {k: v.get(\"risk_factors\", {}) for k,v in signals.items()}},\n",
    "                    \"reasoning\": \"combined context risk (placeholder)\"\n",
    "                }\n",
    "            else:\n",
    "                out[\"ok\"] = False\n",
    "                out[\"output\"] = {\"error\": f\"unknown tool {tool_name}\"}\n",
    "        except Exception as e:\n",
    "            out[\"ok\"] = False\n",
    "            out[\"output\"] = {\"error\": str(e)}\n",
    "        finally:\n",
    "            out[\"latency_ms\"] = int((time.time() - t0)*1000)\n",
    "        return out\n",
    "\n",
    "    # ---- main entry ----\n",
    "    def analyze(self, domain: str, ml_probability: float, trace: Optional[Dict[str, Any]]=None) -> Dict[str, Any]:\n",
    "        trace_enabled = bool(trace) or self.trace_enabled\n",
    "        result = {\n",
    "            \"domain\": domain,\n",
    "            \"ml_probability\": float(ml_probability),\n",
    "            \"is_phishing\": False,\n",
    "            \"confidence\": float(ml_probability),\n",
    "            \"risk_factors\": {},\n",
    "            \"reasoning\": \"\",\n",
    "            \"detected_brands\": [],\n",
    "            \"tools_used\": [],\n",
    "        }\n",
    "        t_all = time.time()\n",
    "\n",
    "        is_obvious, brands, boost = self._check_obvious_phishing(domain)\n",
    "        result[\"detected_brands\"] = brands\n",
    "        result[\"confidence\"] = max(result[\"confidence\"], min(1.0, result[\"confidence\"] + boost))\n",
    "\n",
    "        # tool selection policy following paper: <0.2 => force all tools; >=0.2 => selective\n",
    "        tools = [\"brand_check\", \"short_domain_analysis\", \"cert_analysis\", \"context_risk_assessment\"]\n",
    "        if ml_probability >= 0.2:\n",
    "            tools = [\"brand_check\", \"cert_analysis\", \"context_risk_assessment\"]\n",
    "\n",
    "        # run tools (brand/short/cert first; context after)\n",
    "        signals: Dict[str, Dict[str, Any]] = {}\n",
    "        for t in tools:\n",
    "            if t == \"context_risk_assessment\":\n",
    "                # pass previous signals\n",
    "                out = self._execute_tool(t, {\"domain\": domain, \"signals\": signals})\n",
    "            else:\n",
    "                out = self._execute_tool(t, {\"domain\": domain, \"ml_probability\": ml_probability})\n",
    "                # collect\n",
    "                sig = out.get(\"output\", {}) if out.get(\"ok\") else {}\n",
    "                signals[t] = sig\n",
    "            result[\"tools_used\"].append({k: out.get(k) for k in (\"tool\",\"ok\",\"latency_ms\")})\n",
    "\n",
    "        # combine signals\n",
    "        confs = [signals[k].get(\"confidence\", 0.0) for k in signals if isinstance(signals[k], dict)]\n",
    "        max_conf = max(confs + [result[\"confidence\"]])\n",
    "        is_ph = any(signals[k].get(\"is_phishing\", False) for k in signals if isinstance(signals[k], dict))\n",
    "        # heuristics\n",
    "        if is_obvious or is_ph:\n",
    "            result[\"is_phishing\"] = True\n",
    "            result[\"confidence\"] = max(0.7, max_conf)\n",
    "        else:\n",
    "            result[\"is_phishing\"] = (max_conf >= 0.8)  # conservative\n",
    "\n",
    "        # reasoning\n",
    "        reasons = []\n",
    "        if brands: reasons.append(f\"ブランド一致: {', '.join(brands)}\")\n",
    "        if is_obvious: reasons.append(\"高リスク語とブランド一致\")\n",
    "        # add top 2 signal reasons\n",
    "        for name in [\"brand_check\",\"short_domain_analysis\",\"cert_analysis\"]:\n",
    "            rs = signals.get(name, {})\n",
    "            if rs.get(\"reasoning\"): reasons.append(f\"{name}: {rs['reasoning']}\")\n",
    "        result[\"reasoning\"] = \" / \".join(reasons)[:1500]\n",
    "\n",
    "        if trace_enabled:\n",
    "            result[\"trace_enabled\"] = True\n",
    "            result[\"tool_signals\"] = signals\n",
    "            result[\"total_latency_ms\"] = int((time.time() - t_all)*1000)\n",
    "\n",
    "        # ensure Structured Output\n",
    "        for k in (\"is_phishing\",\"confidence\",\"risk_factors\",\"reasoning\"):\n",
    "            if k not in result:\n",
    "                if k == \"is_phishing\": result[k] = False\n",
    "                elif k == \"confidence\": result[k] = 0.5\n",
    "                elif k == \"risk_factors\": result[k] = {}\n",
    "                elif k == \"reasoning\": result[k] = \"\"\n",
    "        return result\n",
    "\n",
    "# convenience factory for notebooks\n",
    "def make_fixed_agent(run_id: Optional[str]=None, trace_enabled: bool=False) -> FixedPhishingDetectionAgent:\n",
    "    s = _load_llm_setup(run_id)\n",
    "    agent = FixedPhishingDetectionAgent.from_handoff(run_id)\n",
    "    agent.trace_enabled = trace_enabled\n",
    "    return agent\n",
    "\n",
    "print(\"[C-02] FixedPhishingDetectionAgent is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0cb7443",
   "metadata": {
    "tags": [
     "C-03b",
     "handoff",
     "export"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04-4] handoff updated: artifacts/2025-10-22_074213/handoff/04-4_agent_implementation.pkl | keys: ['RUN_ID', 'cfg', 'evaluate_domain__ref', 'meta']\n"
     ]
    }
   ],
   "source": [
    "# === C-03b: Attach evaluation candidates into 04-4 handoff (minimal) ===\n",
    "import warnings, pickle, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 標準パス解決\n",
    "try:\n",
    "    import importlib, run_id_registry as runreg, _compat.paths as paths\n",
    "    rid = runreg.bootstrap()\n",
    "    importlib.reload(paths); \n",
    "    paths.ensure_roots()\n",
    "    RUN_ID = paths.RUN_ID or os.environ.get(\"RUN_ID\")\n",
    "    BASE = paths.compat_base_dirs\n",
    "    HANDOFF_DIR = Path(BASE[\"handoff\"]); RESULTS_DIR = Path(BASE[\"results\"])\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"[04-4] compat paths fallback: {e}\")\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\")\n",
    "    HANDOFF_DIR = Path(f\"artifacts/{RUN_ID}/handoff\"); RESULTS_DIR = Path(f\"artifacts/{RUN_ID}/results\")\n",
    "\n",
    "out_pkl = HANDOFF_DIR / \"04-4_agent_implementation.pkl\"\n",
    "\n",
    "# 既存exportsを読み込み（無ければ空）\n",
    "exports = {}\n",
    "try:\n",
    "    if out_pkl.exists() and out_pkl.stat().st_size > 0:\n",
    "        with open(out_pkl, \"rb\") as f:\n",
    "            exports = pickle.load(f) or {}\n",
    "except Exception as e:\n",
    "    warnings.warn(f\"[04-4] load existing exports failed: {e}; recreate empty\")\n",
    "    exports = {}\n",
    "\n",
    "def _pick_prob_col(df):\n",
    "    for c in [\"ml_probability\",\"ml_prob\",\"prob\",\"proba\",\"pred_prob\",\"pred_proba\",\"probability\",\"phish_prob\",\"p_phish\",\"score\"]:\n",
    "        if c in getattr(df, \"columns\", []): \n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _try_build_eval_samples():\n",
    "    for name in [\"candidates_df\", \"eval_df\", \"evaluation_results\", \"res_df\"]:\n",
    "        if name in globals():\n",
    "            df = globals()[name]\n",
    "            if isinstance(df, pd.DataFrame) and \"domain\" in df.columns:\n",
    "                col = _pick_prob_col(df)\n",
    "                if col:\n",
    "                    return df[[\"domain\", col]].rename(columns={col: \"ml_probability\"}).copy()\n",
    "    # 04-3 handoffのfn_features_dfがあれば流用\n",
    "    try:\n",
    "        src43 = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "        if src43.exists() and src43.stat().st_size > 0:\n",
    "            with open(src43, \"rb\") as f:\n",
    "                d43 = pickle.load(f) or {}\n",
    "            if \"fn_features_df\" in d43:\n",
    "                return d43[\"fn_features_df\"]\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"[04-4] fn_features_df import failed: {e}\")\n",
    "    return None\n",
    "\n",
    "eval_df = _try_build_eval_samples()\n",
    "\n",
    "if eval_df is not None and len(eval_df) > 0:\n",
    "    if len(eval_df) > 5000:\n",
    "        eval_df = eval_df.sample(5000, random_state=42).reset_index(drop=True)\n",
    "    exports[\"eval_samples\"] = eval_df.reset_index(drop=True)\n",
    "    print(f\"[04-4] exports['eval_samples'] set (rows={len(eval_df)})\")\n",
    "else:\n",
    "    # CSVで場所を教える方式（手掛かりが無い場合はスキップ可）\n",
    "    try:\n",
    "        RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        candidates_csv = RESULTS_DIR / \"evaluation_candidates.csv\"\n",
    "        if eval_df is not None:\n",
    "            eval_df.to_csv(candidates_csv, index=False)\n",
    "            exports.setdefault(\"meta\", {}); exports[\"meta\"].setdefault(\"paths\", {})\n",
    "            exports[\"meta\"][\"paths\"][\"evaluation_candidates_csv\"] = str(candidates_csv)\n",
    "            print(f\"[04-4] meta.paths.evaluation_candidates_csv -> {candidates_csv}\")\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"[04-4] cannot save candidates_csv: {e}\")\n",
    "\n",
    "# 参照もあれば格納（Mock回避に寄与）\n",
    "def _ref_info(obj):\n",
    "    return {\"module\": getattr(obj, \"__module__\", None),\n",
    "            \"qualname\": getattr(obj, \"__qualname__\", getattr(obj, \"__name__\", None))}\n",
    "\n",
    "for ref_name in [\"evaluate_domain\", \"evaluate_domain_fixed\"]:\n",
    "    if ref_name in globals():\n",
    "        try:\n",
    "            exports[f\"{ref_name}__ref\"] = _ref_info(globals()[ref_name])\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"[04-4] cannot set {ref_name}__ref: {e}\")\n",
    "\n",
    "# 上書き保存\n",
    "with open(out_pkl, \"wb\") as f:\n",
    "    pickle.dump(exports, f)\n",
    "print(\"[04-4] handoff updated:\", out_pkl, \"| keys:\", sorted(exports.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc97fc2",
   "metadata": {
    "name": "06-A-ASYNC: analyze_domain_async",
    "title": "06-A-ASYNC: analyze_domain_async"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-A-ASYNC: analyze_domain_async (minimal restore) ===\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "# 前提: PhishingDetectionAgent / FixedPhishingDetectionAgent / PhishingDetectionResult が既に定義済み\n",
    "\n",
    "async def _analyze_domain_async_core(agent, domain: str, ml_prob: float, index: int):\n",
    "    \"\"\"\n",
    "    Core logic placeholder:\n",
    "    - Delegates to agent's internal evaluate_domain/equivalent if available\n",
    "    - Ensures structured output (dict or PhishingDetectionResult)\n",
    "    - This is a minimal, non-breaking shim for staged restoration.\n",
    "    \"\"\"\n",
    "    if hasattr(agent, \"evaluate_domain_fixed\"):\n",
    "        return await agent.evaluate_domain_fixed(domain=domain, ml_probability=ml_prob, index=index)\n",
    "    if hasattr(agent, \"evaluate_domain\"):\n",
    "        return await agent.evaluate_domain(domain=domain, ml_probability=ml_prob, index=index)\n",
    "    # フォールバック（構造化）\n",
    "    return {\n",
    "        \"domain\": domain,\n",
    "        \"ml_probability\": ml_prob,\n",
    "        \"index\": index,\n",
    "        \"is_phishing\": None,\n",
    "        \"confidence\": None,\n",
    "        \"risk_factors\": {},\n",
    "        \"reasoning\": \"[04-4] No evaluate_domain* found; returned fallback.\"\n",
    "    }\n",
    "\n",
    "def _patch_agent_with_async_method():\n",
    "    async def analyze_domain_async(self, domain: str, ml_prob: float, index: int):\n",
    "        try:\n",
    "            return await _analyze_domain_async_core(self, domain, ml_prob, index)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": ml_prob,\n",
    "                \"index\": index,\n",
    "                \"error\": f\"[04-4] analyze_domain_async failed: {e}\"\n",
    "            }\n",
    "\n",
    "    # 既存クラス双方にアタッチ（Fixed系にも）\n",
    "    for _cls_name in (\"PhishingDetectionAgent\", \"FixedPhishingDetectionAgent\"):\n",
    "        _cls = globals().get(_cls_name)\n",
    "        if _cls and not hasattr(_cls, \"analyze_domain_async\"):\n",
    "            setattr(_cls, \"analyze_domain_async\", analyze_domain_async)\n",
    "\n",
    "_patch_agent_with_async_method()\n",
    "print(\"✅ [04-4] analyze_domain_async restored (async method attached)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6552ef3",
   "metadata": {
    "name": "06-A-ASYNC-TEST",
    "title": "06-A-ASYNC-TEST"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-A-ASYNC-TEST (Jupyter-safe) ===\n",
    "import asyncio\n",
    "try:\n",
    "    # Running loop exists (Jupyter etc.) -> use top-level await\n",
    "    _ = asyncio.get_running_loop()\n",
    "    test_agent = FixedPhishingDetectionAgent() if 'FixedPhishingDetectionAgent' in globals() else PhishingDetectionAgent()\n",
    "    res = await test_agent.analyze_domain_async(\"paypal-secure-login.info\", 0.34, 0)\n",
    "    print(\"[TEST] analyze_domain_async -> OK\")\n",
    "    if isinstance(res, dict):\n",
    "        print(res)\n",
    "    else:\n",
    "        print(getattr(res, \"__dict__\", res))\n",
    "except RuntimeError:\n",
    "    # No running loop -> asyncio.run\n",
    "    test_agent = FixedPhishingDetectionAgent() if 'FixedPhishingDetectionAgent' in globals() else PhishingDetectionAgent()\n",
    "    res = asyncio.run(test_agent.analyze_domain_async(\"paypal-secure-login.info\", 0.34, 0))\n",
    "    print(\"[TEST] analyze_domain_async -> OK\")\n",
    "    if isinstance(res, dict):\n",
    "        print(res)\n",
    "    else:\n",
    "        print(getattr(res, \"__dict__\", res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861c517",
   "metadata": {
    "name": "06-B-RISK: contextual_risk_assessment",
    "title": "06-B-RISK: contextual_risk_assessment"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-B-RISK: contextual_risk_assessment (restored/fixed + compat aliases) ===\n",
    "from typing import Dict, Any\n",
    "\n",
    "def _safe_get(d: Dict[str, Any], keys, default=None):\n",
    "    for k in keys:\n",
    "        if isinstance(k, (list, tuple)):\n",
    "            cur = d\n",
    "            ok = True\n",
    "            for kk in k:\n",
    "                if isinstance(cur, dict) and kk in cur:\n",
    "                    cur = cur[kk]\n",
    "                else:\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok:\n",
    "                return cur\n",
    "        else:\n",
    "            if isinstance(d, dict) and k in d:\n",
    "                return d[k]\n",
    "    return default\n",
    "\n",
    "def contextual_risk_assessment(domain: str,\n",
    "                               ml_probability: float,\n",
    "                               brand_result: Dict[str, Any],\n",
    "                               cert_result: Dict[str, Any],\n",
    "                               domain_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Return dict: {is_phishing, confidence, risk_factors, reasoning} + compat aliases\"\"\"\n",
    "    ml_prob = float(max(0.0, min(1.0, ml_probability if ml_probability is not None else 0.0)))\n",
    "    risk_from_ml = 1.0 - ml_prob\n",
    "\n",
    "    brand_match = bool(_safe_get(brand_result, [\"brand_match\", \"is_brand_imitated\", \"match\"], False))\n",
    "    brand_name = _safe_get(brand_result, [\"brand\", \"target_brand\", \"matched_brand\"], None)\n",
    "    typo_score = float(_safe_get(brand_result, [\"typosquatting_score\", \"typo_score\"], 0.0) or 0.0)\n",
    "    risk_brand = 0.0\n",
    "    if brand_match:\n",
    "        risk_brand += 0.35\n",
    "    risk_brand += min(0.25, max(0.0, typo_score) * 0.25)\n",
    "\n",
    "    org_present = _safe_get(cert_result, [\"org_present\", [\"subject\",\"O\"], \"has_org\"], None)\n",
    "    is_self_signed = bool(_safe_get(cert_result, [\"is_self_signed\"], False))\n",
    "    validity_days = _safe_get(cert_result, [\"validity_days\", \"days_valid\"], None)\n",
    "    issuer = (_safe_get(cert_result, [\"issuer\", [\"issuer\",\"CN\"]], \"\") or \"\").lower()\n",
    "    san_count = _safe_get(cert_result, [\"san_count\"], None)\n",
    "    wildcard = bool(_safe_get(cert_result, [\"wildcard\", \"is_wildcard\"], False))\n",
    "\n",
    "    risk_cert = 0.0\n",
    "    if org_present is False:\n",
    "        risk_cert += 0.20\n",
    "    if is_self_signed:\n",
    "        risk_cert += 0.25\n",
    "    if isinstance(validity_days, (int, float)) and validity_days < 90:\n",
    "        risk_cert += 0.10\n",
    "    if \"let's encrypt\" in issuer or \"lets encrypt\" in issuer:\n",
    "        risk_cert += 0.05\n",
    "    if isinstance(san_count, int) and san_count <= 1:\n",
    "        risk_cert += 0.05\n",
    "    if wildcard:\n",
    "        risk_cert += 0.05\n",
    "\n",
    "    tld = (_safe_get(domain_result, [\"tld\"], \"\") or \"\").lower().lstrip(\".\")\n",
    "    dlen = _safe_get(domain_result, [\"length\", \"domain_length\"], None)\n",
    "    entropy = float(_safe_get(domain_result, [\"shannon_entropy\",\"entropy\"], 0.0) or 0.0)\n",
    "\n",
    "    suspicious_tlds = {\"buzz\",\"top\",\"xyz\",\"icu\",\"cn\",\"click\",\"work\",\"shop\",\"online\",\"monster\",\"zip\",\"mov\",\"country\"}\n",
    "    risk_domain = 0.0\n",
    "    if tld in suspicious_tlds:\n",
    "        risk_domain += 0.10\n",
    "    if isinstance(dlen, int) and dlen <= 8:\n",
    "        risk_domain += 0.05\n",
    "    if entropy and entropy >= 3.6:\n",
    "        risk_domain += 0.10\n",
    "\n",
    "    score = 0.35 * risk_from_ml + 0.30 * min(1.0, risk_brand) + 0.20 * min(1.0, risk_cert) + 0.15 * min(1.0, risk_domain)\n",
    "    score = max(0.0, min(1.0, score))\n",
    "\n",
    "    is_phishing = bool(score >= 0.50)\n",
    "    confidence = float(score)\n",
    "\n",
    "    reasons = []\n",
    "    if brand_match:\n",
    "        reasons.append(f\"ブランド偽装の疑い（{brand_name or 'unknown'}）\")\n",
    "    if typo_score and typo_score >= 0.5:\n",
    "        reasons.append(f\"タイポスクワッティング指標が高い({typo_score:.2f})\")\n",
    "    if org_present is False:\n",
    "        reasons.append(\"証明書の組織情報が欠如\")\n",
    "    if is_self_signed:\n",
    "        reasons.append(\"自己署名証明書\")\n",
    "    if isinstance(validity_days, (int, float)) and validity_days < 90:\n",
    "        reasons.append(f\"短期証明書({int(validity_days)}日)\")\n",
    "    if \"let's encrypt\" in issuer or \"lets encrypt\" in issuer:\n",
    "        reasons.append(\"無料CA(LE)の使用\")\n",
    "    if tld in suspicious_tlds:\n",
    "        reasons.append(f\"疑わしいTLD(.{tld})\")\n",
    "    if isinstance(dlen, int) and dlen <= 8:\n",
    "        reasons.append(f\"短いドメイン長({dlen})\")\n",
    "    if entropy and entropy >= 3.6:\n",
    "        reasons.append(f\"高エントロピー({entropy:.2f})\")\n",
    "    if not reasons:\n",
    "        reasons.append(\"複合リスクの総合判断\")\n",
    "\n",
    "    # Compat aliases for legacy tests and downstreams\n",
    "    if score >= 0.75:\n",
    "        risk_level = \"high\"\n",
    "    elif score >= 0.50:\n",
    "        risk_level = \"medium\"\n",
    "    else:\n",
    "        risk_level = \"low\"\n",
    "    final_label = \"phishing\" if is_phishing else \"benign\"\n",
    "\n",
    "    out = {\n",
    "        \"is_phishing\": is_phishing,\n",
    "        \"confidence\": confidence,\n",
    "        \"risk_factors\": {\n",
    "            \"ml_low_confidence\": risk_from_ml,\n",
    "            \"brand\": {\n",
    "                \"match\": brand_match,\n",
    "                \"name\": brand_name,\n",
    "                \"typo_score\": float(typo_score),\n",
    "                \"risk_component\": min(1.0, risk_brand),\n",
    "            },\n",
    "            \"certificate\": {\n",
    "                \"org_present\": bool(org_present) if org_present is not None else None,\n",
    "                \"is_self_signed\": is_self_signed,\n",
    "                \"validity_days\": int(validity_days) if isinstance(validity_days, (int, float)) else None,\n",
    "                \"issuer\": issuer,\n",
    "                \"san_count\": int(san_count) if isinstance(san_count, int) else None,\n",
    "                \"wildcard\": wildcard,\n",
    "                \"risk_component\": min(1.0, risk_cert),\n",
    "            },\n",
    "            \"domain\": {\n",
    "                \"tld\": tld,\n",
    "                \"length\": int(dlen) if isinstance(dlen, int) else None,\n",
    "                \"entropy\": float(entropy) if entropy else None,\n",
    "                \"risk_component\": min(1.0, risk_domain),\n",
    "            },\n",
    "            \"combined_score\": score,\n",
    "        },\n",
    "        \"reasoning\": \" / \".join(reasons),\n",
    "\n",
    "        # ---- Backward-compat keys (non-breaking) ----\n",
    "        \"risk_score\": score,      # numeric synonym of confidence\n",
    "        \"risk_level\": risk_level, # \"low\" / \"medium\" / \"high\"\n",
    "        \"final_label\": final_label,  # \"phishing\" / \"benign\"\n",
    "        \"risk\": score,            # additional synonym used by some test cells\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bd2f3",
   "metadata": {
    "name": "06-B-RISK-TEST",
    "title": "06-B-RISK-TEST"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-B-RISK-TEST ===\n",
    "dummy_brand = {\"is_impersonation\": True, \"confidence\": 0.8, \"brand\": \"PayPal\"}\n",
    "dummy_cert = {\"valid_https\": True, \"issuer\": \"Let's Encrypt\"}\n",
    "dummy_domain = {\"suspicious_tld\": True, \"levenshtein_to_brand\": 2}\n",
    "out = contextual_risk_assessment(\n",
    "    domain=\"paypal-secure-login.info\",\n",
    "    ml_probability=0.34,\n",
    "    brand_result=dummy_brand,\n",
    "    cert_result=dummy_cert,\n",
    "    domain_result=dummy_domain,\n",
    ")\n",
    "print(\"[TEST] contextual_risk_assessment ->\", out)\n",
    "assert isinstance(out, dict), \"Output must be dict\"\n",
    "assert \"risk\" in out or \"risk_score\" in out or \"final_label\" in out or \"risk_level\" in out, \"Expect risk-related keys\"\n",
    "print(\"[TEST] contextual_risk_assessment -> OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed195e7",
   "metadata": {
    "name": "06-E-RUN-PARALLEL: run_parallel_evaluation",
    "title": "06-E-RUN-PARALLEL: run_parallel_evaluation"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-E-RUN-PARALLEL: run_parallel_evaluation (restore, minimal) ===\n",
    "import asyncio\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import pandas as pd\n",
    "\n",
    "async def run_parallel_evaluation(sample_size: int = 50,\n",
    "                                  max_concurrent: int = 8,\n",
    "                                  development_mode: bool = False) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Top-level driver that runs parallel evaluation and (optionally) basic analysis.\n",
    "\n",
    "    Notes:\n",
    "    - To avoid coupling with 04-5 (which holds analyze_evaluation_results/generate_evaluation_report),\n",
    "      this function tries to call them *only if they exist in globals()*.\n",
    "    - If not available, returns (results_df, {}) without analysis (04-5 remains non-modified).\n",
    "    - Input dataset policy:\n",
    "        * If development_mode is True, uses a tiny synthetic DataFrame.\n",
    "        * Else, tries to use a global `samples_df` if present; otherwise returns (empty_df, {}).\n",
    "    \"\"\"\n",
    "    # 1) prepare samples\n",
    "    if development_mode:\n",
    "        df = pd.DataFrame({\n",
    "            \"domain\": [\"paypal-secure-login.info\", \"example.com\", \"login-appleid-secure.net\"],\n",
    "            \"ml_probability\": [0.34, 0.80, 0.12],\n",
    "        })\n",
    "    else:\n",
    "        df = globals().get(\"samples_df\")\n",
    "        if df is None or not hasattr(df, \"head\"):\n",
    "            print(\"[run_parallel_evaluation] No global samples_df found; returning empty.\")\n",
    "            return pd.DataFrame(), {}\n",
    "\n",
    "    if sample_size and len(df) > sample_size:\n",
    "        df = df.head(sample_size).copy()\n",
    "\n",
    "    # 2) run parallel evaluation\n",
    "    try:\n",
    "        results_df = await evaluate_samples_parallel(df, max_concurrent=max_concurrent, show_progress=True)\n",
    "    except Exception as e:\n",
    "        print(f\"[run_parallel_evaluation] evaluate_samples_parallel failed: {e}\")\n",
    "        return pd.DataFrame(), {}\n",
    "\n",
    "    if results_df is None or results_df.empty:\n",
    "        print(\"[run_parallel_evaluation] No results; returning.\")\n",
    "        return pd.DataFrame(), {}\n",
    "\n",
    "    # 3) optional analysis (only if 04-5 functions are already in this kernel)\n",
    "    analysis = {}\n",
    "    if \"analyze_evaluation_results\" in globals() and \"generate_evaluation_report\" in globals():\n",
    "        try:\n",
    "            analysis = analyze_evaluation_results(results_df)\n",
    "            report = generate_evaluation_report(analysis, results_df)\n",
    "            print(report)\n",
    "        except Exception as e:\n",
    "            print(f\"[run_parallel_evaluation] analysis/report generation failed: {e}\")\n",
    "            analysis = {}\n",
    "    else:\n",
    "        print(\"[run_parallel_evaluation] 04-5 analysis functions not found; skipped (non-breaking).\")\n",
    "\n",
    "    return results_df, analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 06-F-COMPAT: evaluate_async / evaluate_samples_parallel (wrappers) ===\n",
    "import asyncio\n",
    "from typing import Dict, Any, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# Reuse existing Async API on agent\n",
    "def _get_eval_agent():\n",
    "    if 'FixedPhishingDetectionAgent' in globals():\n",
    "        try:\n",
    "            return FixedPhishingDetectionAgent()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if 'PhishingDetectionAgent' in globals():\n",
    "        try:\n",
    "            return PhishingDetectionAgent()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "async def evaluate_async(domain: str,\n",
    "                         ml_prob: float,\n",
    "                         semaphore: Optional[asyncio.Semaphore] = None,\n",
    "                         index: int = 0,\n",
    "                         agent=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Wrapper for original name compatibility.\n",
    "    Delegates to agent.analyze_domain_async(domain, ml_prob, index).\n",
    "    Returns a dict with at least: domain, ml_probability, is_phishing, confidence, reasoning.\n",
    "    \"\"\"\n",
    "    agent = agent or _get_eval_agent()\n",
    "    if agent is None:\n",
    "        # graceful fallback: minimal mock\n",
    "        return {\"domain\": domain, \"ml_probability\": ml_prob, \"is_phishing\": False, \"confidence\": float(ml_prob or 0.0),\n",
    "                \"reasoning\": \"[04-4] no agent available (mock)\", \"risk_level\": \"low\", \"risk_score\": float(ml_prob or 0.0), \"final_label\":\"benign\"}\n",
    "    async def _run():\n",
    "        if hasattr(agent, \"analyze_domain_async\"):\n",
    "            res = await agent.analyze_domain_async(domain, ml_prob, index)\n",
    "        else:\n",
    "            # fallback to evaluate_domain* (sync wrapped)\n",
    "            if hasattr(agent, \"evaluate_domain_fixed\"):\n",
    "                res = await asyncio.to_thread(agent.evaluate_domain_fixed, domain=domain, ml_probability=ml_prob, index=index)\n",
    "            elif hasattr(agent, \"evaluate_domain\"):\n",
    "                res = await asyncio.to_thread(agent.evaluate_domain, domain=domain, ml_probability=ml_prob, index=index)\n",
    "            else:\n",
    "                res = {\"is_phishing\": False, \"confidence\": 0.0, \"reasoning\": \"no evaluator\"}\n",
    "        if isinstance(res, dict):\n",
    "            # ---- Backward-compat + hardening (None-safe) ----\n",
    "            res.setdefault(\"domain\", domain)\n",
    "            res.setdefault(\"ml_probability\", ml_prob)\n",
    "            # normalize confidence\n",
    "            conf = res.get(\"confidence\")\n",
    "            if conf is None:\n",
    "                conf = 0.0\n",
    "            try:\n",
    "                conf = float(conf)\n",
    "            except Exception:\n",
    "                conf = 0.0\n",
    "            res[\"confidence\"] = conf\n",
    "            # normalize is_phishing\n",
    "            if res.get(\"is_phishing\") is None:\n",
    "                res[\"is_phishing\"] = bool(conf >= 0.5)\n",
    "            # aliases\n",
    "            res.setdefault(\"risk_score\", conf)\n",
    "            if \"risk_level\" not in res:\n",
    "                res[\"risk_level\"] = \"high\" if conf >= 0.75 else (\"medium\" if conf >= 0.5 else \"low\")\n",
    "            if \"final_label\" not in res:\n",
    "                res[\"final_label\"] = \"phishing\" if res.get(\"is_phishing\") else \"benign\"\n",
    "            res.setdefault(\"reasoning\", \"\")\n",
    "            return res\n",
    "        # If class-like result, try to serialize\n",
    "        try:\n",
    "            d = getattr(res, \"__dict__\", {}) or {}\n",
    "            d.setdefault(\"domain\", domain)\n",
    "            d.setdefault(\"ml_probability\", ml_prob)\n",
    "            # also ensure minimal keys\n",
    "            d.setdefault(\"confidence\", 0.0)\n",
    "            d.setdefault(\"is_phishing\", False)\n",
    "            d.setdefault(\"risk_score\", d.get(\"confidence\", 0.0))\n",
    "            d.setdefault(\"risk_level\", \"low\")\n",
    "            d.setdefault(\"final_label\", \"benign\")\n",
    "            d.setdefault(\"reasoning\", \"\")\n",
    "            return d\n",
    "        except Exception:\n",
    "            return {\"domain\": domain, \"ml_probability\": ml_prob, \"is_phishing\": False, \"confidence\": 0.0, \"reasoning\": \"serialize-fallback\",\n",
    "                    \"risk_level\": \"low\", \"risk_score\": 0.0, \"final_label\": \"benign\"}\n",
    "    if semaphore is None:\n",
    "        return await _run()\n",
    "    async with semaphore:\n",
    "        return await _run()\n",
    "\n",
    "async def evaluate_samples_parallel(samples_df: pd.DataFrame,\n",
    "                                    max_concurrent: int = 8,\n",
    "                                    show_progress: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run evaluate_async over rows of samples_df in parallel.\n",
    "    Expected columns: ['domain', 'ml_probability'] (extra columns are preserved via merge).\n",
    "    \"\"\"\n",
    "    if samples_df is None or samples_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df = samples_df.copy()\n",
    "    if \"domain\" not in df.columns or \"ml_probability\" not in df.columns:\n",
    "        # try common fallbacks\n",
    "        domain_col = \"domain\" if \"domain\" in df.columns else next((c for c in df.columns if \"domain\" in c.lower()), None)\n",
    "        prob_col = \"ml_probability\" if \"ml_probability\" in df.columns else next((c for c in df.columns if \"prob\" in c.lower()), None)\n",
    "        if not domain_col or not prob_col:\n",
    "            raise ValueError(\"[04-4] evaluate_samples_parallel: input df must have domain/ml_probability\")\n",
    "        df = df.rename(columns={domain_col: \"domain\", prob_col: \"ml_probability\"})\n",
    "    sem = asyncio.Semaphore(max_concurrent) if max_concurrent and max_concurrent > 0 else None\n",
    "    agent = _get_eval_agent()\n",
    "    tasks = []\n",
    "    for i, row in df.reset_index(drop=True).iterrows():\n",
    "        tasks.append(evaluate_async(row[\"domain\"], float(row[\"ml_probability\"]) if row[\"ml_probability\"] is not None else 0.0, sem, i, agent))\n",
    "    results = []\n",
    "    # gather with progress print (optional)\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        res = await fut\n",
    "        results.append(res)\n",
    "        if show_progress and len(results) % 10 == 0:\n",
    "            print(f\"[04-4] progress: {len(results)}/{len(tasks)}\")\n",
    "    out_df = pd.DataFrame(results)\n",
    "    # ensure minimal columns\n",
    "    for col in [\"domain\",\"ml_probability\",\"is_phishing\",\"confidence\",\"reasoning\",\"risk_level\",\"risk_score\",\"final_label\"]:\n",
    "        if col not in out_df.columns:\n",
    "            out_df[col] = None\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c7ae8",
   "metadata": {
    "name": "06-E-RUN-PARALLEL-TEST",
    "title": "06-E-RUN-PARALLEL-TEST"
   },
   "outputs": [],
   "source": [
    "# === Cell 06-E-RUN-PARALLEL-TEST (Jupyter-safe) ===\n",
    "import pandas as pd\n",
    "try:\n",
    "    # Dev-mode run (no dependency on external dataset or 04-5)\n",
    "    results_df, analysis = await run_parallel_evaluation(sample_size=3, max_concurrent=3, development_mode=True)\n",
    "    print(\"[TEST] run_parallel_evaluation -> results shape:\", results_df.shape)\n",
    "    print(results_df.head())\n",
    "    assert isinstance(results_df, pd.DataFrame), \"results_df must be DataFrame\"\n",
    "    assert not results_df.empty, \"results_df should not be empty in dev mode\"\n",
    "    assert isinstance(analysis, dict), \"analysis must be dict\"\n",
    "    print(\"[TEST] run_parallel_evaluation -> OK (dev mode)\")\n",
    "except Exception as e:\n",
    "    print(\"[TEST] run_parallel_evaluation -> FAILED:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}