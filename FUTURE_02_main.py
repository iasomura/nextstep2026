#!/usr/bin/env python3
"""
Phase 2.1ã§å®Ÿè£…äºˆå®š: å®Œå…¨ç‰ˆ 02_main.py

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ Phase 2.1 ã§å®Ÿè£…ã•ã‚Œã‚‹äºˆå®šã®çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚
ç¾æ™‚ç‚¹ã§ã¯å‹•ä½œã—ã¾ã›ã‚“ï¼ˆå‚è€ƒç”¨ï¼‰ã€‚

Usage:
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã§äºˆæ¸¬
    python 02_main.py --input domains.csv --output results.csv

    # æ—¢å­˜ã®artifactsã§è©•ä¾¡
    python 02_main.py --eval --run-id 2026-01-10_140940

    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    python 02_main.py --train --data train.csv
"""

import argparse
from pathlib import Path
import sys

sys.path.insert(0, "02_stage1_stage2")

from src.config import load_config
from src.features import FeatureEngineer
from src.train_xgb import Stage1Trainer
from src.route1 import Route1ThresholdSelector
from src.stage2_gate import Stage2Gate
import pandas as pd
import json


def main():
    parser = argparse.ArgumentParser(
        description="Phase 2.1 çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå®Œå…¨ç‰ˆï¼‰"
    )

    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument('--predict', action='store_true',
                           help='æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬')
    mode_group.add_argument('--eval', action='store_true',
                           help='æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡')
    mode_group.add_argument('--train', action='store_true',
                           help='æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´')

    # å…±é€šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument('--config', type=str,
                       default='02_stage1_stage2/configs/default.yaml',
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--run-id', type=str,
                       help='ä½¿ç”¨ã™ã‚‹artifactsã®RUN_IDï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ€æ–°ï¼‰')
    parser.add_argument('--output-dir', type=str,
                       default='results',
                       help='çµæœã®å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')

    # äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ç”¨
    parser.add_argument('--input', type=str,
                       help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆdomainåˆ—ãŒå¿…è¦ï¼‰')
    parser.add_argument('--output', type=str,
                       help='å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«')

    # è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ç”¨
    parser.add_argument('--data', type=str,
                       help='è¨“ç·´ãƒ‡ãƒ¼ã‚¿CSV')
    parser.add_argument('--val-data', type=str,
                       help='æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿CSVï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰')

    # Stage2ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument('--skip-stage2', action='store_true',
                       help='Stage2ã‚’ã‚¹ã‚­ãƒƒãƒ—')
    parser.add_argument('--stage2-budget', type=int,
                       help='Stage2ã®äºˆç®—ã‚’ä¸Šæ›¸ã')

    args = parser.parse_args()

    # è¨­å®šèª­ã¿è¾¼ã¿
    cfg = load_config(args.config)
    print(f"âœ… Config loaded from: {args.config}")

    # RUN_IDæ±ºå®š
    if args.run_id:
        run_id = args.run_id
    else:
        # æœ€æ–°ã®RUN_IDã‚’å–å¾—
        artifacts_dir = Path("artifacts")
        runs = [d.name for d in artifacts_dir.iterdir()
                if d.is_dir() and d.name != '_current']
        run_id = sorted(runs)[-1] if runs else None

    if not run_id and args.predict:
        print("âŒ Error: --run-id ãŒå¿…è¦ã§ã™ï¼ˆã¾ãŸã¯ artifacts/ ã«ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰")
        return 1

    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å®Ÿè¡Œ
    if args.predict:
        return run_predict(args, cfg, run_id)
    elif args.eval:
        return run_eval(args, cfg, run_id)
    elif args.train:
        return run_train(args, cfg)

    return 0


def run_predict(args, cfg, run_id):
    """äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ”® äºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰")
    print("="*80)

    if not args.input:
        print("âŒ Error: --input ãŒå¿…è¦ã§ã™")
        return 1

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv(args.input)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df):,} domains from {args.input}")

    # Artifactsã‹ã‚‰å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    artifacts_dir = Path(f"artifacts/{run_id}")
    print(f"âœ… Using artifacts: {run_id}")

    with open(artifacts_dir / "models/brand_keywords.json") as f:
        brand_keywords = json.load(f)

    # ç‰¹å¾´é‡æŠ½å‡º
    print("\nğŸ”§ ç‰¹å¾´é‡æŠ½å‡ºä¸­...")
    engineer = FeatureEngineer(brand_keywords)
    features = [engineer.extract_features(d, None) for d in df['domain']]
    df_features = pd.DataFrame(features, columns=engineer.get_feature_names())

    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸
    for col in df.columns:
        if col not in df_features.columns:
            df_features[col] = df[col].values

    print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(df_features):,} samples")

    # Stage1äºˆæ¸¬
    print("\nğŸ¤– Stage1 äºˆæ¸¬ä¸­...")
    trainer = Stage1Trainer(cfg.xgboost)
    trainer.load_model(artifacts_dir / "models/xgboost_model_baseline.pkl")

    with open(artifacts_dir / "models/feature_order.json") as f:
        feature_order = json.load(f)

    predictions = trainer.predict_proba(df_features, feature_order)
    df_features['stage1_score'] = predictions
    print(f"âœ… Stage1 äºˆæ¸¬å®Œäº†")

    # Route1åˆ†é¡
    print("\nğŸš¦ Route1 é–¾å€¤é©ç”¨ä¸­...")
    with open(artifacts_dir / "results/route1_thresholds.json") as f:
        thresholds = json.load(f)

    selector = Route1ThresholdSelector(cfg.route1)
    selector.t_low = thresholds['t_low']
    selector.t_high = thresholds['t_high']

    decisions = selector.apply_thresholds(predictions)
    decision_map = {0: 'AUTO_BENIGN', 1: 'DEFER', 2: 'AUTO_PHISH'}
    df_features['route1_decision'] = [decision_map[d] for d in decisions]

    print(f"âœ… Route1 åˆ†é¡å®Œäº†:")
    print(f"   AUTO_BENIGN: {(decisions == 0).sum():,}")
    print(f"   DEFER:       {(decisions == 1).sum():,}")
    print(f"   AUTO_PHISH:  {(decisions == 2).sum():,}")

    # Stage2ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if not args.skip_stage2 and (decisions == 1).sum() > 0:
        print("\nğŸšª Stage2 Gateé©ç”¨ä¸­...")
        df_defer = df_features[decisions == 1].copy()

        if args.stage2_budget:
            from dataclasses import replace
            custom_config = replace(cfg.stage2, max_budget=args.stage2_budget)
            gate = Stage2Gate(custom_config, brand_keywords)
        else:
            gate = Stage2Gate(cfg.stage2, brand_keywords)

        p_defer = predictions[decisions == 1]
        df_defer = gate.select_segment_priority(df_defer, p_defer)

        # çµæœã‚’ãƒãƒ¼ã‚¸
        df_features.loc[df_defer.index, 'stage2_decision'] = df_defer['stage2_decision']

        handoff_count = (df_defer['stage2_decision'] == 'handoff').sum()
        print(f"âœ… Stage2 é¸æŠå®Œäº†:")
        print(f"   Handoff: {handoff_count:,}")

    # çµæœä¿å­˜
    output_path = args.output or f"{args.output_dir}/predictions_{run_id}.csv"
    df_features.to_csv(output_path, index=False)
    print(f"\nğŸ’¾ çµæœä¿å­˜: {output_path}")

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*80)
    print("âœ… äºˆæ¸¬å®Œäº†")
    print("="*80)
    return 0


def run_eval(args, cfg, run_id):
    """è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡"""
    print("\n" + "="*80)
    print("ğŸ“Š è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰")
    print("="*80)

    # TODO: Phase 2.1ã§å®Ÿè£…
    # - test_data.pklã‚’èª­ã¿è¾¼ã¿
    # - äºˆæ¸¬ã‚’å®Ÿè¡Œ
    # - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—ï¼ˆAUC, Precision, Recall, etc.ï¼‰
    # - Notebookã®çµæœã¨æ¯”è¼ƒ

    print("âš ï¸  Phase 2.1ã§å®Ÿè£…äºˆå®š")
    return 0


def run_train(args, cfg):
    """è¨“ç·´ãƒ¢ãƒ¼ãƒ‰: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
    print("\n" + "="*80)
    print("ğŸ“ è¨“ç·´ãƒ¢ãƒ¼ãƒ‰")
    print("="*80)

    # TODO: Phase 2.1ã§å®Ÿè£…
    # - ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    # - ç‰¹å¾´é‡æŠ½å‡º
    # - XGBoostè¨“ç·´
    # - Route1é–¾å€¤é¸æŠ
    # - ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    # - çµæœã®å‡ºåŠ›

    print("âš ï¸  Phase 2.1ã§å®Ÿè£…äºˆå®š")
    return 0


if __name__ == '__main__':
    sys.exit(main())
