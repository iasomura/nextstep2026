{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09461286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SET] N_SAMPLE= 500 N_BENIGN_SAMPLE= 500 N_BENIGN_HARD_SAMPLE= 500\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 0: å®Ÿé¨“ä»¶æ•°ã®è¨­å®šï¼ˆphish/random=100, benign=100, benign_hard=100ï¼‰\n",
    "# ============================================\n",
    "# [ChangeLog] 2025-12-15: N_* ã« ALL/0/-1 ã‚’æŒ‡å®šã™ã‚‹ã¨å…¨ä»¶å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µ\n",
    "\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# â–¼â–¼â–¼ ã“ã“ã ã‘ç·¨é›†ã™ã‚Œã°OKï¼ˆå„ªå…ˆåº¦: ç’°å¢ƒå¤‰æ•° > ã“ã“ï¼‰ â–¼â–¼â–¼\n",
    "#   - \"500\" ã®ã‚ˆã†ã«æ•°å€¤ â†’ ãã®ä»¶æ•°ã ã‘å‡¦ç†\n",
    "#   - \"ALL\" / 0 / -1     â†’ å…¨ä»¶å‡¦ç†ï¼ˆåˆ¶é™ãªã—ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "DEFAULT_N_SAMPLE = \"500\"\n",
    "DEFAULT_N_BENIGN_SAMPLE = DEFAULT_N_SAMPLE\n",
    "DEFAULT_N_BENIGN_HARD_SAMPLE = \"500\"\n",
    "\n",
    "def _normalize_n_env(key: str, default: str) -> str:\n",
    "    \"\"\"ç’°å¢ƒå¤‰æ•° N_* ã‚’æ­£è¦åŒ–ã—ã¦ os.environ ã«å…¥ã‚Œã‚‹ã€‚\n",
    "    - 1ä»¥ä¸Š: ãã®ä»¶æ•°ã‚’å‡¦ç†\n",
    "    - 0 / -1 / 'ALL' / '*' / 'FULL': å…¨ä»¶å‡¦ç†ï¼ˆåˆ¶é™ãªã—ï¼‰\n",
    "    \"\"\"\n",
    "    raw = os.getenv(key, default)\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # äººé–“å‘ã‘ã®æŒ‡å®šï¼ˆALL ç­‰ï¼‰â†’ æ•°å€¤ã‚»ãƒ³ãƒãƒãƒ«ã¸\n",
    "    if s.upper() in (\"ALL\", \"*\", \"FULL\"):\n",
    "        return \"-1\"\n",
    "\n",
    "    # æ•°å€¤åŒ–ï¼ˆå¤‰ãªå€¤ãªã‚‰ default ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "    try:\n",
    "        n = int(float(s))\n",
    "    except Exception:\n",
    "        try:\n",
    "            n = int(default)\n",
    "        except Exception:\n",
    "            n = -1\n",
    "    # â˜… 0 / è² å€¤ ã¯ ALL æ‰±ã„ï¼ˆ-1 ã«å¯„ã›ã‚‹ï¼‰\n",
    "    return \"-1\" if n <= 0 else str(n)\n",
    "def _n_label(n_str: str) -> str:\n",
    "    \"\"\"è¡¨ç¤ºç”¨: -1/0 ä»¥ä¸‹ã¯ ALL ã¨è¦‹ã›ã‚‹\"\"\"\n",
    "    try:\n",
    "        n = int(str(n_str).strip())\n",
    "    except Exception:\n",
    "        return str(n_str)\n",
    "    return \"ALL\" if n <= 0 else str(n)\n",
    "\n",
    "# 3ç¾¤ã®ä»¶æ•°\n",
    "os.environ[\"N_SAMPLE\"] = _normalize_n_env(\"N_SAMPLE\", DEFAULT_N_SAMPLE)\n",
    "os.environ[\"N_BENIGN_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_SAMPLE\", DEFAULT_N_BENIGN_SAMPLE)\n",
    "os.environ[\"N_BENIGN_HARD_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_HARD_SAMPLE\", DEFAULT_N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "print(\"[SET] N_SAMPLE=\", _n_label(os.environ[\"N_SAMPLE\"]),\n",
    "      \"N_BENIGN_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_SAMPLE\"]),\n",
    "      \"N_BENIGN_HARD_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_HARD_SAMPLE\"]),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed1e38e-e956-482d-b6f5-28796ade11b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N_SAMPLE=500, N_BENIGN_SAMPLE=500, RANDOM_STATE=42\n",
      "[NX] RUN_ID = 2026-01-10_140940 | paths.RUN_ID = 2026-01-10_140940\n",
      "[INFO] BASE_DIR      = /data/hdd/asomura/nextstep\n",
      "[INFO] RUN_ID        = 2026-01-10_140940\n",
      "[INFO] ARTIFACTS_DIR = artifacts/2026-01-10_140940\n",
      "[INFO] HANDOFF_DIR   = artifacts/2026-01-10_140940/handoff\n",
      "[OK] Handoff directory found: artifacts/2026-01-10_140940/handoff\n",
      "[WARN] Target pickle NOT found in this directory.\n",
      "[INFO] Current Timestamp: 2026-01-10_190841\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 1: ç’°å¢ƒè¨­å®šã¨åˆæœŸåŒ–ï¼ˆCell0æ–¹å¼ã§RUN_IDæ±ºå®šï¼‰\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "import datetime\n",
    "import run_id_registry as runreg\n",
    "import importlib\n",
    "import _compat.paths as paths\n",
    "# ---------------------------------------------------------\n",
    "# â–¼â–¼â–¼ Evaluation sample size (variable) â–¼â–¼â–¼\n",
    "# ---------------------------------------------------------\n",
    "N_SAMPLE = int(os.getenv(\"N_SAMPLE\", \"300\"))\n",
    "N_BENIGN_SAMPLE = int(os.getenv(\"N_BENIGN_SAMPLE\", str(N_SAMPLE)))\n",
    "RANDOM_STATE = int(os.getenv(\"RANDOM_STATE\", \"42\"))\n",
    "def _n_label(n: int) -> str:\n",
    "    return \"ALL\" if int(n) <= 0 else str(int(n))\n",
    "print(f\"[INFO] N_SAMPLE={_n_label(N_SAMPLE)}, N_BENIGN_SAMPLE={_n_label(N_BENIGN_SAMPLE)}, RANDOM_STATE={RANDOM_STATE}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæ¨å®š\n",
    "# ---------------------------------------------------------\n",
    "BASE_DIR = Path(os.environ.get(\"NEXTSTEP_BASE_DIR\", \".\")).resolve()\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# [ChangeLog] 2025-12-16: sys.path ã‹ã‚‰ BASE_DIR/phishing_agent ã‚’é™¤å»ï¼ˆé‡è¤‡ import ã‚’é˜²ãã€Phase6 wiring ã‚’ç¢ºå®ŸåŒ–ï¼‰\n",
    "# NOTE: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ import ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã€sys.path ã«ã¯ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ(BASE_DIR)ã€ã ã‘ã‚’å…¥ã‚Œã‚‹ã€‚\n",
    "#       BASE_DIR/phishing_agent ã‚’å…¥ã‚Œã‚‹ã¨ `langgraph_module` ãªã©ãŒãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ« import ã•ã‚Œã€\n",
    "#       `phishing_agent.langgraph_module` ã¨äºŒé‡ãƒ­ãƒ¼ãƒ‰ã«ãªã‚Š Phase6 ã®ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒãŒåŠ¹ã‹ãªã„ã“ã¨ãŒã‚ã‚‹ã€‚\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "# å¿µã®ãŸã‚èª¤ã£ãŸãƒ‘ã‚¹ã‚’æ¶ˆã™ï¼ˆå­˜åœ¨ã—ã¦ã„ã‚Œã°ï¼‰\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# â–¼â–¼â–¼ RUN_ID ã®æ±ºå®š: 02ä»¥é™å…±é€š Cell0 ã¨åŒã˜æ–¹å¼ â–¼â–¼â–¼\n",
    "#   rid = runreg.bootstrap()  # envâ†’run_id.txtâ†’Part3â†’latestâ†’æ–°è¦\n",
    "#   paths ã‚’ reload ã—ã¦ paths.RUN_ID ã‚’ç¢ºå®š\n",
    "#   rid ã¨ paths.RUN_ID ãŒã‚ºãƒ¬ãŸã‚‰å³æ¤œçŸ¥\n",
    "# ---------------------------------------------------------\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.bootstrap()  # ã“ã“ã§ env RUN_ID ã‚’ã‚»ãƒƒãƒˆã™ã‚‹æƒ³å®šï¼ˆå¿µã®ãŸã‚ä¸‹ã§æ˜ç¤ºä¸Šæ›¸ãï¼‰\n",
    "\n",
    "# å¿µã®ãŸã‚ env ã‚’ rid ã§å›ºå®šï¼ˆbootstrapãŒã‚»ãƒƒãƒˆã—ã¦ã„ã¦ã‚‚å®³ã¯ãªã„ï¼‰\n",
    "os.environ[\"RUN_ID\"] = rid\n",
    "\n",
    "# _compat.paths (ã¾ãŸã¯ paths) ã‚’èª­ã¿è¾¼ã¿ã€env(RUN_ID) ã‚’åæ˜ ã•ã›ã‚‹\n",
    "try:\n",
    "    import _compat.paths as paths\n",
    "except ImportError:\n",
    "    import paths as paths  # fallback\n",
    "\n",
    "importlib.reload(paths)  # Cell0æ–¹å¼ï¼ˆå¿…è¦ãªã‚‰2å›ã§ã‚‚å¯ã ãŒé€šå¸¸1å›ã§ååˆ†ï¼‰\n",
    "\n",
    "# ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼†ã‚ºãƒ¬æ¤œçŸ¥\n",
    "print(\"[NX] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n",
    "assert paths.RUN_ID == rid, f\"RUN_ID mismatch: rid={rid} paths.RUN_ID={paths.RUN_ID}\"\n",
    "\n",
    "# æœ€çµ‚æ¡ç”¨ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ±ºå®šã«ä½¿ã†ã®ã¯ paths.RUN_IDï¼‰\n",
    "RUN_ID = paths.RUN_ID\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# artifacts/<RUN_ID>/... é…ä¸‹ã®å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š\n",
    "# ---------------------------------------------------------\n",
    "ARTIFACTS_DIR = Path(paths.ARTIFACTS) if hasattr(paths, \"ARTIFACTS\") else (BASE_DIR / \"artifacts\" / RUN_ID)\n",
    "RAW_DIR       = Path(paths.compat_base_dirs[\"raw\"])\n",
    "PROCESSED_DIR = Path(paths.compat_base_dirs[\"data\"])\n",
    "MODELS_DIR    = Path(paths.compat_base_dirs[\"models\"])\n",
    "RESULTS_DIR   = Path(paths.compat_base_dirs[\"results\"])\n",
    "HANDOFF_DIR   = Path(paths.compat_base_dirs[\"handoff\"])\n",
    "LOGS_DIR      = Path(paths.compat_base_dirs[\"logs\"])\n",
    "TRACES_DIR    = Path(paths.compat_base_dirs[\"traces\"])\n",
    "\n",
    "print(f\"[INFO] BASE_DIR      = {BASE_DIR}\")\n",
    "print(f\"[INFO] RUN_ID        = {RUN_ID}\")\n",
    "print(f\"[INFO] ARTIFACTS_DIR = {ARTIFACTS_DIR}\")\n",
    "print(f\"[INFO] HANDOFF_DIR   = {HANDOFF_DIR}\")\n",
    "\n",
    "# Handoffãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª\n",
    "if HANDOFF_DIR.exists():\n",
    "    print(f\"[OK] Handoff directory found: {HANDOFF_DIR}\")\n",
    "    target_pkl = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "    if target_pkl.exists():\n",
    "        print(f\"[OK] Target pickle found: {target_pkl.name}\")\n",
    "    else:\n",
    "        print(f\"[WARN] Target pickle NOT found in this directory.\")\n",
    "else:\n",
    "    print(f\"[WARN] Handoff directory NOT found. Check RUN_ID logic.\")\n",
    "\n",
    "# å‡ºåŠ›ç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "print(f\"[INFO] Current Timestamp: {timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Handoff file not found: artifacts/2026-01-10_140940/handoff/04-3_llm_tools_setup_with_tools.pkl\n04-3_llm_tools_setup_with_tools ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ã€artifacts/<RUN_ID>/handoff é…ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m handoff_path = HANDOFF_DIR / \u001b[33m\"\u001b[39m\u001b[33m04-3_llm_tools_setup_with_tools.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handoff_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m     12\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHandoff file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhandoff_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m04-3_llm_tools_setup_with_tools ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ã€artifacts/<RUN_ID>/handoff é…ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(handoff_path, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m     external_data = pickle.load(f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Handoff file not found: artifacts/2026-01-10_140940/handoff/04-3_llm_tools_setup_with_tools.pkl\n04-3_llm_tools_setup_with_tools ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ã€artifacts/<RUN_ID>/handoff é…ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2: External Dataã®èª­ã¿è¾¼ã¿ã¨Brand Keywordsè£œå¼·\n",
    "# ============================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "# handoffã‹ã‚‰external_dataã‚’èª­ã¿è¾¼ã¿\n",
    "handoff_path = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "\n",
    "if not handoff_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Handoff file not found: {handoff_path}\\n\"\n",
    "        \"04-3_llm_tools_setup_with_tools ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ã€artifacts/<RUN_ID>/handoff é…ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚\"\n",
    "    )\n",
    "\n",
    "with open(handoff_path, 'rb') as f:\n",
    "    external_data = pickle.load(f)\n",
    "\n",
    "print(f\"[INFO] external_data loaded from: {handoff_path}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Brand Keywords è£œå¼·ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå…ƒãƒãƒ¼ãƒˆã®å‹•ä½œã‚’è¸è¥²ï¼‰\n",
    "# --------------------------------------------------\n",
    "\n",
    "# æ—¢å­˜ã® brand_keywords ã‚’å–å¾—ï¼ˆç„¡ã‘ã‚Œã°ç©ºãƒªã‚¹ãƒˆï¼‰\n",
    "brand_keywords = external_data.get(\"brand_keywords\") or []\n",
    "brands_lower = [b.lower() for b in brand_keywords]\n",
    "\n",
    "# è«–æ–‡ãƒ»å®Ÿé¨“ã§é‡è¦–ã—ãŸã„ãƒ–ãƒ©ãƒ³ãƒ‰ï¼ˆä¸è¶³ã—ã¦ã„ãŸã‚‚ã®ã‚’è£œã†ï¼‰\n",
    "essential_brands = [\n",
    "    \"mufg\", \"mufg-card\", \"mitsubishi-ufj\", \"ä¸‰è±UFJ\", \"ä¸‰è±ï¼µï¼¦ï¼ª\",\n",
    "    \"smbc\", \"smbc-card\", \"ä¸‰äº•ä½å‹ã‚«ãƒ¼ãƒ‰\", \"ä¸‰äº•ä½å‹éŠ€è¡Œ\",\n",
    "    \"rakuten\", \"rakuten-card\", \"æ¥½å¤©ã‚«ãƒ¼ãƒ‰\", \"æ¥½å¤©éŠ€è¡Œ\",\n",
    "    \"amazon\", \"amazon-jp\", \"amazon.co.jp\",\n",
    "    \"mercari\", \"ãƒ¡ãƒ«ã‚«ãƒª\",\n",
    "    \"metamask\", \"binance\", \"bybit\",\n",
    "    # â–¼â–¼â–¼ è¿½åŠ åˆ† â–¼â–¼â–¼\n",
    "    \"sbi\", \"sbisec\", \"sumishin\", \"ä½ä¿¡SBI\",\n",
    "    \"telegram\", \"tg\",\n",
    "    \"makuake\",\n",
    "    \"aeon\", \"aeonbank\", \"ã‚¤ã‚ªãƒ³éŠ€è¡Œ\",\n",
    "    \"jcb\",\n",
    "    \"imad\"\n",
    "]\n",
    "\n",
    "added_brands = []\n",
    "for brand in essential_brands:\n",
    "    if brand.lower() not in brands_lower:\n",
    "        external_data.setdefault('brand_keywords', []).append(brand)\n",
    "        added_brands.append(brand)\n",
    "        brands_lower.append(brand.lower())\n",
    "\n",
    "print(f\"[INFO] Added {len(added_brands)} new brands\")\n",
    "print(f\"[INFO] Total brand_keywords: {len(external_data['brand_keywords'])}\")\n",
    "\n",
    "# ä¸»è¦ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç¢ºèªè¡¨ç¤º\n",
    "check_brands = [\"mufg\", \"smbc\", \"amazon\", \"mercari\", \"rakuten\", \"metamask\"]\n",
    "print(\"\\n[Brand Check]\")\n",
    "for brand in check_brands:\n",
    "    exists = brand in [b.lower() for b in external_data['brand_keywords']]\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"  {brand:15} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed7391-2b52-48c6-8074-709de2e26a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 2ã®æœ€å¾Œã«è¿½åŠ : 04-2ã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œ\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Loading additional data from 04-2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 04-2ã®ãƒ‘ã‚¹ã‚’æ¢ç´¢\n",
    "pickle_04_2_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "]\n",
    "\n",
    "data_04_2 = None\n",
    "for path in pickle_04_2_paths:\n",
    "    if path.exists():\n",
    "        print(f\"[INFO] Found 04-2 at: {path}\")\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                data_04_2 = pickle.load(f)\n",
    "            print(f\"[INFO] 04-2 loaded successfully\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {path}: {e}\")\n",
    "\n",
    "if data_04_2 is None:\n",
    "    print(\"[WARN] 04-2 not found, continuing with available data\")\n",
    "else:\n",
    "    print(f\"[INFO] 04-2 keys: {list(data_04_2.keys())[:10]}...\")\n",
    "    \n",
    "    # TLDé–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "    tld_keys = [\n",
    "        'dangerous_tlds', 'DANGEROUS_TLDS',\n",
    "        'legitimate_tlds', 'LEGITIMATE_TLDS',\n",
    "        'neutral_tlds', 'NEUTRAL_TLDS',\n",
    "        'phishing_tld_stats', 'TLD_STATS', 'tld_stats'\n",
    "    ]\n",
    "    \n",
    "    added_count = 0\n",
    "    for key in tld_keys:\n",
    "        if key in data_04_2:\n",
    "            # æ¨™æº–åŒ–ã•ã‚ŒãŸã‚­ãƒ¼åã«ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "            standard_key = key.lower()\n",
    "            if 'dangerous' in standard_key:\n",
    "                target_key = 'dangerous_tlds'\n",
    "            elif 'legitimate' in standard_key:\n",
    "                target_key = 'legitimate_tlds'\n",
    "            elif 'neutral' in standard_key:\n",
    "                target_key = 'neutral_tlds'\n",
    "            elif 'tld' in standard_key and 'stat' in standard_key:\n",
    "                target_key = 'phishing_tld_stats'\n",
    "            else:\n",
    "                target_key = key\n",
    "            \n",
    "            if target_key not in external_data:\n",
    "                external_data[target_key] = data_04_2[key]\n",
    "                value = data_04_2[key]\n",
    "                size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "                print(f\"  âœ… Added {target_key}: {type(value).__name__} (len={size})\")\n",
    "                added_count += 1\n",
    "    \n",
    "    # High Risk Words ã‚’è¿½åŠ \n",
    "    hrw_keys = ['HIGH_RISK_WORDS', 'high_risk_words', 'high_risk']\n",
    "    for key in hrw_keys:\n",
    "        if key in data_04_2 and 'high_risk_words' not in external_data:\n",
    "            external_data['high_risk_words'] = data_04_2[key]\n",
    "            words = data_04_2[key]\n",
    "            print(f\"  âœ… Added high_risk_words: {type(words).__name__} (len={len(words)})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    # Known Domains ã‚’è¿½åŠ \n",
    "    kd_keys = ['KNOWN_DOMAINS', 'known_domains', 'legitimate_domains']\n",
    "    for key in kd_keys:\n",
    "        if key in data_04_2 and 'known_domains' not in external_data:\n",
    "            external_data['known_domains'] = data_04_2[key]\n",
    "            domains = data_04_2[key]\n",
    "            size = len(domains) if hasattr(domains, '__len__') else 'N/A'\n",
    "            print(f\"  âœ… Added known_domains: {type(domains).__name__} (len={size})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n[INFO] Added {added_count} data items from 04-2\")\n",
    "\n",
    "# æœ€çµ‚ç¢ºèª\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Final Data Availability Check\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "required_keys = {\n",
    "    'brand_keywords': 'Brand keywords list',\n",
    "    'cert_full_info_map': 'Certificate information',\n",
    "    'dangerous_tlds': 'Dangerous TLDs',\n",
    "    'legitimate_tlds': 'Legitimate TLDs',\n",
    "    'neutral_tlds': 'Neutral TLDs',\n",
    "    'phishing_tld_stats': 'TLD phishing statistics',\n",
    "    'high_risk_words': 'High risk words',\n",
    "    'known_domains': 'Known legitimate domains'\n",
    "}\n",
    "\n",
    "for key, description in required_keys.items():\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "        print(f\"  âœ… {description:30} (len={size})\")\n",
    "    else:\n",
    "        print(f\"  âŒ {description:30} NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell X: External Data ã®å–å¾—å…ƒã¨å†…å®¹ã‚µãƒãƒªï¼ˆå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼‰\n",
    "# ============================================\n",
    "\n",
    "# ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ã† external_data ã¯ã€åŸå‰‡ã“ã“ã¾ã§ã§ä»¥ä¸‹ã‹ã‚‰æ§‹ç¯‰ã•ã‚Œã¾ã™ï¼š\n",
    "#   1) artifacts/<RUN_ID>/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
    "#   2) (ä¸è¶³åˆ†ãŒã‚ã‚‹å ´åˆ) artifacts/<RUN_ID>/handoff/04-2_statistical_analysis.pkl\n",
    "# ãã®å¾Œã€(å¿…è¦ã«å¿œã˜ã¦) brand_keywords ã‚’è£œå¼·ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[External Data Summary]\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "required = [\n",
    "    'brand_keywords',\n",
    "    'cert_full_info_map',\n",
    "    'dangerous_tlds',\n",
    "    'legitimate_tlds',\n",
    "    'neutral_tlds',\n",
    "    'phishing_tld_stats',\n",
    "    'high_risk_words',\n",
    "    'known_domains',\n",
    "]\n",
    "\n",
    "src_hint = {\n",
    "    '04-3': str(HANDOFF_DIR / '04-3_llm_tools_setup_with_tools.pkl'),\n",
    "    '04-2': str(HANDOFF_DIR / '04-2_statistical_analysis.pkl'),\n",
    "}\n",
    "print(\"[INFO] Expected sources:\")\n",
    "pprint(src_hint)\n",
    "\n",
    "missing = [k for k in required if k not in (external_data or {})]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Missing keys in external_data:\")\n",
    "    pprint(missing)\n",
    "else:\n",
    "    print(\"\\n[OK] All required keys exist.\")\n",
    "\n",
    "def _len(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except Exception:\n",
    "        return 'N/A'\n",
    "\n",
    "print(\"\\n[Counts]\")\n",
    "for k in required:\n",
    "    v = (external_data or {}).get(k)\n",
    "    print(f\"  {k:18} : {type(v).__name__:<12} len={_len(v)}\")\n",
    "\n",
    "# None/å‹ã‚†ã‚‰ãå¯¾ç­–: external_data ã® *tlds ãŒ None ã®å ´åˆãŒã‚ã‚‹\n",
    "def _as_list(v):\n",
    "    if v is None:\n",
    "        return []\n",
    "    if isinstance(v, str):\n",
    "        return [v]\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        return list(v)\n",
    "    # pandas Series / numpy array ç­‰\n",
    "    try:\n",
    "        return list(v)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# TLD ã‚»ãƒƒãƒˆã®äº¤å·®ãƒã‚§ãƒƒã‚¯ï¼ˆ.com ãŒ dangerous ã«æ··å…¥ã™ã‚‹ã¨ FP/FN åˆ†æãŒå£Šã‚Œã‚„ã™ã„ï¼‰\n",
    "D = {str(x).lower() for x in _as_list((external_data or {}).get('dangerous_tlds'))}\n",
    "L = {str(x).lower() for x in _as_list((external_data or {}).get('legitimate_tlds'))}\n",
    "N = {str(x).lower() for x in _as_list((external_data or {}).get('neutral_tlds'))}\n",
    "\n",
    "print(\"\\n[TLD Sanity]\")\n",
    "if 'com' in D:\n",
    "    print(\"  âŒ WARNING: 'com' is inside dangerous_tlds. This will over-fire dangerous_tld for normal domains.\")\n",
    "else:\n",
    "    print(\"  âœ… OK: 'com' is NOT in dangerous_tlds.\")\n",
    "\n",
    "overlap_DL = sorted(D & L)\n",
    "overlap_DN = sorted(D & N)\n",
    "overlap_LN = sorted(L & N)\n",
    "if overlap_DL or overlap_DN or overlap_LN:\n",
    "    print(\"  âš  Overlaps found (should ideally be empty):\")\n",
    "    if overlap_DL: print(\"    - dangerous âˆ© legitimate:\", overlap_DL[:20], \"...\" if len(overlap_DL)>20 else \"\")\n",
    "    if overlap_DN: print(\"    - dangerous âˆ© neutral   :\", overlap_DN[:20], \"...\" if len(overlap_DN)>20 else \"\")\n",
    "    if overlap_LN: print(\"    - legitimate âˆ© neutral  :\", overlap_LN[:20], \"...\" if len(overlap_LN)>20 else \"\")\n",
    "else:\n",
    "    print(\"  âœ… OK: No overlaps between dangerous/legitimate/neutral TLD sets.\")\n",
    "\n",
    "print(\"\\n[Known Domains Note]\")\n",
    "kd = (external_data or {}).get('known_domains', {})\n",
    "sample_items = list(kd.items())[:5] if isinstance(kd, dict) else []\n",
    "print(f\"  known_domains type={type(kd).__name__}, sample={sample_items}\")\n",
    "print(\"  NOTE: If known_domains is a 'seen list' (not a strict whitelist), it should NOT be used for safety mitigation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 3: Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆä»¶æ•°=N_SAMPLEï¼‰\n",
    "# ============================================\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "def _search_eval_df(obj):\n",
    "    '''dict/list å†å¸°ã§ DataFrame ã‚’æ¢ã™'''\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        # ã‚ˆãã‚ã‚‹ã‚­ãƒ¼ç›´å‚ç…§\n",
    "        for k in (\"false_negatives_df\", \"fn_df\", \"eval_df\", \"random_eval_df\"):\n",
    "            v = obj.get(k)\n",
    "            if isinstance(v, pd.DataFrame):\n",
    "                return v\n",
    "        for v in obj.values():\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    return None\n",
    "\n",
    "def _normalize_eval_df(df):\n",
    "    '''åˆ—åã®æºã‚Œã«å¯¾å¿œã—ã¦ domain, ml_probability ã®2åˆ—ã«æ­£è¦åŒ–'''\n",
    "    print(\"[DEBUG] columns:\", list(df.columns))\n",
    "    \n",
    "    # lower â†’ å…ƒåã®ãƒãƒƒãƒ—\n",
    "    lower2orig = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # 1) domainå€™è£œ\n",
    "    domain_candidates = [\"domain\", \"fqdn\", \"domain_name\", \"hostname\", \"host\", \"requested_host\"]\n",
    "    domain_key = None\n",
    "    for key in domain_candidates:\n",
    "        if key in lower2orig:\n",
    "            domain_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if domain_key is None:\n",
    "        # éƒ¨åˆ†ä¸€è‡´\n",
    "        for c in df.columns:\n",
    "            if any(kw in c.lower() for kw in [\"domain\", \"fqdn\", \"host\", \"url\"]):\n",
    "                domain_key = c\n",
    "                print(f\"[DEBUG] domain fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    # 2) ml_probabilityå€™è£œ\n",
    "    ml_candidates = [\"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\", \n",
    "                     \"score\", \"pred_proba\", \"proba\", \"confidence\"]\n",
    "    mlp_key = None\n",
    "    for key in ml_candidates:\n",
    "        if key in lower2orig:\n",
    "            mlp_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if mlp_key is None:\n",
    "        # floatã‚«ãƒ©ãƒ ã‹ã‚‰æ¨æ¸¬\n",
    "        float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "        for c in float_cols:\n",
    "            if any(kw in c.lower() for kw in [\"prob\", \"score\", \"pred\"]):\n",
    "                mlp_key = c\n",
    "                print(f\"[DEBUG] ml_probability fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    if domain_key is None or mlp_key is None:\n",
    "        print(\"[ERROR] could not infer domain/ml_probability columns\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"[DEBUG] chosen columns: domain={domain_key}, ml_prob={mlp_key}\")\n",
    "    \n",
    "    tmp = df[[domain_key, mlp_key]].copy()\n",
    "    tmp.columns = [\"domain\", \"ml_probability\"]\n",
    "    \n",
    "    # urlâ†’domainã®æ­£è¦åŒ–\n",
    "    if \"url\" in domain_key.lower():\n",
    "        def _to_domain(x):\n",
    "            if not isinstance(x, str):\n",
    "                return \"\"\n",
    "            if \"://\" in x:\n",
    "                netloc = urlparse(x).netloc\n",
    "            else:\n",
    "                netloc = x\n",
    "            netloc = netloc.split(\"@\")[-1].split(\":\")[0]\n",
    "            return netloc.lower()\n",
    "        tmp[\"domain\"] = tmp[\"domain\"].map(_to_domain)\n",
    "    \n",
    "    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "    tmp[\"domain\"] = tmp[\"domain\"].astype(str).str.strip().str.lower()\n",
    "    tmp = tmp[tmp[\"domain\"].str.len() > 0]\n",
    "    tmp[\"ml_probability\"] = pd.to_numeric(tmp[\"ml_probability\"], errors=\"coerce\")\n",
    "    tmp = tmp[(tmp[\"ml_probability\"] >= 0.0) & (tmp[\"ml_probability\"] <= 1.0)]\n",
    "    tmp = tmp.dropna(subset=[\"ml_probability\"]).reset_index(drop=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "def get_random_domains(sample_size=None):\n",
    "    '''Randomã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆä»¶æ•°=sample_sizeï¼‰'''\n",
    "    if sample_size is None:\n",
    "        sample_size = N_SAMPLE\n",
    "    sample_size = int(sample_size)\n",
    "    \n",
    "    # æ–¹æ³•1: æ—¢å­˜ã®CSVã‹ã‚‰\n",
    "    csv_paths = [\n",
    "    LOGS_DIR / \"random_eval_domains_latest.csv\",\n",
    "]\n",
    "    \n",
    "    for csv_path in csv_paths:\n",
    "        if csv_path.exists():\n",
    "            print(f\"[INFO] Loading existing CSV from: {csv_path}\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "            # ALL æŒ‡å®šï¼ˆ0/-1ï¼‰ãªã‚‰ã€æ—¢å­˜CSVãŒéƒ¨åˆ†ã‚µãƒ³ãƒ—ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ pickle ã‹ã‚‰å†ç”Ÿæˆã™ã‚‹\n",
    "            if sample_size <= 0:\n",
    "                print(f\"[INFO] sample_size={sample_size} (ALL) requested; ignore cache and regenerate from pickle...\")\n",
    "                break\n",
    "            # æ—¢å­˜CSVãŒè¦æ±‚ä»¶æ•°ã¨ä¸€è‡´ã™ã‚‹ãªã‚‰ãã®ã¾ã¾ä½¿ã†ã€‚\n",
    "            # ã‚‚ã—ä»¶æ•°ãŒé•ã†å ´åˆã¯ã€pickle ã‹ã‚‰å†ç”Ÿæˆã™ã‚‹ï¼ˆå¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´ã¾ãªã„ãŸã‚ï¼‰ã€‚\n",
    "            if (sample_size > 0) and (len(df) == sample_size):\n",
    "                return df\n",
    "\n",
    "            if (sample_size > 0) and (len(df) > sample_size):\n",
    "                print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; downsampling.\")\n",
    "                return df.sample(n=sample_size, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "            print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; regenerating from pickle...\")\n",
    "            break\n",
    "    \n",
    "    # æ–¹æ³•2: pickleã‹ã‚‰ç”Ÿæˆï¼ˆå…ƒã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰\n",
    "    print(\"[INFO] CSV not found, generating from pickle...\")\n",
    "    \n",
    "    pickle_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "    HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\",\n",
    "]\n",
    "    \n",
    "    eval_source_df = None\n",
    "    for pickle_path in pickle_paths:\n",
    "        if not pickle_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"[INFO] Trying: {pickle_path}\")\n",
    "        try:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                obj = pickle.load(f)\n",
    "            \n",
    "            # DataFrameã‚’æ¢ã™\n",
    "            raw_df = _search_eval_df(obj)\n",
    "            if raw_df is not None and len(raw_df) > 0:\n",
    "                print(f\"[INFO] Found DataFrame with {len(raw_df)} rows\")\n",
    "                eval_source_df = raw_df\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {pickle_path}: {e}\")\n",
    "    \n",
    "    if eval_source_df is None:\n",
    "        raise RuntimeError(\n",
    "            \"è©•ä¾¡ç”¨DataFrameãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\\n\"\n",
    "            \"04-2 ã¾ãŸã¯ 04-3 ã®pickleãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\"\n",
    "        )\n",
    "    \n",
    "    # æ­£è¦åŒ–\n",
    "    norm_df = _normalize_eval_df(eval_source_df)\n",
    "    if norm_df is None:\n",
    "        raise RuntimeError(\"DataFrameã®æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "    \n",
    "    print(f\"[INFO] Source rows (normalized): {len(norm_df)}\")\n",
    "    \n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå…ƒã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å›ºå®šã‚·ãƒ¼ãƒ‰ãªã—ï¼‰\n",
    "    # [ChangeLog] 2025-12-15: sample_size<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’è¿”ã™\n",
    "    if sample_size <= 0:\n",
    "        sample_n = len(norm_df)\n",
    "        # å…¨ä»¶å‡¦ç†ã®ã¨ãã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã›ãšã€ãã®ã¾ã¾ï¼ˆå†ç¾æ€§ãƒ»é€Ÿåº¦å„ªå…ˆï¼‰\n",
    "        sample_df = norm_df.reset_index(drop=True)\n",
    "    else:\n",
    "        sample_n = min(sample_size, len(norm_df))\n",
    "        sample_df = norm_df.sample(n=sample_n).reset_index(drop=True)\n",
    "    \n",
    "    # CSVä¿å­˜\n",
    "    out_csv = LOGS_DIR / \"random_eval_domains_latest.csv\"\n",
    "    LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    sample_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Random sample saved to: {out_csv} (n={sample_n})\")\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "# Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "target_df = get_random_domains(sample_size=N_SAMPLE)\n",
    "print(f\"[INFO] Target sample loaded: {len(target_df)} domains (N_SAMPLE={N_SAMPLE})\")\n",
    "print(target_df.head())\n",
    "\n",
    "# MLç¢ºç‡ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "print(f\"\\n[ML Probability Distribution]\")\n",
    "print(f\"  Min:    {target_df['ml_probability'].min():.3f}\")\n",
    "print(f\"  Max:    {target_df['ml_probability'].max():.3f}\")\n",
    "print(f\"  Mean:   {target_df['ml_probability'].mean():.3f}\")\n",
    "print(f\"  Median: {target_df['ml_probability'].median():.3f}\")\n",
    "\n",
    "# é«˜ãƒªã‚¹ã‚¯ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆMLç¢ºç‡ > 0.4ï¼‰ã®æ•°\n",
    "high_risk = target_df[target_df['ml_probability'] > 0.4]\n",
    "print(f\"  High risk (>0.4): {len(high_risk)} domains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87892f-5ae4-45c1-acd1-b8e29dfbce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 4: LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚µãƒ³ãƒ—ãƒ«ç”¨ãƒ»LLMå¿…é ˆç‰ˆ, configèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰\n",
    "# ============================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ç’°å¢ƒè¨­å®š\n",
    "os.chdir(BASE_DIR)\n",
    "# [ChangeLog] 2025-12-16: sys.path ã‚’æ•´ç†ï¼ˆPhase6 wiring ã®äºŒé‡ import å•é¡Œã‚’å›é¿ï¼‰\n",
    "# NOTE: sys.path ã«ã¯ BASE_DIR ã®ã¿ã‚’å…¥ã‚Œã¦ package import ã‚’çµ±ä¸€ã™ã‚‹ã€‚\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT INITIALIZATION WITH LLM (MANDATORY, READ-ONLY CONFIG)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. _compat/config.json ã‹ã‚‰ LLM è¨­å®šã‚’èª­ã‚€ï¼ˆâ€»æ›¸ãæ›ãˆãªã„ï¼‰\n",
    "print(\"\\n[1] Loading LLM Configuration from _compat/config.json\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cfg_path = BASE_DIR / \"_compat\" / \"config.json\"\n",
    "cfg_json = {}\n",
    "llm_cfg = {}\n",
    "\n",
    "if not cfg_path.exists():\n",
    "    print(f\"âŒ config.json not found at {cfg_path}\")\n",
    "else:\n",
    "    try:\n",
    "        with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg_json = json.load(f)\n",
    "        llm_cfg = (cfg_json.get(\"llm\") or {})\n",
    "        print(f\"âœ… Loaded config.json from {cfg_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load config.json: {e}\")\n",
    "        cfg_json = {}\n",
    "        llm_cfg = {}\n",
    "\n",
    "# LLMè¨­å®šã®ã‚µãƒãƒªè¡¨ç¤º\n",
    "if not llm_cfg:\n",
    "    print(\"âŒ 'llm' section not found in config.json\")\n",
    "else:\n",
    "    provider   = llm_cfg.get(\"provider\")\n",
    "    base_url   = (\n",
    "        llm_cfg.get(\"base_url\")\n",
    "        or llm_cfg.get(\"vllm_base_url\")\n",
    "        or llm_cfg.get(\"ollama_base_url\")\n",
    "    )\n",
    "    model      = (\n",
    "        llm_cfg.get(\"model\")\n",
    "        or llm_cfg.get(\"vllm_model\")\n",
    "        or llm_cfg.get(\"ollama_model\")\n",
    "    )\n",
    "    enabled    = bool(llm_cfg.get(\"enabled\", False))\n",
    "    temperature = llm_cfg.get(\"temperature\", 0.1)\n",
    "\n",
    "    print(\"LLM config overview:\")\n",
    "    print(f\"  enabled   : {enabled}\")\n",
    "    print(f\"  provider  : {provider}\")\n",
    "    print(f\"  base_url  : {base_url}\")\n",
    "    print(f\"  model     : {model}\")\n",
    "    print(f\"  temperature: {temperature}\")\n",
    "\n",
    "    if not enabled:\n",
    "        print(\"âš  LLM is disabled in config.json (llm.enabled=False)\")\n",
    "    if not base_url:\n",
    "        print(\"âš  llm.base_url / vllm_base_url / ollama_base_url is not set\")\n",
    "    if not model:\n",
    "        print(\"âš  llm.model / vllm_model / ollama_model is not set\")\n",
    "\n",
    "# external_data ã«ã‚‚ cfg ã‚’å…¥ã‚Œã¦ãŠãï¼ˆèª­ã¿å–ã‚Šçµæœã ã‘åæ˜ ï¼‰\n",
    "if \"external_data\" not in globals():\n",
    "    external_data = {}\n",
    "external_data.setdefault(\"cfg\", {})\n",
    "external_data[\"cfg\"][\"llm\"] = llm_cfg\n",
    "\n",
    "# 2. OPENAI_API_KEY ã®è¨­å®šï¼ˆvLLMã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ã§OKï¼‰\n",
    "print(\"\\n[2] Setting OPENAI_API_KEY (dummy for vLLM / Ollama)\")\n",
    "print(\"-\" * 40)\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = llm_cfg.get(\"api_key\") or \"dummy-key-for-local-llm\"\n",
    "    print(\"âœ… OPENAI_API_KEY set (dummy or from config)\")\n",
    "else:\n",
    "    print(\"â„¹ OPENAI_API_KEY already set in environment\")\n",
    "\n",
    "# 3. phishpkg/æ—§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "print(\"\\n[3] Clearing legacy 'phishpkg' modules (if any)\")\n",
    "print(\"-\" * 40)\n",
    "removed = 0\n",
    "for key in list(sys.modules.keys()):\n",
    "    if key.startswith(\"phishpkg\"):\n",
    "        del sys.modules[key]\n",
    "        removed += 1\n",
    "print(f\"âœ… Removed {removed} phishpkg modules from sys.modules\")\n",
    "\n",
    "# 4. Phase6 é…ç·šï¼ˆLLMå¿…é ˆãƒ¢ãƒ¼ãƒ‰ï¼fake_llm=Falseï¼‰\n",
    "print(\"\\n[4] Wiring Phase6 (LLM required, using config.json)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from phishing_agent.phase6_wiring import wire_phase6\n",
    "\n",
    "    # CONFIG_JSON ã‚’æ˜ç¤ºã—ã¦ãŠãã¨å®‰å…¨\n",
    "    cfg_env_path = str(cfg_path)\n",
    "    os.environ[\"CONFIG_JSON\"] = cfg_env_path\n",
    "\n",
    "    # prefer_compat=True: _compat/config.json ã‚’å„ªå…ˆ\n",
    "    # fake_llm=False    : å®Ÿéš›ã® LLM ã‚’ä½¿ã†å‰æï¼ˆå¤±æ•—æ™‚ã¯ä¾‹å¤– or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯phase6_wiringå´ãƒ«ãƒ¼ãƒ«ï¼‰\n",
    "    wire_phase6(prefer_compat=True, fake_llm=False)\n",
    "    print(\"âœ… Phase6 wired with real LLM (using config.json)\")\n",
    "\n",
    "    # [ChangeLog] 2025-12-16: ã©ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹æ˜ç¤ºï¼ˆå–ã‚Šé•ãˆé˜²æ­¢ï¼‰\n",
    "    import phishing_agent.phase6_wiring as _p6w\n",
    "    import phishing_agent.langgraph_module as _l4\n",
    "    import inspect as _inspect\n",
    "    print(f\"  phase6_wiring.__file__      = {_p6w.__file__}\")\n",
    "    print(f\"  langgraph_module.__file__   = {_l4.__file__}\")\n",
    "    try:\n",
    "        _fd = _l4.LangGraphPhishingAgent._final_decision_node\n",
    "        print(f\"  final_decision_node.module  = {_fd.__module__}\")\n",
    "        print(f\"  final_decision_node.file    = {_inspect.getsourcefile(_fd)}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  (warn) could not introspect final_decision_node: {_e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Phase6 wiring failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# 5. LangGraph ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "print(\"\\n[5] Importing LangGraphPhishingAgent\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from phishing_agent.langgraph_module import LangGraphPhishingAgent\n",
    "\n",
    "print(\"âœ… LangGraphPhishingAgent imported\")\n",
    "\n",
    "# 6. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆuse_llm_decision=True ãŒè¶…é‡è¦ï¼‰\n",
    "print(\"\\n[6] Initializing Agent (LLM mandatory, config-driven)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "agent = LangGraphPhishingAgent(\n",
    "    strict_mode=True,              # Graphå…¨ä½“ã¨ã—ã¦ã¯ strict=Falseï¼ˆPhase6å´ã§SOã¯strictã«ã—ã¦OKï¼‰\n",
    "    use_llm_selection=True,\n",
    "    use_llm_decision=True,          # â˜… final_decision ã§å¿…ãš LLM çµŒè·¯ã‚’è©¦ã™\n",
    "    config_path=str(cfg_path),\n",
    "    external_data=external_data,\n",
    ")\n",
    "print(\"âœ… Agent initialized\")\n",
    "\n",
    "# 7. å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆï¼ˆLLMãƒ‘ã‚¹ï¼debug_llm_final ã®ç¢ºèªï¼‰\n",
    "print(\"\\n[7] Quick Verification Test (single domain)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "import time\n",
    "\n",
    "test_domain = \"test-amazon.com\"\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    result = agent.evaluate(test_domain, 0.35)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    print(f\"Test domain         : {test_domain}\")\n",
    "    print(f\"  Time              : {elapsed:.2f}s\")\n",
    "    print(f\"  success           : {result.get('success')}\")\n",
    "    print(f\"  ai_is_phishing    : {result.get('ai_is_phishing')}\")\n",
    "    print(f\"  ai_confidence     : {result.get('ai_confidence')}\")\n",
    "    print(f\"  ai_risk_level     : {result.get('ai_risk_level')}\")\n",
    "\n",
    "    gs = result.get(\"graph_state\") or {}\n",
    "    dbg = gs.get(\"debug_llm_final\") or {}\n",
    "    print(f\"  debug_llm_final   : {dbg}\")\n",
    "\n",
    "    # [ChangeLog] 2025-12-16: Phase6ã®æœ‰åŠ¹åŒ–ã‚’ã€Œç¢ºå®Ÿã«ã€æ¤œè¨¼ï¼ˆPhase4ã§ã‚‚ path==\"llm\" ã¯èµ·ã“ã‚Šå¾—ã‚‹ï¼‰\n",
    "    p6v = gs.get(\"phase6_policy_version\")\n",
    "    dt  = gs.get(\"decision_trace\") or []\n",
    "    print(f\"  phase6_policy_version: {p6v}\")\n",
    "    try:\n",
    "        _dt_len = len(dt) if isinstance(dt, list) else None\n",
    "    except Exception:\n",
    "        _dt_len = None\n",
    "    print(f\"  decision_trace_len    : {_dt_len}\")\n",
    "\n",
    "    if not p6v:\n",
    "        raise RuntimeError(\n",
    "            \"Phase6 is NOT active: graph_state.phase6_policy_version is missing. \"\n",
    "            \"Check sys.path/imports and ensure phase6_wiring is applied before agent init.\"\n",
    "        )\n",
    "\n",
    "    path = dbg.get(\"path\")\n",
    "    if path == \"llm\" and dbg.get(\"success\") is True:\n",
    "        print(\"  âœ… Phase6 LLM path is active (path='llm')\")\n",
    "    elif path == \"fallback\":\n",
    "        print(\"  âš  Phase6 LLM failed; fallback path used (path='fallback')\")\n",
    "    else:\n",
    "        print(\"  â„¹ Phase6 LLM path status is unclear (see debug_llm_final above)\")\n",
    "\n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"  âŒ Test failed after {elapsed:.2f}s: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGENT READY FOR EVALUATION (LLM MANDATORY, CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ… LLM: Loaded from _compat/config.json\")\n",
    "print(\"âœ… Phase6: wired (LLMçµŒè·¯ã‚ã‚Šã€fallbackã¯phase6_wiringå´ãƒ­ã‚¸ãƒƒã‚¯ã«ä¾å­˜)\")\n",
    "print(\"âœ… Agent: Initialized\")\n",
    "print(\"\\nProceed to Cell 5 for RandomSample evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6dd56-b783-442f-a0d7-5178c741ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 4.6: TLDãƒªã‚¹ãƒˆã®å‹•çš„ç”Ÿæˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æç‰ˆï¼‰\n",
    "# â€» DBæ¥ç¶šå¿…é ˆã€‚å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†ã—ã¾ã™ã€‚\n",
    "# ============================================\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ”§ Generating TLD data from Database Analysis...\")\n",
    "\n",
    "# 03_ai_agent_analysis.ipynb ã‹ã‚‰ã® DBè¨­å®š\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# TLDæŠ½å‡ºé–¢æ•° (03ã‹ã‚‰ã®ç§»æ¤)\n",
    "def extract_tld(domain):\n",
    "    \"\"\"ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰TLDã‚’æŠ½å‡º\"\"\"\n",
    "    if not domain:\n",
    "        return None\n",
    "    # URLã®å ´åˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†ã‚’æŠ½å‡º\n",
    "    if '://' in domain:\n",
    "        try:\n",
    "            parsed = urlparse(domain)\n",
    "            domain = parsed.netloc\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # ãƒãƒ¼ãƒˆç•ªå·ã‚’å‰Šé™¤\n",
    "    domain = str(domain).split(':')[0]\n",
    "    \n",
    "    parts = domain.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        # .co.jp, .ac.jp ãªã©ã®è¤‡åˆTLDå¯¾å¿œ\n",
    "        if len(parts) >= 3 and parts[-2] in ['co', 'ac', 'or', 'ne', 'go']:\n",
    "            return f'.{parts[-2]}.{parts[-1]}'\n",
    "        else:\n",
    "            return f'.{parts[-1]}'\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
    "    print(f\"  ğŸ”Œ Connecting to database: {DB_CONFIG['dbname']} at {DB_CONFIG['host']}...\")\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    print(\"  âœ… Database connected successfully\")\n",
    "\n",
    "    # 1. ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã‚µã‚¤ãƒˆã®å–å¾— (å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰)\n",
    "    print(\"  ğŸ“Š Analyzing phishing domains...\")\n",
    "    phishing_queries = [\n",
    "        \"SELECT cert_domain as domain FROM phishtank_entries WHERE cert_status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM jpcert_phishing_urls WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\"\n",
    "    ]\n",
    "    \n",
    "    phishing_domains = []\n",
    "    for query in phishing_queries:\n",
    "        cur.execute(query)\n",
    "        results = cur.fetchall()\n",
    "        for row in results:\n",
    "            if row['domain']: phishing_domains.append(row['domain'])\n",
    "            \n",
    "    if not phishing_domains:\n",
    "        raise ValueError(\"No phishing domains found in database. Analysis cannot proceed.\")\n",
    "\n",
    "    # 2. æ­£å¸¸ã‚µã‚¤ãƒˆã®å–å¾—\n",
    "    print(\"  ğŸ“Š Analyzing trusted domains...\")\n",
    "    cur.execute(\"SELECT domain FROM trusted_certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\")\n",
    "    results = cur.fetchall()\n",
    "    trusted_domains = [row['domain'] for row in results if row['domain']]\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    # 3. ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ (03ã¨åŒæ§˜ã®ãƒ­ã‚¸ãƒƒã‚¯)\n",
    "    # é‡è¤‡é™¤å»\n",
    "    phishing_domains_unique = list(set(phishing_domains))\n",
    "    trusted_domains_unique = list(set(trusted_domains))\n",
    "    \n",
    "    print(f\"    - Phishing unique: {len(phishing_domains_unique)}\")\n",
    "    print(f\"    - Trusted unique: {len(trusted_domains_unique)}\")\n",
    "    \n",
    "    # å°‘ãªã„æ–¹ã«åˆã‚ã›ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "    random.seed(42)\n",
    "    min_unique = min(len(phishing_domains_unique), len(trusted_domains_unique))\n",
    "    \n",
    "    if min_unique == 0:\n",
    "        raise ValueError(\"Insufficient data for analysis (one of the datasets is empty).\")\n",
    "        \n",
    "    phishing_balanced = random.sample(phishing_domains_unique, min(len(phishing_domains_unique), min_unique))\n",
    "    trusted_balanced = random.sample(trusted_domains_unique, min(len(trusted_domains_unique), min_unique))\n",
    "\n",
    "    # 4. TLDé›†è¨ˆ\n",
    "    phishing_tlds = Counter([extract_tld(d) for d in phishing_balanced if extract_tld(d)])\n",
    "    trusted_tlds = Counter([extract_tld(d) for d in trusted_balanced if extract_tld(d)])\n",
    "\n",
    "    # 5. å±é™ºåº¦åˆ†æã¨åˆ†é¡\n",
    "    dangerous_tlds = []\n",
    "    \n",
    "    for tld, phish_count in phishing_tlds.items():\n",
    "        trust_count = trusted_tlds.get(tld, 0)\n",
    "        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã‚‹ã‚‚ã®ã¯é™¤å¤–\n",
    "        if phish_count >= 10:\n",
    "            ratio = phish_count / (trust_count + 1)\n",
    "            phish_pct = phish_count / len(phishing_balanced) * 100\n",
    "            \n",
    "            # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯:\n",
    "            # 1. æ­£å¸¸ã‚µã‚¤ãƒˆã§çš†ç„¡(0ä»¶) ã‹ã¤ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã§10ä»¶ä»¥ä¸Š\n",
    "            # 2. æ¯”ç‡ãŒ10å€ä»¥ä¸Š ã‹ã¤ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°å…¨ä½“ã®0.1%ä»¥ä¸Š\n",
    "            if (trust_count == 0) or (ratio >= 10 and phish_pct >= 0.1):\n",
    "                dangerous_tlds.append(tld)\n",
    "    \n",
    "    # ãƒ‰ãƒƒãƒˆã‚’é™¤å»ã—ã¦æ ¼ç´ (ä¾‹: '.xyz' -> 'xyz')\n",
    "    external_data['dangerous_tlds'] = [t.lstrip('.') for t in dangerous_tlds]\n",
    "\n",
    "    # æ­£å½“ãªTLD\n",
    "    legitimate_tlds = []\n",
    "    for tld, count in trusted_tlds.most_common():\n",
    "        if count >= 1000: # çµ±è¨ˆçš„ä¿¡é ¼æ€§\n",
    "            phish_count = phishing_tlds.get(tld, 0)\n",
    "            ratio = phish_count / count\n",
    "            if ratio < 0.5: # æ­£å¸¸ã‚µã‚¤ãƒˆã§ã®ä½¿ç”¨ãŒ2å€ä»¥ä¸Š\n",
    "                legitimate_tlds.append(tld)\n",
    "    external_data['legitimate_tlds'] = [t.lstrip('.') for t in legitimate_tlds]\n",
    "\n",
    "    # ä¸­ç«‹çš„ãªTLD (ä¸»è¦TLDã®ã†ã¡ã€ä¸Šè¨˜ã«å…¥ã‚‰ãªã‹ã£ãŸã‚‚ã®)\n",
    "    neutral_candidates = ['.com', '.org', '.net', '.info', '.biz']\n",
    "    neutral_tlds = []\n",
    "    for tld in neutral_candidates:\n",
    "        if tld not in dangerous_tlds and tld not in legitimate_tlds:\n",
    "            neutral_tlds.append(tld)\n",
    "    external_data['neutral_tlds'] = [t.lstrip('.') for t in neutral_tlds]\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜ (ç”Ÿã®Counterã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ)\n",
    "    external_data['phishing_tld_stats'] = phishing_tlds\n",
    "\n",
    "    print(f\"  âœ… Generated {len(external_data['dangerous_tlds'])} dangerous TLDs\")\n",
    "    print(f\"  âœ… Generated {len(external_data['legitimate_tlds'])} legitimate TLDs\")\n",
    "\n",
    "    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå†…ã®å‚ç…§æ›´æ–°\n",
    "    if 'agent' in globals():\n",
    "        agent.external_data = external_data\n",
    "        print(\"  âœ… Agent external_data updated\")\n",
    "        \n",
    "    print(\"âœ… TLD data patched via Database Analysis. Ready for evaluation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ DATABASE ANALYSIS FAILED: {e}\")\n",
    "    print(\"â›” Stopping execution to prevent inaccurate results using fallback data.\")\n",
    "    # æ˜ç¤ºçš„ã«ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã¦å‡¦ç†ã‚’æ­¢ã‚ã‚‹\n",
    "    raise RuntimeError(\"Database connection or analysis failed. Please check DB connection and rerun this cell.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24f810-779a-4f5e-9f76-2cff549f577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 5: ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡å®Ÿè¡Œï¼ˆä»¶æ•°=len(target_df), è¶…è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ç‰ˆï¼‰\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io, sys, json, os\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "print(f\"[INFO] Starting FULL AGENT evaluation of {len(target_df)} domains (N_SAMPLE={N_SAMPLE})...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLMè¨­å®šã®ç¢ºèª\n",
    "if 'agent' in globals() and hasattr(agent, 'llm_config'):\n",
    "    llm_config = agent.llm_config\n",
    "    if getattr(llm_config, \"enabled\", False):\n",
    "        print(f\"[INFO] LLM initialized: {llm_config.model}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - results may be limited\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent not properly initialized\")\n",
    "\n",
    "# --- Code fingerprint (reproducibility / verification) ------------------------\n",
    "# [ChangeLog] 2025-12-17: Add code fingerprint (module __file__ + sha256) to each output row.\n",
    "import hashlib\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import datetime as _dt\n",
    "\n",
    "def _sha256_of_file(path: str, chunk_size: int = 1024 * 1024) -> str:\n",
    "    \"\"\"Return sha256 hex digest for a local file. Never raises.\"\"\"\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "                h.update(chunk)\n",
    "        return h.hexdigest()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR:{type(e).__name__}\"\n",
    "\n",
    "def _module_file_and_sha(modname: str):\n",
    "    \"\"\"Import module and return (file_path, sha256, module_obj).\"\"\"\n",
    "    try:\n",
    "        mod = importlib.import_module(modname)\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if f:\n",
    "            f = str(Path(f).resolve())\n",
    "            sha = _sha256_of_file(f)\n",
    "        else:\n",
    "            sha = None\n",
    "        return f, sha, mod\n",
    "    except Exception as e:\n",
    "        return None, f\"IMPORT_ERROR:{type(e).__name__}\", None\n",
    "\n",
    "def make_code_fingerprint() -> dict:\n",
    "    fp = {}\n",
    "    fp[\"eval_id\"] = _dt.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "    # Core modules used by final decision path\n",
    "    p6_file, p6_sha, _p6_mod = _module_file_and_sha(\"phishing_agent.phase6_wiring\")\n",
    "    ld_file, ld_sha, ld_mod = _module_file_and_sha(\"phishing_agent.llm_final_decision\")\n",
    "    lg_file, lg_sha, _lg_mod = _module_file_and_sha(\"phishing_agent.langgraph_module\")\n",
    "\n",
    "    fp[\"phase6_wiring_file\"] = p6_file\n",
    "    fp[\"phase6_wiring_sha256\"] = p6_sha\n",
    "    fp[\"llm_final_decision_file\"] = ld_file\n",
    "    fp[\"llm_final_decision_sha256\"] = ld_sha\n",
    "    fp[\"langgraph_module_file\"] = lg_file\n",
    "    fp[\"langgraph_module_sha256\"] = lg_sha\n",
    "\n",
    "    fp[\"phase6_policy_version_code\"] = getattr(ld_mod, \"PHASE6_POLICY_VERSION\", None) if ld_mod else None\n",
    "    fp[\"python\"] = sys.version.split()[0]\n",
    "    fp[\"dual_import_langgraph_module\"] = (\"langgraph_module\" in sys.modules) and (\"phishing_agent.langgraph_module\" in sys.modules)\n",
    "\n",
    "    return fp\n",
    "\n",
    "# Compute once per notebook run (avoid per-domain overhead)\n",
    "if \"CODE_FINGERPRINT\" not in globals():\n",
    "    CODE_FINGERPRINT = make_code_fingerprint()\n",
    "    CODE_FP_ROW = {\n",
    "        \"eval_id\": CODE_FINGERPRINT.get(\"eval_id\"),\n",
    "        \"phase6_policy_version_code\": CODE_FINGERPRINT.get(\"phase6_policy_version_code\"),\n",
    "        \"phase6_wiring_file\": CODE_FINGERPRINT.get(\"phase6_wiring_file\"),\n",
    "        \"phase6_wiring_sha256\": CODE_FINGERPRINT.get(\"phase6_wiring_sha256\"),\n",
    "        \"llm_final_decision_file\": CODE_FINGERPRINT.get(\"llm_final_decision_file\"),\n",
    "        \"llm_final_decision_sha256\": CODE_FINGERPRINT.get(\"llm_final_decision_sha256\"),\n",
    "        \"langgraph_module_file\": CODE_FINGERPRINT.get(\"langgraph_module_file\"),\n",
    "        \"langgraph_module_sha256\": CODE_FINGERPRINT.get(\"langgraph_module_sha256\"),\n",
    "        \"dual_import_langgraph_module\": CODE_FINGERPRINT.get(\"dual_import_langgraph_module\"),\n",
    "    }\n",
    "    print(\"[INFO] code_fingerprint:\", CODE_FP_ROW)\n",
    "else:\n",
    "    # Reuse existing in case notebook cells are re-run\n",
    "    CODE_FP_ROW = globals().get(\"CODE_FP_ROW\", {})\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "# --- ä¿å­˜è¨­å®š: 500ä»¶ã”ã¨ã«è¿½è¨˜ï¼ˆåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ãªã—ï¼‰ -----------------\n",
    "SAVE_EVERY_ROWS = 500  # è¦ä»¶: 500ä»¶ã”ã¨ã«ä¿å­˜ï¼ˆè¿½è¨˜ï¼‰\n",
    "if \"LOGS_DIR\" not in globals() or not globals().get(\"LOGS_DIR\"):\n",
    "    raise RuntimeError(\"LOGS_DIR is not set. Run Cell 1 to initialize run_id/paths first.\")\n",
    "\n",
    "OUT_DIR = Path(globals()[\"LOGS_DIR\"])\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# eval_id ã¯ Notebookå®Ÿè¡Œå˜ä½ã§å›ºå®šï¼ˆCODE_FP_ROW ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼‰\n",
    "_eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    _eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not _eval_id:\n",
    "    _eval_id = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "_ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "# è¿½è¨˜å…ˆï¼ˆrun_id/logs é…ä¸‹ã¸ï¼‰\n",
    "full_eval_path = OUT_DIR / f\"random{len(target_df)}_full_eval__evalid_{_eval_id}__ts_{_ts}.csv\"\n",
    "print(f\"[INFO] Results will be appended to: {full_eval_path} (flush every {SAVE_EVERY_ROWS} rows)\")\n",
    "\n",
    "_chunk_buf = []\n",
    "_written_header = False\n",
    "_written_rows = 0\n",
    "\n",
    "def _flush_chunk_if_needed(force: bool = False):\n",
    "    \"\"\"_chunk_buf ã‚’ full_eval_path ã«è¿½è¨˜ä¿å­˜ï¼ˆãƒ˜ãƒƒãƒ€ã¯æœ€åˆã ã‘ï¼‰ã€‚\"\"\"\n",
    "    global _written_header, _written_rows\n",
    "    if (not force) and (len(_chunk_buf) < SAVE_EVERY_ROWS):\n",
    "        return\n",
    "    if not _chunk_buf:\n",
    "        return\n",
    "    df_chunk = pd.DataFrame(_chunk_buf)\n",
    "    df_chunk.to_csv(full_eval_path, mode=\"a\", header=(not _written_header), index=False)\n",
    "    _written_header = True\n",
    "    _written_rows += int(len(_chunk_buf))\n",
    "    _chunk_buf.clear()\n",
    "\n",
    "# --- Notebookç”»é¢å‡ºåŠ›ã®åˆ¶å¾¡ï¼ˆdebug_log ã®æƒ…å ±é‡ã¯ç¶­æŒï¼‰ -----------------\n",
    "# [ChangeLog] 2025-12-15: å¤§é‡ä»¶æ•°ã§ã‚‚Jupyterã®å‡ºåŠ›ãŒé‡ããªã‚‰ãªã„ã‚ˆã†ã€ç”»é¢å‡ºåŠ›ã‚’é–“å¼•ã\n",
    "TOTAL_N = len(target_df)\n",
    "\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å°‘æ•°ä»¶ã¯å¾“æ¥ã©ãŠã‚Šè©³ç´°è¡¨ç¤º / å¤šæ•°ä»¶ã¯ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆè¡¨ç¤º\n",
    "SHOW_DOMAIN_LOG_ON_SCREEN = (TOTAL_N <= 20)\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯: 1/true/yes/on ã§è©³ç´°è¡¨ç¤º\n",
    "_env = os.getenv(\"SHOW_DOMAIN_LOG_ON_SCREEN\")\n",
    "if _env is not None:\n",
    "    SHOW_DOMAIN_LOG_ON_SCREEN = str(_env).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# é€²æ—è¡¨ç¤ºã®æ›´æ–°é »åº¦ï¼ˆç”»é¢ã‚’è»½ãã™ã‚‹ãŸã‚ã€ä»¶æ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ï¼‰\n",
    "if TOTAL_N <= 30:\n",
    "    PROGRESS_EVERY = 1\n",
    "elif TOTAL_N <= 300:\n",
    "    PROGRESS_EVERY = 10\n",
    "elif TOTAL_N <= 3000:\n",
    "    PROGRESS_EVERY = 25\n",
    "else:\n",
    "    PROGRESS_EVERY = 50\n",
    "\n",
    "# Jupyterãªã‚‰ clear_output ã§è¡¨ç¤ºã‚’ç½®ãæ›ãˆï¼ˆãƒ­ã‚°ã¯CSVå´ã«æ®‹ã‚‹ï¼‰\n",
    "_USE_CLEAR_OUTPUT = (not SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "try:\n",
    "    from IPython.display import clear_output  # type: ignore\n",
    "    _HAS_CLEAR_OUTPUT = True\n",
    "except Exception:\n",
    "    _HAS_CLEAR_OUTPUT = False\n",
    "\n",
    "print(f\"[INFO] Console output mode: {'VERBOSE' if SHOW_DOMAIN_LOG_ON_SCREEN else 'COMPACT'} \"\n",
    "      f\"(PROGRESS_EVERY={PROGRESS_EVERY}, clear_output={_USE_CLEAR_OUTPUT and _HAS_CLEAR_OUTPUT})\")\n",
    "\n",
    "# é€²æ—ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆç”»é¢è¡¨ç¤ºç”¨ï¼‰\n",
    "_screen_counts = {\"phish\": 0, \"benign\": 0, \"error\": 0}\n",
    "\n",
    "# --- è¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ ----------------------------------------------------\n",
    "def _fmt_issues(issues):\n",
    "    return \", \".join(issues) if issues else \"None\"\n",
    "\n",
    "def _safe_dict(d):\n",
    "    return d if isinstance(d, dict) else {}\n",
    "\n",
    "def _log_tool_selection(graph_state, ml_probability):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    pre = _safe_dict(gs.get(\"precheck_hints\"))\n",
    "    ml_cat   = pre.get(\"ml_category\", \"-\")\n",
    "    tld_cat  = pre.get(\"tld_category\", \"-\")\n",
    "    quick_risk = pre.get(\"quick_risk\", \"-\")\n",
    "    known_info = _safe_dict(pre.get(\"known_domain_info\"))\n",
    "    known_label = known_info.get(\"label\") or known_info.get(\"kind\") or known_info.get(\"brand\")\n",
    "\n",
    "    selected_tools = gs.get(\"selected_tools\", [])\n",
    "    flags = _safe_dict(gs.get(\"tool_execution_flags\"))\n",
    "    llm_used = gs.get(\"llm_used_selection\")\n",
    "    llm_err  = gs.get(\"llm_selection_error\")\n",
    "\n",
    "    print(\"  [ToolSelection]\")\n",
    "    print(f\"    ml_probability      : {ml_probability:.3f} (category={ml_cat})\")\n",
    "    print(f\"    tld_category        : {tld_cat}  quick_risk={quick_risk}\")\n",
    "    if known_label:\n",
    "        print(f\"    known_domain_info   : {known_label}\")\n",
    "    print(f\"    selected_tools      : {selected_tools}\")\n",
    "    print(f\"    tool_execution_flags: {flags}\")\n",
    "    print(f\"    llm_used_selection  : {llm_used}\")\n",
    "    if llm_err:\n",
    "        print(f\"    llm_selection_error : {llm_err}\")\n",
    "\n",
    "    if llm_used:\n",
    "        strategy = \"llm_structured_output\"\n",
    "    else:\n",
    "        strategy = \"ml_bucket_fallback\"\n",
    "    print(f\"    selection_strategy  : {strategy}\")\n",
    "\n",
    "    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã¯ã€ã©ã®ãƒã‚±ãƒƒãƒˆãƒãƒªã‚·ãƒ¼ã«ãªã£ãŸã‹ã‚‚è¡¨ç¤º\n",
    "    if not llm_used:\n",
    "        if ml_probability < 0.2:\n",
    "            policy = \"ML<0.2 â†’ brand+cert+domain (3 tools)\"\n",
    "        elif ml_probability < 0.5:\n",
    "            policy = \"0.2â‰¦ML<0.5 â†’ brand+cert+domain (3 tools)\"\n",
    "        else:\n",
    "            policy = \"MLâ‰§0.5 â†’ brand+cert (2 tools)\"\n",
    "        print(f\"    selection_policy    : {policy}\")\n",
    "\n",
    "def _log_brand_tool(brand_res):\n",
    "    br = _safe_dict(brand_res)\n",
    "    if not br:\n",
    "        print(\"  [BrandTool] not executed\")\n",
    "        return\n",
    "\n",
    "    details = _safe_dict(br.get(\"details\"))\n",
    "    issues  = br.get(\"detected_issues\") or []\n",
    "    # â€» brand_impersonation_check ã®æ§‹é€ ã«åˆã‚ã›ã¦ details å´ã‚’å„ªå…ˆ\n",
    "    brands  = details.get(\"detected_brands\") or br.get(\"detected_brands\") or []\n",
    "    used_llm    = details.get(\"used_llm\")\n",
    "    llm_conf    = details.get(\"llm_confidence\")\n",
    "    llm_reason  = details.get(\"llm_reasoning\")\n",
    "    #llm_reason  = (details.get(\"llm_reasoning\") or \"\")[:160]\n",
    "\n",
    "    print(\"  [BrandTool]\")\n",
    "    if br.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback           : True (brand tool exception or disabled)\")\n",
    "    print(f\"    risk_score           : {br.get('risk_score')}\")\n",
    "    print(f\"    detected_issues      : {issues}\")\n",
    "    print(f\"    detected_brands      : {brands}\")\n",
    "    print(f\"    used_llm             : {used_llm}\")\n",
    "    print(f\"    llm_confidence       : {llm_conf}\")\n",
    "    print(f\"    llm_reasoning (head) : {llm_reason}\")\n",
    "    if used_llm:\n",
    "        print(\"    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\")\n",
    "    if brands:\n",
    "        print(f\"    âœ… ãƒ–ãƒ©ãƒ³ãƒ‰æ¤œå‡ºãŒã‚ã‚Šã¾ã™: {brands}\")\n",
    "\n",
    "def _log_cert_tool(cert_res):\n",
    "    cr = _safe_dict(cert_res)\n",
    "    if not cr:\n",
    "        print(\"  [CertTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cr.get(\"details\"))\n",
    "    print(\"  [CertTool]\")\n",
    "    if cr.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback      : True (cert tool exception or disabled)\")\n",
    "    print(f\"    risk_score      : {cr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues : {cr.get('detected_issues') or []}\")\n",
    "    print(f\"    issuer          : {details.get('issuer')}\")\n",
    "    print(f\"    is_free_ca      : {details.get('is_free_ca')}\")\n",
    "    print(f\"    has_org         : {details.get('has_org')}\")\n",
    "    print(f\"    valid_days      : {details.get('valid_days')}\")\n",
    "    print(f\"    is_short_term   : {details.get('is_short_term')}\")\n",
    "    print(f\"    san_count       : {details.get('san_count')}\")\n",
    "    print(f\"    is_self_signed  : {details.get('is_self_signed')}\")\n",
    "    print(f\"    is_wildcard     : {details.get('is_wildcard')}\")\n",
    "\n",
    "def _log_domain_tool(domain_res):\n",
    "    dr = _safe_dict(domain_res)\n",
    "    if not dr:\n",
    "        print(\"  [DomainTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(dr.get(\"details\"))\n",
    "    print(\"  [DomainTool]\")\n",
    "    if dr.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback            : True (domain tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {dr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {dr.get('detected_issues') or []}\")\n",
    "    print(f\"    base_domain           : {details.get('base_domain')}\")\n",
    "    print(f\"    domain_length         : {details.get('domain_length')}\"\n",
    "          f\" (category={details.get('domain_length_category')})\")\n",
    "    print(f\"    tld / tld_category    : {details.get('tld')} / {details.get('tld_category')}\")\n",
    "    print(f\"    entropy               : {details.get('entropy')}\")\n",
    "    print(f\"    combo_flags           : {details.get('combo_flags')}\")\n",
    "    legit = _safe_dict(details.get('legitimate_check'))\n",
    "    if legit:\n",
    "        print(f\"    legitimate_check      : is_legit={legit.get('is_legitimate')}\"\n",
    "              f\", brand={legit.get('brand')}, conf={legit.get('confidence')}\")\n",
    "\n",
    "def _log_contextual_tool(ctx_res):\n",
    "    cx = _safe_dict(ctx_res)\n",
    "    if not cx:\n",
    "        print(\"  [Contextual] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cx.get(\"details\"))\n",
    "    print(\"  [Contextual]\")\n",
    "    if cx.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback            : True (contextual tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {cx.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {cx.get('detected_issues') or []}\")\n",
    "    print(f\"    ml_probability        : {details.get('ml_probability')}\"\n",
    "          f\" (category={details.get('ml_category')})\")\n",
    "    print(f\"    tool_average_risk     : {details.get('tool_average_risk')}\")\n",
    "    print(f\"    high_risk_hits        : {details.get('high_risk_hits')}\")\n",
    "    known = _safe_dict(details.get('known_domain'))\n",
    "    if known:\n",
    "        print(f\"    known_domain          : {known}\")\n",
    "    paradox = _safe_dict(details.get('paradox'))\n",
    "    if paradox:\n",
    "        print(f\"    paradox_info          : {paradox}\")\n",
    "\n",
    "def _log_final_decision(graph_state, result):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    dbg = _safe_dict(gs.get(\"debug_llm_final\"))\n",
    "    dt_list = gs.get(\"decision_trace\") or []\n",
    "    print(\"  [FinalDecision]\")\n",
    "    print(f\"    use_llm_decision      : {dbg.get('use_llm_decision')}\")\n",
    "    print(f\"    llm_is_none           : {dbg.get('llm_is_none')}\")\n",
    "    print(f\"    path                  : {dbg.get('path')}\")\n",
    "    print(f\"    success               : {dbg.get('success')}\")\n",
    "    if dbg.get(\"error\"):\n",
    "        print(f\"    error                 : {dbg.get('error')}\")\n",
    "\n",
    "    if dt_list:\n",
    "        last = _safe_dict(dt_list[-1])\n",
    "        print(f\"    phase6_policy_version : {gs.get('phase6_policy_version', last.get('phase6_version'))}\")\n",
    "        print(f\"    ctx_risk_score        : {last.get('ctx_score')}\")\n",
    "        rules = [s.get(\"rule\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"rule\" in s]\n",
    "        notes = [s.get(\"note\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"note\" in s]\n",
    "        if rules:\n",
    "            print(f\"    policy_rules          : {rules}\")\n",
    "        if notes:\n",
    "            print(f\"    policy_notes          : {notes}\")\n",
    "\n",
    "    print(f\"    ai_is_phishing        : {result.get('ai_is_phishing')} \"\n",
    "          f\"(risk_level={result.get('ai_risk_level')}, conf={result.get('ai_confidence'):.2f})\")\n",
    "    print(f\"    final_reasoning(head) : {(result.get('reasoning') or '')[:160]}\")\n",
    "\n",
    "def _log_graph_messages(graph_state, prefix=\"    \"):\n",
    "    \"\"\"LangGraph ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã€é‡è¦ãã†ãªã‚‚ã®ã ã‘æŠœç²‹è¡¨ç¤º\"\"\"\n",
    "    gs = _safe_dict(graph_state)\n",
    "    msgs = gs.get(\"messages\") or []\n",
    "    if not msgs:\n",
    "        return\n",
    "    print(\"  [GraphMessages] (tool_selection / tool_execution / final_decision only)\")\n",
    "    for m in msgs:\n",
    "        if isinstance(m, dict):\n",
    "            content = m.get(\"content\", \"\")\n",
    "            role = m.get(\"role\", \"msg\")\n",
    "        else:\n",
    "            content = getattr(m, \"content\", \"\")\n",
    "            role = getattr(m, \"role\", \"msg\")\n",
    "        if not isinstance(content, str):\n",
    "            content = str(content)\n",
    "        if any(tag in content for tag in [\"[tool_selection]\", \"[tool_execution]\", \"[final_decision]\"]):\n",
    "            print(f\"{prefix}[{role}] {content}\")\n",
    "\n",
    "\n",
    "# --- ãƒ­ã‚°ã‚’CSVã«æ®‹ã™ãŸã‚ã®æ¨™æº–å‡ºåŠ›/æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆprint/loggingä¸¡å¯¾å¿œï¼‰ ---\n",
    "class _TeeIO:\n",
    "    def __init__(self, primary, buffer, *, enable_primary: bool = True):\n",
    "        self.primary = primary\n",
    "        self.buffer = buffer\n",
    "        self.enable_primary = bool(enable_primary)\n",
    "    def write(self, s):\n",
    "        if self.enable_primary:\n",
    "            self.primary.write(s)\n",
    "        self.buffer.write(s)\n",
    "        return len(s)\n",
    "    def flush(self):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.flush()\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            self.buffer.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _json_dumps(obj):\n",
    "    \"\"\"CSVã«å®‰å…¨ã«è¼‰ã›ã‚‹ãŸã‚ã®JSONåŒ–ï¼ˆå¤±æ•—ã—ã¦ã‚‚è½ã¨ã•ãªã„ï¼‰\"\"\"\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return json.dumps(str(obj), ensure_ascii=False, default=str)\n",
    "\n",
    "# --- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è©•ä¾¡ ---------------------------------------------------\n",
    "for idx, row in target_df.iterrows():\n",
    "    before_len = len(results)  # è¿½è¨˜ä¿å­˜ç”¨ï¼ˆã“ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è¿½åŠ ã•ã‚ŒãŸè¡Œã ã‘æ‹¾ã†ï¼‰\n",
    "    domain = row['domain']\n",
    "    ml_prob = row['ml_probability']\n",
    "    _buf = io.StringIO()\n",
    "    _tee_out = _TeeIO(sys.stdout, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    _tee_err = _TeeIO(sys.stderr, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    with redirect_stdout(_tee_out), redirect_stderr(_tee_err):\n",
    "\n",
    "        try:\n",
    "            eval_start = time.time()\n",
    "            result = agent.evaluate(domain, ml_prob)\n",
    "            elapsed = time.time() - eval_start\n",
    "\n",
    "            # --- åŸºæœ¬æƒ…å ± ---\n",
    "            is_phishing = result.get('ai_is_phishing', False)\n",
    "            confidence  = result.get('ai_confidence', 0.0)\n",
    "            risk_level  = result.get('ai_risk_level', 'unknown')\n",
    "\n",
    "            graph_state = _safe_dict(result.get(\"graph_state\"))\n",
    "            tool_res = _safe_dict(graph_state.get(\"tool_results\")) or _safe_dict(result.get(\"tool_results\"))\n",
    "\n",
    "            # Phase4 ä»•æ§˜: brand/cert/domain/contextual_risk_assessment ã¯ data æœ¬ä½“ãŒå…¥ã£ã¦ã„ã‚‹æƒ³å®š\n",
    "            brand_res  = _safe_dict(tool_res.get('brand'))\n",
    "            cert_res   = _safe_dict(tool_res.get('cert'))\n",
    "            domain_res = _safe_dict(tool_res.get('domain'))\n",
    "            ctx_res    = _safe_dict(tool_res.get('contextual_risk_assessment') or tool_res.get('contextual'))\n",
    "\n",
    "            # Brand details\n",
    "            brand_details   = _safe_dict(brand_res.get('details'))\n",
    "            detected_brands = brand_details.get('detected_brands', [])\n",
    "\n",
    "            # brand_detected / brand_suspected ã‚’ tool å´ã®ãƒ•ãƒ©ã‚°ã‹ã‚‰å–å¾—ï¼ˆbrandsé…åˆ—ã®æœ‰ç„¡ã§æ±ºã‚ãªã„ï¼‰\n",
    "            _b_issues = brand_res.get('detected_issues', []) if isinstance(brand_res, dict) else []\n",
    "            brand_detected_flag = bool(brand_details.get('brand_detected')) or ('brand_detected' in (_b_issues or []))\n",
    "            brand_suspected_flag = bool(brand_details.get('brand_suspected')) or ('brand_suspected' in (_b_issues or [])) or ('brand_llm_candidate' in (_b_issues or []))\n",
    "\n",
    "\n",
    "            # Cert details\n",
    "            cert_details = _safe_dict(cert_res.get('details'))\n",
    "            cert_issuer  = cert_details.get('issuer', 'unknown')\n",
    "\n",
    "            # Domain details\n",
    "            domain_details = _safe_dict(domain_res.get('details'))\n",
    "            tld_cat        = domain_details.get('tld_category', '-')\n",
    "\n",
    "            # Contextual issues\n",
    "            ctx_issues = ctx_res.get('detected_issues', []) if ctx_res else []\n",
    "\n",
    "            mark = \"ğŸ”´\" if is_phishing else \"ğŸŸ¢\"\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] {mark} {domain:<35} (ML: {ml_prob:.3f} / Time: {elapsed:.2f}s)\")\n",
    "            print(f\"ğŸ” Domain: {domain} (ml_probability={ml_prob:.3f})\")\n",
    "\n",
    "            # --- Tool Selection è©³ç´° ---\n",
    "            _log_tool_selection(graph_state, ml_prob)\n",
    "\n",
    "            # --- å„ãƒ„ãƒ¼ãƒ«è©³ç´° ---\n",
    "            _log_brand_tool(brand_res)\n",
    "            _log_cert_tool(cert_res)\n",
    "            _log_domain_tool(domain_res)\n",
    "            if ctx_res:\n",
    "                _log_contextual_tool(ctx_res)\n",
    "\n",
    "            # --- Final Decision è©³ç´° ---\n",
    "            _log_final_decision(graph_state, result)\n",
    "\n",
    "            # --- LangGraph ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠœç²‹ ---\n",
    "            _log_graph_messages(graph_state)\n",
    "\n",
    "            # --- ä¿å­˜ç”¨ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ ---\n",
    "            dbg_final = _safe_dict(graph_state.get(\"debug_llm_final\"))\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': is_phishing,\n",
    "                'ai_confidence': confidence,\n",
    "                'ai_risk_level': risk_level,\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps(graph_state),\n",
    "                'tool_results_json': _json_dumps(tool_res),\n",
    "                # Brand\n",
    "                'brand_detected': brand_detected_flag,\n",
    "                'brand_suspected': brand_suspected_flag,\n",
    "                'brands': detected_brands,\n",
    "                'brand_used_llm': brand_details.get('used_llm'),\n",
    "                'brand_llm_quality': brand_details.get('llm_candidate_quality'),\n",
    "                'brand_llm_evidence_token': brand_details.get('llm_evidence_token'),\n",
    "                'brand_llm_detected_brand': brand_details.get('llm_detected_brand'),\n",
    "                'brand_llm_confidence': brand_details.get('llm_confidence'),\n",
    "                'brand_risk_score': brand_res.get('risk_score'),\n",
    "                'brand_issues': brand_res.get('detected_issues', []),\n",
    "                # Cert\n",
    "                'cert_issues': cert_res.get('detected_issues', []),\n",
    "                'cert_issuer': cert_issuer,\n",
    "                'cert_score': cert_res.get('risk_score', 0.0),\n",
    "                # Domain\n",
    "                'domain_issues': domain_res.get('detected_issues', []),\n",
    "                'domain_score': domain_res.get('risk_score', 0.0),\n",
    "                'tld_category': tld_cat,\n",
    "                # Contextual\n",
    "                'ctx_issues': ctx_issues,\n",
    "                'ctx_score': ctx_res.get('risk_score', None) if ctx_res else None,\n",
    "                # Tool Selection / Final LLM debug\n",
    "                'tool_selection_llm_used': graph_state.get('llm_used_selection'),\n",
    "                'tool_selection_llm_error': graph_state.get('llm_selection_error'),\n",
    "                'final_llm_path': dbg_final.get('path'),\n",
    "                'final_llm_success': dbg_final.get('success'),\n",
    "                'phase6_policy_version': graph_state.get('phase6_policy_version'),\n",
    "                'module_version': result.get('module_version'),\n",
    "                'error': None,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - eval_start\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] âŒ ERROR: {domain} - {str(e)}\")\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': False,\n",
    "                'ai_confidence': 0.0,\n",
    "                'ai_risk_level': 'error',\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps({}),\n",
    "                'tool_results_json': _json_dumps({}),\n",
    "                'error': str(e),\n",
    "            })\n",
    "\n",
    "    # --- è¿½è¨˜ä¿å­˜ï¼ˆ500ä»¶ã”ã¨ï¼‰: ã“ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®çµæœï¼ˆresults[-1]ï¼‰ã‚’ãƒãƒƒãƒ•ã‚¡ã«ç©ã¿ã€å¿…è¦ãªã‚‰è¿½è¨˜ ---\n",
    "    try:\n",
    "        if len(results) > before_len:\n",
    "            _chunk_buf.append(results[-1])\n",
    "            _flush_chunk_if_needed(force=False)\n",
    "    except Exception:\n",
    "        # è¿½è¨˜ä¿å­˜ã®å¤±æ•—ã§è©•ä¾¡è‡ªä½“ã‚’æ­¢ã‚ãªã„ï¼ˆãƒ­ã‚°ã¯çµæœå´ã«æ®‹ã™ï¼‰\n",
    "        pass\n",
    "    # --- ç”»é¢è¡¨ç¤ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆé€²æ—ï¼‰ ---------------------------------------\n",
    "    # NOTE: è©³ç´°ãƒ­ã‚°ã¯ _buf ã«å…¨é‡ä¿å­˜ã—ã¦ã„ã‚‹ã®ã§ã€ç”»é¢å´ã¯è»½ãã™ã‚‹\n",
    "    try:\n",
    "        _last = results[-1] if results else None\n",
    "    except Exception:\n",
    "        _last = None\n",
    "\n",
    "    if _last is not None:\n",
    "        if _last.get(\"error\"):\n",
    "            _screen_counts[\"error\"] += 1\n",
    "        else:\n",
    "            if bool(_last.get(\"ai_is_phishing\")):\n",
    "                _screen_counts[\"phish\"] += 1\n",
    "            else:\n",
    "                _screen_counts[\"benign\"] += 1\n",
    "\n",
    "        # è©³ç´°ãƒ­ã‚°ã‚’ç”»é¢ã«å‡ºã•ãªã„ãƒ¢ãƒ¼ãƒ‰ã®ã¨ãã ã‘ã€é€²æ—ã‚’é–“å¼•ã„ã¦è¡¨ç¤º\n",
    "        if (not SHOW_DOMAIN_LOG_ON_SCREEN) and (\n",
    "            ((idx + 1) % PROGRESS_EVERY == 0) or (idx == (len(target_df) - 1)) or _last.get(\"error\")\n",
    "        ):\n",
    "            if _HAS_CLEAR_OUTPUT and _USE_CLEAR_OUTPUT:\n",
    "                try:\n",
    "                    clear_output(wait=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            elapsed_total = time.time() - start_time\n",
    "            mark = \"âŒ\" if _last.get(\"error\") else (\"ğŸ”´\" if _last.get(\"ai_is_phishing\") else \"ğŸŸ¢\")\n",
    "            dom  = _last.get(\"domain\", \"-\")\n",
    "            mlp  = float(_last.get(\"ml_probability\") or 0.0)\n",
    "            conf = float(_last.get(\"ai_confidence\") or 0.0)\n",
    "            rl   = _last.get(\"ai_risk_level\", \"-\")\n",
    "            tsec = float(_last.get(\"processing_time\") or 0.0)\n",
    "\n",
    "            print(f\"[PROGRESS] {idx+1}/{len(target_df)}  phishing={_screen_counts['phish']}  benign={_screen_counts['benign']}  error={_screen_counts['error']}  elapsed={elapsed_total:.1f}s\")\n",
    "            print(f\"          last: {mark} {dom} (ML={mlp:.3f} risk={rl} conf={conf:.2f} t={tsec:.2f}s)\")\n",
    "            if _last.get(\"error\"):\n",
    "                print(f\"          last_error: {_last.get('error')}\")\n",
    "\n",
    "# --- å®Œäº†å‡¦ç† ------------------------------------------------------------\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] Full evaluation complete! Total time: {total_time:.2f}s\")\n",
    "\n",
    "# DataFrameåŒ–ï¼ˆå¾Œç¶šã‚»ãƒ«ã®åˆ†æç”¨ã«ãƒ¡ãƒ¢ãƒªä¸Šã«ã‚‚ä¿æŒï¼‰\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# --- è¿½è¨˜ä¿å­˜: ç«¯æ•°ï¼ˆ<500ä»¶ï¼‰ã‚‚å¿…ãšä¿å­˜ã—ã¦çµ‚äº† ---\n",
    "_flush_chunk_if_needed(force=True)\n",
    "\n",
    "print(f\"[INFO] Results saved (append) to: {full_eval_path}  rows_written={_written_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3acadd-4036-4bc3-891e-b0e63bbad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_one_domain(domain: str, ml: float = 0.3):\n",
    "    res = agent.evaluate(domain, ml)\n",
    "    gs = (res.get(\"graph_state\") or {})\n",
    "    dbg = (gs.get(\"debug_llm_final\") or {})\n",
    "    asmt = gs.get(\"final_assessment\")\n",
    "\n",
    "    print(\"=== RAW RESULT ===\")\n",
    "    print(f\"domain         : {res.get('domain')}\")\n",
    "    print(f\"ml_probability : {res.get('ml_probability')}\")\n",
    "    print(f\"success        : {res.get('success')}\")\n",
    "    print(f\"ai_is_phishing : {res.get('ai_is_phishing')}\")\n",
    "    print(f\"ai_confidence  : {res.get('ai_confidence')}\")\n",
    "    print(f\"ai_risk_level  : {res.get('ai_risk_level')}\")\n",
    "    print(f\"reasoning      : {res.get('reasoning')[:120]!r}...\")\n",
    "\n",
    "    print(\"\\n=== LLM FINAL DEBUG (debug_llm_final) ===\")\n",
    "    print(\"  path           :\", dbg.get(\"path\"))\n",
    "    print(\"  success        :\", dbg.get(\"success\"))\n",
    "    print(\"  error          :\", dbg.get(\"error\"))\n",
    "    print(\"  exception_type :\", dbg.get(\"exception_type\"))\n",
    "    print(\"  use_llm_decision:\", dbg.get(\"use_llm_decision\"))\n",
    "    print(\"  llm_is_none    :\", dbg.get(\"llm_is_none\"))\n",
    "    print(\"  strict_mode    :\", dbg.get(\"strict_mode\"))\n",
    "    print(\"  fallback_reason:\", dbg.get(\"fallback_reason\"))\n",
    "\n",
    "    print(\"\\n=== FINAL ASSESSMENT OBJECT ===\")\n",
    "    print(\"  type(asmt):\", type(asmt))\n",
    "    if asmt is not None:\n",
    "        print(\"  is_phishing :\", getattr(asmt, 'is_phishing', None))\n",
    "        print(\"  confidence  :\", getattr(asmt, 'confidence', None))\n",
    "        print(\"  risk_level  :\", getattr(asmt, 'risk_level', None))\n",
    "\n",
    "    print(\"\\n=== FALLBACK LOCATIONS ===\")\n",
    "    print(\"  \", gs.get(\"fallback_locations\"))\n",
    "\n",
    "    return res, gs, dbg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94248864-8072-4fad-8053-61e812d7d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6: graph.stream ã‚’ä½¿ã£ãŸå˜ç™ºãƒ‡ãƒãƒƒã‚°\n",
    "# ============================================\n",
    "from copy import deepcopy\n",
    "\n",
    "# â˜… ã©ã®è¡Œã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã‹æŒ‡å®šï¼ˆä¾‹: 0ç•ªç›® = 1ä»¶ç›®ï¼‰\n",
    "debug_idx = 0\n",
    "\n",
    "# guard: target_df ãŒç©ºãªã‚‰åŸå› ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®š/ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã‚’å…ˆã«ç¢ºèª\n",
    "if target_df is None or len(target_df) == 0:\n",
    "    raise ValueError(\n",
    "        \"target_df is empty. N_SAMPLE=0/-1(ALL) ã®å ´åˆã¯ã€æ—¢å­˜CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦ pickle ã‹ã‚‰å†ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n",
    "        \"â†’ Cell0/Cell3 ã‚’ä¸Šã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\"\n",
    "    )\n",
    "\n",
    "row = target_df.iloc[debug_idx]\n",
    "domain = row[\"domain\"]\n",
    "ml_prob = float(row[\"ml_probability\"])\n",
    "print(f\"[DEBUG] domain={domain}, ml_probability={ml_prob:.4f}\")\n",
    "\n",
    "# --- evaluate() ãŒå†…éƒ¨ã§ä½œã‚‹ initial_state ã¨ã»ã¼åŒã˜ã‚‚ã®ã‚’ç”¨æ„ ---\n",
    "initial_state = {\n",
    "    \"domain\": domain,\n",
    "    \"ml_probability\": float(ml_prob or 0.0),\n",
    "    \"strict_mode\": agent.strict_mode,\n",
    "    \"current_step\": \"initial\",\n",
    "    \"precheck_hints\": {},\n",
    "    \"selected_tools\": [],\n",
    "    \"tool_results\": {},\n",
    "    \"final_assessment\": None,\n",
    "    \"error\": None,\n",
    "    \"retry_count\": 0,\n",
    "    \"fallback_count\": 0,\n",
    "    \"fallback_locations\": [],\n",
    "    \"tool_execution_flags\": {},\n",
    "    \"next_step\": \"\",\n",
    "    \"messages\": [],  # AgentState ã«è¿½åŠ ã—ãŸ debug ç”¨ãƒãƒ£ãƒ³ãƒãƒ«\n",
    "}\n",
    "\n",
    "if agent.graph is None:\n",
    "    raise RuntimeError(\"agent.graph ãŒ None ãªã®ã§ stream() ãŒä½¿ãˆã¾ã›ã‚“\")\n",
    "\n",
    "final_state = None\n",
    "for step in agent.graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    print(f\"\\n[STEP] current_step={step.get('current_step')}\")\n",
    "    msgs = step.get(\"messages\") or []\n",
    "    if not msgs:\n",
    "        continue\n",
    "\n",
    "    last = msgs[-1]\n",
    "\n",
    "    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡ã®å–ã‚Šå‡ºã—\n",
    "    if hasattr(last, \"content\"):\n",
    "        text = last.content if isinstance(last.content, str) else str(last.content)\n",
    "    elif isinstance(last, dict):\n",
    "        text = str(last.get(\"content\", last))\n",
    "    else:\n",
    "        text = str(last)\n",
    "\n",
    "    # precheck / tool_selection / tool_execution ã ã‘è¡¨ç¤º\n",
    "    if any(tag in text for tag in (\"[precheck]\", \"[tool_selection]\", \"[tool_execution]\")):\n",
    "        if hasattr(last, \"pretty_print\"):\n",
    "            last.pretty_print()\n",
    "        else:\n",
    "            print(\"    \" + text)\n",
    "\n",
    "    final_state = step\n",
    "\n",
    "# --- æœ€çµ‚çŠ¶æ…‹ã®ã–ã£ãã‚Šç¢ºèªï¼ˆä½™è£•ãŒã‚ã‚Œã°ï¼‰---\n",
    "if final_state is not None:\n",
    "    fa = final_state.get(\"final_assessment\")\n",
    "    print(\"\\n[FINAL STATE]\")\n",
    "    print(\"  is_phishing :\", getattr(fa, \"is_phishing\", None))\n",
    "    print(\"  confidence  :\", getattr(fa, \"confidence\", None))\n",
    "    print(\"  risk_level  :\", getattr(fa, \"risk_level\", None))\n",
    "    print(\"  tool_keys   :\", list((final_state.get(\"tool_results\") or {}).keys()))\n",
    "else:\n",
    "    print(\"[DEBUG] final_state ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3149a-01ec-4b2b-8c47-437626986896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6: ãƒ„ãƒ¼ãƒ«åˆ¥è©³ç´°çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "# ============================================\n",
    "import numpy as np\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "valid_df = results_df[results_df['error'].isna()].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” DETAILED TOOL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. å…¨ä½“çµ±è¨ˆ\n",
    "phish_count = valid_df['ai_is_phishing'].sum()\n",
    "total = len(valid_df)\n",
    "print(f\"\\nğŸ“Š Overall Performance\")\n",
    "print(f\"  Total Domains: {total}\")\n",
    "print(f\"  Phishing Detected: {phish_count} ({phish_count/total*100:.1f}%)\")\n",
    "print(f\"  Avg Processing Time: {valid_df['processing_time'].mean():.2f}s\")\n",
    "\n",
    "# 2. Certificate Analysis çµ±è¨ˆ (ä»Šå›æ³¨ç›®ã®æ©Ÿèƒ½)\n",
    "print(f\"\\nğŸ”’ Certificate Analysis Stats\")\n",
    "# Issueã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "all_cert_issues = []\n",
    "for issues in valid_df['cert_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_cert_issues.extend(issues)\n",
    "    elif isinstance(issues, str) and issues: # æ–‡å­—åˆ—ã®å ´åˆã®ã‚±ã‚¢\n",
    "        import ast\n",
    "        try:\n",
    "            all_cert_issues.extend(ast.literal_eval(issues))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if all_cert_issues:\n",
    "    from collections import Counter\n",
    "    cert_counts = Counter(all_cert_issues)\n",
    "    for issue, count in cert_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "else:\n",
    "    print(\"  No certificate issues detected.\")\n",
    "\n",
    "# ç™ºè¡Œè€…(Issuer)ã®Top5 (Free CAã®ç¢ºèªãªã©)\n",
    "issuers = valid_df[valid_df['cert_issuer'] != 'unknown']['cert_issuer']\n",
    "if not issuers.empty:\n",
    "    print(f\"  [Top Issuers]\")\n",
    "    print(issuers.value_counts().head(5).to_string(header=False))\n",
    "\n",
    "# 3. Domain Analysis çµ±è¨ˆ\n",
    "print(f\"\\nğŸŒ Domain Analysis Stats\")\n",
    "all_domain_issues = []\n",
    "for issues in valid_df['domain_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_domain_issues.extend(issues)\n",
    "\n",
    "if all_domain_issues:\n",
    "    dom_counts = Counter(all_domain_issues)\n",
    "    for issue, count in dom_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "\n",
    "# 4. Brand Analysis çµ±è¨ˆ\n",
    "print(f\"\\nğŸ·ï¸  Brand Analysis Stats\")\n",
    "brand_hits = valid_df[valid_df['brand_detected'] == True]\n",
    "print(f\"  Brand Detected: {len(brand_hits)} domains\")\n",
    "if not brand_hits.empty:\n",
    "    all_brands = []\n",
    "    for brands in brand_hits['brands']:\n",
    "        if isinstance(brands, list): all_brands.extend(brands)\n",
    "    print(f\"  [Top Detected Brands]\")\n",
    "    print(pd.Series(all_brands).value_counts().head(5).to_string(header=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Verification Complete. Check CSV for per-domain details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e40ed-3cc6-4c82-90d2-9bb658c259b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«1: ãƒ‘ã‚¹è¨­å®š & test_data / ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆartifacts/<RUN_ID>/... ã«çµ±ä¸€ï¼‰ ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cell 1 ã§å®šç¾©ã•ã‚ŒãŸ PROCESSED_DIR / MODELS_DIR / RUN_ID ã‚’åˆ©ç”¨\n",
    "if \"PROCESSED_DIR\" not in globals() or \"MODELS_DIR\" not in globals():\n",
    "    raise RuntimeError(\"PROCESSED_DIR / MODELS_DIR ãŒæœªå®šç¾©ã§ã™ã€‚å…ˆã« Cell 1 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "DATA_DIR = Path(PROCESSED_DIR)\n",
    "MODELS_DIR = Path(MODELS_DIR)  # ã™ã§ã« Path ã®ã¯ãšã ãŒå¿µã®ãŸã‚\n",
    "\n",
    "# 02_xgboost_training_evaluation_... ã®æ–°ä»•æ§˜ã«åˆã‚ã›ã¦:\n",
    "#   - test_data.pkl: artifacts/<RUN_ID>/processed/test_data.pkl\n",
    "#   - xgboost_model.pkl, scaler.pkl: artifacts/<RUN_ID>/models/...\n",
    "TEST_DATA_PKL = DATA_DIR / \"test_data.pkl\"\n",
    "XGB_MODEL_PKL = MODELS_DIR / \"xgboost_model.pkl\"\n",
    "SCALER_PKL    = MODELS_DIR / \"scaler.pkl\"\n",
    "\n",
    "print(\"TEST_DATA_PKL :\", TEST_DATA_PKL)\n",
    "print(\"XGB_MODEL_PKL :\", XGB_MODEL_PKL)\n",
    "print(\"SCALER_PKL    :\", SCALER_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ae907-89e0-44a1-95f0-01377fce73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«2: test_data + XGBoost ã§ ml_probability ã‚’å†è¨ˆç®— ===\n",
    "\n",
    "# 02 ã§ joblib.dump ã—ã¦ã„ã‚Œã° joblib.load ã§ãã®ã¾ã¾èª­ã‚ã¾ã™\n",
    "test_data = joblib.load(TEST_DATA_PKL)\n",
    "\n",
    "X_test = np.asarray(test_data[\"X\"])\n",
    "y_test = np.asarray(test_data[\"y\"]).astype(int)\n",
    "domains_test = np.asarray(test_data[\"domains\"])\n",
    "\n",
    "xgb_model = joblib.load(XGB_MODEL_PKL)\n",
    "try:\n",
    "    scaler = joblib.load(SCALER_PKL)\n",
    "except FileNotFoundError:\n",
    "    scaler = None\n",
    "    print(\"âš  scaler.pkl ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã®ã§ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç„¡ã—ã§æ¨è«–ã—ã¾ã™ã€‚\")\n",
    "\n",
    "def compute_ml_probabilities(model, X, scaler=None):\n",
    "    \"\"\"XGBoost ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ P(phish) ã‚’æ¨å®šã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼\"\"\"\n",
    "    X_in = scaler.transform(X) if scaler is not None else X\n",
    "\n",
    "    # sklearn API (XGBClassifier) ã®å ´åˆ\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = np.asarray(model.predict_proba(X_in))\n",
    "        if proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "            return proba[:, 1]\n",
    "        return proba.ravel()\n",
    "\n",
    "    # Booster API ã®å ´åˆ\n",
    "    if hasattr(model, \"predict\"):\n",
    "        dtest = xgb.DMatrix(X_in)\n",
    "        proba = np.asarray(model.predict(dtest))\n",
    "        return proba.ravel()\n",
    "\n",
    "    raise RuntimeError(\"äºˆæœŸã—ãªã„ XGBoost ãƒ¢ãƒ‡ãƒ«å‹ã§ã™ (predict_proba/predict ãŒè¦‹ã¤ã‹ã‚‰ãªã„)ã€‚\")\n",
    "\n",
    "ml_probs_test = compute_ml_probabilities(xgb_model, X_test, scaler=scaler)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"domain\": domains_test,\n",
    "    \"label\": y_test,\n",
    "    \"ml_probability\": ml_probs_test,\n",
    "})\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951945a-58e4-4610-b2cd-f9e4fed7ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«3: æ­£å¸¸ (label==0) ã‹ã‚‰ N_BENIGN_SAMPLE ä»¶ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ===\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_SAMPLE<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’ä½¿ã†\n",
    "\n",
    "# N_BENIGN_SAMPLE ã¯ Cell 1 ã®è¨­å®šã«å¾“ã†ï¼ˆå¿…è¦ãªã‚‰ç’°å¢ƒå¤‰æ•° N_BENIGN_SAMPLE ã§ä¸Šæ›¸ãï¼‰\n",
    "# RANDOM_STATE ã¯ Cell 1 ã§å®šç¾©ï¼ˆç’°å¢ƒå¤‰æ•° RANDOM_STATE ã§ã‚‚ä¸Šæ›¸ãå¯ï¼‰\n",
    "\n",
    "benign_candidates = test_df.query(\"label == 0 and ml_probability < 0.5\").copy()\n",
    "print(\"benign candidates (label==0 & ml_prob<0.5):\", len(benign_candidates))\n",
    "\n",
    "# N_BENIGN_SAMPLE <= 0 ã®å ´åˆã¯ã€Œå…¨ä»¶å‡¦ç†ã€\n",
    "if (N_BENIGN_SAMPLE <= 0) or (len(benign_candidates) <= N_BENIGN_SAMPLE):\n",
    "    print(f\"å€™è£œãŒ {len(benign_candidates)} ä»¶ãªã®ã§ã€ãã®ã¾ã¾å…¨ä»¶ä½¿ã„ã¾ã™ã€‚\")\n",
    "    benign_sample_df = benign_candidates.reset_index(drop=True)\n",
    "else:\n",
    "    benign_sample_df = benign_candidates.sample(N_BENIGN_SAMPLE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "benign_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdddae-6ae3-4940-a755-9a4eb919a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«4: benign ã‚µãƒ³ãƒ—ãƒ«ã« LangGraphPhishingAgent ã‚’å®Ÿè¡Œ ===\n",
    "# ã“ã“ã§ã¯ agent ã¯æ—¢ã«å‰ã®ã‚»ãƒ«ã§åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å‰æ\n",
    "\n",
    "benign_agent_results = []\n",
    "for row in benign_sample_df.itertuples(index=False):\n",
    "    res = agent.evaluate(\n",
    "        domain=row.domain,\n",
    "        ml_probability=float(row.ml_probability),\n",
    "        # external_data ã¯ __init__ ã§æ¸¡ã—ã¦ã„ã‚‹ãªã‚‰çœç•¥ã§OK\n",
    "    )\n",
    "    # [ChangeLog] 2025-12-17: Attach code fingerprint columns to each record.\n",
    "    if isinstance(res, dict) and 'CODE_FP_ROW' in globals():\n",
    "        res.update(CODE_FP_ROW)\n",
    "    benign_agent_results.append(res)\n",
    "\n",
    "benign_agent_df = pd.DataFrame(benign_agent_results)\n",
    "\n",
    "# å¿…è¦ãªåˆ—ã ã‘ã‚’ãƒãƒ¼ã‚¸\n",
    "benign_eval_df = benign_sample_df.merge(\n",
    "    benign_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_eval_df[\"label\"] = 0  # ground truth\n",
    "benign_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: benign è©•ä¾¡çµæœã‚’CSVã¸ä¿å­˜ï¼ˆå…±æœ‰ç”¨ï¼‰ ===\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ãƒ©ãƒ™ãƒ«ä»˜ãç°¡æ˜“ã‚µãƒãƒª\n",
    "out_dir = Path(LOGS_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_path = out_dir / f\"benign{len(benign_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) ãƒ•ãƒ«ãƒ­ã‚°ï¼ˆagent.evaluate ã®ç”Ÿå‡ºåŠ›ã‚’å«ã‚€ï¼‰\n",
    "full_path = out_dir / f\"benign{len(benign_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: hard-negative benign ã‚’ä½œæˆï¼ˆMLãŒé«˜ã„æ­£å¸¸ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ ===\n",
    "# ç›®çš„: ã€ŒMLãŒé«˜ã„æ­£å¸¸ã€ã‚’é›†ã‚ã¦ã€FPãŒå¢—ãˆãªã„ã‹æ¤œè¨¼ã™ã‚‹ï¼ˆhard negativesï¼‰\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 200 ä»¶ã€‚å¿…è¦ãªã‚‰ç’°å¢ƒå¤‰æ•° N_BENIGN_HARD_SAMPLE ã§ä¸Šæ›¸ãã§ãã¾ã™ã€‚\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_HARD_SAMPLE<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’ä½¿ã†\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "N_BENIGN_HARD_SAMPLE = int(os.getenv(\"N_BENIGN_HARD_SAMPLE\", \"200\"))\n",
    "\n",
    "# label==0 å…¨ä½“ã‹ã‚‰ ML ã®é«˜ã„é †ã«ä¸¦ã¹ã‚‹\n",
    "benign_all = test_df.query(\"label == 0\").copy()\n",
    "benign_all = benign_all.sort_values(\"ml_probability\", ascending=False)\n",
    "\n",
    "# ã™ã§ã« benign_sample_df ã‚’ä½œã£ã¦ã„ã‚‹å ´åˆã¯é‡è¤‡ã‚’é¿ã‘ã‚‹ï¼ˆä»»æ„ï¼‰\n",
    "try:\n",
    "    used = set(benign_sample_df[\"domain\"].astype(str))\n",
    "    benign_all = benign_all[~benign_all[\"domain\"].astype(str).isin(used)]\n",
    "    print(\"removed overlap with benign_sample_df:\", len(used), \"used\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# å…¨ä»¶å‡¦ç†ï¼ˆN<=0ï¼‰ or å€™è£œä¸è¶³ãªã‚‰å…¨ä»¶\n",
    "if (N_BENIGN_HARD_SAMPLE <= 0) or (len(benign_all) <= N_BENIGN_HARD_SAMPLE):\n",
    "    print(f\"hard benign candidates are only {len(benign_all)}; using all.\")\n",
    "    benign_hard_sample_df = benign_all\n",
    "else:\n",
    "    benign_hard_sample_df = benign_all.head(N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "benign_hard_sample_df = benign_hard_sample_df.reset_index(drop=True)\n",
    "\n",
    "print(\"hard benign sample size:\", len(benign_hard_sample_df))\n",
    "if len(benign_hard_sample_df):\n",
    "    print(\"ml_probability (hard benign) min/mean/max:\",\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].min()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].mean()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].max()))\n",
    "benign_hard_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: hard-negative benign ã‚’è©•ä¾¡ï¼ˆfull_eval ã‚’ä½œã‚‹ï¼‰ ===\n",
    "# ã“ã“ã§ã‚‚ agent ã¯æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å‰æã§ã™ã€‚\n",
    "\n",
    "benign_hard_agent_results = []\n",
    "for row in benign_hard_sample_df.itertuples(index=False):\n",
    "    res = agent.evaluate(\n",
    "        domain=row.domain,\n",
    "        ml_probability=float(row.ml_probability),\n",
    "    )\n",
    "    # [ChangeLog] 2025-12-17: Attach code fingerprint columns to each record.\n",
    "    if isinstance(res, dict) and 'CODE_FP_ROW' in globals():\n",
    "        res.update(CODE_FP_ROW)\n",
    "    benign_hard_agent_results.append(res)\n",
    "\n",
    "benign_hard_agent_df = pd.DataFrame(benign_hard_agent_results)\n",
    "\n",
    "# å¿…è¦ãªåˆ—ã ã‘ã‚’ãƒãƒ¼ã‚¸ï¼ˆlabel=0ï¼‰\n",
    "benign_hard_eval_df = benign_hard_sample_df.merge(\n",
    "    benign_hard_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_hard_eval_df[\"label\"] = 0  # ground truth\n",
    "benign_hard_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dafa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: benign_hard è©•ä¾¡çµæœã‚’CSVã¸ä¿å­˜ï¼ˆå…±æœ‰ç”¨ï¼‰ ===\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ãƒ©ãƒ™ãƒ«ä»˜ãç°¡æ˜“ã‚µãƒãƒª\n",
    "out_dir = Path(LOGS_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_path = out_dir / f\"benign_hard{len(benign_hard_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) ãƒ•ãƒ«ãƒ­ã‚°ï¼ˆagent.evaluate ã®ç”Ÿå‡ºåŠ›ã‚’å«ã‚€ï¼‰\n",
    "full_path = out_dir / f\"benign_hard{len(benign_hard_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c9e08-5d3c-4a3d-9f0d-c48022b7fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«5: FN ã‚µãƒ³ãƒ—ãƒ«å´ã®æ•´å½¢ (å…¨éƒ¨ label=1) ===\n",
    "\n",
    "# target_df: FN ã‚µãƒ³ãƒ—ãƒ«ï¼ˆn=len(target_df), å…¨éƒ¨ phishæƒ³å®šï¼‰\n",
    "# results_df: target_df ã«å¯¾ã—ã¦ agent.evaluate() æ¸ˆã¿ã® DataFrame\n",
    "fn_eval_df = (\n",
    "    target_df[[\"domain\", \"ml_probability\"]]\n",
    "    .merge(\n",
    "        results_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "        on=\"domain\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "fn_eval_df[\"label\"] = 1  # ground truth = phishing\n",
    "fn_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be900d16-c5ac-4bc3-8904-ef2a600e3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«6: phishN + benignN ã‚’çµåˆ ===\n",
    "\n",
    "eval_df = pd.concat(\n",
    "    [fn_eval_df, benign_eval_df],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "print(eval_df[[\"label\", \"ai_is_phishing\"]].value_counts())\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7d6dc-f7e2-4a35-a37c-6dcacb8f8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«7: Agent å˜ä½“ã®æ··åŒè¡Œåˆ—ã¨å„ç¨®æŒ‡æ¨™ã‚’è¨ˆç®— ===\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ConfusionResult:\n",
    "    TP: int\n",
    "    FP: int\n",
    "    TN: int\n",
    "    FN: int\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    fbeta: float\n",
    "    fpr: float\n",
    "\n",
    "def compute_confusion_and_scores(\n",
    "    df: pd.DataFrame,\n",
    "    label_col: str = \"label\",\n",
    "    pred_col: str = \"ai_is_phishing\",\n",
    "    beta: float = 2.0,\n",
    ") -> ConfusionResult:\n",
    "    y_true = df[label_col].astype(int).to_numpy()\n",
    "    y_pred = df[pred_col].astype(int).to_numpy()\n",
    "\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    beta2 = beta ** 2\n",
    "    denom = beta2 * precision + recall\n",
    "    fbeta = ((1 + beta2) * precision * recall) / denom if denom > 0 else 0.0\n",
    "\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "    return ConfusionResult(tp, fp, tn, fn, precision, recall, f1, fbeta, fpr)\n",
    "\n",
    "metrics_agent = compute_confusion_and_scores(eval_df, beta=2.0)\n",
    "metrics_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5c681-d436-4ad3-acd0-5b1ad993a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã„ã¾ã®ã¾ã¾ã§ã‚‚OKãª FP/FN ã®æŠ½å‡º\n",
    "is_tp = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_fp = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_tn = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "is_fn = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "\n",
    "tp_df = eval_df[is_tp].copy()\n",
    "fp_df = eval_df[is_fp].copy()\n",
    "tn_df = eval_df[is_tn].copy()\n",
    "fn_df = eval_df[is_fn].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2aaf4-1e46-4285-85a6-81e94b0479cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å€™è£œã«ã™ã‚‹åˆ—ï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦å¢—æ¸›OKï¼‰\n",
    "candidate_cols = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "    \"error\",\n",
    "    \"phase\",\n",
    "    \"graph_state\",\n",
    "    # \"tools_used\",  # â† ä»Šã¯ç„¡ã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ\n",
    "]\n",
    "\n",
    "# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã ã‘ã‚’ä½¿ã†\n",
    "fp_cols = [c for c in candidate_cols if c in fp_df.columns]\n",
    "fn_cols = [c for c in candidate_cols if c in fn_df.columns]\n",
    "\n",
    "print(\"FP columns:\", fp_cols)\n",
    "display(fp_df[fp_cols].head(20))\n",
    "\n",
    "print(\"FN columns:\", fn_cols)\n",
    "display(fn_df[fn_cols].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7954ed-cd6b-4d8b-8a75-cb788ee0d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# åˆ—ã‚’çœç•¥ã›ãšè¡¨ç¤º\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# æ¨ªå¹…ã‚’åºƒã’ã‚‹ï¼ˆå¥½ã¿ã§èª¿æ•´ï¼‰\n",
    "pd.set_option(\"display.width\", 200)\n",
    "# é•·ã„æ–‡å­—åˆ—ã‚‚çœç•¥ã—ãªã„\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd75ed-4ac9-4cf2-80b5-380f2b16494b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb328b-9b2d-4059-9b47-3205535374e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP ã®å…¨åˆ—ãƒ»å…¨è¡Œ\n",
    "#display(fp_df)\n",
    "\n",
    "# FN ã®å…¨åˆ—ãƒ»å…¨è¡Œ\n",
    "display(fn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dce5d-19e9-45a0-9850-d39b9a2baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FP / FN åˆ†æCSVã®ç”Ÿæˆï¼ˆeval_id å›ºå®šãƒ»å‚ç…§å…ƒå›ºå®šç‰ˆï¼‰\n",
    "#   - 500ä»¶ã”ã¨ã«ã€Œè¿½è¨˜ã€ä¿å­˜ï¼ˆåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã‚‰ãªã„ï¼‰\n",
    "#   - ç«¯æ•°ã‚‚æ¨ã¦ãšã«ä¿å­˜\n",
    "#   - é€²æ—è¡¨ç¤ºã‚ã‚Š\n",
    "#   - ä¸€æ™‚åœæ­¢: LOGS_DIR/_PAUSE_FP_FN_EXPORT ãŒå­˜åœ¨ã™ã‚‹ã¨æ¬¡chunkæ‰‹å‰ã§åœæ­¢\n",
    "#   - å†é–‹: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆ.checkpoint.jsonï¼‰ã§é‡è¤‡è¿½è¨˜ã‚’é˜²æ­¢\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(\"=== Export FP/FN analysis CSVs (append mode, eval_id-fixed) ===\")\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# è¿½è·¡ç”¨ã®æŒ‡ç´‹åˆ—ï¼ˆå­˜åœ¨ã™ã‚‹åˆ†ã ã‘ä½¿ã†ï¼‰\n",
    "FINGERPRINT_COLS = [\n",
    "    \"eval_id\",\n",
    "    \"phase6_policy_version_code\",\n",
    "    \"phase6_wiring_file\",\n",
    "    \"phase6_wiring_sha256\",\n",
    "    \"llm_final_decision_file\",\n",
    "    \"llm_final_decision_sha256\",\n",
    "    \"langgraph_module_file\",\n",
    "    \"langgraph_module_sha256\",\n",
    "    \"dual_import_langgraph_module\",\n",
    "]\n",
    "\n",
    "BASE_CASE_COLS = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "]\n",
    "\n",
    "def _infer_eval_id(*dfs) -> str:\n",
    "    # 1) CODE_FP_ROW ã‚’æœ€å„ªå…ˆï¼ˆNotebookå®Ÿè¡Œå˜ä½ã§å›ºå®šã•ã‚Œã‚‹æƒ³å®šï¼‰\n",
    "    if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "        _eid = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "        if _eid:\n",
    "            return str(_eid)\n",
    "\n",
    "    # 2) å„DFã® eval_id ãŒå˜ä¸€ãªã‚‰ãã‚Œã‚’æ¡ç”¨\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame) and \"eval_id\" in df.columns:\n",
    "            vals = df[\"eval_id\"].dropna().astype(str).unique()\n",
    "            if len(vals) == 1:\n",
    "                return vals[0]\n",
    "\n",
    "    # 3) æœ€å¾Œã®æ‰‹æ®µ\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def _existing(cols, df):\n",
    "    return [c for c in cols if isinstance(df, pd.DataFrame) and c in df.columns]\n",
    "\n",
    "\n",
    "def _load_ckpt(path: Path) -> int:\n",
    "    \"\"\"checkpoint ã‹ã‚‰ next_start ã‚’èª­ã‚€ï¼ˆç„¡ã‘ã‚Œã°0ï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        if path.exists():\n",
    "            obj = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "            n = int(obj.get(\"next_start\", 0))\n",
    "            return max(0, n)\n",
    "    except Exception:\n",
    "        return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _save_ckpt(path: Path, next_start: int) -> None:\n",
    "    try:\n",
    "        path.write_text(json.dumps({\"next_start\": int(next_start)}, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def _append_df_in_chunks(df_in: pd.DataFrame, out_path: Path, ckpt_path: Path, pause_path: Path, tag: str):\n",
    "    \"\"\"\n",
    "    df_in ã‚’ out_path ã« 500è¡Œã”ã¨è¿½è¨˜ã™ã‚‹ã€‚\n",
    "    - ckpt_path ã® next_start ã‹ã‚‰å†é–‹ï¼ˆé‡è¤‡è¿½è¨˜é˜²æ­¢ï¼‰\n",
    "    - pause_path ãŒã‚ã‚Œã°æ¬¡chunkæ‰‹å‰ã§åœæ­¢ï¼ˆç«¯æ•°ã¯æ¨ã¦ãªã„ï¼‰\n",
    "    \"\"\"\n",
    "    total = int(len(df_in))\n",
    "    start = _load_ckpt(ckpt_path)\n",
    "\n",
    "    # æ—¢å­˜CSVãŒç„¡ã„ã®ã« start>0 ã¯çŸ›ç›¾ â†’ 0ã«æˆ»ã™\n",
    "    if start > 0 and (not out_path.exists()):\n",
    "        start = 0\n",
    "        _save_ckpt(ckpt_path, 0)\n",
    "\n",
    "    # ãƒ˜ãƒƒãƒ€ã®æœ‰ç„¡: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¦ã‚µã‚¤ã‚º>0ãªã‚‰ header=False\n",
    "    wrote_any = out_path.exists() and (out_path.stat().st_size > 0)\n",
    "\n",
    "    if total == 0:\n",
    "        # ç©ºã§ã‚‚ãƒ˜ãƒƒãƒ€ã ã‘ä½œã£ã¦ãŠãï¼ˆå¾Œå·¥ç¨‹ã®å­˜åœ¨ç¢ºèªãŒæ¥½ï¼‰\n",
    "        if not wrote_any:\n",
    "            df_in.head(0).to_csv(out_path, index=False)\n",
    "        return {\"path\": str(out_path), \"total\": total, \"written\": 0, \"start\": start, \"paused\": False}\n",
    "\n",
    "    if start >= total:\n",
    "        print(f\"[EXPORT:{tag}] already complete: {total}/{total} -> {out_path.name}\")\n",
    "        return {\"path\": str(out_path), \"total\": total, \"written\": 0, \"start\": start, \"paused\": False}\n",
    "\n",
    "    t0 = time.time()\n",
    "    written = 0\n",
    "    paused = False\n",
    "\n",
    "    for s in range(start, total, CHUNK_SIZE):\n",
    "        if pause_path.exists():\n",
    "            print(f\"[PAUSE] {pause_path} exists. Stop before writing chunk {s}:{min(s+CHUNK_SIZE,total)} for {out_path.name}\")\n",
    "            paused = True\n",
    "            break\n",
    "\n",
    "        e = min(s + CHUNK_SIZE, total)\n",
    "        chunk_df = df_in.iloc[s:e]\n",
    "        chunk_df.to_csv(out_path, mode=\"a\", header=(not wrote_any), index=False)\n",
    "        wrote_any = True\n",
    "        written += int(len(chunk_df))\n",
    "        _save_ckpt(ckpt_path, e)\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"[EXPORT:{tag}] {e}/{total} appended -> {out_path.name}  (elapsed={elapsed:.1f}s)\")\n",
    "\n",
    "    return {\"path\": str(out_path), \"total\": total, \"written\": written, \"start\": start, \"paused\": paused}\n",
    "\n",
    "\n",
    "def _export_cases_and_details(*, full_df: pd.DataFrame, label: int, dataset_tag: str, out_dir: Path, pause_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    full_dfï¼ˆï¼ãã®å®Ÿè¡Œã§ä½œã£ãŸfull_eval DFï¼‰ã ã‘ã‚’å‚ç…§ã—ã¦ FN/FP ã‚’ä½œã‚Šã€500ä»¶ã”ã¨ã«è¿½è¨˜ä¿å­˜ã™ã‚‹ã€‚\n",
    "\n",
    "    - label=1: FNï¼ˆçœŸ:phish ãªã®ã« AIãŒ benign ã¨åˆ¤å®šï¼‰\n",
    "    - label=0: FPï¼ˆçœŸ:benign ãªã®ã« AIãŒ phish ã¨åˆ¤å®šï¼‰\n",
    "\n",
    "    é‡è¦:\n",
    "      - åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä½œã‚‰ãªã„ï¼ˆçµåˆãƒŸã‚¹é˜²æ­¢ï¼‰\n",
    "      - debug_log ç­‰ã®æƒ…å ±é‡ã¯å‰Šã‚‰ãªã„ï¼ˆdetailsã¯è©²å½“è¡Œã‚’ä¸¸ã”ã¨ï¼‰\n",
    "      - å†é–‹ã¯ checkpoint ã§åˆ¶å¾¡ï¼ˆCSVã®æ”¹è¡Œæ··å…¥ãŒã‚ã‚‹ã®ã§è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆã¯å±é™ºï¼‰\n",
    "    \"\"\"\n",
    "    assert isinstance(full_df, pd.DataFrame)\n",
    "\n",
    "    eval_id = _infer_eval_id(full_df)\n",
    "    fp_cols = _existing(FINGERPRINT_COLS, full_df)\n",
    "\n",
    "    df = full_df.copy()\n",
    "    df[\"label\"] = int(label)\n",
    "\n",
    "    if int(label) == 1:\n",
    "        # FN: phishing(1) ãªã®ã« ai_is_phishing=False\n",
    "        kind = \"fn\"\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == False)\n",
    "    else:\n",
    "        # FP: benign(0) ãªã®ã« ai_is_phishing=True\n",
    "        kind = \"fp\"\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == True)\n",
    "\n",
    "    # cases: è»½é‡ï¼ˆåˆ†æè»¸ + fingerprintï¼‰\n",
    "    cases_cols = _existing(BASE_CASE_COLS, df) + fp_cols\n",
    "    cases_df = df.loc[cases_mask, cases_cols].copy()\n",
    "\n",
    "    # details: æƒ…å ±é‡ã‚’è½ã¨ã•ãªã„ï¼ˆè©²å½“è¡Œã‚’ä¸¸ã”ã¨ï¼‰\n",
    "    details_df = df.loc[cases_mask].copy()\n",
    "\n",
    "    n_total = int(len(df))\n",
    "    n_cases = int(len(cases_df))\n",
    "\n",
    "    cases_path = out_dir / f\"{kind}_cases_full_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "    details_path = out_dir / f\"{kind}_details_full_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "\n",
    "    cases_ckpt = out_dir / f\"{cases_path.name}.checkpoint.json\"\n",
    "    details_ckpt = out_dir / f\"{details_path.name}.checkpoint.json\"\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"[EXPORT] {kind.upper()} {dataset_tag}  cases={n_cases}/{n_total}  chunk={CHUNK_SIZE}\")\n",
    "\n",
    "    cases_info = _append_df_in_chunks(cases_df, cases_path, cases_ckpt, pause_path, f\"{kind}-cases:{dataset_tag}\")\n",
    "    details_info = _append_df_in_chunks(details_df, details_path, details_ckpt, pause_path, f\"{kind}-details:{dataset_tag}\")\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_tag,\n",
    "        \"label\": int(label),\n",
    "        \"kind\": kind,\n",
    "        \"eval_id\": eval_id,\n",
    "        \"n_total\": n_total,\n",
    "        \"n_cases\": n_cases,\n",
    "        \"cases_path\": str(cases_path),\n",
    "        \"details_path\": str(details_path),\n",
    "        \"cases_checkpoint\": str(cases_ckpt),\n",
    "        \"details_checkpoint\": str(details_ckpt),\n",
    "        \"paused\": bool(cases_info.get(\"paused\") or details_info.get(\"paused\")),\n",
    "    }\n",
    "\n",
    "\n",
    "# å‡ºåŠ›å…ˆï¼ˆè¦ä»¶: run_id/logs é…ä¸‹ã¸å›ºå®šï¼‰\n",
    "if \"LOGS_DIR\" not in globals() or not globals().get(\"LOGS_DIR\"):\n",
    "    raise RuntimeError(\"LOGS_DIR is not set. Run Cell 1 first.\")\n",
    "out_dir = Path(globals()[\"LOGS_DIR\"]).resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ä¸€æ™‚åœæ­¢ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã“ã“ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã¨æ¬¡chunkæ‰‹å‰ã§åœæ­¢ï¼‰\n",
    "pause_path = out_dir / \"_PAUSE_FP_FN_EXPORT\"\n",
    "\n",
    "manifest = []\n",
    "\n",
    "# --- randomï¼ˆphishæƒ³å®šï¼‰: results_df ãŒ full_eval ---\n",
    "if \"results_df\" in globals() and isinstance(globals().get(\"results_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"results_df\"],\n",
    "            label=1,\n",
    "            dataset_tag=f\"random{len(globals()['results_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) results_df not found -> random FN export skipped\")\n",
    "\n",
    "# --- benign: benign_agent_df ãŒ full_eval ---\n",
    "if \"benign_agent_df\" in globals() and isinstance(globals().get(\"benign_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign{len(globals()['benign_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_agent_df not found -> benign FP export skipped\")\n",
    "\n",
    "# --- benign_hard ---\n",
    "if \"benign_hard_agent_df\" in globals() and isinstance(globals().get(\"benign_hard_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_hard_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign_hard{len(globals()['benign_hard_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_hard_agent_df not found -> hard FP export skipped\")\n",
    "\n",
    "# å¿µã®ãŸã‚ï¼ˆNoneæ··å…¥äº‹æ•…é˜²æ­¢ï¼‰\n",
    "manifest = [m for m in manifest if isinstance(m, dict)]\n",
    "\n",
    "manifest_df = pd.DataFrame(manifest)\n",
    "manifest_eval_id = _infer_eval_id(*(globals().get(n) for n in [\"results_df\", \"benign_agent_df\", \"benign_hard_agent_df\"]))\n",
    "manifest_path = out_dir / f\"analysis_manifest__evalid_{manifest_eval_id}.csv\"\n",
    "manifest_df.to_csv(manifest_path, index=False)\n",
    "\n",
    "print(\"\\nSaved analysis CSVs to:\")\n",
    "for r in manifest:\n",
    "    print(f\"  - {str(r['kind']).upper()} {r['dataset']}: {r['n_cases']}/{r['n_total']}  paused={r.get('paused')}\")\n",
    "    print(f\"      cases      : {r['cases_path']}\")\n",
    "    print(f\"      details    : {r['details_path']}\")\n",
    "    print(f\"      cases_ckpt : {r['cases_checkpoint']}\")\n",
    "    print(f\"      details_ckpt: {r['details_checkpoint']}\")\n",
    "print(f\"  - manifest : {manifest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c686c-5124-4492-8148-07ffc87a3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Preview: FP / FN casesï¼ˆä¸Šä½ã ã‘è¡¨ç¤ºï¼‰\n",
    "# =========================\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== Preview (top cases) ===\")\n",
    "\n",
    "def _preview(df, title, n=10, sort_col=None, ascending=False):\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or len(df)==0:\n",
    "        print(f\"  (none) {title}\")\n",
    "        return\n",
    "    _df=df.copy()\n",
    "    if sort_col and sort_col in _df.columns:\n",
    "        _df=_df.sort_values(sort_col, ascending=ascending)\n",
    "    display(_df.head(n))\n",
    "\n",
    "# random FN\n",
    "if \"results_df\" in globals() and isinstance(globals().get(\"results_df\"), pd.DataFrame):\n",
    "    fn_df_preview = globals()[\"results_df\"][globals()[\"results_df\"][\"ai_is_phishing\"]==False][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\"] if c in globals()[\"results_df\"].columns]\n",
    "    ]\n",
    "    print(f\"random FN: {len(fn_df_preview)}/{len(globals()['results_df'])}\")\n",
    "    _preview(fn_df_preview, \"random FN (ml_probability desc)\", n=15, sort_col=\"ml_probability\", ascending=False)\n",
    "\n",
    "# benign FP\n",
    "if \"benign_agent_df\" in globals() and isinstance(globals().get(\"benign_agent_df\"), pd.DataFrame):\n",
    "    fp_df_preview = globals()[\"benign_agent_df\"][globals()[\"benign_agent_df\"][\"ai_is_phishing\"]==True][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\",\"detected_brands\"] if c in globals()[\"benign_agent_df\"].columns]\n",
    "    ]\n",
    "    print(f\"benign FP: {len(fp_df_preview)}/{len(globals()['benign_agent_df'])}\")\n",
    "    _preview(fp_df_preview, \"benign FP (ml_probability desc)\", n=20, sort_col=\"ml_probability\", ascending=False)\n",
    "\n",
    "# benign_hard FP\n",
    "if \"benign_hard_agent_df\" in globals() and isinstance(globals().get(\"benign_hard_agent_df\"), pd.DataFrame):\n",
    "    fp_hard_preview = globals()[\"benign_hard_agent_df\"][globals()[\"benign_hard_agent_df\"][\"ai_is_phishing\"]==True][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\",\"detected_brands\"] if c in globals()[\"benign_hard_agent_df\"].columns]\n",
    "    ]\n",
    "    print(f\"benign_hard FP: {len(fp_hard_preview)}/{len(globals()['benign_hard_agent_df'])}\")\n",
    "    _preview(fp_hard_preview, \"benign_hard FP (ml_probability desc)\", n=20, sort_col=\"ml_probability\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa2916-6315-4f1c-867b-cfe9f42252d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === ConfusionResult ã‹ã‚‰æ··åŒè¡Œåˆ—ã‚’ä½œæˆ ===\n",
    "cm = np.array([\n",
    "    [metrics_agent.TN, metrics_agent.FP],\n",
    "    [metrics_agent.FN, metrics_agent.TP],\n",
    "])\n",
    "\n",
    "labels = [\"benign (0)\", \"phish (1)\"]\n",
    "\n",
    "# å¯è¦–åŒ–ã—ãŸã„æŒ‡æ¨™ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¢—æ¸›ã•ã›ã¦ãã ã•ã„ï¼‰\n",
    "score_names = [\"precision\", \"recall\", \"f1\", \"fbeta\", \"fpr\"]\n",
    "score_values = [\n",
    "    metrics_agent.precision,\n",
    "    metrics_agent.recall,\n",
    "    metrics_agent.f1,\n",
    "    metrics_agent.fbeta,\n",
    "    metrics_agent.fpr,\n",
    "]\n",
    "\n",
    "# === æç”» ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 1) æ··åŒè¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "ax = axes[0]\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "# è»¸ãƒ©ãƒ™ãƒ«\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
    "ax.set_yticklabels([\"True 0\", \"True 1\"])\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_title(\"Confusion Matrix (Agent)\")\n",
    "\n",
    "# å€¤ã‚’ãƒã‚¹ã®ä¸Šã«è¡¨ç¤º\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(\n",
    "            j, i,\n",
    "            cm[i, j],\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# 2) Precision / Recall / F1 / Fbeta / FPR ã®æ£’ã‚°ãƒ©ãƒ•\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(score_names))\n",
    "ax2.bar(x, score_values)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(score_names, rotation=30)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "ax2.set_ylabel(\"Score\")\n",
    "ax2.set_title(\"Agent Metrics (eval_df)\")\n",
    "\n",
    "# å€¤ã‚’æ£’ã®ä¸Šã«è¡¨ç¤ºï¼ˆå°æ•°3æ¡ï¼‰\n",
    "for i, v in enumerate(score_values):\n",
    "    ax2.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18807a01-7020-4be8-99b7-771d86c83f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43616881-c74e-4902-a2c0-41b7e67af685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7035e94-c14a-43d2-9439-7ea533b6cbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
