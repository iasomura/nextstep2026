{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09461286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SET] N_SAMPLE= 500 N_BENIGN_SAMPLE= 500 N_BENIGN_HARD_SAMPLE= 500\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 0: 実験件数の設定（phish/random=100, benign=100, benign_hard=100）\n",
    "# ============================================\n",
    "# [ChangeLog] 2025-12-15: N_* に ALL/0/-1 を指定すると全件処理できるように拡張\n",
    "\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ▼▼▼ ここだけ編集すればOK（優先度: 環境変数 > ここ） ▼▼▼\n",
    "#   - \"500\" のように数値 → その件数だけ処理\n",
    "#   - \"ALL\" / 0 / -1     → 全件処理（制限なし）\n",
    "# ------------------------------------------------------------\n",
    "DEFAULT_N_SAMPLE = \"500\"\n",
    "DEFAULT_N_BENIGN_SAMPLE = DEFAULT_N_SAMPLE\n",
    "DEFAULT_N_BENIGN_HARD_SAMPLE = \"500\"\n",
    "\n",
    "def _normalize_n_env(key: str, default: str) -> str:\n",
    "    \"\"\"環境変数 N_* を正規化して os.environ に入れる。\n",
    "    - 1以上: その件数を処理\n",
    "    - 0 / -1 / 'ALL' / '*' / 'FULL': 全件処理（制限なし）\n",
    "    \"\"\"\n",
    "    raw = os.getenv(key, default)\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # 人間向けの指定（ALL 等）→ 数値センチネルへ\n",
    "    if s.upper() in (\"ALL\", \"*\", \"FULL\"):\n",
    "        return \"-1\"\n",
    "\n",
    "    # 数値化（変な値なら default にフォールバック）\n",
    "    try:\n",
    "        n = int(float(s))\n",
    "    except Exception:\n",
    "        try:\n",
    "            n = int(default)\n",
    "        except Exception:\n",
    "            n = -1\n",
    "    # ★ 0 / 負値 は ALL 扱い（-1 に寄せる）\n",
    "    return \"-1\" if n <= 0 else str(n)\n",
    "def _n_label(n_str: str) -> str:\n",
    "    \"\"\"表示用: -1/0 以下は ALL と見せる\"\"\"\n",
    "    try:\n",
    "        n = int(str(n_str).strip())\n",
    "    except Exception:\n",
    "        return str(n_str)\n",
    "    return \"ALL\" if n <= 0 else str(n)\n",
    "\n",
    "# 3群の件数\n",
    "os.environ[\"N_SAMPLE\"] = _normalize_n_env(\"N_SAMPLE\", DEFAULT_N_SAMPLE)\n",
    "os.environ[\"N_BENIGN_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_SAMPLE\", DEFAULT_N_BENIGN_SAMPLE)\n",
    "os.environ[\"N_BENIGN_HARD_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_HARD_SAMPLE\", DEFAULT_N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "print(\"[SET] N_SAMPLE=\", _n_label(os.environ[\"N_SAMPLE\"]),\n",
    "      \"N_BENIGN_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_SAMPLE\"]),\n",
    "      \"N_BENIGN_HARD_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_HARD_SAMPLE\"]),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed1e38e-e956-482d-b6f5-28796ade11b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N_SAMPLE=500, N_BENIGN_SAMPLE=500, RANDOM_STATE=42\n",
      "[NX] RUN_ID = 2025-12-07_143907 | paths.RUN_ID = 2025-12-07_143907\n",
      "[INFO] BASE_DIR      = /home/asomura/backup/nextstep\n",
      "[INFO] RUN_ID        = 2025-12-07_143907\n",
      "[INFO] ARTIFACTS_DIR = artifacts/2025-12-07_143907\n",
      "[INFO] HANDOFF_DIR   = artifacts/2025-12-07_143907/handoff\n",
      "[OK] Handoff directory found: artifacts/2025-12-07_143907/handoff\n",
      "[OK] Target pickle found: 04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] Current Timestamp: 2025-12-21_233447\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 1: 環境設定と初期化（Cell0方式でRUN_ID決定）\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "import datetime\n",
    "import run_id_registry as runreg\n",
    "import importlib\n",
    "import _compat.paths as paths\n",
    "# ---------------------------------------------------------\n",
    "# ▼▼▼ Evaluation sample size (variable) ▼▼▼\n",
    "# ---------------------------------------------------------\n",
    "N_SAMPLE = int(os.getenv(\"N_SAMPLE\", \"300\"))\n",
    "N_BENIGN_SAMPLE = int(os.getenv(\"N_BENIGN_SAMPLE\", str(N_SAMPLE)))\n",
    "RANDOM_STATE = int(os.getenv(\"RANDOM_STATE\", \"42\"))\n",
    "def _n_label(n: int) -> str:\n",
    "    return \"ALL\" if int(n) <= 0 else str(int(n))\n",
    "print(f\"[INFO] N_SAMPLE={_n_label(N_SAMPLE)}, N_BENIGN_SAMPLE={_n_label(N_BENIGN_SAMPLE)}, RANDOM_STATE={RANDOM_STATE}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# プロジェクトルート推定\n",
    "# ---------------------------------------------------------\n",
    "BASE_DIR = Path(os.environ.get(\"NEXTSTEP_BASE_DIR\", \".\")).resolve()\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# [ChangeLog] 2025-12-16: sys.path から BASE_DIR/phishing_agent を除去（重複 import を防ぎ、Phase6 wiring を確実化）\n",
    "# NOTE: パッケージ import を安定させるため、sys.path には「プロジェクトルート(BASE_DIR)」だけを入れる。\n",
    "#       BASE_DIR/phishing_agent を入れると `langgraph_module` などがトップレベル import され、\n",
    "#       `phishing_agent.langgraph_module` と二重ロードになり Phase6 のモンキーパッチが効かないことがある。\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "# 念のため誤ったパスを消す（存在していれば）\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ▼▼▼ RUN_ID の決定: 02以降共通 Cell0 と同じ方式 ▼▼▼\n",
    "#   rid = runreg.bootstrap()  # env→run_id.txt→Part3→latest→新規\n",
    "#   paths を reload して paths.RUN_ID を確定\n",
    "#   rid と paths.RUN_ID がズレたら即検知\n",
    "# ---------------------------------------------------------\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.bootstrap()  # ここで env RUN_ID をセットする想定（念のため下で明示上書き）\n",
    "\n",
    "# 念のため env を rid で固定（bootstrapがセットしていても害はない）\n",
    "os.environ[\"RUN_ID\"] = rid\n",
    "\n",
    "# _compat.paths (または paths) を読み込み、env(RUN_ID) を反映させる\n",
    "try:\n",
    "    import _compat.paths as paths\n",
    "except ImportError:\n",
    "    import paths as paths  # fallback\n",
    "\n",
    "importlib.reload(paths)  # Cell0方式（必要なら2回でも可だが通常1回で十分）\n",
    "\n",
    "# デバッグ表示＆ズレ検知\n",
    "print(\"[NX] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n",
    "assert paths.RUN_ID == rid, f\"RUN_ID mismatch: rid={rid} paths.RUN_ID={paths.RUN_ID}\"\n",
    "\n",
    "# 最終採用（ディレクトリ決定に使うのは paths.RUN_ID）\n",
    "RUN_ID = paths.RUN_ID\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# artifacts/<RUN_ID>/... 配下の各ディレクトリ設定\n",
    "# ---------------------------------------------------------\n",
    "ARTIFACTS_DIR = Path(paths.ARTIFACTS) if hasattr(paths, \"ARTIFACTS\") else (BASE_DIR / \"artifacts\" / RUN_ID)\n",
    "RAW_DIR       = Path(paths.compat_base_dirs[\"raw\"])\n",
    "PROCESSED_DIR = Path(paths.compat_base_dirs[\"data\"])\n",
    "MODELS_DIR    = Path(paths.compat_base_dirs[\"models\"])\n",
    "RESULTS_DIR   = Path(paths.compat_base_dirs[\"results\"])\n",
    "HANDOFF_DIR   = Path(paths.compat_base_dirs[\"handoff\"])\n",
    "LOGS_DIR      = Path(paths.compat_base_dirs[\"logs\"])\n",
    "TRACES_DIR    = Path(paths.compat_base_dirs[\"traces\"])\n",
    "\n",
    "print(f\"[INFO] BASE_DIR      = {BASE_DIR}\")\n",
    "print(f\"[INFO] RUN_ID        = {RUN_ID}\")\n",
    "print(f\"[INFO] ARTIFACTS_DIR = {ARTIFACTS_DIR}\")\n",
    "print(f\"[INFO] HANDOFF_DIR   = {HANDOFF_DIR}\")\n",
    "\n",
    "# Handoffディレクトリの存在確認\n",
    "if HANDOFF_DIR.exists():\n",
    "    print(f\"[OK] Handoff directory found: {HANDOFF_DIR}\")\n",
    "    target_pkl = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "    if target_pkl.exists():\n",
    "        print(f\"[OK] Target pickle found: {target_pkl.name}\")\n",
    "    else:\n",
    "        print(f\"[WARN] Target pickle NOT found in this directory.\")\n",
    "else:\n",
    "    print(f\"[WARN] Handoff directory NOT found. Check RUN_ID logic.\")\n",
    "\n",
    "# 出力用のタイムスタンプ\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "print(f\"[INFO] Current Timestamp: {timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] external_data loaded from: artifacts/2025-12-07_143907/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] Added 33 new brands\n",
      "[INFO] Total brand_keywords: 35\n",
      "\n",
      "[Brand Check]\n",
      "  mufg            ✅\n",
      "  smbc            ✅\n",
      "  amazon          ✅\n",
      "  mercari         ✅\n",
      "  rakuten         ✅\n",
      "  metamask        ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2: External Dataの読み込みとBrand Keywords補強\n",
    "# ============================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "# handoffからexternal_dataを読み込み\n",
    "handoff_path = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "\n",
    "if not handoff_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Handoff file not found: {handoff_path}\\n\"\n",
    "        \"04-3_llm_tools_setup_with_tools を先に実行して、artifacts/<RUN_ID>/handoff 配下に配置してください。\"\n",
    "    )\n",
    "\n",
    "with open(handoff_path, 'rb') as f:\n",
    "    external_data = pickle.load(f)\n",
    "\n",
    "print(f\"[INFO] external_data loaded from: {handoff_path}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Brand Keywords 補強ロジック（元ノートの動作を踏襲）\n",
    "# --------------------------------------------------\n",
    "\n",
    "# 既存の brand_keywords を取得（無ければ空リスト）\n",
    "brand_keywords = external_data.get(\"brand_keywords\") or []\n",
    "brands_lower = [b.lower() for b in brand_keywords]\n",
    "\n",
    "# 論文・実験で重視したいブランド（不足していたものを補う）\n",
    "essential_brands = [\n",
    "    \"mufg\", \"mufg-card\", \"mitsubishi-ufj\", \"三菱UFJ\", \"三菱ＵＦＪ\",\n",
    "    \"smbc\", \"smbc-card\", \"三井住友カード\", \"三井住友銀行\",\n",
    "    \"rakuten\", \"rakuten-card\", \"楽天カード\", \"楽天銀行\",\n",
    "    \"amazon\", \"amazon-jp\", \"amazon.co.jp\",\n",
    "    \"mercari\", \"メルカリ\",\n",
    "    \"metamask\", \"binance\", \"bybit\",\n",
    "    # ▼▼▼ 追加分 ▼▼▼\n",
    "    \"sbi\", \"sbisec\", \"sumishin\", \"住信SBI\",\n",
    "    \"telegram\", \"tg\",\n",
    "    \"makuake\",\n",
    "    \"aeon\", \"aeonbank\", \"イオン銀行\",\n",
    "    \"jcb\",\n",
    "    \"imad\"\n",
    "]\n",
    "\n",
    "added_brands = []\n",
    "for brand in essential_brands:\n",
    "    if brand.lower() not in brands_lower:\n",
    "        external_data.setdefault('brand_keywords', []).append(brand)\n",
    "        added_brands.append(brand)\n",
    "        brands_lower.append(brand.lower())\n",
    "\n",
    "print(f\"[INFO] Added {len(added_brands)} new brands\")\n",
    "print(f\"[INFO] Total brand_keywords: {len(external_data['brand_keywords'])}\")\n",
    "\n",
    "# 主要ブランドの確認表示\n",
    "check_brands = [\"mufg\", \"smbc\", \"amazon\", \"mercari\", \"rakuten\", \"metamask\"]\n",
    "print(\"\\n[Brand Check]\")\n",
    "for brand in check_brands:\n",
    "    exists = brand in [b.lower() for b in external_data['brand_keywords']]\n",
    "    status = \"✅\" if exists else \"❌\"\n",
    "    print(f\"  {brand:15} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ed7391-2b52-48c6-8074-709de2e26a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] Loading additional data from 04-2\n",
      "================================================================================\n",
      "[INFO] Found 04-2 at: artifacts/2025-12-07_143907/handoff/04-2_statistical_analysis.pkl\n",
      "[INFO] 04-2 loaded successfully\n",
      "[INFO] 04-2 keys: ['cfg', 'RUN_ID', 'SESSION_ID', 'output_dirs', 'brand_keywords', 'cert_full_info_map', 'false_negatives_df', 'fn_features_df', 'HIGH_RISK_WORDS', 'suspicious_words_stats']...\n",
      "  ✅ Added dangerous_tlds: NoneType (len=N/A)\n",
      "  ✅ Added legitimate_tlds: NoneType (len=N/A)\n",
      "  ✅ Added neutral_tlds: NoneType (len=N/A)\n",
      "  ✅ Added phishing_tld_stats: DataFrame (len=177)\n",
      "  ✅ Added high_risk_words: list (len=2)\n",
      "  ✅ Added known_domains: dict (len=4148)\n",
      "\n",
      "[INFO] Added 6 data items from 04-2\n",
      "\n",
      "================================================================================\n",
      "[INFO] Final Data Availability Check\n",
      "================================================================================\n",
      "  ✅ Brand keywords list            (len=35)\n",
      "  ✅ Certificate information        (len=4148)\n",
      "  ✅ Dangerous TLDs                 (len=N/A)\n",
      "  ✅ Legitimate TLDs                (len=N/A)\n",
      "  ✅ Neutral TLDs                   (len=N/A)\n",
      "  ✅ TLD phishing statistics        (len=177)\n",
      "  ✅ High risk words                (len=2)\n",
      "  ✅ Known legitimate domains       (len=4148)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2の最後に追加: 04-2から不足データを補完\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Loading additional data from 04-2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 04-2のパスを探索\n",
    "pickle_04_2_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "]\n",
    "\n",
    "data_04_2 = None\n",
    "for path in pickle_04_2_paths:\n",
    "    if path.exists():\n",
    "        print(f\"[INFO] Found 04-2 at: {path}\")\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                data_04_2 = pickle.load(f)\n",
    "            print(f\"[INFO] 04-2 loaded successfully\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {path}: {e}\")\n",
    "\n",
    "if data_04_2 is None:\n",
    "    print(\"[WARN] 04-2 not found, continuing with available data\")\n",
    "else:\n",
    "    print(f\"[INFO] 04-2 keys: {list(data_04_2.keys())[:10]}...\")\n",
    "    \n",
    "    # TLD関連データを追加\n",
    "    tld_keys = [\n",
    "        'dangerous_tlds', 'DANGEROUS_TLDS',\n",
    "        'legitimate_tlds', 'LEGITIMATE_TLDS',\n",
    "        'neutral_tlds', 'NEUTRAL_TLDS',\n",
    "        'phishing_tld_stats', 'TLD_STATS', 'tld_stats'\n",
    "    ]\n",
    "    \n",
    "    added_count = 0\n",
    "    for key in tld_keys:\n",
    "        if key in data_04_2:\n",
    "            # 標準化されたキー名にマッピング\n",
    "            standard_key = key.lower()\n",
    "            if 'dangerous' in standard_key:\n",
    "                target_key = 'dangerous_tlds'\n",
    "            elif 'legitimate' in standard_key:\n",
    "                target_key = 'legitimate_tlds'\n",
    "            elif 'neutral' in standard_key:\n",
    "                target_key = 'neutral_tlds'\n",
    "            elif 'tld' in standard_key and 'stat' in standard_key:\n",
    "                target_key = 'phishing_tld_stats'\n",
    "            else:\n",
    "                target_key = key\n",
    "            \n",
    "            if target_key not in external_data:\n",
    "                external_data[target_key] = data_04_2[key]\n",
    "                value = data_04_2[key]\n",
    "                size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "                print(f\"  ✅ Added {target_key}: {type(value).__name__} (len={size})\")\n",
    "                added_count += 1\n",
    "    \n",
    "    # High Risk Words を追加\n",
    "    hrw_keys = ['HIGH_RISK_WORDS', 'high_risk_words', 'high_risk']\n",
    "    for key in hrw_keys:\n",
    "        if key in data_04_2 and 'high_risk_words' not in external_data:\n",
    "            external_data['high_risk_words'] = data_04_2[key]\n",
    "            words = data_04_2[key]\n",
    "            print(f\"  ✅ Added high_risk_words: {type(words).__name__} (len={len(words)})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    # Known Domains を追加\n",
    "    kd_keys = ['KNOWN_DOMAINS', 'known_domains', 'legitimate_domains']\n",
    "    for key in kd_keys:\n",
    "        if key in data_04_2 and 'known_domains' not in external_data:\n",
    "            external_data['known_domains'] = data_04_2[key]\n",
    "            domains = data_04_2[key]\n",
    "            size = len(domains) if hasattr(domains, '__len__') else 'N/A'\n",
    "            print(f\"  ✅ Added known_domains: {type(domains).__name__} (len={size})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n[INFO] Added {added_count} data items from 04-2\")\n",
    "\n",
    "# 最終確認\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Final Data Availability Check\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "required_keys = {\n",
    "    'brand_keywords': 'Brand keywords list',\n",
    "    'cert_full_info_map': 'Certificate information',\n",
    "    'dangerous_tlds': 'Dangerous TLDs',\n",
    "    'legitimate_tlds': 'Legitimate TLDs',\n",
    "    'neutral_tlds': 'Neutral TLDs',\n",
    "    'phishing_tld_stats': 'TLD phishing statistics',\n",
    "    'high_risk_words': 'High risk words',\n",
    "    'known_domains': 'Known legitimate domains'\n",
    "}\n",
    "\n",
    "for key, description in required_keys.items():\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "        print(f\"  ✅ {description:30} (len={size})\")\n",
    "    else:\n",
    "        print(f\"  ❌ {description:30} NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b765008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[External Data Summary]\n",
      "================================================================================\n",
      "[INFO] Expected sources:\n",
      "{'04-2': 'artifacts/2025-12-07_143907/handoff/04-2_statistical_analysis.pkl',\n",
      " '04-3': 'artifacts/2025-12-07_143907/handoff/04-3_llm_tools_setup_with_tools.pkl'}\n",
      "\n",
      "[OK] All required keys exist.\n",
      "\n",
      "[Counts]\n",
      "  brand_keywords     : list         len=35\n",
      "  cert_full_info_map : dict         len=4148\n",
      "  dangerous_tlds     : NoneType     len=N/A\n",
      "  legitimate_tlds    : NoneType     len=N/A\n",
      "  neutral_tlds       : NoneType     len=N/A\n",
      "  phishing_tld_stats : DataFrame    len=177\n",
      "  high_risk_words    : list         len=2\n",
      "  known_domains      : dict         len=4148\n",
      "\n",
      "[TLD Sanity]\n",
      "  ✅ OK: 'com' is NOT in dangerous_tlds.\n",
      "  ✅ OK: No overlaps between dangerous/legitimate/neutral TLD sets.\n",
      "\n",
      "[Known Domains Note]\n",
      "  known_domains type=dict, sample=[('ulnln.cn', True), ('iberoprint.com', True), ('libreriatinta.com', True), ('hilfe-debixapp.com', True), ('liberta-jikohasan.com', True)]\n",
      "  NOTE: If known_domains is a 'seen list' (not a strict whitelist), it should NOT be used for safety mitigation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell X: External Data の取得元と内容サマリ（健全性チェック）\n",
    "# ============================================\n",
    "\n",
    "# このノートブックで使う external_data は、原則ここまでで以下から構築されます：\n",
    "#   1) artifacts/<RUN_ID>/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
    "#   2) (不足分がある場合) artifacts/<RUN_ID>/handoff/04-2_statistical_analysis.pkl\n",
    "# その後、(必要に応じて) brand_keywords を補強しています。\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[External Data Summary]\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "required = [\n",
    "    'brand_keywords',\n",
    "    'cert_full_info_map',\n",
    "    'dangerous_tlds',\n",
    "    'legitimate_tlds',\n",
    "    'neutral_tlds',\n",
    "    'phishing_tld_stats',\n",
    "    'high_risk_words',\n",
    "    'known_domains',\n",
    "]\n",
    "\n",
    "src_hint = {\n",
    "    '04-3': str(HANDOFF_DIR / '04-3_llm_tools_setup_with_tools.pkl'),\n",
    "    '04-2': str(HANDOFF_DIR / '04-2_statistical_analysis.pkl'),\n",
    "}\n",
    "print(\"[INFO] Expected sources:\")\n",
    "pprint(src_hint)\n",
    "\n",
    "missing = [k for k in required if k not in (external_data or {})]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Missing keys in external_data:\")\n",
    "    pprint(missing)\n",
    "else:\n",
    "    print(\"\\n[OK] All required keys exist.\")\n",
    "\n",
    "def _len(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except Exception:\n",
    "        return 'N/A'\n",
    "\n",
    "print(\"\\n[Counts]\")\n",
    "for k in required:\n",
    "    v = (external_data or {}).get(k)\n",
    "    print(f\"  {k:18} : {type(v).__name__:<12} len={_len(v)}\")\n",
    "\n",
    "# None/型ゆらぎ対策: external_data の *tlds が None の場合がある\n",
    "def _as_list(v):\n",
    "    if v is None:\n",
    "        return []\n",
    "    if isinstance(v, str):\n",
    "        return [v]\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        return list(v)\n",
    "    # pandas Series / numpy array 等\n",
    "    try:\n",
    "        return list(v)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# TLD セットの交差チェック（.com が dangerous に混入すると FP/FN 分析が壊れやすい）\n",
    "D = {str(x).lower() for x in _as_list((external_data or {}).get('dangerous_tlds'))}\n",
    "L = {str(x).lower() for x in _as_list((external_data or {}).get('legitimate_tlds'))}\n",
    "N = {str(x).lower() for x in _as_list((external_data or {}).get('neutral_tlds'))}\n",
    "\n",
    "print(\"\\n[TLD Sanity]\")\n",
    "if 'com' in D:\n",
    "    print(\"  ❌ WARNING: 'com' is inside dangerous_tlds. This will over-fire dangerous_tld for normal domains.\")\n",
    "else:\n",
    "    print(\"  ✅ OK: 'com' is NOT in dangerous_tlds.\")\n",
    "\n",
    "overlap_DL = sorted(D & L)\n",
    "overlap_DN = sorted(D & N)\n",
    "overlap_LN = sorted(L & N)\n",
    "if overlap_DL or overlap_DN or overlap_LN:\n",
    "    print(\"  ⚠ Overlaps found (should ideally be empty):\")\n",
    "    if overlap_DL: print(\"    - dangerous ∩ legitimate:\", overlap_DL[:20], \"...\" if len(overlap_DL)>20 else \"\")\n",
    "    if overlap_DN: print(\"    - dangerous ∩ neutral   :\", overlap_DN[:20], \"...\" if len(overlap_DN)>20 else \"\")\n",
    "    if overlap_LN: print(\"    - legitimate ∩ neutral  :\", overlap_LN[:20], \"...\" if len(overlap_LN)>20 else \"\")\n",
    "else:\n",
    "    print(\"  ✅ OK: No overlaps between dangerous/legitimate/neutral TLD sets.\")\n",
    "\n",
    "print(\"\\n[Known Domains Note]\")\n",
    "kd = (external_data or {}).get('known_domains', {})\n",
    "sample_items = list(kd.items())[:5] if isinstance(kd, dict) else []\n",
    "print(f\"  known_domains type={type(kd).__name__}, sample={sample_items}\")\n",
    "print(\"  NOTE: If known_domains is a 'seen list' (not a strict whitelist), it should NOT be used for safety mitigation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CSV not found, generating from pickle...\n",
      "[INFO] Trying: artifacts/2025-12-07_143907/handoff/04-2_statistical_analysis.pkl\n",
      "[INFO] Found DataFrame with 4148 rows\n",
      "[DEBUG] columns: ['domain', 'source', 'prediction_proba', 'confidence']\n",
      "[DEBUG] chosen columns: domain=domain, ml_prob=prediction_proba\n",
      "[INFO] Source rows (normalized): 4148\n",
      "[INFO] Random sample saved to: artifacts/2025-12-07_143907/logs/random_eval_domains_latest.csv (n=500)\n",
      "[INFO] Target sample loaded: 500 domains (N_SAMPLE=500)\n",
      "                 domain  ml_probability\n",
      "0      roesmeraldas.com        0.040932\n",
      "1  calabasaschatter.com        0.084901\n",
      "2         mimpikami.com        0.009163\n",
      "3            tg1.com.cn        0.080132\n",
      "4           nowives.com        0.270551\n",
      "\n",
      "[ML Probability Distribution]\n",
      "  Min:    0.005\n",
      "  Max:    0.500\n",
      "  Mean:   0.199\n",
      "  Median: 0.171\n",
      "  High risk (>0.4): 68 domains\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 3: Randomサンプルデータの準備（件数=N_SAMPLE）\n",
    "# ============================================\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# データ探索用ヘルパー関数\n",
    "def _search_eval_df(obj):\n",
    "    '''dict/list 再帰で DataFrame を探す'''\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        # よくあるキー直参照\n",
    "        for k in (\"false_negatives_df\", \"fn_df\", \"eval_df\", \"random_eval_df\"):\n",
    "            v = obj.get(k)\n",
    "            if isinstance(v, pd.DataFrame):\n",
    "                return v\n",
    "        for v in obj.values():\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    return None\n",
    "\n",
    "def _normalize_eval_df(df):\n",
    "    '''列名の揺れに対応して domain, ml_probability の2列に正規化'''\n",
    "    print(\"[DEBUG] columns:\", list(df.columns))\n",
    "    \n",
    "    # lower → 元名のマップ\n",
    "    lower2orig = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # 1) domain候補\n",
    "    domain_candidates = [\"domain\", \"fqdn\", \"domain_name\", \"hostname\", \"host\", \"requested_host\"]\n",
    "    domain_key = None\n",
    "    for key in domain_candidates:\n",
    "        if key in lower2orig:\n",
    "            domain_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if domain_key is None:\n",
    "        # 部分一致\n",
    "        for c in df.columns:\n",
    "            if any(kw in c.lower() for kw in [\"domain\", \"fqdn\", \"host\", \"url\"]):\n",
    "                domain_key = c\n",
    "                print(f\"[DEBUG] domain fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    # 2) ml_probability候補\n",
    "    ml_candidates = [\"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\", \n",
    "                     \"score\", \"pred_proba\", \"proba\", \"confidence\"]\n",
    "    mlp_key = None\n",
    "    for key in ml_candidates:\n",
    "        if key in lower2orig:\n",
    "            mlp_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if mlp_key is None:\n",
    "        # floatカラムから推測\n",
    "        float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "        for c in float_cols:\n",
    "            if any(kw in c.lower() for kw in [\"prob\", \"score\", \"pred\"]):\n",
    "                mlp_key = c\n",
    "                print(f\"[DEBUG] ml_probability fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    if domain_key is None or mlp_key is None:\n",
    "        print(\"[ERROR] could not infer domain/ml_probability columns\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"[DEBUG] chosen columns: domain={domain_key}, ml_prob={mlp_key}\")\n",
    "    \n",
    "    tmp = df[[domain_key, mlp_key]].copy()\n",
    "    tmp.columns = [\"domain\", \"ml_probability\"]\n",
    "    \n",
    "    # url→domainの正規化\n",
    "    if \"url\" in domain_key.lower():\n",
    "        def _to_domain(x):\n",
    "            if not isinstance(x, str):\n",
    "                return \"\"\n",
    "            if \"://\" in x:\n",
    "                netloc = urlparse(x).netloc\n",
    "            else:\n",
    "                netloc = x\n",
    "            netloc = netloc.split(\"@\")[-1].split(\":\")[0]\n",
    "            return netloc.lower()\n",
    "        tmp[\"domain\"] = tmp[\"domain\"].map(_to_domain)\n",
    "    \n",
    "    # クリーンアップ\n",
    "    tmp[\"domain\"] = tmp[\"domain\"].astype(str).str.strip().str.lower()\n",
    "    tmp = tmp[tmp[\"domain\"].str.len() > 0]\n",
    "    tmp[\"ml_probability\"] = pd.to_numeric(tmp[\"ml_probability\"], errors=\"coerce\")\n",
    "    tmp = tmp[(tmp[\"ml_probability\"] >= 0.0) & (tmp[\"ml_probability\"] <= 1.0)]\n",
    "    tmp = tmp.dropna(subset=[\"ml_probability\"]).reset_index(drop=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# Randomサンプルデータを取得\n",
    "def get_random_domains(sample_size=None):\n",
    "    '''Randomサンプルのドメインリストを取得（件数=sample_size）'''\n",
    "    if sample_size is None:\n",
    "        sample_size = N_SAMPLE\n",
    "    sample_size = int(sample_size)\n",
    "    \n",
    "    # 方法1: 既存のCSVから\n",
    "    csv_paths = [\n",
    "    LOGS_DIR / \"random_eval_domains_latest.csv\",\n",
    "]\n",
    "    \n",
    "    for csv_path in csv_paths:\n",
    "        if csv_path.exists():\n",
    "            print(f\"[INFO] Loading existing CSV from: {csv_path}\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "            # ALL 指定（0/-1）なら、既存CSVが部分サンプルの可能性があるので pickle から再生成する\n",
    "            if sample_size <= 0:\n",
    "                print(f\"[INFO] sample_size={sample_size} (ALL) requested; ignore cache and regenerate from pickle...\")\n",
    "                break\n",
    "            # 既存CSVが要求件数と一致するならそのまま使う。\n",
    "            # もし件数が違う場合は、pickle から再生成する（古いキャッシュを掴まないため）。\n",
    "            if (sample_size > 0) and (len(df) == sample_size):\n",
    "                return df\n",
    "\n",
    "            if (sample_size > 0) and (len(df) > sample_size):\n",
    "                print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; downsampling.\")\n",
    "                return df.sample(n=sample_size, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "            print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; regenerating from pickle...\")\n",
    "            break\n",
    "    \n",
    "    # 方法2: pickleから生成（元のノートブックのロジック）\n",
    "    print(\"[INFO] CSV not found, generating from pickle...\")\n",
    "    \n",
    "    pickle_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "    HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\",\n",
    "]\n",
    "    \n",
    "    eval_source_df = None\n",
    "    for pickle_path in pickle_paths:\n",
    "        if not pickle_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"[INFO] Trying: {pickle_path}\")\n",
    "        try:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                obj = pickle.load(f)\n",
    "            \n",
    "            # DataFrameを探す\n",
    "            raw_df = _search_eval_df(obj)\n",
    "            if raw_df is not None and len(raw_df) > 0:\n",
    "                print(f\"[INFO] Found DataFrame with {len(raw_df)} rows\")\n",
    "                eval_source_df = raw_df\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {pickle_path}: {e}\")\n",
    "    \n",
    "    if eval_source_df is None:\n",
    "        raise RuntimeError(\n",
    "            \"評価用DataFrameが見つかりません。\\n\"\n",
    "            \"04-2 または 04-3 のpickleファイルを確認してください。\"\n",
    "        )\n",
    "    \n",
    "    # 正規化\n",
    "    norm_df = _normalize_eval_df(eval_source_df)\n",
    "    if norm_df is None:\n",
    "        raise RuntimeError(\"DataFrameの正規化に失敗しました\")\n",
    "    \n",
    "    print(f\"[INFO] Source rows (normalized): {len(norm_df)}\")\n",
    "    \n",
    "    # ランダムサンプリング（元のノートブックは固定シードなし）\n",
    "    # [ChangeLog] 2025-12-15: sample_size<=0(ALL) の場合は全件を返す\n",
    "    if sample_size <= 0:\n",
    "        sample_n = len(norm_df)\n",
    "        # 全件処理のときはシャッフルせず、そのまま（再現性・速度優先）\n",
    "        sample_df = norm_df.reset_index(drop=True)\n",
    "    else:\n",
    "        sample_n = min(sample_size, len(norm_df))\n",
    "        sample_df = norm_df.sample(n=sample_n).reset_index(drop=True)\n",
    "    \n",
    "    # CSV保存\n",
    "    out_csv = LOGS_DIR / \"random_eval_domains_latest.csv\"\n",
    "    LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    sample_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Random sample saved to: {out_csv} (n={sample_n})\")\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "# Randomサンプルデータを取得\n",
    "target_df = get_random_domains(sample_size=N_SAMPLE)\n",
    "print(f\"[INFO] Target sample loaded: {len(target_df)} domains (N_SAMPLE={N_SAMPLE})\")\n",
    "print(target_df.head())\n",
    "\n",
    "# ML確率の分布を確認\n",
    "print(f\"\\n[ML Probability Distribution]\")\n",
    "print(f\"  Min:    {target_df['ml_probability'].min():.3f}\")\n",
    "print(f\"  Max:    {target_df['ml_probability'].max():.3f}\")\n",
    "print(f\"  Mean:   {target_df['ml_probability'].mean():.3f}\")\n",
    "print(f\"  Median: {target_df['ml_probability'].median():.3f}\")\n",
    "\n",
    "# 高リスクドメイン（ML確率 > 0.4）の数\n",
    "high_risk = target_df[target_df['ml_probability'] > 0.4]\n",
    "print(f\"  High risk (>0.4): {len(high_risk)} domains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af87892f-5ae4-45c1-acd1-b8e29dfbce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT INITIALIZATION WITH LLM (MANDATORY, READ-ONLY CONFIG)\n",
      "================================================================================\n",
      "\n",
      "[1] Loading LLM Configuration from _compat/config.json\n",
      "----------------------------------------\n",
      "✅ Loaded config.json from /home/asomura/backup/nextstep/_compat/config.json\n",
      "LLM config overview:\n",
      "  enabled   : True\n",
      "  provider  : vllm\n",
      "  base_url  : http://localhost:8000/v1\n",
      "  model     : JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8\n",
      "  temperature: 0.1\n",
      "\n",
      "[2] Setting OPENAI_API_KEY (dummy for vLLM / Ollama)\n",
      "----------------------------------------\n",
      "✅ OPENAI_API_KEY set (dummy or from config)\n",
      "\n",
      "[3] Clearing legacy 'phishpkg' modules (if any)\n",
      "----------------------------------------\n",
      "✅ Removed 0 phishpkg modules from sys.modules\n",
      "\n",
      "[4] Wiring Phase6 (LLM required, using config.json)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asomura/waseda/phish-core/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Phase6 wired with real LLM (using config.json)\n",
      "  phase6_wiring.__file__      = /home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py\n",
      "  langgraph_module.__file__   = /home/asomura/backup/nextstep/phishing_agent/langgraph_module.py\n",
      "  final_decision_node.module  = phishing_agent.phase6_wiring\n",
      "  final_decision_node.file    = /home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py\n",
      "\n",
      "[5] Importing LangGraphPhishingAgent\n",
      "----------------------------------------\n",
      "✅ LangGraphPhishingAgent imported\n",
      "\n",
      "[6] Initializing Agent (LLM mandatory, config-driven)\n",
      "----------------------------------------\n",
      "✅ Agent initialized\n",
      "\n",
      "[7] Quick Verification Test (single domain)\n",
      "----------------------------------------\n",
      "Test domain         : test-amazon.com\n",
      "  Time              : 0.03s\n",
      "  success           : False\n",
      "  ai_is_phishing    : False\n",
      "  ai_confidence     : 0.0\n",
      "  ai_risk_level     : low\n",
      "  debug_llm_final   : {}\n",
      "  phase6_policy_version: None\n",
      "  decision_trace_len    : 0\n",
      "  ❌ Test failed after 0.03s: Phase6 is NOT active: graph_state.phase6_policy_version is missing. Check sys.path/imports and ensure phase6_wiring is applied before agent init.\n",
      "\n",
      "================================================================================\n",
      "AGENT READY FOR EVALUATION (LLM MANDATORY, CONFIG-DRIVEN)\n",
      "================================================================================\n",
      "✅ LLM: Loaded from _compat/config.json\n",
      "✅ Phase6: wired (LLM経路あり、fallbackはphase6_wiring側ロジックに依存)\n",
      "✅ Agent: Initialized\n",
      "\n",
      "Proceed to Cell 5 for RandomSample evaluation\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4: LangGraphエージェントの初期化（サンプル用・LLM必須版, config読み取り専用）\n",
    "# ============================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 環境設定\n",
    "os.chdir(BASE_DIR)\n",
    "# [ChangeLog] 2025-12-16: sys.path を整理（Phase6 wiring の二重 import 問題を回避）\n",
    "# NOTE: sys.path には BASE_DIR のみを入れて package import を統一する。\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT INITIALIZATION WITH LLM (MANDATORY, READ-ONLY CONFIG)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. _compat/config.json から LLM 設定を読む（※書き換えない）\n",
    "print(\"\\n[1] Loading LLM Configuration from _compat/config.json\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cfg_path = BASE_DIR / \"_compat\" / \"config.json\"\n",
    "cfg_json = {}\n",
    "llm_cfg = {}\n",
    "\n",
    "if not cfg_path.exists():\n",
    "    print(f\"❌ config.json not found at {cfg_path}\")\n",
    "else:\n",
    "    try:\n",
    "        with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg_json = json.load(f)\n",
    "        llm_cfg = (cfg_json.get(\"llm\") or {})\n",
    "        print(f\"✅ Loaded config.json from {cfg_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load config.json: {e}\")\n",
    "        cfg_json = {}\n",
    "        llm_cfg = {}\n",
    "\n",
    "# LLM設定のサマリ表示\n",
    "if not llm_cfg:\n",
    "    print(\"❌ 'llm' section not found in config.json\")\n",
    "else:\n",
    "    provider   = llm_cfg.get(\"provider\")\n",
    "    base_url   = (\n",
    "        llm_cfg.get(\"base_url\")\n",
    "        or llm_cfg.get(\"vllm_base_url\")\n",
    "        or llm_cfg.get(\"ollama_base_url\")\n",
    "    )\n",
    "    model      = (\n",
    "        llm_cfg.get(\"model\")\n",
    "        or llm_cfg.get(\"vllm_model\")\n",
    "        or llm_cfg.get(\"ollama_model\")\n",
    "    )\n",
    "    enabled    = bool(llm_cfg.get(\"enabled\", False))\n",
    "    temperature = llm_cfg.get(\"temperature\", 0.1)\n",
    "\n",
    "    print(\"LLM config overview:\")\n",
    "    print(f\"  enabled   : {enabled}\")\n",
    "    print(f\"  provider  : {provider}\")\n",
    "    print(f\"  base_url  : {base_url}\")\n",
    "    print(f\"  model     : {model}\")\n",
    "    print(f\"  temperature: {temperature}\")\n",
    "\n",
    "    if not enabled:\n",
    "        print(\"⚠ LLM is disabled in config.json (llm.enabled=False)\")\n",
    "    if not base_url:\n",
    "        print(\"⚠ llm.base_url / vllm_base_url / ollama_base_url is not set\")\n",
    "    if not model:\n",
    "        print(\"⚠ llm.model / vllm_model / ollama_model is not set\")\n",
    "\n",
    "# external_data にも cfg を入れておく（読み取り結果だけ反映）\n",
    "if \"external_data\" not in globals():\n",
    "    external_data = {}\n",
    "external_data.setdefault(\"cfg\", {})\n",
    "external_data[\"cfg\"][\"llm\"] = llm_cfg\n",
    "\n",
    "# 2. OPENAI_API_KEY の設定（vLLMの場合はダミーでOK）\n",
    "print(\"\\n[2] Setting OPENAI_API_KEY (dummy for vLLM / Ollama)\")\n",
    "print(\"-\" * 40)\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = llm_cfg.get(\"api_key\") or \"dummy-key-for-local-llm\"\n",
    "    print(\"✅ OPENAI_API_KEY set (dummy or from config)\")\n",
    "else:\n",
    "    print(\"ℹ OPENAI_API_KEY already set in environment\")\n",
    "\n",
    "# 3. phishpkg/旧モジュールをクリア（あれば）\n",
    "print(\"\\n[3] Clearing legacy 'phishpkg' modules (if any)\")\n",
    "print(\"-\" * 40)\n",
    "removed = 0\n",
    "for key in list(sys.modules.keys()):\n",
    "    if key.startswith(\"phishpkg\"):\n",
    "        del sys.modules[key]\n",
    "        removed += 1\n",
    "print(f\"✅ Removed {removed} phishpkg modules from sys.modules\")\n",
    "\n",
    "# 4. Phase6 配線（LLM必須モード／fake_llm=False）\n",
    "print(\"\\n[4] Wiring Phase6 (LLM required, using config.json)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from phishing_agent.phase6_wiring import wire_phase6\n",
    "\n",
    "    # CONFIG_JSON を明示しておくと安全\n",
    "    cfg_env_path = str(cfg_path)\n",
    "    os.environ[\"CONFIG_JSON\"] = cfg_env_path\n",
    "\n",
    "    # prefer_compat=True: _compat/config.json を優先\n",
    "    # fake_llm=False    : 実際の LLM を使う前提（失敗時は例外 or フォールバックはphase6_wiring側ルール）\n",
    "    wire_phase6(prefer_compat=True, fake_llm=False)\n",
    "    print(\"✅ Phase6 wired with real LLM (using config.json)\")\n",
    "\n",
    "    # [ChangeLog] 2025-12-16: どのモジュールが読み込まれているか明示（取り違え防止）\n",
    "    import phishing_agent.phase6_wiring as _p6w\n",
    "    import phishing_agent.langgraph_module as _l4\n",
    "    import inspect as _inspect\n",
    "    print(f\"  phase6_wiring.__file__      = {_p6w.__file__}\")\n",
    "    print(f\"  langgraph_module.__file__   = {_l4.__file__}\")\n",
    "    try:\n",
    "        _fd = _l4.LangGraphPhishingAgent._final_decision_node\n",
    "        print(f\"  final_decision_node.module  = {_fd.__module__}\")\n",
    "        print(f\"  final_decision_node.file    = {_inspect.getsourcefile(_fd)}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  (warn) could not introspect final_decision_node: {_e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Phase6 wiring failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# 5. LangGraph エージェントをインポート\n",
    "print(\"\\n[5] Importing LangGraphPhishingAgent\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from phishing_agent.langgraph_module import LangGraphPhishingAgent\n",
    "\n",
    "print(\"✅ LangGraphPhishingAgent imported\")\n",
    "\n",
    "# 6. エージェント初期化（use_llm_decision=True が超重要）\n",
    "print(\"\\n[6] Initializing Agent (LLM mandatory, config-driven)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "agent = LangGraphPhishingAgent(\n",
    "    strict_mode=True,              # Graph全体としては strict=False（Phase6側でSOはstrictにしてOK）\n",
    "    use_llm_selection=True,\n",
    "    use_llm_decision=True,          # ★ final_decision で必ず LLM 経路を試す\n",
    "    config_path=str(cfg_path),\n",
    "    external_data=external_data,\n",
    ")\n",
    "print(\"✅ Agent initialized\")\n",
    "\n",
    "# 7. 動作確認テスト（LLMパス／debug_llm_final の確認）\n",
    "print(\"\\n[7] Quick Verification Test (single domain)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "import time\n",
    "\n",
    "test_domain = \"test-amazon.com\"\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    result = agent.evaluate(test_domain, 0.35)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    print(f\"Test domain         : {test_domain}\")\n",
    "    print(f\"  Time              : {elapsed:.2f}s\")\n",
    "    print(f\"  success           : {result.get('success')}\")\n",
    "    print(f\"  ai_is_phishing    : {result.get('ai_is_phishing')}\")\n",
    "    print(f\"  ai_confidence     : {result.get('ai_confidence')}\")\n",
    "    print(f\"  ai_risk_level     : {result.get('ai_risk_level')}\")\n",
    "\n",
    "    gs = result.get(\"graph_state\") or {}\n",
    "    dbg = gs.get(\"debug_llm_final\") or {}\n",
    "    print(f\"  debug_llm_final   : {dbg}\")\n",
    "\n",
    "    # [ChangeLog] 2025-12-16: Phase6の有効化を「確実に」検証（Phase4でも path==\"llm\" は起こり得る）\n",
    "    p6v = gs.get(\"phase6_policy_version\")\n",
    "    dt  = gs.get(\"decision_trace\") or []\n",
    "    print(f\"  phase6_policy_version: {p6v}\")\n",
    "    try:\n",
    "        _dt_len = len(dt) if isinstance(dt, list) else None\n",
    "    except Exception:\n",
    "        _dt_len = None\n",
    "    print(f\"  decision_trace_len    : {_dt_len}\")\n",
    "\n",
    "    if not p6v:\n",
    "        raise RuntimeError(\n",
    "            \"Phase6 is NOT active: graph_state.phase6_policy_version is missing. \"\n",
    "            \"Check sys.path/imports and ensure phase6_wiring is applied before agent init.\"\n",
    "        )\n",
    "\n",
    "    path = dbg.get(\"path\")\n",
    "    if path == \"llm\" and dbg.get(\"success\") is True:\n",
    "        print(\"  ✅ Phase6 LLM path is active (path='llm')\")\n",
    "    elif path == \"fallback\":\n",
    "        print(\"  ⚠ Phase6 LLM failed; fallback path used (path='fallback')\")\n",
    "    else:\n",
    "        print(\"  ℹ Phase6 LLM path status is unclear (see debug_llm_final above)\")\n",
    "\n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"  ❌ Test failed after {elapsed:.2f}s: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGENT READY FOR EVALUATION (LLM MANDATORY, CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✅ LLM: Loaded from _compat/config.json\")\n",
    "print(\"✅ Phase6: wired (LLM経路あり、fallbackはphase6_wiring側ロジックに依存)\")\n",
    "print(\"✅ Agent: Initialized\")\n",
    "print(\"\\nProceed to Cell 5 for RandomSample evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b6dd56-b783-442f-a0d7-5178c741ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Generating TLD data from Database Analysis...\n",
      "  🔌 Connecting to database: rapids_data at localhost...\n",
      "  ✅ Database connected successfully\n",
      "  📊 Analyzing phishing domains...\n",
      "  📊 Analyzing trusted domains...\n",
      "    - Phishing unique: 320409\n",
      "    - Trusted unique: 450656\n",
      "  ✅ Generated 29 dangerous TLDs\n",
      "  ✅ Generated 27 legitimate TLDs\n",
      "  ✅ Agent external_data updated\n",
      "✅ TLD data patched via Database Analysis. Ready for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4.6: TLDリストの動的生成（データベース分析版）\n",
    "# ※ DB接続必須。失敗時はエラー終了します。\n",
    "# ============================================\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"🔧 Generating TLD data from Database Analysis...\")\n",
    "\n",
    "# 03_ai_agent_analysis.ipynb からの DB設定\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# TLD抽出関数 (03からの移植)\n",
    "def extract_tld(domain):\n",
    "    \"\"\"ドメインからTLDを抽出\"\"\"\n",
    "    if not domain:\n",
    "        return None\n",
    "    # URLの場合はドメイン部分を抽出\n",
    "    if '://' in domain:\n",
    "        try:\n",
    "            parsed = urlparse(domain)\n",
    "            domain = parsed.netloc\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # ポート番号を削除\n",
    "    domain = str(domain).split(':')[0]\n",
    "    \n",
    "    parts = domain.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        # .co.jp, .ac.jp などの複合TLD対応\n",
    "        if len(parts) >= 3 and parts[-2] in ['co', 'ac', 'or', 'ne', 'go']:\n",
    "            return f'.{parts[-2]}.{parts[-1]}'\n",
    "        else:\n",
    "            return f'.{parts[-1]}'\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    # データベース接続テスト\n",
    "    print(f\"  🔌 Connecting to database: {DB_CONFIG['dbname']} at {DB_CONFIG['host']}...\")\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    print(\"  ✅ Database connected successfully\")\n",
    "\n",
    "    # 1. フィッシングサイトの取得 (各ソースから)\n",
    "    print(\"  📊 Analyzing phishing domains...\")\n",
    "    phishing_queries = [\n",
    "        \"SELECT cert_domain as domain FROM phishtank_entries WHERE cert_status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM jpcert_phishing_urls WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\"\n",
    "    ]\n",
    "    \n",
    "    phishing_domains = []\n",
    "    for query in phishing_queries:\n",
    "        cur.execute(query)\n",
    "        results = cur.fetchall()\n",
    "        for row in results:\n",
    "            if row['domain']: phishing_domains.append(row['domain'])\n",
    "            \n",
    "    if not phishing_domains:\n",
    "        raise ValueError(\"No phishing domains found in database. Analysis cannot proceed.\")\n",
    "\n",
    "    # 2. 正常サイトの取得\n",
    "    print(\"  📊 Analyzing trusted domains...\")\n",
    "    cur.execute(\"SELECT domain FROM trusted_certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\")\n",
    "    results = cur.fetchall()\n",
    "    trusted_domains = [row['domain'] for row in results if row['domain']]\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    # 3. データバランス調整 (03と同様のロジック)\n",
    "    # 重複除去\n",
    "    phishing_domains_unique = list(set(phishing_domains))\n",
    "    trusted_domains_unique = list(set(trusted_domains))\n",
    "    \n",
    "    print(f\"    - Phishing unique: {len(phishing_domains_unique)}\")\n",
    "    print(f\"    - Trusted unique: {len(trusted_domains_unique)}\")\n",
    "    \n",
    "    # 少ない方に合わせてサンプリング\n",
    "    random.seed(42)\n",
    "    min_unique = min(len(phishing_domains_unique), len(trusted_domains_unique))\n",
    "    \n",
    "    if min_unique == 0:\n",
    "        raise ValueError(\"Insufficient data for analysis (one of the datasets is empty).\")\n",
    "        \n",
    "    phishing_balanced = random.sample(phishing_domains_unique, min(len(phishing_domains_unique), min_unique))\n",
    "    trusted_balanced = random.sample(trusted_domains_unique, min(len(trusted_domains_unique), min_unique))\n",
    "\n",
    "    # 4. TLD集計\n",
    "    phishing_tlds = Counter([extract_tld(d) for d in phishing_balanced if extract_tld(d)])\n",
    "    trusted_tlds = Counter([extract_tld(d) for d in trusted_balanced if extract_tld(d)])\n",
    "\n",
    "    # 5. 危険度分析と分類\n",
    "    dangerous_tlds = []\n",
    "    \n",
    "    for tld, phish_count in phishing_tlds.items():\n",
    "        trust_count = trusted_tlds.get(tld, 0)\n",
    "        # サンプル数が少なすぎるものは除外\n",
    "        if phish_count >= 10:\n",
    "            ratio = phish_count / (trust_count + 1)\n",
    "            phish_pct = phish_count / len(phishing_balanced) * 100\n",
    "            \n",
    "            # 判定ロジック:\n",
    "            # 1. 正常サイトで皆無(0件) かつ フィッシングで10件以上\n",
    "            # 2. 比率が10倍以上 かつ フィッシング全体の0.1%以上\n",
    "            if (trust_count == 0) or (ratio >= 10 and phish_pct >= 0.1):\n",
    "                dangerous_tlds.append(tld)\n",
    "    \n",
    "    # ドットを除去して格納 (例: '.xyz' -> 'xyz')\n",
    "    external_data['dangerous_tlds'] = [t.lstrip('.') for t in dangerous_tlds]\n",
    "\n",
    "    # 正当なTLD\n",
    "    legitimate_tlds = []\n",
    "    for tld, count in trusted_tlds.most_common():\n",
    "        if count >= 1000: # 統計的信頼性\n",
    "            phish_count = phishing_tlds.get(tld, 0)\n",
    "            ratio = phish_count / count\n",
    "            if ratio < 0.5: # 正常サイトでの使用が2倍以上\n",
    "                legitimate_tlds.append(tld)\n",
    "    external_data['legitimate_tlds'] = [t.lstrip('.') for t in legitimate_tlds]\n",
    "\n",
    "    # 中立的なTLD (主要TLDのうち、上記に入らなかったもの)\n",
    "    neutral_candidates = ['.com', '.org', '.net', '.info', '.biz']\n",
    "    neutral_tlds = []\n",
    "    for tld in neutral_candidates:\n",
    "        if tld not in dangerous_tlds and tld not in legitimate_tlds:\n",
    "            neutral_tlds.append(tld)\n",
    "    external_data['neutral_tlds'] = [t.lstrip('.') for t in neutral_tlds]\n",
    "    \n",
    "    # 統計情報を保存 (生のCounterオブジェクト)\n",
    "    external_data['phishing_tld_stats'] = phishing_tlds\n",
    "\n",
    "    print(f\"  ✅ Generated {len(external_data['dangerous_tlds'])} dangerous TLDs\")\n",
    "    print(f\"  ✅ Generated {len(external_data['legitimate_tlds'])} legitimate TLDs\")\n",
    "\n",
    "    # エージェント内の参照更新\n",
    "    if 'agent' in globals():\n",
    "        agent.external_data = external_data\n",
    "        print(\"  ✅ Agent external_data updated\")\n",
    "        \n",
    "    print(\"✅ TLD data patched via Database Analysis. Ready for evaluation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ DATABASE ANALYSIS FAILED: {e}\")\n",
    "    print(\"⛔ Stopping execution to prevent inaccurate results using fallback data.\")\n",
    "    # 明示的にエラーを発生させて処理を止める\n",
    "    raise RuntimeError(\"Database connection or analysis failed. Please check DB connection and rerun this cell.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24f810-779a-4f5e-9f76-2cff549f577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting FULL AGENT evaluation of 1000 domains (N_SAMPLE=1000)...\n",
      "================================================================================\n",
      "[INFO] LLM initialized: JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8\n",
      "[INFO] code_fingerprint: {'eval_id': '2025-12-21_222059', 'phase6_policy_version_code': 'v1.4.3-r4tweak2', 'phase6_wiring_file': '/home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py', 'phase6_wiring_sha256': '95ac49aae1913c218e1028c966cff73cda81c7ececda392c8ebbfa5d897d65dc', 'llm_final_decision_file': '/home/asomura/backup/nextstep/phishing_agent/llm_final_decision.py', 'llm_final_decision_sha256': '598f6cc4437f6a4d6a2fd2a1b9542b0eb8fd1ac5792b4fcb21ffc3adff1c089e', 'langgraph_module_file': '/home/asomura/backup/nextstep/phishing_agent/langgraph_module.py', 'langgraph_module_sha256': 'b19f2c7f7ee2039be1a96e54b753d2c3236cd229604a99fd651a6720c11e58c3', 'dual_import_langgraph_module': False}\n",
      "[INFO] Results will be appended to: artifacts/2025-12-07_143907/logs/random1000_full_eval__evalid_2025-12-21_222059__ts_2025-12-21_222059.csv (flush every 500 rows)\n",
      "[INFO] Console output mode: COMPACT (PROGRESS_EVERY=25, clear_output=True)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 5: サンプル評価実行（件数=len(target_df), 超詳細デバッグログ版）\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io, sys, json, os\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "print(f\"[INFO] Starting FULL AGENT evaluation of {len(target_df)} domains (N_SAMPLE={N_SAMPLE})...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLM設定の確認\n",
    "if 'agent' in globals() and hasattr(agent, 'llm_config'):\n",
    "    llm_config = agent.llm_config\n",
    "    if getattr(llm_config, \"enabled\", False):\n",
    "        print(f\"[INFO] LLM initialized: {llm_config.model}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - results may be limited\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent not properly initialized\")\n",
    "\n",
    "# --- Code fingerprint (reproducibility / verification) ------------------------\n",
    "# [ChangeLog] 2025-12-17: Add code fingerprint (module __file__ + sha256) to each output row.\n",
    "import hashlib\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import datetime as _dt\n",
    "\n",
    "def _sha256_of_file(path: str, chunk_size: int = 1024 * 1024) -> str:\n",
    "    \"\"\"Return sha256 hex digest for a local file. Never raises.\"\"\"\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "                h.update(chunk)\n",
    "        return h.hexdigest()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR:{type(e).__name__}\"\n",
    "\n",
    "def _module_file_and_sha(modname: str):\n",
    "    \"\"\"Import module and return (file_path, sha256, module_obj).\"\"\"\n",
    "    try:\n",
    "        mod = importlib.import_module(modname)\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if f:\n",
    "            f = str(Path(f).resolve())\n",
    "            sha = _sha256_of_file(f)\n",
    "        else:\n",
    "            sha = None\n",
    "        return f, sha, mod\n",
    "    except Exception as e:\n",
    "        return None, f\"IMPORT_ERROR:{type(e).__name__}\", None\n",
    "\n",
    "def make_code_fingerprint() -> dict:\n",
    "    fp = {}\n",
    "    fp[\"eval_id\"] = _dt.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "    # Core modules used by final decision path\n",
    "    p6_file, p6_sha, _p6_mod = _module_file_and_sha(\"phishing_agent.phase6_wiring\")\n",
    "    ld_file, ld_sha, ld_mod = _module_file_and_sha(\"phishing_agent.llm_final_decision\")\n",
    "    lg_file, lg_sha, _lg_mod = _module_file_and_sha(\"phishing_agent.langgraph_module\")\n",
    "\n",
    "    fp[\"phase6_wiring_file\"] = p6_file\n",
    "    fp[\"phase6_wiring_sha256\"] = p6_sha\n",
    "    fp[\"llm_final_decision_file\"] = ld_file\n",
    "    fp[\"llm_final_decision_sha256\"] = ld_sha\n",
    "    fp[\"langgraph_module_file\"] = lg_file\n",
    "    fp[\"langgraph_module_sha256\"] = lg_sha\n",
    "\n",
    "    fp[\"phase6_policy_version_code\"] = getattr(ld_mod, \"PHASE6_POLICY_VERSION\", None) if ld_mod else None\n",
    "    fp[\"python\"] = sys.version.split()[0]\n",
    "    fp[\"dual_import_langgraph_module\"] = (\"langgraph_module\" in sys.modules) and (\"phishing_agent.langgraph_module\" in sys.modules)\n",
    "\n",
    "    return fp\n",
    "\n",
    "# Compute once per notebook run (avoid per-domain overhead)\n",
    "if \"CODE_FINGERPRINT\" not in globals():\n",
    "    CODE_FINGERPRINT = make_code_fingerprint()\n",
    "    CODE_FP_ROW = {\n",
    "        \"eval_id\": CODE_FINGERPRINT.get(\"eval_id\"),\n",
    "        \"phase6_policy_version_code\": CODE_FINGERPRINT.get(\"phase6_policy_version_code\"),\n",
    "        \"phase6_wiring_file\": CODE_FINGERPRINT.get(\"phase6_wiring_file\"),\n",
    "        \"phase6_wiring_sha256\": CODE_FINGERPRINT.get(\"phase6_wiring_sha256\"),\n",
    "        \"llm_final_decision_file\": CODE_FINGERPRINT.get(\"llm_final_decision_file\"),\n",
    "        \"llm_final_decision_sha256\": CODE_FINGERPRINT.get(\"llm_final_decision_sha256\"),\n",
    "        \"langgraph_module_file\": CODE_FINGERPRINT.get(\"langgraph_module_file\"),\n",
    "        \"langgraph_module_sha256\": CODE_FINGERPRINT.get(\"langgraph_module_sha256\"),\n",
    "        \"dual_import_langgraph_module\": CODE_FINGERPRINT.get(\"dual_import_langgraph_module\"),\n",
    "    }\n",
    "    print(\"[INFO] code_fingerprint:\", CODE_FP_ROW)\n",
    "else:\n",
    "    # Reuse existing in case notebook cells are re-run\n",
    "    CODE_FP_ROW = globals().get(\"CODE_FP_ROW\", {})\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "# --- 保存設定: 500件ごとに追記（分割ファイルなし） -----------------\n",
    "SAVE_EVERY_ROWS = 500  # 要件: 500件ごとに保存（追記）\n",
    "if \"LOGS_DIR\" not in globals() or not globals().get(\"LOGS_DIR\"):\n",
    "    raise RuntimeError(\"LOGS_DIR is not set. Run Cell 1 to initialize run_id/paths first.\")\n",
    "\n",
    "OUT_DIR = Path(globals()[\"LOGS_DIR\"])\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# eval_id は Notebook実行単位で固定（CODE_FP_ROW があればそれを使う）\n",
    "_eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    _eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not _eval_id:\n",
    "    _eval_id = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "_ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "# 追記先（run_id/logs 配下へ）\n",
    "full_eval_path = OUT_DIR / f\"random{len(target_df)}_full_eval__evalid_{_eval_id}__ts_{_ts}.csv\"\n",
    "print(f\"[INFO] Results will be appended to: {full_eval_path} (flush every {SAVE_EVERY_ROWS} rows)\")\n",
    "\n",
    "_chunk_buf = []\n",
    "_written_header = False\n",
    "_written_rows = 0\n",
    "\n",
    "def _flush_chunk_if_needed(force: bool = False):\n",
    "    \"\"\"_chunk_buf を full_eval_path に追記保存（ヘッダは最初だけ）。\"\"\"\n",
    "    global _written_header, _written_rows\n",
    "    if (not force) and (len(_chunk_buf) < SAVE_EVERY_ROWS):\n",
    "        return\n",
    "    if not _chunk_buf:\n",
    "        return\n",
    "    df_chunk = pd.DataFrame(_chunk_buf)\n",
    "    df_chunk.to_csv(full_eval_path, mode=\"a\", header=(not _written_header), index=False)\n",
    "    _written_header = True\n",
    "    _written_rows += int(len(_chunk_buf))\n",
    "    _chunk_buf.clear()\n",
    "\n",
    "# --- Notebook画面出力の制御（debug_log の情報量は維持） -----------------\n",
    "# [ChangeLog] 2025-12-15: 大量件数でもJupyterの出力が重くならないよう、画面出力を間引く\n",
    "TOTAL_N = len(target_df)\n",
    "\n",
    "# デフォルト: 少数件は従来どおり詳細表示 / 多数件はコンパクト表示\n",
    "SHOW_DOMAIN_LOG_ON_SCREEN = (TOTAL_N <= 20)\n",
    "\n",
    "# 環境変数で上書き可: 1/true/yes/on で詳細表示\n",
    "_env = os.getenv(\"SHOW_DOMAIN_LOG_ON_SCREEN\")\n",
    "if _env is not None:\n",
    "    SHOW_DOMAIN_LOG_ON_SCREEN = str(_env).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# 進捗表示の更新頻度（画面を軽くするため、件数に応じて自動調整）\n",
    "if TOTAL_N <= 30:\n",
    "    PROGRESS_EVERY = 1\n",
    "elif TOTAL_N <= 300:\n",
    "    PROGRESS_EVERY = 10\n",
    "elif TOTAL_N <= 3000:\n",
    "    PROGRESS_EVERY = 25\n",
    "else:\n",
    "    PROGRESS_EVERY = 50\n",
    "\n",
    "# Jupyterなら clear_output で表示を置き換え（ログはCSV側に残る）\n",
    "_USE_CLEAR_OUTPUT = (not SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "try:\n",
    "    from IPython.display import clear_output  # type: ignore\n",
    "    _HAS_CLEAR_OUTPUT = True\n",
    "except Exception:\n",
    "    _HAS_CLEAR_OUTPUT = False\n",
    "\n",
    "print(f\"[INFO] Console output mode: {'VERBOSE' if SHOW_DOMAIN_LOG_ON_SCREEN else 'COMPACT'} \"\n",
    "      f\"(PROGRESS_EVERY={PROGRESS_EVERY}, clear_output={_USE_CLEAR_OUTPUT and _HAS_CLEAR_OUTPUT})\")\n",
    "\n",
    "# 進捗カウンタ（画面表示用）\n",
    "_screen_counts = {\"phish\": 0, \"benign\": 0, \"error\": 0}\n",
    "\n",
    "# --- 表示用ヘルパー ----------------------------------------------------\n",
    "def _fmt_issues(issues):\n",
    "    return \", \".join(issues) if issues else \"None\"\n",
    "\n",
    "def _safe_dict(d):\n",
    "    return d if isinstance(d, dict) else {}\n",
    "\n",
    "def _log_tool_selection(graph_state, ml_probability):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    pre = _safe_dict(gs.get(\"precheck_hints\"))\n",
    "    ml_cat   = pre.get(\"ml_category\", \"-\")\n",
    "    tld_cat  = pre.get(\"tld_category\", \"-\")\n",
    "    quick_risk = pre.get(\"quick_risk\", \"-\")\n",
    "    known_info = _safe_dict(pre.get(\"known_domain_info\"))\n",
    "    known_label = known_info.get(\"label\") or known_info.get(\"kind\") or known_info.get(\"brand\")\n",
    "\n",
    "    selected_tools = gs.get(\"selected_tools\", [])\n",
    "    flags = _safe_dict(gs.get(\"tool_execution_flags\"))\n",
    "    llm_used = gs.get(\"llm_used_selection\")\n",
    "    llm_err  = gs.get(\"llm_selection_error\")\n",
    "\n",
    "    print(\"  [ToolSelection]\")\n",
    "    print(f\"    ml_probability      : {ml_probability:.3f} (category={ml_cat})\")\n",
    "    print(f\"    tld_category        : {tld_cat}  quick_risk={quick_risk}\")\n",
    "    if known_label:\n",
    "        print(f\"    known_domain_info   : {known_label}\")\n",
    "    print(f\"    selected_tools      : {selected_tools}\")\n",
    "    print(f\"    tool_execution_flags: {flags}\")\n",
    "    print(f\"    llm_used_selection  : {llm_used}\")\n",
    "    if llm_err:\n",
    "        print(f\"    llm_selection_error : {llm_err}\")\n",
    "\n",
    "    if llm_used:\n",
    "        strategy = \"llm_structured_output\"\n",
    "    else:\n",
    "        strategy = \"ml_bucket_fallback\"\n",
    "    print(f\"    selection_strategy  : {strategy}\")\n",
    "\n",
    "    # フォールバック時は、どのバケットポリシーになったかも表示\n",
    "    if not llm_used:\n",
    "        if ml_probability < 0.2:\n",
    "            policy = \"ML<0.2 → brand+cert+domain (3 tools)\"\n",
    "        elif ml_probability < 0.5:\n",
    "            policy = \"0.2≦ML<0.5 → brand+cert+domain (3 tools)\"\n",
    "        else:\n",
    "            policy = \"ML≧0.5 → brand+cert (2 tools)\"\n",
    "        print(f\"    selection_policy    : {policy}\")\n",
    "\n",
    "def _log_brand_tool(brand_res):\n",
    "    br = _safe_dict(brand_res)\n",
    "    if not br:\n",
    "        print(\"  [BrandTool] not executed\")\n",
    "        return\n",
    "\n",
    "    details = _safe_dict(br.get(\"details\"))\n",
    "    issues  = br.get(\"detected_issues\") or []\n",
    "    # ※ brand_impersonation_check の構造に合わせて details 側を優先\n",
    "    brands  = details.get(\"detected_brands\") or br.get(\"detected_brands\") or []\n",
    "    used_llm    = details.get(\"used_llm\")\n",
    "    llm_conf    = details.get(\"llm_confidence\")\n",
    "    llm_reason  = details.get(\"llm_reasoning\")\n",
    "    #llm_reason  = (details.get(\"llm_reasoning\") or \"\")[:160]\n",
    "\n",
    "    print(\"  [BrandTool]\")\n",
    "    if br.get(\"_fallback\"):\n",
    "        print(\"    ⚠ fallback           : True (brand tool exception or disabled)\")\n",
    "    print(f\"    risk_score           : {br.get('risk_score')}\")\n",
    "    print(f\"    detected_issues      : {issues}\")\n",
    "    print(f\"    detected_brands      : {brands}\")\n",
    "    print(f\"    used_llm             : {used_llm}\")\n",
    "    print(f\"    llm_confidence       : {llm_conf}\")\n",
    "    print(f\"    llm_reasoning (head) : {llm_reason}\")\n",
    "    if used_llm:\n",
    "        print(\"    ✅ LLM が実行されました (used_llm=True)\")\n",
    "    if brands:\n",
    "        print(f\"    ✅ ブランド検出があります: {brands}\")\n",
    "\n",
    "def _log_cert_tool(cert_res):\n",
    "    cr = _safe_dict(cert_res)\n",
    "    if not cr:\n",
    "        print(\"  [CertTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cr.get(\"details\"))\n",
    "    print(\"  [CertTool]\")\n",
    "    if cr.get(\"_fallback\"):\n",
    "        print(\"    ⚠ fallback      : True (cert tool exception or disabled)\")\n",
    "    print(f\"    risk_score      : {cr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues : {cr.get('detected_issues') or []}\")\n",
    "    print(f\"    issuer          : {details.get('issuer')}\")\n",
    "    print(f\"    is_free_ca      : {details.get('is_free_ca')}\")\n",
    "    print(f\"    has_org         : {details.get('has_org')}\")\n",
    "    print(f\"    valid_days      : {details.get('valid_days')}\")\n",
    "    print(f\"    is_short_term   : {details.get('is_short_term')}\")\n",
    "    print(f\"    san_count       : {details.get('san_count')}\")\n",
    "    print(f\"    is_self_signed  : {details.get('is_self_signed')}\")\n",
    "    print(f\"    is_wildcard     : {details.get('is_wildcard')}\")\n",
    "\n",
    "def _log_domain_tool(domain_res):\n",
    "    dr = _safe_dict(domain_res)\n",
    "    if not dr:\n",
    "        print(\"  [DomainTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(dr.get(\"details\"))\n",
    "    print(\"  [DomainTool]\")\n",
    "    if dr.get(\"_fallback\"):\n",
    "        print(\"    ⚠ fallback            : True (domain tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {dr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {dr.get('detected_issues') or []}\")\n",
    "    print(f\"    base_domain           : {details.get('base_domain')}\")\n",
    "    print(f\"    domain_length         : {details.get('domain_length')}\"\n",
    "          f\" (category={details.get('domain_length_category')})\")\n",
    "    print(f\"    tld / tld_category    : {details.get('tld')} / {details.get('tld_category')}\")\n",
    "    print(f\"    entropy               : {details.get('entropy')}\")\n",
    "    print(f\"    combo_flags           : {details.get('combo_flags')}\")\n",
    "    legit = _safe_dict(details.get('legitimate_check'))\n",
    "    if legit:\n",
    "        print(f\"    legitimate_check      : is_legit={legit.get('is_legitimate')}\"\n",
    "              f\", brand={legit.get('brand')}, conf={legit.get('confidence')}\")\n",
    "\n",
    "def _log_contextual_tool(ctx_res):\n",
    "    cx = _safe_dict(ctx_res)\n",
    "    if not cx:\n",
    "        print(\"  [Contextual] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cx.get(\"details\"))\n",
    "    print(\"  [Contextual]\")\n",
    "    if cx.get(\"_fallback\"):\n",
    "        print(\"    ⚠ fallback            : True (contextual tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {cx.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {cx.get('detected_issues') or []}\")\n",
    "    print(f\"    ml_probability        : {details.get('ml_probability')}\"\n",
    "          f\" (category={details.get('ml_category')})\")\n",
    "    print(f\"    tool_average_risk     : {details.get('tool_average_risk')}\")\n",
    "    print(f\"    high_risk_hits        : {details.get('high_risk_hits')}\")\n",
    "    known = _safe_dict(details.get('known_domain'))\n",
    "    if known:\n",
    "        print(f\"    known_domain          : {known}\")\n",
    "    paradox = _safe_dict(details.get('paradox'))\n",
    "    if paradox:\n",
    "        print(f\"    paradox_info          : {paradox}\")\n",
    "\n",
    "def _log_final_decision(graph_state, result):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    dbg = _safe_dict(gs.get(\"debug_llm_final\"))\n",
    "    dt_list = gs.get(\"decision_trace\") or []\n",
    "    print(\"  [FinalDecision]\")\n",
    "    print(f\"    use_llm_decision      : {dbg.get('use_llm_decision')}\")\n",
    "    print(f\"    llm_is_none           : {dbg.get('llm_is_none')}\")\n",
    "    print(f\"    path                  : {dbg.get('path')}\")\n",
    "    print(f\"    success               : {dbg.get('success')}\")\n",
    "    if dbg.get(\"error\"):\n",
    "        print(f\"    error                 : {dbg.get('error')}\")\n",
    "\n",
    "    if dt_list:\n",
    "        last = _safe_dict(dt_list[-1])\n",
    "        print(f\"    phase6_policy_version : {gs.get('phase6_policy_version', last.get('phase6_version'))}\")\n",
    "        print(f\"    ctx_risk_score        : {last.get('ctx_score')}\")\n",
    "        rules = [s.get(\"rule\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"rule\" in s]\n",
    "        notes = [s.get(\"note\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"note\" in s]\n",
    "        if rules:\n",
    "            print(f\"    policy_rules          : {rules}\")\n",
    "        if notes:\n",
    "            print(f\"    policy_notes          : {notes}\")\n",
    "\n",
    "    print(f\"    ai_is_phishing        : {result.get('ai_is_phishing')} \"\n",
    "          f\"(risk_level={result.get('ai_risk_level')}, conf={result.get('ai_confidence'):.2f})\")\n",
    "    print(f\"    final_reasoning(head) : {(result.get('reasoning') or '')[:160]}\")\n",
    "\n",
    "def _log_graph_messages(graph_state, prefix=\"    \"):\n",
    "    \"\"\"LangGraph のメッセージストリームから、重要そうなものだけ抜粋表示\"\"\"\n",
    "    gs = _safe_dict(graph_state)\n",
    "    msgs = gs.get(\"messages\") or []\n",
    "    if not msgs:\n",
    "        return\n",
    "    print(\"  [GraphMessages] (tool_selection / tool_execution / final_decision only)\")\n",
    "    for m in msgs:\n",
    "        if isinstance(m, dict):\n",
    "            content = m.get(\"content\", \"\")\n",
    "            role = m.get(\"role\", \"msg\")\n",
    "        else:\n",
    "            content = getattr(m, \"content\", \"\")\n",
    "            role = getattr(m, \"role\", \"msg\")\n",
    "        if not isinstance(content, str):\n",
    "            content = str(content)\n",
    "        if any(tag in content for tag in [\"[tool_selection]\", \"[tool_execution]\", \"[final_decision]\"]):\n",
    "            print(f\"{prefix}[{role}] {content}\")\n",
    "\n",
    "\n",
    "# --- ログをCSVに残すための標準出力/標準エラーキャプチャ（print/logging両対応） ---\n",
    "class _TeeIO:\n",
    "    def __init__(self, primary, buffer, *, enable_primary: bool = True):\n",
    "        self.primary = primary\n",
    "        self.buffer = buffer\n",
    "        self.enable_primary = bool(enable_primary)\n",
    "    def write(self, s):\n",
    "        if self.enable_primary:\n",
    "            self.primary.write(s)\n",
    "        self.buffer.write(s)\n",
    "        return len(s)\n",
    "    def flush(self):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.flush()\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            self.buffer.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _json_dumps(obj):\n",
    "    \"\"\"CSVに安全に載せるためのJSON化（失敗しても落とさない）\"\"\"\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return json.dumps(str(obj), ensure_ascii=False, default=str)\n",
    "\n",
    "# --- 各ドメインを評価 ---------------------------------------------------\n",
    "for idx, row in target_df.iterrows():\n",
    "    before_len = len(results)  # 追記保存用（このイテレーションで追加された行だけ拾う）\n",
    "    domain = row['domain']\n",
    "    ml_prob = row['ml_probability']\n",
    "    _buf = io.StringIO()\n",
    "    _tee_out = _TeeIO(sys.stdout, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    _tee_err = _TeeIO(sys.stderr, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    with redirect_stdout(_tee_out), redirect_stderr(_tee_err):\n",
    "\n",
    "        try:\n",
    "            eval_start = time.time()\n",
    "            result = agent.evaluate(domain, ml_prob)\n",
    "            elapsed = time.time() - eval_start\n",
    "\n",
    "            # --- 基本情報 ---\n",
    "            is_phishing = result.get('ai_is_phishing', False)\n",
    "            confidence  = result.get('ai_confidence', 0.0)\n",
    "            risk_level  = result.get('ai_risk_level', 'unknown')\n",
    "\n",
    "            graph_state = _safe_dict(result.get(\"graph_state\"))\n",
    "            tool_res = _safe_dict(graph_state.get(\"tool_results\")) or _safe_dict(result.get(\"tool_results\"))\n",
    "\n",
    "            # Phase4 仕様: brand/cert/domain/contextual_risk_assessment は data 本体が入っている想定\n",
    "            brand_res  = _safe_dict(tool_res.get('brand'))\n",
    "            cert_res   = _safe_dict(tool_res.get('cert'))\n",
    "            domain_res = _safe_dict(tool_res.get('domain'))\n",
    "            ctx_res    = _safe_dict(tool_res.get('contextual_risk_assessment') or tool_res.get('contextual'))\n",
    "\n",
    "            # Brand details\n",
    "            brand_details   = _safe_dict(brand_res.get('details'))\n",
    "            detected_brands = brand_details.get('detected_brands', [])\n",
    "\n",
    "            # brand_detected / brand_suspected を tool 側のフラグから取得（brands配列の有無で決めない）\n",
    "            _b_issues = brand_res.get('detected_issues', []) if isinstance(brand_res, dict) else []\n",
    "            brand_detected_flag = bool(brand_details.get('brand_detected')) or ('brand_detected' in (_b_issues or []))\n",
    "            brand_suspected_flag = bool(brand_details.get('brand_suspected')) or ('brand_suspected' in (_b_issues or [])) or ('brand_llm_candidate' in (_b_issues or []))\n",
    "\n",
    "\n",
    "            # Cert details\n",
    "            cert_details = _safe_dict(cert_res.get('details'))\n",
    "            cert_issuer  = cert_details.get('issuer', 'unknown')\n",
    "\n",
    "            # Domain details\n",
    "            domain_details = _safe_dict(domain_res.get('details'))\n",
    "            tld_cat        = domain_details.get('tld_category', '-')\n",
    "\n",
    "            # Contextual issues\n",
    "            ctx_issues = ctx_res.get('detected_issues', []) if ctx_res else []\n",
    "\n",
    "            mark = \"🔴\" if is_phishing else \"🟢\"\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] {mark} {domain:<35} (ML: {ml_prob:.3f} / Time: {elapsed:.2f}s)\")\n",
    "            print(f\"🔍 Domain: {domain} (ml_probability={ml_prob:.3f})\")\n",
    "\n",
    "            # --- Tool Selection 詳細 ---\n",
    "            _log_tool_selection(graph_state, ml_prob)\n",
    "\n",
    "            # --- 各ツール詳細 ---\n",
    "            _log_brand_tool(brand_res)\n",
    "            _log_cert_tool(cert_res)\n",
    "            _log_domain_tool(domain_res)\n",
    "            if ctx_res:\n",
    "                _log_contextual_tool(ctx_res)\n",
    "\n",
    "            # --- Final Decision 詳細 ---\n",
    "            _log_final_decision(graph_state, result)\n",
    "\n",
    "            # --- LangGraph メッセージ抜粋 ---\n",
    "            _log_graph_messages(graph_state)\n",
    "\n",
    "            # --- 保存用データの構築 ---\n",
    "            dbg_final = _safe_dict(graph_state.get(\"debug_llm_final\"))\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': is_phishing,\n",
    "                'ai_confidence': confidence,\n",
    "                'ai_risk_level': risk_level,\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps(graph_state),\n",
    "                'tool_results_json': _json_dumps(tool_res),\n",
    "                # Brand\n",
    "                'brand_detected': brand_detected_flag,\n",
    "                'brand_suspected': brand_suspected_flag,\n",
    "                'brands': detected_brands,\n",
    "                'brand_used_llm': brand_details.get('used_llm'),\n",
    "                'brand_llm_quality': brand_details.get('llm_candidate_quality'),\n",
    "                'brand_llm_evidence_token': brand_details.get('llm_evidence_token'),\n",
    "                'brand_llm_detected_brand': brand_details.get('llm_detected_brand'),\n",
    "                'brand_llm_confidence': brand_details.get('llm_confidence'),\n",
    "                'brand_risk_score': brand_res.get('risk_score'),\n",
    "                'brand_issues': brand_res.get('detected_issues', []),\n",
    "                # Cert\n",
    "                'cert_issues': cert_res.get('detected_issues', []),\n",
    "                'cert_issuer': cert_issuer,\n",
    "                'cert_score': cert_res.get('risk_score', 0.0),\n",
    "                # Domain\n",
    "                'domain_issues': domain_res.get('detected_issues', []),\n",
    "                'domain_score': domain_res.get('risk_score', 0.0),\n",
    "                'tld_category': tld_cat,\n",
    "                # Contextual\n",
    "                'ctx_issues': ctx_issues,\n",
    "                'ctx_score': ctx_res.get('risk_score', None) if ctx_res else None,\n",
    "                # Tool Selection / Final LLM debug\n",
    "                'tool_selection_llm_used': graph_state.get('llm_used_selection'),\n",
    "                'tool_selection_llm_error': graph_state.get('llm_selection_error'),\n",
    "                'final_llm_path': dbg_final.get('path'),\n",
    "                'final_llm_success': dbg_final.get('success'),\n",
    "                'phase6_policy_version': graph_state.get('phase6_policy_version'),\n",
    "                'module_version': result.get('module_version'),\n",
    "                'error': None,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - eval_start\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] ❌ ERROR: {domain} - {str(e)}\")\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': False,\n",
    "                'ai_confidence': 0.0,\n",
    "                'ai_risk_level': 'error',\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps({}),\n",
    "                'tool_results_json': _json_dumps({}),\n",
    "                'error': str(e),\n",
    "            })\n",
    "\n",
    "    # --- 追記保存（500件ごと）: このドメインの結果（results[-1]）をバッファに積み、必要なら追記 ---\n",
    "    try:\n",
    "        if len(results) > before_len:\n",
    "            _chunk_buf.append(results[-1])\n",
    "            _flush_chunk_if_needed(force=False)\n",
    "    except Exception:\n",
    "        # 追記保存の失敗で評価自体を止めない（ログは結果側に残す）\n",
    "        pass\n",
    "    # --- 画面表示（コンパクト進捗） ---------------------------------------\n",
    "    # NOTE: 詳細ログは _buf に全量保存しているので、画面側は軽くする\n",
    "    try:\n",
    "        _last = results[-1] if results else None\n",
    "    except Exception:\n",
    "        _last = None\n",
    "\n",
    "    if _last is not None:\n",
    "        if _last.get(\"error\"):\n",
    "            _screen_counts[\"error\"] += 1\n",
    "        else:\n",
    "            if bool(_last.get(\"ai_is_phishing\")):\n",
    "                _screen_counts[\"phish\"] += 1\n",
    "            else:\n",
    "                _screen_counts[\"benign\"] += 1\n",
    "\n",
    "        # 詳細ログを画面に出さないモードのときだけ、進捗を間引いて表示\n",
    "        if (not SHOW_DOMAIN_LOG_ON_SCREEN) and (\n",
    "            ((idx + 1) % PROGRESS_EVERY == 0) or (idx == (len(target_df) - 1)) or _last.get(\"error\")\n",
    "        ):\n",
    "            if _HAS_CLEAR_OUTPUT and _USE_CLEAR_OUTPUT:\n",
    "                try:\n",
    "                    clear_output(wait=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            elapsed_total = time.time() - start_time\n",
    "            mark = \"❌\" if _last.get(\"error\") else (\"🔴\" if _last.get(\"ai_is_phishing\") else \"🟢\")\n",
    "            dom  = _last.get(\"domain\", \"-\")\n",
    "            mlp  = float(_last.get(\"ml_probability\") or 0.0)\n",
    "            conf = float(_last.get(\"ai_confidence\") or 0.0)\n",
    "            rl   = _last.get(\"ai_risk_level\", \"-\")\n",
    "            tsec = float(_last.get(\"processing_time\") or 0.0)\n",
    "\n",
    "            print(f\"[PROGRESS] {idx+1}/{len(target_df)}  phishing={_screen_counts['phish']}  benign={_screen_counts['benign']}  error={_screen_counts['error']}  elapsed={elapsed_total:.1f}s\")\n",
    "            print(f\"          last: {mark} {dom} (ML={mlp:.3f} risk={rl} conf={conf:.2f} t={tsec:.2f}s)\")\n",
    "            if _last.get(\"error\"):\n",
    "                print(f\"          last_error: {_last.get('error')}\")\n",
    "\n",
    "# --- 完了処理 ------------------------------------------------------------\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] Full evaluation complete! Total time: {total_time:.2f}s\")\n",
    "\n",
    "# DataFrame化（後続セルの分析用にメモリ上にも保持）\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# --- 追記保存: 端数（<500件）も必ず保存して終了 ---\n",
    "_flush_chunk_if_needed(force=True)\n",
    "\n",
    "print(f\"[INFO] Results saved (append) to: {full_eval_path}  rows_written={_written_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3acadd-4036-4bc3-891e-b0e63bbad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_one_domain(domain: str, ml: float = 0.3):\n",
    "    res = agent.evaluate(domain, ml)\n",
    "    gs = (res.get(\"graph_state\") or {})\n",
    "    dbg = (gs.get(\"debug_llm_final\") or {})\n",
    "    asmt = gs.get(\"final_assessment\")\n",
    "\n",
    "    print(\"=== RAW RESULT ===\")\n",
    "    print(f\"domain         : {res.get('domain')}\")\n",
    "    print(f\"ml_probability : {res.get('ml_probability')}\")\n",
    "    print(f\"success        : {res.get('success')}\")\n",
    "    print(f\"ai_is_phishing : {res.get('ai_is_phishing')}\")\n",
    "    print(f\"ai_confidence  : {res.get('ai_confidence')}\")\n",
    "    print(f\"ai_risk_level  : {res.get('ai_risk_level')}\")\n",
    "    print(f\"reasoning      : {res.get('reasoning')[:120]!r}...\")\n",
    "\n",
    "    print(\"\\n=== LLM FINAL DEBUG (debug_llm_final) ===\")\n",
    "    print(\"  path           :\", dbg.get(\"path\"))\n",
    "    print(\"  success        :\", dbg.get(\"success\"))\n",
    "    print(\"  error          :\", dbg.get(\"error\"))\n",
    "    print(\"  exception_type :\", dbg.get(\"exception_type\"))\n",
    "    print(\"  use_llm_decision:\", dbg.get(\"use_llm_decision\"))\n",
    "    print(\"  llm_is_none    :\", dbg.get(\"llm_is_none\"))\n",
    "    print(\"  strict_mode    :\", dbg.get(\"strict_mode\"))\n",
    "    print(\"  fallback_reason:\", dbg.get(\"fallback_reason\"))\n",
    "\n",
    "    print(\"\\n=== FINAL ASSESSMENT OBJECT ===\")\n",
    "    print(\"  type(asmt):\", type(asmt))\n",
    "    if asmt is not None:\n",
    "        print(\"  is_phishing :\", getattr(asmt, 'is_phishing', None))\n",
    "        print(\"  confidence  :\", getattr(asmt, 'confidence', None))\n",
    "        print(\"  risk_level  :\", getattr(asmt, 'risk_level', None))\n",
    "\n",
    "    print(\"\\n=== FALLBACK LOCATIONS ===\")\n",
    "    print(\"  \", gs.get(\"fallback_locations\"))\n",
    "\n",
    "    return res, gs, dbg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94248864-8072-4fad-8053-61e812d7d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6: graph.stream を使った単発デバッグ\n",
    "# ============================================\n",
    "from copy import deepcopy\n",
    "\n",
    "# ★ どの行をデバッグするか指定（例: 0番目 = 1件目）\n",
    "debug_idx = 0\n",
    "\n",
    "# guard: target_df が空なら原因（サンプリング設定/キャッシュ）を先に確認\n",
    "if target_df is None or len(target_df) == 0:\n",
    "    raise ValueError(\n",
    "        \"target_df is empty. N_SAMPLE=0/-1(ALL) の場合は、既存CSVキャッシュを無視して pickle から再生成する必要があります。\\n\"\n",
    "        \"→ Cell0/Cell3 を上から再実行してください。\"\n",
    "    )\n",
    "\n",
    "row = target_df.iloc[debug_idx]\n",
    "domain = row[\"domain\"]\n",
    "ml_prob = float(row[\"ml_probability\"])\n",
    "print(f\"[DEBUG] domain={domain}, ml_probability={ml_prob:.4f}\")\n",
    "\n",
    "# --- evaluate() が内部で作る initial_state とほぼ同じものを用意 ---\n",
    "initial_state = {\n",
    "    \"domain\": domain,\n",
    "    \"ml_probability\": float(ml_prob or 0.0),\n",
    "    \"strict_mode\": agent.strict_mode,\n",
    "    \"current_step\": \"initial\",\n",
    "    \"precheck_hints\": {},\n",
    "    \"selected_tools\": [],\n",
    "    \"tool_results\": {},\n",
    "    \"final_assessment\": None,\n",
    "    \"error\": None,\n",
    "    \"retry_count\": 0,\n",
    "    \"fallback_count\": 0,\n",
    "    \"fallback_locations\": [],\n",
    "    \"tool_execution_flags\": {},\n",
    "    \"next_step\": \"\",\n",
    "    \"messages\": [],  # AgentState に追加した debug 用チャンネル\n",
    "}\n",
    "\n",
    "if agent.graph is None:\n",
    "    raise RuntimeError(\"agent.graph が None なので stream() が使えません\")\n",
    "\n",
    "final_state = None\n",
    "for step in agent.graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    print(f\"\\n[STEP] current_step={step.get('current_step')}\")\n",
    "    msgs = step.get(\"messages\") or []\n",
    "    if not msgs:\n",
    "        continue\n",
    "\n",
    "    last = msgs[-1]\n",
    "\n",
    "    # メッセージ本文の取り出し\n",
    "    if hasattr(last, \"content\"):\n",
    "        text = last.content if isinstance(last.content, str) else str(last.content)\n",
    "    elif isinstance(last, dict):\n",
    "        text = str(last.get(\"content\", last))\n",
    "    else:\n",
    "        text = str(last)\n",
    "\n",
    "    # precheck / tool_selection / tool_execution だけ表示\n",
    "    if any(tag in text for tag in (\"[precheck]\", \"[tool_selection]\", \"[tool_execution]\")):\n",
    "        if hasattr(last, \"pretty_print\"):\n",
    "            last.pretty_print()\n",
    "        else:\n",
    "            print(\"    \" + text)\n",
    "\n",
    "    final_state = step\n",
    "\n",
    "# --- 最終状態のざっくり確認（余裕があれば）---\n",
    "if final_state is not None:\n",
    "    fa = final_state.get(\"final_assessment\")\n",
    "    print(\"\\n[FINAL STATE]\")\n",
    "    print(\"  is_phishing :\", getattr(fa, \"is_phishing\", None))\n",
    "    print(\"  confidence  :\", getattr(fa, \"confidence\", None))\n",
    "    print(\"  risk_level  :\", getattr(fa, \"risk_level\", None))\n",
    "    print(\"  tool_keys   :\", list((final_state.get(\"tool_results\") or {}).keys()))\n",
    "else:\n",
    "    print(\"[DEBUG] final_state が取得できませんでした\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3149a-01ec-4b2b-8c47-437626986896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6: ツール別詳細統計サマリー\n",
    "# ============================================\n",
    "import numpy as np\n",
    "\n",
    "# データの準備（エラーなしのデータのみ）\n",
    "valid_df = results_df[results_df['error'].isna()].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🔍 DETAILED TOOL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. 全体統計\n",
    "phish_count = valid_df['ai_is_phishing'].sum()\n",
    "total = len(valid_df)\n",
    "print(f\"\\n📊 Overall Performance\")\n",
    "print(f\"  Total Domains: {total}\")\n",
    "print(f\"  Phishing Detected: {phish_count} ({phish_count/total*100:.1f}%)\")\n",
    "print(f\"  Avg Processing Time: {valid_df['processing_time'].mean():.2f}s\")\n",
    "\n",
    "# 2. Certificate Analysis 統計 (今回注目の機能)\n",
    "print(f\"\\n🔒 Certificate Analysis Stats\")\n",
    "# Issueごとのカウント\n",
    "all_cert_issues = []\n",
    "for issues in valid_df['cert_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_cert_issues.extend(issues)\n",
    "    elif isinstance(issues, str) and issues: # 文字列の場合のケア\n",
    "        import ast\n",
    "        try:\n",
    "            all_cert_issues.extend(ast.literal_eval(issues))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if all_cert_issues:\n",
    "    from collections import Counter\n",
    "    cert_counts = Counter(all_cert_issues)\n",
    "    for issue, count in cert_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "else:\n",
    "    print(\"  No certificate issues detected.\")\n",
    "\n",
    "# 発行者(Issuer)のTop5 (Free CAの確認など)\n",
    "issuers = valid_df[valid_df['cert_issuer'] != 'unknown']['cert_issuer']\n",
    "if not issuers.empty:\n",
    "    print(f\"  [Top Issuers]\")\n",
    "    print(issuers.value_counts().head(5).to_string(header=False))\n",
    "\n",
    "# 3. Domain Analysis 統計\n",
    "print(f\"\\n🌐 Domain Analysis Stats\")\n",
    "all_domain_issues = []\n",
    "for issues in valid_df['domain_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_domain_issues.extend(issues)\n",
    "\n",
    "if all_domain_issues:\n",
    "    dom_counts = Counter(all_domain_issues)\n",
    "    for issue, count in dom_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "\n",
    "# 4. Brand Analysis 統計\n",
    "print(f\"\\n🏷️  Brand Analysis Stats\")\n",
    "brand_hits = valid_df[valid_df['brand_detected'] == True]\n",
    "print(f\"  Brand Detected: {len(brand_hits)} domains\")\n",
    "if not brand_hits.empty:\n",
    "    all_brands = []\n",
    "    for brands in brand_hits['brands']:\n",
    "        if isinstance(brands, list): all_brands.extend(brands)\n",
    "    print(f\"  [Top Detected Brands]\")\n",
    "    print(pd.Series(all_brands).value_counts().head(5).to_string(header=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✅ Verification Complete. Check CSV for per-domain details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e40ed-3cc6-4c82-90d2-9bb658c259b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル1: パス設定 & test_data / モデル読み込み（artifacts/<RUN_ID>/... に統一） ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cell 1 で定義された PROCESSED_DIR / MODELS_DIR / RUN_ID を利用\n",
    "if \"PROCESSED_DIR\" not in globals() or \"MODELS_DIR\" not in globals():\n",
    "    raise RuntimeError(\"PROCESSED_DIR / MODELS_DIR が未定義です。先に Cell 1 を実行してください。\")\n",
    "\n",
    "DATA_DIR = Path(PROCESSED_DIR)\n",
    "MODELS_DIR = Path(MODELS_DIR)  # すでに Path のはずだが念のため\n",
    "\n",
    "# 02_xgboost_training_evaluation_... の新仕様に合わせて:\n",
    "#   - test_data.pkl: artifacts/<RUN_ID>/processed/test_data.pkl\n",
    "#   - xgboost_model.pkl, scaler.pkl: artifacts/<RUN_ID>/models/...\n",
    "TEST_DATA_PKL = DATA_DIR / \"test_data.pkl\"\n",
    "XGB_MODEL_PKL = MODELS_DIR / \"xgboost_model.pkl\"\n",
    "SCALER_PKL    = MODELS_DIR / \"scaler.pkl\"\n",
    "\n",
    "print(\"TEST_DATA_PKL :\", TEST_DATA_PKL)\n",
    "print(\"XGB_MODEL_PKL :\", XGB_MODEL_PKL)\n",
    "print(\"SCALER_PKL    :\", SCALER_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ae907-89e0-44a1-95f0-01377fce73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル2: test_data + XGBoost で ml_probability を再計算 ===\n",
    "\n",
    "# 02 で joblib.dump していれば joblib.load でそのまま読めます\n",
    "test_data = joblib.load(TEST_DATA_PKL)\n",
    "\n",
    "X_test = np.asarray(test_data[\"X\"])\n",
    "y_test = np.asarray(test_data[\"y\"]).astype(int)\n",
    "domains_test = np.asarray(test_data[\"domains\"])\n",
    "\n",
    "xgb_model = joblib.load(XGB_MODEL_PKL)\n",
    "try:\n",
    "    scaler = joblib.load(SCALER_PKL)\n",
    "except FileNotFoundError:\n",
    "    scaler = None\n",
    "    print(\"⚠ scaler.pkl が見つからなかったので、スケーリング無しで推論します。\")\n",
    "\n",
    "def compute_ml_probabilities(model, X, scaler=None):\n",
    "    \"\"\"XGBoost モデルから P(phish) を推定するヘルパー\"\"\"\n",
    "    X_in = scaler.transform(X) if scaler is not None else X\n",
    "\n",
    "    # sklearn API (XGBClassifier) の場合\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = np.asarray(model.predict_proba(X_in))\n",
    "        if proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "            return proba[:, 1]\n",
    "        return proba.ravel()\n",
    "\n",
    "    # Booster API の場合\n",
    "    if hasattr(model, \"predict\"):\n",
    "        dtest = xgb.DMatrix(X_in)\n",
    "        proba = np.asarray(model.predict(dtest))\n",
    "        return proba.ravel()\n",
    "\n",
    "    raise RuntimeError(\"予期しない XGBoost モデル型です (predict_proba/predict が見つからない)。\")\n",
    "\n",
    "ml_probs_test = compute_ml_probabilities(xgb_model, X_test, scaler=scaler)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"domain\": domains_test,\n",
    "    \"label\": y_test,\n",
    "    \"ml_probability\": ml_probs_test,\n",
    "})\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951945a-58e4-4610-b2cd-f9e4fed7ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル3: 正常 (label==0) から N_BENIGN_SAMPLE 件サンプリング ===\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_SAMPLE<=0(ALL) の場合は全件を使う\n",
    "\n",
    "# N_BENIGN_SAMPLE は Cell 1 の設定に従う（必要なら環境変数 N_BENIGN_SAMPLE で上書き）\n",
    "# RANDOM_STATE は Cell 1 で定義（環境変数 RANDOM_STATE でも上書き可）\n",
    "\n",
    "benign_candidates = test_df.query(\"label == 0 and ml_probability < 0.5\").copy()\n",
    "print(\"benign candidates (label==0 & ml_prob<0.5):\", len(benign_candidates))\n",
    "\n",
    "# N_BENIGN_SAMPLE <= 0 の場合は「全件処理」\n",
    "if (N_BENIGN_SAMPLE <= 0) or (len(benign_candidates) <= N_BENIGN_SAMPLE):\n",
    "    print(f\"候補が {len(benign_candidates)} 件なので、そのまま全件使います。\")\n",
    "    benign_sample_df = benign_candidates.reset_index(drop=True)\n",
    "else:\n",
    "    benign_sample_df = benign_candidates.sample(N_BENIGN_SAMPLE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "benign_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdddae-6ae3-4940-a755-9a4eb919a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル4: benign サンプルに LangGraphPhishingAgent を実行 ===\n",
    "# ここでは agent は既に前のセルで初期化されている前提\n",
    "\n",
    "benign_agent_results = []\n",
    "for row in benign_sample_df.itertuples(index=False):\n",
    "    res = agent.evaluate(\n",
    "        domain=row.domain,\n",
    "        ml_probability=float(row.ml_probability),\n",
    "        # external_data は __init__ で渡しているなら省略でOK\n",
    "    )\n",
    "    # [ChangeLog] 2025-12-17: Attach code fingerprint columns to each record.\n",
    "    if isinstance(res, dict) and 'CODE_FP_ROW' in globals():\n",
    "        res.update(CODE_FP_ROW)\n",
    "    benign_agent_results.append(res)\n",
    "\n",
    "benign_agent_df = pd.DataFrame(benign_agent_results)\n",
    "\n",
    "# 必要な列だけをマージ\n",
    "benign_eval_df = benign_sample_df.merge(\n",
    "    benign_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_eval_df[\"label\"] = 0  # ground truth\n",
    "benign_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 追加セル: benign 評価結果をCSVへ保存（共有用） ===\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ラベル付き簡易サマリ\n",
    "out_dir = Path(LOGS_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_path = out_dir / f\"benign{len(benign_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) フルログ（agent.evaluate の生出力を含む）\n",
    "full_path = out_dir / f\"benign{len(benign_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 追加セル: hard-negative benign を作成（MLが高い正常ドメイン） ===\n",
    "# 目的: 「MLが高い正常」を集めて、FPが増えないか検証する（hard negatives）\n",
    "# デフォルトは 200 件。必要なら環境変数 N_BENIGN_HARD_SAMPLE で上書きできます。\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_HARD_SAMPLE<=0(ALL) の場合は全件を使う\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "N_BENIGN_HARD_SAMPLE = int(os.getenv(\"N_BENIGN_HARD_SAMPLE\", \"200\"))\n",
    "\n",
    "# label==0 全体から ML の高い順に並べる\n",
    "benign_all = test_df.query(\"label == 0\").copy()\n",
    "benign_all = benign_all.sort_values(\"ml_probability\", ascending=False)\n",
    "\n",
    "# すでに benign_sample_df を作っている場合は重複を避ける（任意）\n",
    "try:\n",
    "    used = set(benign_sample_df[\"domain\"].astype(str))\n",
    "    benign_all = benign_all[~benign_all[\"domain\"].astype(str).isin(used)]\n",
    "    print(\"removed overlap with benign_sample_df:\", len(used), \"used\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 全件処理（N<=0） or 候補不足なら全件\n",
    "if (N_BENIGN_HARD_SAMPLE <= 0) or (len(benign_all) <= N_BENIGN_HARD_SAMPLE):\n",
    "    print(f\"hard benign candidates are only {len(benign_all)}; using all.\")\n",
    "    benign_hard_sample_df = benign_all\n",
    "else:\n",
    "    benign_hard_sample_df = benign_all.head(N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "benign_hard_sample_df = benign_hard_sample_df.reset_index(drop=True)\n",
    "\n",
    "print(\"hard benign sample size:\", len(benign_hard_sample_df))\n",
    "if len(benign_hard_sample_df):\n",
    "    print(\"ml_probability (hard benign) min/mean/max:\",\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].min()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].mean()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].max()))\n",
    "benign_hard_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 追加セル: hard-negative benign を評価（full_eval を作る） ===\n",
    "# ここでも agent は既に初期化済みの前提です。\n",
    "\n",
    "benign_hard_agent_results = []\n",
    "for row in benign_hard_sample_df.itertuples(index=False):\n",
    "    res = agent.evaluate(\n",
    "        domain=row.domain,\n",
    "        ml_probability=float(row.ml_probability),\n",
    "    )\n",
    "    # [ChangeLog] 2025-12-17: Attach code fingerprint columns to each record.\n",
    "    if isinstance(res, dict) and 'CODE_FP_ROW' in globals():\n",
    "        res.update(CODE_FP_ROW)\n",
    "    benign_hard_agent_results.append(res)\n",
    "\n",
    "benign_hard_agent_df = pd.DataFrame(benign_hard_agent_results)\n",
    "\n",
    "# 必要な列だけをマージ（label=0）\n",
    "benign_hard_eval_df = benign_hard_sample_df.merge(\n",
    "    benign_hard_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_hard_eval_df[\"label\"] = 0  # ground truth\n",
    "benign_hard_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dafa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 追加セル: benign_hard 評価結果をCSVへ保存（共有用） ===\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ラベル付き簡易サマリ\n",
    "out_dir = Path(LOGS_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "eval_path = out_dir / f\"benign_hard{len(benign_hard_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) フルログ（agent.evaluate の生出力を含む）\n",
    "full_path = out_dir / f\"benign_hard{len(benign_hard_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c9e08-5d3c-4a3d-9f0d-c48022b7fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル5: FN サンプル側の整形 (全部 label=1) ===\n",
    "\n",
    "# target_df: FN サンプル（n=len(target_df), 全部 phish想定）\n",
    "# results_df: target_df に対して agent.evaluate() 済みの DataFrame\n",
    "fn_eval_df = (\n",
    "    target_df[[\"domain\", \"ml_probability\"]]\n",
    "    .merge(\n",
    "        results_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "        on=\"domain\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "fn_eval_df[\"label\"] = 1  # ground truth = phishing\n",
    "fn_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be900d16-c5ac-4bc3-8904-ef2a600e3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル6: phishN + benignN を結合 ===\n",
    "\n",
    "eval_df = pd.concat(\n",
    "    [fn_eval_df, benign_eval_df],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "print(eval_df[[\"label\", \"ai_is_phishing\"]].value_counts())\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7d6dc-f7e2-4a35-a37c-6dcacb8f8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === セル7: Agent 単体の混同行列と各種指標を計算 ===\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ConfusionResult:\n",
    "    TP: int\n",
    "    FP: int\n",
    "    TN: int\n",
    "    FN: int\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    fbeta: float\n",
    "    fpr: float\n",
    "\n",
    "def compute_confusion_and_scores(\n",
    "    df: pd.DataFrame,\n",
    "    label_col: str = \"label\",\n",
    "    pred_col: str = \"ai_is_phishing\",\n",
    "    beta: float = 2.0,\n",
    ") -> ConfusionResult:\n",
    "    y_true = df[label_col].astype(int).to_numpy()\n",
    "    y_pred = df[pred_col].astype(int).to_numpy()\n",
    "\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    beta2 = beta ** 2\n",
    "    denom = beta2 * precision + recall\n",
    "    fbeta = ((1 + beta2) * precision * recall) / denom if denom > 0 else 0.0\n",
    "\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "    return ConfusionResult(tp, fp, tn, fn, precision, recall, f1, fbeta, fpr)\n",
    "\n",
    "metrics_agent = compute_confusion_and_scores(eval_df, beta=2.0)\n",
    "metrics_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5c681-d436-4ad3-acd0-5b1ad993a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# いまのままでもOKな FP/FN の抽出\n",
    "is_tp = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_fp = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_tn = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "is_fn = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "\n",
    "tp_df = eval_df[is_tp].copy()\n",
    "fp_df = eval_df[is_fp].copy()\n",
    "tn_df = eval_df[is_tn].copy()\n",
    "fn_df = eval_df[is_fn].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2aaf4-1e46-4285-85a6-81e94b0479cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 候補にする列（環境に合わせて増減OK）\n",
    "candidate_cols = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "    \"error\",\n",
    "    \"phase\",\n",
    "    \"graph_state\",\n",
    "    # \"tools_used\",  # ← 今は無いのでコメントアウト\n",
    "]\n",
    "\n",
    "# 実際に存在する列だけを使う\n",
    "fp_cols = [c for c in candidate_cols if c in fp_df.columns]\n",
    "fn_cols = [c for c in candidate_cols if c in fn_df.columns]\n",
    "\n",
    "print(\"FP columns:\", fp_cols)\n",
    "display(fp_df[fp_cols].head(20))\n",
    "\n",
    "print(\"FN columns:\", fn_cols)\n",
    "display(fn_df[fn_cols].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7954ed-cd6b-4d8b-8a75-cb788ee0d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 列を省略せず表示\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# 横幅を広げる（好みで調整）\n",
    "pd.set_option(\"display.width\", 200)\n",
    "# 長い文字列も省略しない\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd75ed-4ac9-4cf2-80b5-380f2b16494b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb328b-9b2d-4059-9b47-3205535374e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP の全列・全行\n",
    "#display(fp_df)\n",
    "\n",
    "# FN の全列・全行\n",
    "display(fn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dce5d-19e9-45a0-9850-d39b9a2baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FP / FN 分析CSVの生成（eval_id 固定・参照元固定版）\n",
    "#   - 500件ごとに「追記」保存（分割ファイルを作らない）\n",
    "#   - 端数も捨てずに保存\n",
    "#   - 進捗表示あり\n",
    "#   - 一時停止: LOGS_DIR/_PAUSE_FP_FN_EXPORT が存在すると次chunk手前で停止\n",
    "#   - 再開: チェックポイント（.checkpoint.json）で重複追記を防止\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(\"=== Export FP/FN analysis CSVs (append mode, eval_id-fixed) ===\")\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 追跡用の指紋列（存在する分だけ使う）\n",
    "FINGERPRINT_COLS = [\n",
    "    \"eval_id\",\n",
    "    \"phase6_policy_version_code\",\n",
    "    \"phase6_wiring_file\",\n",
    "    \"phase6_wiring_sha256\",\n",
    "    \"llm_final_decision_file\",\n",
    "    \"llm_final_decision_sha256\",\n",
    "    \"langgraph_module_file\",\n",
    "    \"langgraph_module_sha256\",\n",
    "    \"dual_import_langgraph_module\",\n",
    "]\n",
    "\n",
    "BASE_CASE_COLS = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "]\n",
    "\n",
    "def _infer_eval_id(*dfs) -> str:\n",
    "    # 1) CODE_FP_ROW を最優先（Notebook実行単位で固定される想定）\n",
    "    if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "        _eid = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "        if _eid:\n",
    "            return str(_eid)\n",
    "\n",
    "    # 2) 各DFの eval_id が単一ならそれを採用\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame) and \"eval_id\" in df.columns:\n",
    "            vals = df[\"eval_id\"].dropna().astype(str).unique()\n",
    "            if len(vals) == 1:\n",
    "                return vals[0]\n",
    "\n",
    "    # 3) 最後の手段\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "\n",
    "def _existing(cols, df):\n",
    "    return [c for c in cols if isinstance(df, pd.DataFrame) and c in df.columns]\n",
    "\n",
    "\n",
    "def _load_ckpt(path: Path) -> int:\n",
    "    \"\"\"checkpoint から next_start を読む（無ければ0）。\"\"\"\n",
    "    try:\n",
    "        if path.exists():\n",
    "            obj = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "            n = int(obj.get(\"next_start\", 0))\n",
    "            return max(0, n)\n",
    "    except Exception:\n",
    "        return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _save_ckpt(path: Path, next_start: int) -> None:\n",
    "    try:\n",
    "        path.write_text(json.dumps({\"next_start\": int(next_start)}, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def _append_df_in_chunks(df_in: pd.DataFrame, out_path: Path, ckpt_path: Path, pause_path: Path, tag: str):\n",
    "    \"\"\"\n",
    "    df_in を out_path に 500行ごと追記する。\n",
    "    - ckpt_path の next_start から再開（重複追記防止）\n",
    "    - pause_path があれば次chunk手前で停止（端数は捨てない）\n",
    "    \"\"\"\n",
    "    total = int(len(df_in))\n",
    "    start = _load_ckpt(ckpt_path)\n",
    "\n",
    "    # 既存CSVが無いのに start>0 は矛盾 → 0に戻す\n",
    "    if start > 0 and (not out_path.exists()):\n",
    "        start = 0\n",
    "        _save_ckpt(ckpt_path, 0)\n",
    "\n",
    "    # ヘッダの有無: ファイルが存在してサイズ>0なら header=False\n",
    "    wrote_any = out_path.exists() and (out_path.stat().st_size > 0)\n",
    "\n",
    "    if total == 0:\n",
    "        # 空でもヘッダだけ作っておく（後工程の存在確認が楽）\n",
    "        if not wrote_any:\n",
    "            df_in.head(0).to_csv(out_path, index=False)\n",
    "        return {\"path\": str(out_path), \"total\": total, \"written\": 0, \"start\": start, \"paused\": False}\n",
    "\n",
    "    if start >= total:\n",
    "        print(f\"[EXPORT:{tag}] already complete: {total}/{total} -> {out_path.name}\")\n",
    "        return {\"path\": str(out_path), \"total\": total, \"written\": 0, \"start\": start, \"paused\": False}\n",
    "\n",
    "    t0 = time.time()\n",
    "    written = 0\n",
    "    paused = False\n",
    "\n",
    "    for s in range(start, total, CHUNK_SIZE):\n",
    "        if pause_path.exists():\n",
    "            print(f\"[PAUSE] {pause_path} exists. Stop before writing chunk {s}:{min(s+CHUNK_SIZE,total)} for {out_path.name}\")\n",
    "            paused = True\n",
    "            break\n",
    "\n",
    "        e = min(s + CHUNK_SIZE, total)\n",
    "        chunk_df = df_in.iloc[s:e]\n",
    "        chunk_df.to_csv(out_path, mode=\"a\", header=(not wrote_any), index=False)\n",
    "        wrote_any = True\n",
    "        written += int(len(chunk_df))\n",
    "        _save_ckpt(ckpt_path, e)\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"[EXPORT:{tag}] {e}/{total} appended -> {out_path.name}  (elapsed={elapsed:.1f}s)\")\n",
    "\n",
    "    return {\"path\": str(out_path), \"total\": total, \"written\": written, \"start\": start, \"paused\": paused}\n",
    "\n",
    "\n",
    "def _export_cases_and_details(*, full_df: pd.DataFrame, label: int, dataset_tag: str, out_dir: Path, pause_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    full_df（＝その実行で作ったfull_eval DF）だけを参照して FN/FP を作り、500件ごとに追記保存する。\n",
    "\n",
    "    - label=1: FN（真:phish なのに AIが benign と判定）\n",
    "    - label=0: FP（真:benign なのに AIが phish と判定）\n",
    "\n",
    "    重要:\n",
    "      - 分割ファイルは作らない（結合ミス防止）\n",
    "      - debug_log 等の情報量は削らない（detailsは該当行を丸ごと）\n",
    "      - 再開は checkpoint で制御（CSVの改行混入があるので行数カウントは危険）\n",
    "    \"\"\"\n",
    "    assert isinstance(full_df, pd.DataFrame)\n",
    "\n",
    "    eval_id = _infer_eval_id(full_df)\n",
    "    fp_cols = _existing(FINGERPRINT_COLS, full_df)\n",
    "\n",
    "    df = full_df.copy()\n",
    "    df[\"label\"] = int(label)\n",
    "\n",
    "    if int(label) == 1:\n",
    "        # FN: phishing(1) なのに ai_is_phishing=False\n",
    "        kind = \"fn\"\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == False)\n",
    "    else:\n",
    "        # FP: benign(0) なのに ai_is_phishing=True\n",
    "        kind = \"fp\"\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == True)\n",
    "\n",
    "    # cases: 軽量（分析軸 + fingerprint）\n",
    "    cases_cols = _existing(BASE_CASE_COLS, df) + fp_cols\n",
    "    cases_df = df.loc[cases_mask, cases_cols].copy()\n",
    "\n",
    "    # details: 情報量を落とさない（該当行を丸ごと）\n",
    "    details_df = df.loc[cases_mask].copy()\n",
    "\n",
    "    n_total = int(len(df))\n",
    "    n_cases = int(len(cases_df))\n",
    "\n",
    "    cases_path = out_dir / f\"{kind}_cases_full_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "    details_path = out_dir / f\"{kind}_details_full_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "\n",
    "    cases_ckpt = out_dir / f\"{cases_path.name}.checkpoint.json\"\n",
    "    details_ckpt = out_dir / f\"{details_path.name}.checkpoint.json\"\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"[EXPORT] {kind.upper()} {dataset_tag}  cases={n_cases}/{n_total}  chunk={CHUNK_SIZE}\")\n",
    "\n",
    "    cases_info = _append_df_in_chunks(cases_df, cases_path, cases_ckpt, pause_path, f\"{kind}-cases:{dataset_tag}\")\n",
    "    details_info = _append_df_in_chunks(details_df, details_path, details_ckpt, pause_path, f\"{kind}-details:{dataset_tag}\")\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_tag,\n",
    "        \"label\": int(label),\n",
    "        \"kind\": kind,\n",
    "        \"eval_id\": eval_id,\n",
    "        \"n_total\": n_total,\n",
    "        \"n_cases\": n_cases,\n",
    "        \"cases_path\": str(cases_path),\n",
    "        \"details_path\": str(details_path),\n",
    "        \"cases_checkpoint\": str(cases_ckpt),\n",
    "        \"details_checkpoint\": str(details_ckpt),\n",
    "        \"paused\": bool(cases_info.get(\"paused\") or details_info.get(\"paused\")),\n",
    "    }\n",
    "\n",
    "\n",
    "# 出力先（要件: run_id/logs 配下へ固定）\n",
    "if \"LOGS_DIR\" not in globals() or not globals().get(\"LOGS_DIR\"):\n",
    "    raise RuntimeError(\"LOGS_DIR is not set. Run Cell 1 first.\")\n",
    "out_dir = Path(globals()[\"LOGS_DIR\"]).resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 一時停止ファイル（ここにファイルがあると次chunk手前で停止）\n",
    "pause_path = out_dir / \"_PAUSE_FP_FN_EXPORT\"\n",
    "\n",
    "manifest = []\n",
    "\n",
    "# --- random（phish想定）: results_df が full_eval ---\n",
    "if \"results_df\" in globals() and isinstance(globals().get(\"results_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"results_df\"],\n",
    "            label=1,\n",
    "            dataset_tag=f\"random{len(globals()['results_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) results_df not found -> random FN export skipped\")\n",
    "\n",
    "# --- benign: benign_agent_df が full_eval ---\n",
    "if \"benign_agent_df\" in globals() and isinstance(globals().get(\"benign_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign{len(globals()['benign_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_agent_df not found -> benign FP export skipped\")\n",
    "\n",
    "# --- benign_hard ---\n",
    "if \"benign_hard_agent_df\" in globals() and isinstance(globals().get(\"benign_hard_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_hard_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign_hard{len(globals()['benign_hard_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "            pause_path=pause_path,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_hard_agent_df not found -> hard FP export skipped\")\n",
    "\n",
    "# 念のため（None混入事故防止）\n",
    "manifest = [m for m in manifest if isinstance(m, dict)]\n",
    "\n",
    "manifest_df = pd.DataFrame(manifest)\n",
    "manifest_eval_id = _infer_eval_id(*(globals().get(n) for n in [\"results_df\", \"benign_agent_df\", \"benign_hard_agent_df\"]))\n",
    "manifest_path = out_dir / f\"analysis_manifest__evalid_{manifest_eval_id}.csv\"\n",
    "manifest_df.to_csv(manifest_path, index=False)\n",
    "\n",
    "print(\"\\nSaved analysis CSVs to:\")\n",
    "for r in manifest:\n",
    "    print(f\"  - {str(r['kind']).upper()} {r['dataset']}: {r['n_cases']}/{r['n_total']}  paused={r.get('paused')}\")\n",
    "    print(f\"      cases      : {r['cases_path']}\")\n",
    "    print(f\"      details    : {r['details_path']}\")\n",
    "    print(f\"      cases_ckpt : {r['cases_checkpoint']}\")\n",
    "    print(f\"      details_ckpt: {r['details_checkpoint']}\")\n",
    "print(f\"  - manifest : {manifest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c686c-5124-4492-8148-07ffc87a3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Preview: FP / FN cases（上位だけ表示）\n",
    "# =========================\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== Preview (top cases) ===\")\n",
    "\n",
    "def _preview(df, title, n=10, sort_col=None, ascending=False):\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or len(df)==0:\n",
    "        print(f\"  (none) {title}\")\n",
    "        return\n",
    "    _df=df.copy()\n",
    "    if sort_col and sort_col in _df.columns:\n",
    "        _df=_df.sort_values(sort_col, ascending=ascending)\n",
    "    display(_df.head(n))\n",
    "\n",
    "# random FN\n",
    "if \"results_df\" in globals() and isinstance(globals().get(\"results_df\"), pd.DataFrame):\n",
    "    fn_df_preview = globals()[\"results_df\"][globals()[\"results_df\"][\"ai_is_phishing\"]==False][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\"] if c in globals()[\"results_df\"].columns]\n",
    "    ]\n",
    "    print(f\"random FN: {len(fn_df_preview)}/{len(globals()['results_df'])}\")\n",
    "    _preview(fn_df_preview, \"random FN (ml_probability desc)\", n=15, sort_col=\"ml_probability\", ascending=False)\n",
    "\n",
    "# benign FP\n",
    "if \"benign_agent_df\" in globals() and isinstance(globals().get(\"benign_agent_df\"), pd.DataFrame):\n",
    "    fp_df_preview = globals()[\"benign_agent_df\"][globals()[\"benign_agent_df\"][\"ai_is_phishing\"]==True][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\",\"detected_brands\"] if c in globals()[\"benign_agent_df\"].columns]\n",
    "    ]\n",
    "    print(f\"benign FP: {len(fp_df_preview)}/{len(globals()['benign_agent_df'])}\")\n",
    "    _preview(fp_df_preview, \"benign FP (ml_probability desc)\", n=20, sort_col=\"ml_probability\", ascending=False)\n",
    "\n",
    "# benign_hard FP\n",
    "if \"benign_hard_agent_df\" in globals() and isinstance(globals().get(\"benign_hard_agent_df\"), pd.DataFrame):\n",
    "    fp_hard_preview = globals()[\"benign_hard_agent_df\"][globals()[\"benign_hard_agent_df\"][\"ai_is_phishing\"]==True][\n",
    "        [c for c in [\"domain\",\"ml_probability\",\"ai_is_phishing\",\"ai_confidence\",\"ai_risk_level\",\"detected_brands\"] if c in globals()[\"benign_hard_agent_df\"].columns]\n",
    "    ]\n",
    "    print(f\"benign_hard FP: {len(fp_hard_preview)}/{len(globals()['benign_hard_agent_df'])}\")\n",
    "    _preview(fp_hard_preview, \"benign_hard FP (ml_probability desc)\", n=20, sort_col=\"ml_probability\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa2916-6315-4f1c-867b-cfe9f42252d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === ConfusionResult から混同行列を作成 ===\n",
    "cm = np.array([\n",
    "    [metrics_agent.TN, metrics_agent.FP],\n",
    "    [metrics_agent.FN, metrics_agent.TP],\n",
    "])\n",
    "\n",
    "labels = [\"benign (0)\", \"phish (1)\"]\n",
    "\n",
    "# 可視化したい指標（必要に応じて増減させてください）\n",
    "score_names = [\"precision\", \"recall\", \"f1\", \"fbeta\", \"fpr\"]\n",
    "score_values = [\n",
    "    metrics_agent.precision,\n",
    "    metrics_agent.recall,\n",
    "    metrics_agent.f1,\n",
    "    metrics_agent.fbeta,\n",
    "    metrics_agent.fpr,\n",
    "]\n",
    "\n",
    "# === 描画 ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 1) 混同行列のヒートマップ\n",
    "ax = axes[0]\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "# 軸ラベル\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
    "ax.set_yticklabels([\"True 0\", \"True 1\"])\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_title(\"Confusion Matrix (Agent)\")\n",
    "\n",
    "# 値をマスの上に表示\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(\n",
    "            j, i,\n",
    "            cm[i, j],\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# 2) Precision / Recall / F1 / Fbeta / FPR の棒グラフ\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(score_names))\n",
    "ax2.bar(x, score_values)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(score_names, rotation=30)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "ax2.set_ylabel(\"Score\")\n",
    "ax2.set_title(\"Agent Metrics (eval_df)\")\n",
    "\n",
    "# 値を棒の上に表示（小数3桁）\n",
    "for i, v in enumerate(score_values):\n",
    "    ax2.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18807a01-7020-4be8-99b7-771d86c83f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43616881-c74e-4902-a2c0-41b7e67af685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7035e94-c14a-43d2-9439-7ea533b6cbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
