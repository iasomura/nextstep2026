{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7d8d1d-b4e2-47d8-8c43-affa2fbf6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] BASE_DIR = /home/asomura/nextstep\n",
      "[INFO] RUN_ID = 2025-11-22_020618\n",
      "[INFO] ARTIFACTS_DIR = /home/asomura/nextstep/artifacts/2025-11-22_020618\n",
      "[INFO] Timestamp: 2025-11-22_020618\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 1: Áí∞Â¢ÉË®≠ÂÆö„Å®ÂàùÊúüÂåñ\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# „Éë„Çπ„ÅÆË®≠ÂÆö\n",
    "BASE_DIR = Path(\"/home/asomura/nextstep\")\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# _compat„Çí‰ΩøÁî®Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ\n",
    "try:\n",
    "    from _compat import paths\n",
    "    cfg = paths.load_config(os.getenv(\"CONFIG_JSON\"), strict=False)\n",
    "    RUN_ID = cfg.get(\"run_id\") or os.getenv(\"RUN_ID\") or \"20251030_004055\"\n",
    "except ImportError:\n",
    "    RUN_ID = \"20251030_004055\"\n",
    "    print(\"[INFO] _compat not found, using default RUN_ID\")\n",
    "\n",
    "ARTIFACTS_DIR = BASE_DIR / \"artifacts\" / RUN_ID\n",
    "HANDOFF_DIR = ARTIFACTS_DIR / \"handoff\"\n",
    "LOGS_DIR = ARTIFACTS_DIR / \"logs\"\n",
    "\n",
    "print(f\"[INFO] BASE_DIR = {BASE_DIR}\")\n",
    "print(f\"[INFO] RUN_ID = {RUN_ID}\")\n",
    "print(f\"[INFO] ARTIFACTS_DIR = {ARTIFACTS_DIR}\")\n",
    "\n",
    "# Âá∫ÂäõÁî®„ÅÆ„Çø„Ç§„É†„Çπ„Çø„É≥„Éó\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "print(f\"[INFO] Timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Handoff file not found: /home/asomura/nextstep/artifacts/2025-11-22_020618/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] Trying alternative path...\n",
      "[INFO] external_data loaded from: /home/asomura/nextstep/artifacts/20251030_004055/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] external_data keys: ['cfg', 'brand_keywords', 'cert_full_info_map', 'tools', 'llm', 'async_client', 'tools_code', 'present_top'] ...\n",
      "[INFO] Current brand_keywords count: 100\n",
      "[INFO] Added 39 new brands\n",
      "[INFO] Total brand_keywords: 139\n",
      "\n",
      "[Brand Check]\n",
      "  mufg            ‚úÖ\n",
      "  smbc            ‚úÖ\n",
      "  amazon          ‚úÖ\n",
      "  mercari         ‚úÖ\n",
      "  rakuten         ‚úÖ\n",
      "  metamask        ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2: External Data„ÅÆË™≠„ÅøËæº„Åø„Å®Brand KeywordsË£úÂº∑\n",
    "# ============================================\n",
    "\n",
    "# handoff„Åã„Çâexternal_data„ÇíË™≠„ÅøËæº„Åø\n",
    "handoff_path = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "\n",
    "if not handoff_path.exists():\n",
    "    print(f\"[ERROR] Handoff file not found: {handoff_path}\")\n",
    "    print(\"[INFO] Trying alternative path...\")\n",
    "    handoff_path = Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-3_llm_tools_setup_with_tools.pkl\")\n",
    "\n",
    "with open(handoff_path, 'rb') as f:\n",
    "    external_data = pickle.load(f)\n",
    "\n",
    "print(f\"[INFO] external_data loaded from: {handoff_path}\")\n",
    "print(f\"[INFO] external_data keys: {list(external_data.keys())[:8]} ...\")\n",
    "\n",
    "# brand_keywords„ÅÆÁ¢∫Ë™ç„Å®Ë£úÂº∑\n",
    "if 'brand_keywords' not in external_data:\n",
    "    external_data['brand_keywords'] = []\n",
    "    print(\"[WARNING] brand_keywords not found, creating new list\")\n",
    "\n",
    "# ÁèæÂú®„ÅÆ„Éñ„É©„É≥„Éâ„ÇíÂ∞èÊñáÂ≠ó„ÅßÂèñÂæó\n",
    "brands_lower = [b.lower() for b in external_data['brand_keywords'] if isinstance(b, str)]\n",
    "print(f\"[INFO] Current brand_keywords count: {len(external_data['brand_keywords'])}\")\n",
    "\n",
    "# ÈáçË¶Å„Éñ„É©„É≥„Éâ„ÅÆ„É™„Çπ„ÉàÔºàÊó•Êú¨„ÅÆÈáëËûçÊ©üÈñ¢„ÇíÈáçÁÇπÁöÑ„Å´Ôºâ\n",
    "essential_brands = {\n",
    "    # Êó•Êú¨„ÅÆÈáëËûçÊ©üÈñ¢\n",
    "    \"mufg\", \"smbc\", \"mizuho\", \"ufj\", \"mitsubishi\", \"sumitomo\", \"mitsui\",\n",
    "    \"resona\", \"jcb\", \"visa\", \"mastercard\", \"amex\",\n",
    "    \"japanpost\", \"jppost\", \"yucho\", \"jabank\", \"shinkin\",\n",
    "    # Êó•Êú¨„ÅÆ„Çµ„Éº„Éì„Çπ\n",
    "    \"rakuten\", \"mercari\", \"yahoo\", \"line\", \"docomo\", \"au\", \"softbank\",\n",
    "    \"ntt\", \"kddi\", \"uniqlo\", \"muji\", \"nitori\",\n",
    "    # „Ç∞„É≠„Éº„Éê„É´„Éñ„É©„É≥„Éâ\n",
    "    \"amazon\", \"google\", \"apple\", \"microsoft\", \"paypal\", \"netflix\",\n",
    "    \"facebook\", \"meta\", \"instagram\", \"twitter\", \"x\",\n",
    "    \"metamask\", \"binance\", \"coinbase\", \"ethereum\", \"bitcoin\",\n",
    "    # Áü≠Á∏ÆURL„ÉªCDN\n",
    "    \"bit\", \"tinyurl\", \"shorturl\", \"cdn\", \"cloudflare\", \"akamai\"\n",
    "}\n",
    "\n",
    "# ‰∏çË∂≥„Åó„Å¶„ÅÑ„Çã„Éñ„É©„É≥„Éâ„ÇíËøΩÂä†\n",
    "added_brands = []\n",
    "for brand in essential_brands:\n",
    "    if brand not in brands_lower:\n",
    "        external_data['brand_keywords'].append(brand)\n",
    "        added_brands.append(brand)\n",
    "\n",
    "print(f\"[INFO] Added {len(added_brands)} new brands\")\n",
    "print(f\"[INFO] Total brand_keywords: {len(external_data['brand_keywords'])}\")\n",
    "\n",
    "# ‰∏ªË¶Å„Éñ„É©„É≥„Éâ„ÅÆÁ¢∫Ë™çË°®Á§∫\n",
    "check_brands = [\"mufg\", \"smbc\", \"amazon\", \"mercari\", \"rakuten\", \"metamask\"]\n",
    "print(\"\\n[Brand Check]\")\n",
    "for brand in check_brands:\n",
    "    exists = brand in [b.lower() for b in external_data['brand_keywords']]\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"  {brand:15} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ed7391-2b52-48c6-8074-709de2e26a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] Loading additional data from 04-2\n",
      "================================================================================\n",
      "[INFO] Found 04-2 at: /home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\n",
      "[INFO] 04-2 loaded successfully\n",
      "[INFO] 04-2 keys: ['cfg', 'RUN_ID', 'SESSION_ID', 'output_dirs', 'brand_keywords', 'cert_full_info_map', 'false_negatives_df', 'fn_features_df', 'HIGH_RISK_WORDS', 'suspicious_words_stats']...\n",
      "  ‚úÖ Added dangerous_tlds: NoneType (len=N/A)\n",
      "  ‚úÖ Added legitimate_tlds: NoneType (len=N/A)\n",
      "  ‚úÖ Added neutral_tlds: NoneType (len=N/A)\n",
      "  ‚úÖ Added phishing_tld_stats: DataFrame (len=178)\n",
      "  ‚úÖ Added high_risk_words: list (len=100)\n",
      "  ‚úÖ Added known_domains: dict (len=4132)\n",
      "\n",
      "[INFO] Added 6 data items from 04-2\n",
      "\n",
      "================================================================================\n",
      "[INFO] Final Data Availability Check\n",
      "================================================================================\n",
      "  ‚úÖ Brand keywords list            (len=139)\n",
      "  ‚úÖ Certificate information        (len=4132)\n",
      "  ‚úÖ Dangerous TLDs                 (len=N/A)\n",
      "  ‚úÖ Legitimate TLDs                (len=N/A)\n",
      "  ‚úÖ Neutral TLDs                   (len=N/A)\n",
      "  ‚úÖ TLD phishing statistics        (len=178)\n",
      "  ‚úÖ High risk words                (len=100)\n",
      "  ‚úÖ Known legitimate domains       (len=4132)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2„ÅÆÊúÄÂæå„Å´ËøΩÂä†: 04-2„Åã„Çâ‰∏çË∂≥„Éá„Éº„Çø„ÇíË£úÂÆå\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Loading additional data from 04-2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 04-2„ÅÆ„Éë„Çπ„ÇíÊé¢Á¥¢\n",
    "pickle_04_2_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "    Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\"),\n",
    "]\n",
    "\n",
    "data_04_2 = None\n",
    "for path in pickle_04_2_paths:\n",
    "    if path.exists():\n",
    "        print(f\"[INFO] Found 04-2 at: {path}\")\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                data_04_2 = pickle.load(f)\n",
    "            print(f\"[INFO] 04-2 loaded successfully\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {path}: {e}\")\n",
    "\n",
    "if data_04_2 is None:\n",
    "    print(\"[WARN] 04-2 not found, continuing with available data\")\n",
    "else:\n",
    "    print(f\"[INFO] 04-2 keys: {list(data_04_2.keys())[:10]}...\")\n",
    "    \n",
    "    # TLDÈñ¢ÈÄ£„Éá„Éº„Çø„ÇíËøΩÂä†\n",
    "    tld_keys = [\n",
    "        'dangerous_tlds', 'DANGEROUS_TLDS',\n",
    "        'legitimate_tlds', 'LEGITIMATE_TLDS',\n",
    "        'neutral_tlds', 'NEUTRAL_TLDS',\n",
    "        'phishing_tld_stats', 'TLD_STATS', 'tld_stats'\n",
    "    ]\n",
    "    \n",
    "    added_count = 0\n",
    "    for key in tld_keys:\n",
    "        if key in data_04_2:\n",
    "            # Ê®ôÊ∫ñÂåñ„Åï„Çå„Åü„Ç≠„ÉºÂêç„Å´„Éû„ÉÉ„Éî„É≥„Ç∞\n",
    "            standard_key = key.lower()\n",
    "            if 'dangerous' in standard_key:\n",
    "                target_key = 'dangerous_tlds'\n",
    "            elif 'legitimate' in standard_key:\n",
    "                target_key = 'legitimate_tlds'\n",
    "            elif 'neutral' in standard_key:\n",
    "                target_key = 'neutral_tlds'\n",
    "            elif 'tld' in standard_key and 'stat' in standard_key:\n",
    "                target_key = 'phishing_tld_stats'\n",
    "            else:\n",
    "                target_key = key\n",
    "            \n",
    "            if target_key not in external_data:\n",
    "                external_data[target_key] = data_04_2[key]\n",
    "                value = data_04_2[key]\n",
    "                size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "                print(f\"  ‚úÖ Added {target_key}: {type(value).__name__} (len={size})\")\n",
    "                added_count += 1\n",
    "    \n",
    "    # High Risk Words „ÇíËøΩÂä†\n",
    "    hrw_keys = ['HIGH_RISK_WORDS', 'high_risk_words', 'high_risk']\n",
    "    for key in hrw_keys:\n",
    "        if key in data_04_2 and 'high_risk_words' not in external_data:\n",
    "            external_data['high_risk_words'] = data_04_2[key]\n",
    "            words = data_04_2[key]\n",
    "            print(f\"  ‚úÖ Added high_risk_words: {type(words).__name__} (len={len(words)})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    # Known Domains „ÇíËøΩÂä†\n",
    "    kd_keys = ['KNOWN_DOMAINS', 'known_domains', 'legitimate_domains']\n",
    "    for key in kd_keys:\n",
    "        if key in data_04_2 and 'known_domains' not in external_data:\n",
    "            external_data['known_domains'] = data_04_2[key]\n",
    "            domains = data_04_2[key]\n",
    "            size = len(domains) if hasattr(domains, '__len__') else 'N/A'\n",
    "            print(f\"  ‚úÖ Added known_domains: {type(domains).__name__} (len={size})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n[INFO] Added {added_count} data items from 04-2\")\n",
    "\n",
    "# ÊúÄÁµÇÁ¢∫Ë™ç\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Final Data Availability Check\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "required_keys = {\n",
    "    'brand_keywords': 'Brand keywords list',\n",
    "    'cert_full_info_map': 'Certificate information',\n",
    "    'dangerous_tlds': 'Dangerous TLDs',\n",
    "    'legitimate_tlds': 'Legitimate TLDs',\n",
    "    'neutral_tlds': 'Neutral TLDs',\n",
    "    'phishing_tld_stats': 'TLD phishing statistics',\n",
    "    'high_risk_words': 'High risk words',\n",
    "    'known_domains': 'Known legitimate domains'\n",
    "}\n",
    "\n",
    "for key, description in required_keys.items():\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "        print(f\"  ‚úÖ {description:30} (len={size})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {description:30} NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading existing CSV from: /home/asomura/nextstep/artifacts/2025-11-16_184237/logs/random_eval_domains_latest.csv\n",
      "[INFO] Random100 loaded: 100 domains\n",
      "            domain  ml_probability\n",
      "0          jmbf.cn        0.453648\n",
      "1  baidu-xiamen.cn        0.244429\n",
      "2      tsjianye.cn        0.236587\n",
      "3    internetku.id        0.129556\n",
      "4  teslafarmer.com        0.094156\n",
      "\n",
      "[ML Probability Distribution]\n",
      "  Min:    0.004\n",
      "  Max:    0.497\n",
      "  Mean:   0.201\n",
      "  Median: 0.179\n",
      "  High risk (>0.4): 10 domains\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 3: Random100„Éá„Éº„Çø„ÅÆÊ∫ñÂÇôÔºàÂÖÉ„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØÊ∫ñÊã†Ôºâ\n",
    "# ============================================\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# „Éá„Éº„ÇøÊé¢Á¥¢Áî®„Éò„É´„Éë„ÉºÈñ¢Êï∞\n",
    "def _search_eval_df(obj):\n",
    "    '''dict/list ÂÜçÂ∏∞„Åß DataFrame „ÇíÊé¢„Åô'''\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        # „Çà„Åè„ÅÇ„Çã„Ç≠„ÉºÁõ¥ÂèÇÁÖß\n",
    "        for k in (\"false_negatives_df\", \"fn_df\", \"eval_df\", \"random_eval_df\"):\n",
    "            v = obj.get(k)\n",
    "            if isinstance(v, pd.DataFrame):\n",
    "                return v\n",
    "        for v in obj.values():\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    return None\n",
    "\n",
    "def _normalize_eval_df(df):\n",
    "    '''ÂàóÂêç„ÅÆÊè∫„Çå„Å´ÂØæÂøú„Åó„Å¶ domain, ml_probability „ÅÆ2Âàó„Å´Ê≠£Ë¶èÂåñ'''\n",
    "    print(\"[DEBUG] columns:\", list(df.columns))\n",
    "    \n",
    "    # lower ‚Üí ÂÖÉÂêç„ÅÆ„Éû„ÉÉ„Éó\n",
    "    lower2orig = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # 1) domainÂÄôË£ú\n",
    "    domain_candidates = [\"domain\", \"fqdn\", \"domain_name\", \"hostname\", \"host\", \"requested_host\"]\n",
    "    domain_key = None\n",
    "    for key in domain_candidates:\n",
    "        if key in lower2orig:\n",
    "            domain_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if domain_key is None:\n",
    "        # ÈÉ®ÂàÜ‰∏ÄËá¥\n",
    "        for c in df.columns:\n",
    "            if any(kw in c.lower() for kw in [\"domain\", \"fqdn\", \"host\", \"url\"]):\n",
    "                domain_key = c\n",
    "                print(f\"[DEBUG] domain fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    # 2) ml_probabilityÂÄôË£ú\n",
    "    ml_candidates = [\"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\", \n",
    "                     \"score\", \"pred_proba\", \"proba\", \"confidence\"]\n",
    "    mlp_key = None\n",
    "    for key in ml_candidates:\n",
    "        if key in lower2orig:\n",
    "            mlp_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if mlp_key is None:\n",
    "        # float„Ç´„É©„É†„Åã„ÇâÊé®Ê∏¨\n",
    "        float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "        for c in float_cols:\n",
    "            if any(kw in c.lower() for kw in [\"prob\", \"score\", \"pred\"]):\n",
    "                mlp_key = c\n",
    "                print(f\"[DEBUG] ml_probability fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    if domain_key is None or mlp_key is None:\n",
    "        print(\"[ERROR] could not infer domain/ml_probability columns\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"[DEBUG] chosen columns: domain={domain_key}, ml_prob={mlp_key}\")\n",
    "    \n",
    "    tmp = df[[domain_key, mlp_key]].copy()\n",
    "    tmp.columns = [\"domain\", \"ml_probability\"]\n",
    "    \n",
    "    # url‚Üídomain„ÅÆÊ≠£Ë¶èÂåñ\n",
    "    if \"url\" in domain_key.lower():\n",
    "        def _to_domain(x):\n",
    "            if not isinstance(x, str):\n",
    "                return \"\"\n",
    "            if \"://\" in x:\n",
    "                netloc = urlparse(x).netloc\n",
    "            else:\n",
    "                netloc = x\n",
    "            netloc = netloc.split(\"@\")[-1].split(\":\")[0]\n",
    "            return netloc.lower()\n",
    "        tmp[\"domain\"] = tmp[\"domain\"].map(_to_domain)\n",
    "    \n",
    "    # „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó\n",
    "    tmp[\"domain\"] = tmp[\"domain\"].astype(str).str.strip().str.lower()\n",
    "    tmp = tmp[tmp[\"domain\"].str.len() > 0]\n",
    "    tmp[\"ml_probability\"] = pd.to_numeric(tmp[\"ml_probability\"], errors=\"coerce\")\n",
    "    tmp = tmp[(tmp[\"ml_probability\"] >= 0.0) & (tmp[\"ml_probability\"] <= 1.0)]\n",
    "    tmp = tmp.dropna(subset=[\"ml_probability\"]).reset_index(drop=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# Random100„Éá„Éº„Çø„ÇíÂèñÂæó\n",
    "def get_random100_domains():\n",
    "    '''Random100„ÅÆ„Éâ„É°„Ç§„É≥„É™„Çπ„Éà„ÇíÂèñÂæóÔºàÂÖÉ„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅÆ„É≠„Ç∏„ÉÉ„ÇØÊ∫ñÊã†Ôºâ'''\n",
    "    \n",
    "    # ÊñπÊ≥ï1: Êó¢Â≠ò„ÅÆCSV„Åã„Çâ\n",
    "    csv_paths = [\n",
    "        LOGS_DIR / \"random_eval_domains_latest.csv\",\n",
    "        ARTIFACTS_DIR / \"logs\" / \"random_eval_domains_latest.csv\",\n",
    "        Path(\"/home/asomura/nextstep/artifacts/2025-11-16_184237/logs/random_eval_domains_latest.csv\")\n",
    "    ]\n",
    "    \n",
    "    for csv_path in csv_paths:\n",
    "        if csv_path.exists():\n",
    "            print(f\"[INFO] Loading existing CSV from: {csv_path}\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "            return df\n",
    "    \n",
    "    # ÊñπÊ≥ï2: pickle„Åã„ÇâÁîüÊàêÔºàÂÖÉ„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅÆ„É≠„Ç∏„ÉÉ„ÇØÔºâ\n",
    "    print(\"[INFO] CSV not found, generating from pickle...\")\n",
    "    \n",
    "    pickle_paths = [\n",
    "        HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "        HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\",\n",
    "        Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\"),\n",
    "        Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-3_llm_tools_setup_with_tools.pkl\")\n",
    "    ]\n",
    "    \n",
    "    eval_source_df = None\n",
    "    for pickle_path in pickle_paths:\n",
    "        if not pickle_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"[INFO] Trying: {pickle_path}\")\n",
    "        try:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                obj = pickle.load(f)\n",
    "            \n",
    "            # DataFrame„ÇíÊé¢„Åô\n",
    "            raw_df = _search_eval_df(obj)\n",
    "            if raw_df is not None and len(raw_df) > 0:\n",
    "                print(f\"[INFO] Found DataFrame with {len(raw_df)} rows\")\n",
    "                eval_source_df = raw_df\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {pickle_path}: {e}\")\n",
    "    \n",
    "    if eval_source_df is None:\n",
    "        raise RuntimeError(\n",
    "            \"Ë©ï‰æ°Áî®DataFrame„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ\\n\"\n",
    "            \"04-2 „Åæ„Åü„ÅØ 04-3 „ÅÆpickle„Éï„Ç°„Ç§„É´„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
    "        )\n",
    "    \n",
    "    # Ê≠£Ë¶èÂåñ\n",
    "    norm_df = _normalize_eval_df(eval_source_df)\n",
    "    if norm_df is None:\n",
    "        raise RuntimeError(\"DataFrame„ÅÆÊ≠£Ë¶èÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü\")\n",
    "    \n",
    "    print(f\"[INFO] Source rows (normalized): {len(norm_df)}\")\n",
    "    \n",
    "    # „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàÂÖÉ„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅØÂõ∫ÂÆö„Ç∑„Éº„Éâ„Å™„ÅóÔºâ\n",
    "    sample_n = min(100, len(norm_df))\n",
    "    random100 = norm_df.sample(n=sample_n).reset_index(drop=True)\n",
    "    \n",
    "    # CSV‰øùÂ≠ò\n",
    "    out_csv = LOGS_DIR / \"random_eval_domains_latest.csv\"\n",
    "    LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    random100.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Random100 saved to: {out_csv}\")\n",
    "    \n",
    "    return random100\n",
    "\n",
    "# Random100„Éá„Éº„Çø„ÇíÂèñÂæó\n",
    "random100_df = get_random100_domains()\n",
    "print(f\"[INFO] Random100 loaded: {len(random100_df)} domains\")\n",
    "print(random100_df.head())\n",
    "\n",
    "# MLÁ¢∫Áéá„ÅÆÂàÜÂ∏É„ÇíÁ¢∫Ë™ç\n",
    "print(f\"\\n[ML Probability Distribution]\")\n",
    "print(f\"  Min:    {random100_df['ml_probability'].min():.3f}\")\n",
    "print(f\"  Max:    {random100_df['ml_probability'].max():.3f}\")\n",
    "print(f\"  Mean:   {random100_df['ml_probability'].mean():.3f}\")\n",
    "print(f\"  Median: {random100_df['ml_probability'].median():.3f}\")\n",
    "\n",
    "# È´ò„É™„Çπ„ÇØ„Éâ„É°„Ç§„É≥ÔºàMLÁ¢∫Áéá > 0.4Ôºâ„ÅÆÊï∞\n",
    "high_risk = random100_df[random100_df['ml_probability'] > 0.4]\n",
    "print(f\"  High risk (>0.4): {len(high_risk)} domains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT INITIALIZATION WITH LLM\n",
      "================================================================================\n",
      "\n",
      "[1] Fixing LLM Configuration\n",
      "----------------------------------------\n",
      "‚úÖ LLM configuration enabled\n",
      "\n",
      "[2] Creating LLM Client\n",
      "----------------------------------------\n",
      "‚úÖ LLM client created and set\n",
      "\n",
      "[3] Wiring Phase6\n",
      "----------------------------------------\n",
      "‚úÖ Phase6 wired with real LLM\n",
      "\n",
      "[4] Importing LangGraphPhishingAgent\n",
      "----------------------------------------\n",
      "‚úÖ LangGraphPhishingAgent imported\n",
      "\n",
      "[6] Initializing Agent\n",
      "----------------------------------------\n",
      "‚úÖ Agent initialized\n",
      "   LLM Status: enabled=True\n",
      "\n",
      "[7] Quick Verification Test\n",
      "----------------------------------------\n",
      "Test domain: test-amazon.com\n",
      "  Time: 5.53s\n",
      "  is_phishing: True\n",
      "  ‚úÖ LLM is working (slow response)\n",
      "\n",
      "================================================================================\n",
      "AGENT READY FOR EVALUATION\n",
      "================================================================================\n",
      "‚úÖ LLM: Enabled\n",
      "‚úÖ Brand Detection: Using phishing_agent module version\n",
      "‚úÖ Agent: Initialized\n",
      "\n",
      "Proceed to Cell 5 for Random100 evaluation\n",
      "Expected time: ~8-10 minutes for 100 domains\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4: LangGraph„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÂàùÊúüÂåñÔºàRandom100Áî®ÂÆåÂÖ®ÁâàÔºâ\n",
    "# ============================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import types\n",
    "\n",
    "# Áí∞Â¢ÉË®≠ÂÆö\n",
    "os.chdir(BASE_DIR)\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(phishing_agent_path) not in sys.path:\n",
    "    sys.path.insert(0, str(phishing_agent_path))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT INITIALIZATION WITH LLM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. VLLM„ÅÆ„ÉÄ„Éü„ÉºAPI„Ç≠„Éº„ÇíË®≠ÂÆöÔºàÂøÖÈ†àÔºâ\n",
    "os.environ['OPENAI_API_KEY'] = 'dummy-key-for-vllm'\n",
    "base_url = \"http://192.168.100.71:30000\"\n",
    "\n",
    "# 2. LLMË®≠ÂÆö„ÇíÂº∑Âà∂ÊúâÂäπÂåñ\n",
    "print(\"\\n[1] Fixing LLM Configuration\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'external_data' not in globals():\n",
    "    print(\"‚ùå external_data not found! Run Cell 2 first.\")\n",
    "else:\n",
    "    if 'cfg' not in external_data:\n",
    "        external_data['cfg'] = {}\n",
    "    \n",
    "    external_data['cfg']['llm'] = {\n",
    "        'enabled': True,\n",
    "        'provider': 'vllm',\n",
    "        'base_url': base_url,\n",
    "        'vllm_base_url': base_url,\n",
    "        'model': 'Qwen/Qwen3-14B-FP8',\n",
    "        'vllm_model': 'Qwen/Qwen3-14B-FP8'\n",
    "    }\n",
    "    print(\"‚úÖ LLM configuration enabled\")\n",
    "\n",
    "# 3. phishpkg„Çí„ÇØ„É™„Ç¢ÔºàÂè§„ÅÑ„ÇÇ„ÅÆ„Åå„ÅÇ„Çå„Å∞Ôºâ\n",
    "for key in list(sys.modules.keys()):\n",
    "    if key.startswith('phishpkg'):\n",
    "        del sys.modules[key]\n",
    "\n",
    "# 4. LLM„ÇØ„É©„Ç§„Ç¢„É≥„Éà„Çí‰ΩúÊàê\n",
    "print(\"\\n[2] Creating LLM Client\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from langchain_community.llms import VLLMOpenAI\n",
    "    \n",
    "    llm_client = VLLMOpenAI(\n",
    "        openai_api_base=base_url,\n",
    "        openai_api_key=\"dummy\",\n",
    "        model_name=\"Qwen/Qwen3-14B-FP8\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    \n",
    "    external_data['llm'] = llm_client\n",
    "    print(\"‚úÖ LLM client created and set\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM client creation failed: {e}\")\n",
    "\n",
    "# 5. Phase6ÈÖçÁ∑öÔºàLLMÊúâÂäπÔºâ\n",
    "print(\"\\n[3] Wiring Phase6\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from phishing_agent.phase6_wiring import wire_phase6\n",
    "    wire_phase6(prefer_compat=True, fake_llm=False)  # fake_llm=False„ÅåÈáçË¶ÅÔºÅ\n",
    "    print(\"‚úÖ Phase6 wired with real LLM\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Phase6 wiring: {e}\")\n",
    "\n",
    "# 6. LangGraph„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí„Ç§„É≥„Éù„Éº„Éà\n",
    "print(\"\\n[4] Importing LangGraphPhishingAgent\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from phishing_agent.langgraph_module import LangGraphPhishingAgent\n",
    "print(\"‚úÖ LangGraphPhishingAgent imported\")\n",
    "\n",
    "# ========================================\n",
    "# [COMMENTED OUT] Brand Detection Patching\n",
    "# ========================================\n",
    "# ÊîπËâØÁâàbrand_impersonation_check„Å∏„ÅÆÂ∑Æ„ÅóÊõø„Åà„Çí„Ç≥„É°„É≥„Éà„Ç¢„Ç¶„Éà\n",
    "# ÁêÜÁî±: Cell 3ÔºàÊîπËâØÁâà„ÅÆÂÆöÁæ©Ôºâ„ÇíÂâäÈô§„Åó„Åü„Åü„ÇÅ„ÄÅÊú™ÂÆöÁæ©„Ç®„É©„Éº„ÇíÂõûÈÅø\n",
    "#\n",
    "# print(\"\\n[5] Patching Brand Detection\")\n",
    "# print(\"-\" * 40)\n",
    "#\n",
    "# if 'phishpkg.tools_module' in sys.modules:\n",
    "#     tools_module = sys.modules['phishpkg.tools_module']\n",
    "#     \n",
    "#     # ÂÖÉ„ÅÆÈñ¢Êï∞„Çí‰øùÂ≠ò\n",
    "#     if hasattr(tools_module, 'brand_impersonation_check'):\n",
    "#         tools_module._original_brand_check = tools_module.brand_impersonation_check\n",
    "#     \n",
    "#     # ÊîπËâØÁâà„ÅßÁΩÆ„ÅçÊèõ„Åà\n",
    "#     tools_module.brand_impersonation_check = brand_impersonation_check_enhanced\n",
    "#     print(\"‚úÖ Brand detection patched with enhanced version\")\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è phishpkg.tools_module not found, brand detection might not be enhanced\")\n",
    "\n",
    "# 8. „Ç®„Éº„Ç∏„Çß„É≥„ÉàÂàùÊúüÂåñ\n",
    "print(\"\\n[6] Initializing Agent\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "agent = LangGraphPhishingAgent(\n",
    "    strict_mode=False,\n",
    "    external_data=external_data\n",
    ")\n",
    "print(\"‚úÖ Agent initialized\")\n",
    "\n",
    "# LLMË®≠ÂÆö„ÅÆÁ¢∫Ë™ç„Å®Âº∑Âà∂ÊúâÂäπÂåñ\n",
    "if hasattr(agent, 'llm_config'):\n",
    "    if not agent.llm_config.enabled:\n",
    "        agent.llm_config.enabled = True\n",
    "        print(\"‚úÖ Forced LLM enabled=True\")\n",
    "    print(f\"   LLM Status: enabled={agent.llm_config.enabled}\")\n",
    "\n",
    "# 9. Âãï‰ΩúÁ¢∫Ë™ç„ÉÜ„Çπ„Éà\n",
    "print(\"\\n[7] Quick Verification Test\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "import time\n",
    "test_domain = \"test-amazon.com\"\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    result = agent.evaluate(test_domain, 0.35)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Test domain: {test_domain}\")\n",
    "    print(f\"  Time: {elapsed:.2f}s\")\n",
    "    print(f\"  is_phishing: {result.get('ai_is_phishing')}\")\n",
    "    \n",
    "    if elapsed > 2.0:\n",
    "        print(\"  ‚úÖ LLM is working (slow response)\")\n",
    "    elif elapsed > 0.5:\n",
    "        print(\"  ‚ö†Ô∏è LLM might be working\")\n",
    "    else:\n",
    "        print(\"  ‚ùå LLM not working (too fast)\")\n",
    "        print(\"  ‚ö†Ô∏è Check VLLM server status\")\n",
    "    \n",
    "    # BrandÊ§úÂá∫„ÅÆÁ¢∫Ë™ç\n",
    "    brand_result = result.get('tool_results', {}).get('brand', {})\n",
    "    if brand_result.get('data', {}).get('detected_issues'):\n",
    "        brands = brand_result['data']['details'].get('detected_brands', [])\n",
    "        print(f\"  Brands detected: {brands}\")\n",
    "        print(\"  ‚úÖ Brand detection is working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ‚ùå Test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGENT READY FOR EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ LLM: Enabled\")\n",
    "print(\"‚úÖ Brand Detection: Using phishing_agent module version\")\n",
    "print(\"‚úÖ Agent: Initialized\")\n",
    "print(\"\\nProceed to Cell 5 for Random100 evaluation\")\n",
    "print(\"Expected time: ~8-10 minutes for 100 domains\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b6dd56-b783-442f-a0d7-5178c741ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Generating TLD data from Database Analysis...\n",
      "  üîå Connecting to database: rapids_data at localhost...\n",
      "  ‚úÖ Database connected successfully\n",
      "  üìä Analyzing phishing domains...\n",
      "  üìä Analyzing trusted domains...\n",
      "    - Phishing unique: 320409\n",
      "    - Trusted unique: 450656\n",
      "  ‚úÖ Generated 28 dangerous TLDs\n",
      "  ‚úÖ Generated 26 legitimate TLDs\n",
      "  ‚úÖ Agent external_data updated\n",
      "‚úÖ TLD data patched via Database Analysis. Ready for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4.6: TLD„É™„Çπ„Éà„ÅÆÂãïÁöÑÁîüÊàêÔºà„Éá„Éº„Çø„Éô„Éº„ÇπÂàÜÊûêÁâàÔºâ\n",
    "# ‚Äª DBÊé•Á∂öÂøÖÈ†à„ÄÇÂ§±ÊïóÊôÇ„ÅØ„Ç®„É©„ÉºÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ\n",
    "# ============================================\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"üîß Generating TLD data from Database Analysis...\")\n",
    "\n",
    "# 03_ai_agent_analysis.ipynb „Åã„Çâ„ÅÆ DBË®≠ÂÆö\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# TLDÊäΩÂá∫Èñ¢Êï∞ (03„Åã„Çâ„ÅÆÁßªÊ§ç)\n",
    "def extract_tld(domain):\n",
    "    \"\"\"„Éâ„É°„Ç§„É≥„Åã„ÇâTLD„ÇíÊäΩÂá∫\"\"\"\n",
    "    if not domain:\n",
    "        return None\n",
    "    # URL„ÅÆÂ†¥Âêà„ÅØ„Éâ„É°„Ç§„É≥ÈÉ®ÂàÜ„ÇíÊäΩÂá∫\n",
    "    if '://' in domain:\n",
    "        try:\n",
    "            parsed = urlparse(domain)\n",
    "            domain = parsed.netloc\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # „Éù„Éº„ÉàÁï™Âè∑„ÇíÂâäÈô§\n",
    "    domain = str(domain).split(':')[0]\n",
    "    \n",
    "    parts = domain.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        # .co.jp, .ac.jp „Å™„Å©„ÅÆË§áÂêàTLDÂØæÂøú\n",
    "        if len(parts) >= 3 and parts[-2] in ['co', 'ac', 'or', 'ne', 'go']:\n",
    "            return f'.{parts[-2]}.{parts[-1]}'\n",
    "        else:\n",
    "            return f'.{parts[-1]}'\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    # „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„ÉÜ„Çπ„Éà\n",
    "    print(f\"  üîå Connecting to database: {DB_CONFIG['dbname']} at {DB_CONFIG['host']}...\")\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    print(\"  ‚úÖ Database connected successfully\")\n",
    "\n",
    "    # 1. „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Çµ„Ç§„Éà„ÅÆÂèñÂæó (ÂêÑ„ÇΩ„Éº„Çπ„Åã„Çâ)\n",
    "    print(\"  üìä Analyzing phishing domains...\")\n",
    "    phishing_queries = [\n",
    "        \"SELECT cert_domain as domain FROM phishtank_entries WHERE cert_status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM jpcert_phishing_urls WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\"\n",
    "    ]\n",
    "    \n",
    "    phishing_domains = []\n",
    "    for query in phishing_queries:\n",
    "        cur.execute(query)\n",
    "        results = cur.fetchall()\n",
    "        for row in results:\n",
    "            if row['domain']: phishing_domains.append(row['domain'])\n",
    "            \n",
    "    if not phishing_domains:\n",
    "        raise ValueError(\"No phishing domains found in database. Analysis cannot proceed.\")\n",
    "\n",
    "    # 2. Ê≠£Â∏∏„Çµ„Ç§„Éà„ÅÆÂèñÂæó\n",
    "    print(\"  üìä Analyzing trusted domains...\")\n",
    "    cur.execute(\"SELECT domain FROM trusted_certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\")\n",
    "    results = cur.fetchall()\n",
    "    trusted_domains = [row['domain'] for row in results if row['domain']]\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    # 3. „Éá„Éº„Çø„Éê„É©„É≥„ÇπË™øÊï¥ (03„Å®ÂêåÊßò„ÅÆ„É≠„Ç∏„ÉÉ„ÇØ)\n",
    "    # ÈáçË§áÈô§Âéª\n",
    "    phishing_domains_unique = list(set(phishing_domains))\n",
    "    trusted_domains_unique = list(set(trusted_domains))\n",
    "    \n",
    "    print(f\"    - Phishing unique: {len(phishing_domains_unique)}\")\n",
    "    print(f\"    - Trusted unique: {len(trusted_domains_unique)}\")\n",
    "    \n",
    "    # Â∞ë„Å™„ÅÑÊñπ„Å´Âêà„Çè„Åõ„Å¶„Çµ„É≥„Éó„É™„É≥„Ç∞\n",
    "    random.seed(42)\n",
    "    min_unique = min(len(phishing_domains_unique), len(trusted_domains_unique))\n",
    "    \n",
    "    if min_unique == 0:\n",
    "        raise ValueError(\"Insufficient data for analysis (one of the datasets is empty).\")\n",
    "        \n",
    "    phishing_balanced = random.sample(phishing_domains_unique, min(len(phishing_domains_unique), min_unique))\n",
    "    trusted_balanced = random.sample(trusted_domains_unique, min(len(trusted_domains_unique), min_unique))\n",
    "\n",
    "    # 4. TLDÈõÜË®à\n",
    "    phishing_tlds = Counter([extract_tld(d) for d in phishing_balanced if extract_tld(d)])\n",
    "    trusted_tlds = Counter([extract_tld(d) for d in trusted_balanced if extract_tld(d)])\n",
    "\n",
    "    # 5. Âç±Èô∫Â∫¶ÂàÜÊûê„Å®ÂàÜÈ°û\n",
    "    dangerous_tlds = []\n",
    "    \n",
    "    for tld, phish_count in phishing_tlds.items():\n",
    "        trust_count = trusted_tlds.get(tld, 0)\n",
    "        # „Çµ„É≥„Éó„É´Êï∞„ÅåÂ∞ë„Å™„Åô„Åé„Çã„ÇÇ„ÅÆ„ÅØÈô§Â§ñ\n",
    "        if phish_count >= 10:\n",
    "            ratio = phish_count / (trust_count + 1)\n",
    "            phish_pct = phish_count / len(phishing_balanced) * 100\n",
    "            \n",
    "            # Âà§ÂÆö„É≠„Ç∏„ÉÉ„ÇØ:\n",
    "            # 1. Ê≠£Â∏∏„Çµ„Ç§„Éà„ÅßÁöÜÁÑ°(0‰ª∂) „Åã„Å§ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Åß10‰ª∂‰ª•‰∏ä\n",
    "            # 2. ÊØîÁéá„Åå10ÂÄç‰ª•‰∏ä „Åã„Å§ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞ÂÖ®‰Ωì„ÅÆ0.1%‰ª•‰∏ä\n",
    "            if (trust_count == 0) or (ratio >= 10 and phish_pct >= 0.1):\n",
    "                dangerous_tlds.append(tld)\n",
    "    \n",
    "    # „Éâ„ÉÉ„Éà„ÇíÈô§Âéª„Åó„Å¶Ê†ºÁ¥ç (‰æã: '.xyz' -> 'xyz')\n",
    "    external_data['dangerous_tlds'] = [t.lstrip('.') for t in dangerous_tlds]\n",
    "\n",
    "    # Ê≠£ÂΩì„Å™TLD\n",
    "    legitimate_tlds = []\n",
    "    for tld, count in trusted_tlds.most_common():\n",
    "        if count >= 1000: # Áµ±Ë®àÁöÑ‰ø°È†ºÊÄß\n",
    "            phish_count = phishing_tlds.get(tld, 0)\n",
    "            ratio = phish_count / count\n",
    "            if ratio < 0.5: # Ê≠£Â∏∏„Çµ„Ç§„Éà„Åß„ÅÆ‰ΩøÁî®„Åå2ÂÄç‰ª•‰∏ä\n",
    "                legitimate_tlds.append(tld)\n",
    "    external_data['legitimate_tlds'] = [t.lstrip('.') for t in legitimate_tlds]\n",
    "\n",
    "    # ‰∏≠Á´ãÁöÑ„Å™TLD (‰∏ªË¶ÅTLD„ÅÆ„ÅÜ„Å°„ÄÅ‰∏äË®ò„Å´ÂÖ•„Çâ„Å™„Åã„Å£„Åü„ÇÇ„ÅÆ)\n",
    "    neutral_candidates = ['.com', '.org', '.net', '.info', '.biz']\n",
    "    neutral_tlds = []\n",
    "    for tld in neutral_candidates:\n",
    "        if tld not in dangerous_tlds and tld not in legitimate_tlds:\n",
    "            neutral_tlds.append(tld)\n",
    "    external_data['neutral_tlds'] = [t.lstrip('.') for t in neutral_tlds]\n",
    "    \n",
    "    # Áµ±Ë®àÊÉÖÂ†±„Çí‰øùÂ≠ò (Áîü„ÅÆCounter„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà)\n",
    "    external_data['phishing_tld_stats'] = phishing_tlds\n",
    "\n",
    "    print(f\"  ‚úÖ Generated {len(external_data['dangerous_tlds'])} dangerous TLDs\")\n",
    "    print(f\"  ‚úÖ Generated {len(external_data['legitimate_tlds'])} legitimate TLDs\")\n",
    "\n",
    "    # „Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÜÖ„ÅÆÂèÇÁÖßÊõ¥Êñ∞\n",
    "    if 'agent' in globals():\n",
    "        agent.external_data = external_data\n",
    "        print(\"  ‚úÖ Agent external_data updated\")\n",
    "        \n",
    "    print(\"‚úÖ TLD data patched via Database Analysis. Ready for evaluation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå DATABASE ANALYSIS FAILED: {e}\")\n",
    "    print(\"‚õî Stopping execution to prevent inaccurate results using fallback data.\")\n",
    "    # ÊòéÁ§∫ÁöÑ„Å´„Ç®„É©„Éº„ÇíÁô∫Áîü„Åï„Åõ„Å¶Âá¶ÁêÜ„ÇíÊ≠¢„ÇÅ„Çã\n",
    "    raise RuntimeError(\"Database connection or analysis failed. Check DB_CONFIG and database status.\") from eprint(\"‚úÖ TLD data patched. Ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd43fd4-670a-4a11-a60a-deaf0eff4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXTERNAL DATA INSPECTION (DETAILED)\n",
      "================================================================================\n",
      "\n",
      "[0] External Data Structure\n",
      "----------------------------------------\n",
      "Type: <class 'dict'>\n",
      "\n",
      "All keys in external_data:\n",
      "   1. async_client                   dict            (len=0)\n",
      "   2. brand_keywords                 list            (len=139)\n",
      "   3. cert_full_info_map             dict            (len=4132)\n",
      "   4. cfg                            dict            (len=4)\n",
      "   5. dangerous_tlds                 list            (len=28)\n",
      "   6. high_risk_words                list            (len=100)\n",
      "   7. known_domains                  dict            (len=4132)\n",
      "   8. legitimate_tlds                list            (len=26)\n",
      "   9. llm                            VLLMOpenAI      \n",
      "  10. neutral_tlds                   list            (len=3)\n",
      "  11. phishing_tld_stats             Counter         (len=447)\n",
      "  12. present_top                    list            (len=1)\n",
      "  13. timestamp                      str             (len=26 chars)\n",
      "  14. tools                          dict            (len=2)\n",
      "  15. tools_code                     dict            (len=1)\n",
      "  16. top_level_keys                 list            (len=2)\n",
      "\n",
      "================================================================================\n",
      "[1] Brand Keywords\n",
      "----------------------------------------\n",
      "Total count: 139\n",
      "Type: <class 'list'>\n",
      "\n",
      "First 10 brands:\n",
      "   1. allegro\n",
      "   2. facebook\n",
      "   3. microsoft\n",
      "   4. at&t\n",
      "   5. adobe\n",
      "   6. optus\n",
      "   7. aeoncard\n",
      "   8. amazon\n",
      "   9. apple\n",
      "  10. yahoo\n",
      "\n",
      "... (119 brands omitted) ...\n",
      "\n",
      "Last 10 brands:\n",
      "  130. google\n",
      "  131. docomo\n",
      "  132. mufg\n",
      "  133. japanpost\n",
      "  134. ntt\n",
      "  135. jppost\n",
      "  136. metamask\n",
      "  137. visa\n",
      "  138. shinkin\n",
      "  139. ethereum\n",
      "\n",
      "================================================================================\n",
      "[2] Certificate Full Info Map (DETAILED)\n",
      "----------------------------------------\n",
      "Total domains: 4132\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Detailed sample (first 3 domains):\n",
      "\n",
      "[1] Domain: 3t.fit\n",
      "    Type: <class 'dict'>\n",
      "    All keys: ['issuer_org', 'cert_age_days', 'is_free_ca', 'san_count', 'is_wildcard', 'is_self_signed', 'has_organization', 'not_before', 'not_after', 'has_certificate', 'source']\n",
      "    Full content:\n",
      "      issuer_org: Let's Encrypt\n",
      "      cert_age_days: 549\n",
      "      is_free_ca: True\n",
      "      san_count: 1\n",
      "      is_wildcard: False\n",
      "      is_self_signed: False\n",
      "      has_organization: False\n",
      "      not_before: 2024-04-28 07:54:11\n",
      "      not_after: 2024-07-27 07:54:10\n",
      "      has_certificate: True\n",
      "      source: certificates\n",
      "\n",
      "[2] Domain: 6479788.com\n",
      "    Type: <class 'dict'>\n",
      "    All keys: ['issuer_org', 'cert_age_days', 'is_free_ca', 'san_count', 'is_wildcard', 'is_self_signed', 'has_organization', 'not_before', 'not_after', 'has_certificate', 'source']\n",
      "    Full content:\n",
      "      issuer_org: Cloudflare, Inc.\n",
      "      cert_age_days: 1375\n",
      "      is_free_ca: True\n",
      "      san_count: 2\n",
      "      is_wildcard: False\n",
      "      is_self_signed: False\n",
      "      has_organization: True\n",
      "      not_before: 2022-01-23 00:00:00\n",
      "      not_after: 2023-01-23 23:59:59\n",
      "      has_certificate: True\n",
      "      source: certificates\n",
      "\n",
      "[3] Domain: 6up.cc\n",
      "    Type: <class 'dict'>\n",
      "    All keys: ['issuer_org', 'cert_age_days', 'is_free_ca', 'san_count', 'is_wildcard', 'is_self_signed', 'has_organization', 'not_before', 'not_after', 'has_certificate', 'source']\n",
      "    Full content:\n",
      "      issuer_org: Let's Encrypt\n",
      "      cert_age_days: 216\n",
      "      is_free_ca: True\n",
      "      san_count: 1\n",
      "      is_wildcard: False\n",
      "      is_self_signed: False\n",
      "      has_organization: False\n",
      "      not_before: 2025-03-27 09:14:59\n",
      "      not_after: 2025-06-25 09:14:58\n",
      "      has_certificate: True\n",
      "      source: certificates\n",
      "\n",
      "================================================================================\n",
      "[3] TLD Information Search\n",
      "----------------------------------------\n",
      "\n",
      "Searching in external_data root:\n",
      "  ‚úÖ dangerous_tlds: list (len=28)\n",
      "  ‚úÖ legitimate_tlds: list (len=26)\n",
      "  ‚úÖ neutral_tlds: list (len=3)\n",
      "  ‚úÖ phishing_tld_stats: Counter (len=447)\n",
      "  ‚ùå TLD_STATS: not found\n",
      "  ‚ùå tld_stats: not found\n",
      "\n",
      "Searching in external_data['cfg']:\n",
      "  cfg type: <class 'dict'>\n",
      "  cfg keys: ['run_id', 'paths', 'llm', 'brand_keywords_cfg']...\n",
      "\n",
      "================================================================================\n",
      "[4] High Risk Words Search\n",
      "----------------------------------------\n",
      "Searching in external_data root:\n",
      "  ‚úÖ high_risk_words: list (len=100)\n",
      "     First 10: ['abnamrobanknv', 'absabank', 'accurint', 'adobe', 'aeoncard', 'aetna', 'alibabagroup', 'allegro', 'alliedbanklimited', 'amazon']\n",
      "  ‚ùå HIGH_RISK_WORDS: not found\n",
      "  ‚ùå high_risk: not found\n",
      "\n",
      "================================================================================\n",
      "[5] Known Domains Search\n",
      "----------------------------------------\n",
      "Searching in external_data root:\n",
      "  ‚úÖ known_domains: dict (len=4132)\n",
      "     Sample (5 entries):\n",
      "       salescenter.allegro.com: True\n",
      "       xxxbleachhentai.com: True\n",
      "       TINy.Cc: True\n",
      "       activateweb.org: True\n",
      "       kaiguifs.com: True\n",
      "  ‚ùå KNOWN_DOMAINS: not found\n",
      "  ‚ùå legitimate_domains: not found\n",
      "\n",
      "================================================================================\n",
      "[6] Data Source Hint\n",
      "----------------------------------------\n",
      "Note: TLD lists and statistics might be in:\n",
      "  - 04-2_statistical_analysis.pkl\n",
      "  - config.json (tld_analysis section)\n",
      "  - Or need to be loaded separately\n",
      "\n",
      "Current pickle source: 04-3_llm_tools_setup_with_tools.pkl\n",
      "Consider loading 04-2 for complete TLD information.\n",
      "\n",
      "================================================================================\n",
      "DETAILED INSPECTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 5: External DataÂÜÖÂÆπÁ¢∫Ë™çÔºàË©≥Á¥∞ÁâàÔºâ\n",
    "# ============================================\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXTERNAL DATA INSPECTION (DETAILED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 0. External Data„ÅÆÂÖ®‰ΩìÊßãÈÄ†\n",
    "print(\"\\n[0] External Data Structure\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Type: {type(external_data)}\")\n",
    "print(f\"\\nAll keys in external_data:\")\n",
    "for i, key in enumerate(sorted(external_data.keys()), 1):\n",
    "    value = external_data[key]\n",
    "    value_type = type(value).__name__\n",
    "    \n",
    "    # „Çµ„Ç§„Ç∫ÊÉÖÂ†±\n",
    "    if isinstance(value, (list, dict)):\n",
    "        size_info = f\"(len={len(value)})\"\n",
    "    elif isinstance(value, str):\n",
    "        size_info = f\"(len={len(value)} chars)\"\n",
    "    else:\n",
    "        size_info = \"\"\n",
    "    \n",
    "    print(f\"  {i:2}. {key:30} {value_type:15} {size_info}\")\n",
    "\n",
    "# 1. Brand Keywords\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[1] Brand Keywords\")\n",
    "print(\"-\" * 40)\n",
    "if 'brand_keywords' in external_data:\n",
    "    brands = external_data['brand_keywords']\n",
    "    print(f\"Total count: {len(brands)}\")\n",
    "    print(f\"Type: {type(brands)}\")\n",
    "    \n",
    "    # ÊúÄÂàù„ÅÆ10‰ª∂\n",
    "    print(f\"\\nFirst 10 brands:\")\n",
    "    for i, brand in enumerate(brands[:10], 1):\n",
    "        print(f\"  {i:2}. {brand}\")\n",
    "    \n",
    "    # ÊúÄÂæå„ÅÆ10‰ª∂\n",
    "    if len(brands) > 20:\n",
    "        print(f\"\\n... ({len(brands) - 20} brands omitted) ...\")\n",
    "        print(f\"\\nLast 10 brands:\")\n",
    "        for i, brand in enumerate(brands[-10:], len(brands)-9):\n",
    "            print(f\"  {i:2}. {brand}\")\n",
    "    elif len(brands) > 10:\n",
    "        print(f\"\\nRemaining brands:\")\n",
    "        for i, brand in enumerate(brands[10:], 11):\n",
    "            print(f\"  {i:2}. {brand}\")\n",
    "else:\n",
    "    print(\"‚ùå brand_keywords not found\")\n",
    "\n",
    "# 2. Certificate Full Info Map (Ë©≥Á¥∞Áâà)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[2] Certificate Full Info Map (DETAILED)\")\n",
    "print(\"-\" * 40)\n",
    "if 'cert_full_info_map' in external_data:\n",
    "    cert_map = external_data['cert_full_info_map']\n",
    "    print(f\"Total domains: {len(cert_map)}\")\n",
    "    print(f\"Type: {type(cert_map)}\")\n",
    "    \n",
    "    # „Çµ„É≥„Éó„É´Ë°®Á§∫ÔºàÊúÄÂ§ß3‰ª∂„ÄÅÂÖ®„Éï„Ç£„Éº„É´„ÉâË°®Á§∫Ôºâ\n",
    "    sample_domains = list(cert_map.keys())[:3]\n",
    "    print(f\"\\nDetailed sample (first {len(sample_domains)} domains):\\n\")\n",
    "    \n",
    "    for idx, domain in enumerate(sample_domains, 1):\n",
    "        cert_info = cert_map[domain]\n",
    "        print(f\"[{idx}] Domain: {domain}\")\n",
    "        print(f\"    Type: {type(cert_info)}\")\n",
    "        \n",
    "        if isinstance(cert_info, dict):\n",
    "            print(f\"    All keys: {list(cert_info.keys())}\")\n",
    "            print(f\"    Full content:\")\n",
    "            for key, value in cert_info.items():\n",
    "                if isinstance(value, list) and len(value) > 3:\n",
    "                    print(f\"      {key}: {value[:3]} ... ({len(value)} total)\")\n",
    "                elif isinstance(value, dict):\n",
    "                    print(f\"      {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"      {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"    Content: {cert_info}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ùå cert_full_info_map not found\")\n",
    "\n",
    "# 3. ConfigÂÜÖ„ÅÆTLDÊÉÖÂ†±„ÇíÊé¢Á¥¢\n",
    "print(\"=\" * 80)\n",
    "print(\"[3] TLD Information Search\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3-1. Áõ¥Êé•„ÅÆ„Ç≠„Éº„ÇíÁ¢∫Ë™ç\n",
    "tld_keys = ['dangerous_tlds', 'legitimate_tlds', 'neutral_tlds', \n",
    "            'phishing_tld_stats', 'TLD_STATS', 'tld_stats']\n",
    "print(\"\\nSearching in external_data root:\")\n",
    "for key in tld_keys:\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        print(f\"  ‚úÖ {key}: {type(value).__name__} (len={len(value) if hasattr(value, '__len__') else 'N/A'})\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {key}: not found\")\n",
    "\n",
    "# 3-2. cfgÂÜÖ„ÇíÊé¢Á¥¢\n",
    "print(\"\\nSearching in external_data['cfg']:\")\n",
    "if 'cfg' in external_data:\n",
    "    cfg = external_data['cfg']\n",
    "    print(f\"  cfg type: {type(cfg)}\")\n",
    "    \n",
    "    if isinstance(cfg, dict):\n",
    "        print(f\"  cfg keys: {list(cfg.keys())[:10]}...\")\n",
    "        \n",
    "        # TLDÈñ¢ÈÄ£„ÇícfgÂÜÖ„ÅßÊé¢„Åô\n",
    "        for key in tld_keys:\n",
    "            if key in cfg:\n",
    "                value = cfg[key]\n",
    "                print(f\"  ‚úÖ cfg['{key}']: {type(value).__name__} (len={len(value) if hasattr(value, '__len__') else 'N/A'})\")\n",
    "        \n",
    "        # tld_analysis „ÇíÊé¢„Åô\n",
    "        if 'tld_analysis' in cfg:\n",
    "            tld_analysis = cfg['tld_analysis']\n",
    "            print(f\"\\n  Found 'tld_analysis' in cfg:\")\n",
    "            print(f\"    Type: {type(tld_analysis)}\")\n",
    "            if isinstance(tld_analysis, dict):\n",
    "                print(f\"    Keys: {list(tld_analysis.keys())}\")\n",
    "else:\n",
    "    print(\"  ‚ùå cfg not found\")\n",
    "\n",
    "# 4. High Risk Words „ÅÆÊé¢Á¥¢\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[4] High Risk Words Search\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "hrw_keys = ['high_risk_words', 'HIGH_RISK_WORDS', 'high_risk']\n",
    "print(\"Searching in external_data root:\")\n",
    "for key in hrw_keys:\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        print(f\"  ‚úÖ {key}: {type(value).__name__} (len={len(value) if hasattr(value, '__len__') else 'N/A'})\")\n",
    "        if isinstance(value, list) and len(value) > 0:\n",
    "            print(f\"     First 10: {value[:10]}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {key}: not found\")\n",
    "\n",
    "# 5. Known Domains „ÅÆÊé¢Á¥¢\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[5] Known Domains Search\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "kd_keys = ['known_domains', 'KNOWN_DOMAINS', 'legitimate_domains']\n",
    "print(\"Searching in external_data root:\")\n",
    "for key in kd_keys:\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        print(f\"  ‚úÖ {key}: {type(value).__name__} (len={len(value) if hasattr(value, '__len__') else 'N/A'})\")\n",
    "        if isinstance(value, dict) and len(value) > 0:\n",
    "            sample = dict(list(value.items())[:5])\n",
    "            print(f\"     Sample (5 entries):\")\n",
    "            for k, v in sample.items():\n",
    "                print(f\"       {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {key}: not found\")\n",
    "\n",
    "# 6. ÈáçË¶Å„Å™„Éá„Éº„Çø„Åå04-2„Å´„ÅÇ„Çã„ÅãÁ¢∫Ë™ç„ÅÆ„Éí„É≥„Éà\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[6] Data Source Hint\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Note: TLD lists and statistics might be in:\")\n",
    "print(\"  - 04-2_statistical_analysis.pkl\")\n",
    "print(\"  - config.json (tld_analysis section)\")\n",
    "print(\"  - Or need to be loaded separately\")\n",
    "print(\"\\nCurrent pickle source: 04-3_llm_tools_setup_with_tools.pkl\")\n",
    "print(\"Consider loading 04-2 for complete TLD information.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED INSPECTION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b2d18-cc04-4eab-bc45-93f6a10e24c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3d1be5-4376-4e25-af10-0492e941061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Module Verification\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÇ Checking: certificate_analysis...\n",
      "  ‚úÖ OK: New file loaded correctly\n",
      "  üìç Path: /home/asomura/nextstep/phishing_agent/tools/certificate_analysis.py\n",
      "\n",
      "üìÇ Checking: brand_impersonation_check...\n",
      "  ‚úÖ OK: New file loaded correctly\n",
      "  üìç Path: /home/asomura/nextstep/phishing_agent/tools/brand_impersonation_check.py\n",
      "\n",
      "------------------------------------------------------------\n",
      "‚úÖ ‰∏°Êñπ„Å®„ÇÇ 'OK' „Å™„Çâ„ÄÅÊ∫ñÂÇôÂÆå‰∫Ü„Åß„Åô„ÄÇ\n",
      "   'Kernel' -> 'Restart Kernel' „ÇíË°å„ÅÑ„ÄÅÊúÄÂàù„Åã„ÇâÂÆüË°å„Åô„Çå„Å∞\n",
      "   „Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„Åì„Çå„Çâ„ÅÆÊñ∞„Åó„ÅÑ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4.5: „ÉÑ„Éº„É´Ë™≠„ÅøËæº„ÅøÁä∂ÊÖã„ÅÆÊúÄÁµÇÁ¢∫Ë™ç\n",
    "# ============================================\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "print(\"üîç Tool Module Verification\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# „ÉÅ„Çß„ÉÉ„ÇØÂØæË±°\n",
    "targets = [\n",
    "    \"phishing_agent.tools.certificate_analysis\",\n",
    "    \"phishing_agent.tools.brand_impersonation_check\"\n",
    "]\n",
    "\n",
    "\n",
    "for module_name in targets:\n",
    "    short_name = module_name.split('.')[-1]\n",
    "    print(f\"\\nüìÇ Checking: {short_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. „Ç≠„É£„ÉÉ„Ç∑„É•Ê∂àÂéªÔºàÁ¢∫ÂÆü„Å´„Éï„Ç°„Ç§„É´„Åã„ÇâË™≠„ÇÄ„Åü„ÇÅÔºâ\n",
    "        if module_name in sys.modules:\n",
    "            del sys.modules[module_name]\n",
    "            \n",
    "        # 2. „Ç§„É≥„Éù„Éº„ÉàË©¶Ë°å\n",
    "        mod = importlib.import_module(module_name)\n",
    "        \n",
    "        # 3. „Éë„ÇπÁ¢∫Ë™ç\n",
    "        file_path = mod.__file__\n",
    "        \n",
    "        if f\"phishing_agent/tools/{short_name}.py\" in file_path:\n",
    "            print(f\"  ‚úÖ OK: New file loaded correctly\")\n",
    "            print(f\"  üìç Path: {file_path}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è WARNING: Unexpected path -> {file_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå ERROR: Failed to load -> {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"‚úÖ ‰∏°Êñπ„Å®„ÇÇ 'OK' „Å™„Çâ„ÄÅÊ∫ñÂÇôÂÆå‰∫Ü„Åß„Åô„ÄÇ\")\n",
    "print(\"   'Kernel' -> 'Restart Kernel' „ÇíË°å„ÅÑ„ÄÅÊúÄÂàù„Åã„ÇâÂÆüË°å„Åô„Çå„Å∞\")\n",
    "print(\"   „Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„Åì„Çå„Çâ„ÅÆÊñ∞„Åó„ÅÑ„ÉÑ„Éº„É´„Çí‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b3f4c8-5ab0-4e30-b757-41ec38802a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting FULL AGENT evaluation of 100 domains...\n",
      "================================================================================\n",
      "[INFO] LLM initialized: Qwen/Qwen3-14B-FP8\n",
      "[INFO] LLM initialized successfully: Qwen/Qwen3-14B-FP8 at http://192.168.100.71:30000/v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asomura/nextstep/phishing_agent/tools/brand_impersonation_check.py:263: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = self.llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/100] üü¢ jmbf.cn                             (ML: 0.454 / Time: 22.18s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld, random_pattern (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.45 (medium)\n",
      "------------------------------------------------------------\n",
      "[  2/100] üî¥ baidu-xiamen.cn                     (ML: 0.244 / Time: 6.13s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[  3/100] üî¥ tsjianye.cn                         (ML: 0.237 / Time: 4.34s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[  4/100] üî¥ internetku.id                       (ML: 0.130 / Time: 4.05s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Sectigo Limited)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[  5/100] üî¥ teslafarmer.com                     (ML: 0.094 / Time: 3.93s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[  6/100] üü¢ casefb332123.me                     (ML: 0.397 / Time: 23.84s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Sectigo Limited)\n",
      "    üèÅ Final : Conf=0.31 (low)\n",
      "------------------------------------------------------------\n",
      "[  7/100] üî¥ scottsorchids.com                   (ML: 0.175 / Time: 4.04s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[  8/100] üî¥ timwinterforiowa.com                (ML: 0.139 / Time: 3.09s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Sectigo Limited)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[  9/100] üî¥ onlinetolling-nzta.com              (ML: 0.092 / Time: 6.16s)\n",
      "    üè∑Ô∏è  Brand : ['line(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 10/100] üî¥ hengguai.cn                         (ML: 0.118 / Time: 3.74s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 11/100] üî¥ meezainc.com                        (ML: 0.149 / Time: 5.63s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 12/100] üî¥ pranksamillion.com                  (ML: 0.297 / Time: 4.89s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 13/100] üî¥ nanosorting.com                     (ML: 0.164 / Time: 4.85s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 14/100] üî¥ tempkool.com                        (ML: 0.245 / Time: 4.61s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 15/100] üî¥ beckli.online                       (ML: 0.329 / Time: 8.74s)\n",
      "    üè∑Ô∏è  Brand : ['line(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca (Issuer: Cloudflare, Inc.)\n",
      "    üåê Domain: short (TLD: unknown)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 16/100] üî¥ dompatr.icu                         (ML: 0.273 / Time: 4.80s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 17/100] üî¥ dourosailing.com                    (ML: 0.114 / Time: 3.09s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 18/100] üî¥ trycellegene.com                    (ML: 0.206 / Time: 4.06s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 19/100] üî¥ discountdealsmarket.icu             (ML: 0.101 / Time: 4.53s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 20/100] üî¥ home-i-land.jp                      (ML: 0.053 / Time: 3.54s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 21/100] üî¥ usptranuex.com                      (ML: 0.422 / Time: 4.75s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 22/100] üî¥ massmobilepayments.com              (ML: 0.212 / Time: 4.78s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 23/100] üü¢ amjhsag1009.com                     (ML: 0.468 / Time: 23.56s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld, random_pattern (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.47 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 24/100] üî¥ zhonglianguoji.com                  (ML: 0.198 / Time: 3.98s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 25/100] üî¥ login-service-index.com             (ML: 0.398 / Time: 4.60s)\n",
      "    üè∑Ô∏è  Brand : ['x(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 26/100] üî¥ stowawaypay.com                     (ML: 0.012 / Time: 5.86s)\n",
      "    üîí Cert  : free_ca, no_org, wildcard (Issuer: DigiCert Inc)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 27/100] üü¢ transit-depot.com                   (ML: 0.351 / Time: 20.86s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.35 (low)\n",
      "------------------------------------------------------------\n",
      "[ 28/100] üî¥ akmemeats.com                       (ML: 0.078 / Time: 3.95s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 29/100] üî¥ yiwzp.com                           (ML: 0.164 / Time: 7.04s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 30/100] üî¥ prombezpeka.com                     (ML: 0.094 / Time: 4.73s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 31/100] üî¥ kurkoyamato.one                     (ML: 0.182 / Time: 4.13s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 32/100] üî¥ artqeramika.com                     (ML: 0.144 / Time: 3.99s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 33/100] üî¥ projectwrangler.com                 (ML: 0.265 / Time: 4.45s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 34/100] üî¥ vveb3-exodus-vvallet.top            (ML: 0.313 / Time: 5.05s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 35/100] üî¥ myrobohamster.com                   (ML: 0.270 / Time: 5.66s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 36/100] üî¥ toyama-tokeigankyouten.com          (ML: 0.184 / Time: 4.24s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 37/100] üî¥ kuronekohelp.com                    (ML: 0.110 / Time: 3.60s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 38/100] üî¥ sparkasse-spush.de                  (ML: 0.023 / Time: 3.52s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 39/100] üü¢ payreviews.jp                       (ML: 0.466 / Time: 23.38s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.47 (low)\n",
      "------------------------------------------------------------\n",
      "[ 40/100] üî¥ zsedsu.cn                           (ML: 0.156 / Time: 6.39s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 41/100] üî¥ padangbaycity.com                   (ML: 0.040 / Time: 4.12s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 42/100] üî¥ forumkahvesi.com                    (ML: 0.046 / Time: 3.85s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 43/100] üî¥ eye-lucir.com                       (ML: 0.109 / Time: 3.57s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 44/100] üü¢ takakuya.com                        (ML: 0.308 / Time: 4.44s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.28 (low)\n",
      "------------------------------------------------------------\n",
      "[ 45/100] üî¥ gadgetrate.com                      (ML: 0.115 / Time: 4.75s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 46/100] üî¥ bamaky.com                          (ML: 0.261 / Time: 6.81s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 47/100] üî¥ dodgeandson.com                     (ML: 0.109 / Time: 4.95s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 48/100] üî¥ manupandey.com                      (ML: 0.287 / Time: 4.78s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 49/100] üî¥ unitedreflections.com               (ML: 0.056 / Time: 3.93s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 50/100] üî¥ calvinchina.com                     (ML: 0.009 / Time: 4.47s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 51/100] üî¥ fertravail.jp                       (ML: 0.187 / Time: 4.04s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 52/100] üî¥ banghexep.com                       (ML: 0.216 / Time: 5.42s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 53/100] üî¥ abichan.net                         (ML: 0.109 / Time: 4.84s)\n",
      "    üè∑Ô∏è  Brand : ['ntt(fuzzy)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 54/100] üü¢ mini0906.com                        (ML: 0.480 / Time: 21.74s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.48 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 55/100] üü¢ kucoinkb.com                        (ML: 0.461 / Time: 21.43s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.46 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 56/100] üî¥ visamir.com                         (ML: 0.051 / Time: 6.82s)\n",
      "    üè∑Ô∏è  Brand : ['visa(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 57/100] üü¢ 4aeh9ep.cn                          (ML: 0.497 / Time: 21.62s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.50 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 58/100] üî¥ scboutttique.shop                   (ML: 0.258 / Time: 4.52s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 59/100] üî¥ xyemmanuellucius.cn                 (ML: 0.260 / Time: 4.20s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 60/100] üî¥ tianxiqianhe.com                    (ML: 0.012 / Time: 4.68s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 61/100] üü¢ kuichbsjg.com                       (ML: 0.338 / Time: 4.54s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.29 (low)\n",
      "------------------------------------------------------------\n",
      "[ 62/100] üü¢ asiabow.com                         (ML: 0.489 / Time: 21.53s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.49 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 63/100] üü¢ columbusnebraskarealestate.com      (ML: 0.317 / Time: 4.46s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.29 (low)\n",
      "------------------------------------------------------------\n",
      "[ 64/100] üî¥ gettestosteroneonline.com           (ML: 0.157 / Time: 4.15s)\n",
      "    üè∑Ô∏è  Brand : ['line(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 65/100] üî¥ pms-agency.com                      (ML: 0.086 / Time: 4.76s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 66/100] üî¥ lkiex.com                           (ML: 0.247 / Time: 8.02s)\n",
      "    üè∑Ô∏è  Brand : ['x(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 67/100] üü¢ abbygabs.com                        (ML: 0.314 / Time: 5.18s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.29 (low)\n",
      "------------------------------------------------------------\n",
      "[ 68/100] üü¢ etc-japan-go.co                     (ML: 0.247 / Time: 4.03s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.00 (low)\n",
      "------------------------------------------------------------\n",
      "[ 69/100] üî¥ bdointernetaccess.com               (ML: 0.091 / Time: 4.68s)\n",
      "    üîí Cert  : free_ca, no_org, wildcard (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 70/100] üî¥ sparkass-ueberp.xyz                 (ML: 0.291 / Time: 5.86s)\n",
      "    üè∑Ô∏è  Brand : ['x(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 71/100] üî¥ sprotra.com                         (ML: 0.055 / Time: 5.83s)\n",
      "    üîí Cert  : free_ca, no_org, wildcard (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 72/100] üî¥ tl7999.com                          (ML: 0.117 / Time: 6.23s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 73/100] üî¥ bdoconcernapp.com                   (ML: 0.085 / Time: 3.87s)\n",
      "    üîí Cert  : free_ca, no_org, wildcard (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 74/100] üî¥ rancon.com.bd                       (ML: 0.169 / Time: 5.95s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short (TLD: unknown)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 75/100] üî¥ zlaysjme.com                        (ML: 0.104 / Time: 4.28s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 76/100] üü¢ ifwdzanz.top                        (ML: 0.346 / Time: 5.77s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.35 (low)\n",
      "------------------------------------------------------------\n",
      "[ 77/100] üî¥ marukoh1971.co.jp                   (ML: 0.061 / Time: 3.60s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 78/100] üî¥ tiyolog.com                         (ML: 0.225 / Time: 4.87s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 79/100] üî¥ zfaija.cn                           (ML: 0.081 / Time: 3.63s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 80/100] üî¥ nnutu.com                           (ML: 0.253 / Time: 7.18s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 81/100] üî¥ com-tiarxzsi.icu                    (ML: 0.027 / Time: 4.31s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 82/100] üî¥ gaufo.cn                            (ML: 0.137 / Time: 6.60s)\n",
      "    üè∑Ô∏è  Brand : ['au(substring)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: short, dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 83/100] üî¥ aifulvipprojp.sbs                   (ML: 0.287 / Time: 5.72s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 84/100] üî¥ aicolumns.com                       (ML: 0.295 / Time: 4.33s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 85/100] üü¢ motorsportphotoagency.com           (ML: 0.427 / Time: 22.10s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.33 (medium)\n",
      "------------------------------------------------------------\n",
      "[ 86/100] üî¥ biccenomoer.com                     (ML: 0.299 / Time: 4.81s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 87/100] üî¥ crmufgvipcards.top                  (ML: 0.477 / Time: 6.10s)\n",
      "    üè∑Ô∏è  Brand : ['mufg(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 88/100] üî¥ aeoncardmyups.com                   (ML: 0.182 / Time: 5.66s)\n",
      "    üè∑Ô∏è  Brand : ['aeoncard(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 89/100] üî¥ nta-japan-x.co                      (ML: 0.274 / Time: 7.87s)\n",
      "    üè∑Ô∏è  Brand : ['x(compound)'] (Issues: brand_detected)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.70 (high)\n",
      "------------------------------------------------------------\n",
      "[ 90/100] üî¥ hengyahose.com                      (ML: 0.143 / Time: 4.07s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 91/100] üî¥ actonpropertygroup.com              (ML: 0.152 / Time: 5.64s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 92/100] üü¢ viuagigzgqd220.com                  (ML: 0.399 / Time: 21.72s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.35 (low)\n",
      "------------------------------------------------------------\n",
      "[ 93/100] üî¥ wvw-pichinchaweb.site               (ML: 0.056 / Time: 4.05s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 94/100] üî¥ carhebty.com                        (ML: 0.075 / Time: 4.37s)\n",
      "    üîí Cert  : free_ca, no_org, wildcard (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 95/100] üî¥ lifestylebusinessmagazine.com       (ML: 0.200 / Time: 4.40s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 96/100] üü¢ canadiantranslator.ca               (ML: 0.004 / Time: 4.19s)\n",
      "    üîí Cert  : no_org (Issuer: Starfield Technologies, Inc.)\n",
      "    üèÅ Final : Conf=0.00 (low)\n",
      "------------------------------------------------------------\n",
      "[ 97/100] üî¥ dowagiacroundoakstoves.com          (ML: 0.094 / Time: 3.97s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 98/100] üî¥ electrorecycle.cl                   (ML: 0.043 / Time: 4.24s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[ 99/100] üî¥ ecommercetube.com                   (ML: 0.081 / Time: 4.53s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "[100/100] üî¥ sangally-decor.com                  (ML: 0.016 / Time: 3.90s)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Google Trust Services)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "------------------------------------------------------------\n",
      "================================================================================\n",
      "[INFO] Full evaluation complete! Total time: 674.78s\n",
      "[INFO] Detailed results saved to: /home/asomura/nextstep/random100_full_eval_2025-11-22_021746.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 5: Random100Ë©ï‰æ°ÂÆüË°åÔºàÂÖ®„ÉÑ„Éº„É´Ë©≥Á¥∞Ë°®Á§∫ÁâàÔºâ\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"[INFO] Starting FULL AGENT evaluation of 100 domains...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLMË®≠ÂÆö„ÅÆÁ¢∫Ë™ç\n",
    "if 'agent' in globals() and hasattr(agent, 'llm_config'):\n",
    "    llm_config = agent.llm_config\n",
    "    if llm_config.enabled:\n",
    "        print(f\"[INFO] LLM initialized: {llm_config.model}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - results may be limited\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent not properly initialized\")\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Ë°®Á§∫Áî®„Éò„É´„Éë„Éº\n",
    "def _fmt_issues(issues):\n",
    "    return \", \".join(issues) if issues else \"None\"\n",
    "\n",
    "# ÂêÑ„Éâ„É°„Ç§„É≥„ÇíË©ï‰æ°\n",
    "for idx, row in random100_df.iterrows():\n",
    "    domain = row['domain']\n",
    "    ml_prob = row['ml_probability']\n",
    "    \n",
    "    try:\n",
    "        # --- „Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË°å ---\n",
    "        eval_start = time.time()\n",
    "        result = agent.evaluate(domain, ml_prob)\n",
    "        elapsed = time.time() - eval_start\n",
    "        \n",
    "        # --- ÁµêÊûú„ÅÆÊäΩÂá∫ ---\n",
    "        # 1. Âü∫Êú¨ÊÉÖÂ†±\n",
    "        is_phishing = result.get('ai_is_phishing', False)\n",
    "        confidence = result.get('ai_confidence', 0.0)\n",
    "        risk_level = result.get('ai_risk_level', 'unknown')\n",
    "        \n",
    "        # 2. „ÉÑ„Éº„É´ÁµêÊûú (tool_results) „ÅÆÂèñÂæó\n",
    "        # ‚Äª LangGraph„ÅÆÊßãÈÄ†‰∏ä„ÄÅgraph_state „Åæ„Åü„ÅØ tool_results „Ç≠„Éº„Å´ÂÖ•„Å£„Å¶„ÅÑ„Çã\n",
    "        tool_res = {}\n",
    "        if 'graph_state' in result and 'tool_results' in result['graph_state']:\n",
    "            tool_res = result['graph_state']['tool_results']\n",
    "        elif 'tool_results' in result:\n",
    "            # Âè§„ÅÑ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆÂ†¥Âêà„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ\n",
    "            tool_res = result.get('tool_results', {})\n",
    "\n",
    "        # 3. ÂêÑ„ÉÑ„Éº„É´„ÅÆË©≥Á¥∞ÊäΩÂá∫\n",
    "        # [Brand]\n",
    "        brand_res = tool_res.get('brand', {})\n",
    "        brand_issues = brand_res.get('detected_issues', [])\n",
    "        brand_details = brand_res.get('details', {})\n",
    "        detected_brands = brand_details.get('detected_brands', [])\n",
    "        \n",
    "        # [Cert] - ‰ªäÂõûËøΩÂä†„Åó„Åü„ÉÑ„Éº„É´\n",
    "        cert_res = tool_res.get('cert', {})\n",
    "        cert_issues = cert_res.get('detected_issues', [])\n",
    "        cert_score = cert_res.get('risk_score', 0.0)\n",
    "        cert_details = cert_res.get('details', {})\n",
    "        cert_issuer = cert_details.get('issuer', 'unknown')\n",
    "        \n",
    "        # [Domain]\n",
    "        domain_res = tool_res.get('domain', {})\n",
    "        domain_issues = domain_res.get('detected_issues', [])\n",
    "        domain_details = domain_res.get('details', {})\n",
    "        tld_cat = domain_details.get('tld_category', '-')\n",
    "        \n",
    "        # [Contextual]\n",
    "        ctx_res = tool_res.get('contextual_risk_assessment', {})\n",
    "        ctx_issues = ctx_res.get('detected_issues', [])\n",
    "        \n",
    "        # --- „É≠„Ç∞Ë°®Á§∫ („É™„ÉÉ„ÉÅ„Éï„Ç©„Éº„Éû„ÉÉ„Éà) ---\n",
    "        mark = \"üî¥\" if is_phishing else \"üü¢\"\n",
    "        print(f\"[{idx+1:3}/{len(random100_df)}] {mark} {domain:<35} (ML: {ml_prob:.3f} / Time: {elapsed:.2f}s)\")\n",
    "        \n",
    "        # Brand info\n",
    "        if brand_issues or detected_brands:\n",
    "            print(f\"    üè∑Ô∏è  Brand : {detected_brands} (Issues: {_fmt_issues(brand_issues)})\")\n",
    "        \n",
    "        # Cert info (ÈáçË¶Å)\n",
    "        if cert_issues or cert_score > 0:\n",
    "            print(f\"    üîí Cert  : {_fmt_issues(cert_issues)} (Issuer: {cert_issuer})\")\n",
    "        \n",
    "        # Domain info\n",
    "        if domain_issues:\n",
    "            print(f\"    üåê Domain: {_fmt_issues(domain_issues)} (TLD: {tld_cat})\")\n",
    "            \n",
    "        # Contextual / Final\n",
    "        print(f\"    üèÅ Final : Conf={confidence:.2f} ({risk_level})\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # --- ‰øùÂ≠òÁî®„Éá„Éº„Çø„ÅÆÊßãÁØâ ---\n",
    "        results.append({\n",
    "            'domain': domain,\n",
    "            'ml_probability': ml_prob,\n",
    "            'ai_is_phishing': is_phishing,\n",
    "            'ai_confidence': confidence,\n",
    "            'ai_risk_level': risk_level,\n",
    "            'processing_time': elapsed,\n",
    "            # Brand\n",
    "            'brand_detected': bool(detected_brands),\n",
    "            'brands': detected_brands,\n",
    "            # Cert\n",
    "            'cert_issues': cert_issues,\n",
    "            'cert_issuer': cert_issuer,\n",
    "            'cert_score': cert_score,\n",
    "            # Domain\n",
    "            'domain_issues': domain_issues,\n",
    "            'tld_category': tld_cat,\n",
    "            # Contextual\n",
    "            'ctx_issues': ctx_issues,\n",
    "            'error': None\n",
    "        })\n",
    "            \n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - eval_start\n",
    "        print(f\"[{idx+1:3}/{len(random100_df)}] ‚ùå ERROR: {domain} - {str(e)}\")\n",
    "        results.append({\n",
    "            'domain': domain,\n",
    "            'ml_probability': ml_prob,\n",
    "            'ai_is_phishing': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# --- ÂÆå‰∫ÜÂá¶ÁêÜ ---\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] Full evaluation complete! Total time: {total_time:.2f}s\")\n",
    "\n",
    "# DataFrameÂåñ„Å®‰øùÂ≠ò\n",
    "results_df = pd.DataFrame(results)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "result_file = BASE_DIR / f\"random100_full_eval_{timestamp}.csv\"\n",
    "results_df.to_csv(result_file, index=False)\n",
    "print(f\"[INFO] Detailed results saved to: {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c3149a-01ec-4b2b-8c47-437626986896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç DETAILED TOOL ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä Overall Performance\n",
      "  Total Domains: 100\n",
      "  Phishing Detected: 82 (82.0%)\n",
      "  Avg Processing Time: 6.75s\n",
      "\n",
      "üîí Certificate Analysis Stats\n",
      "  - free_ca             : 99 domains\n",
      "  - no_org              : 99 domains\n",
      "  - wildcard            : 5 domains\n",
      "  [Top Issuers]\n",
      "Let's Encrypt            87\n",
      "Google Trust Services     7\n",
      "Sectigo Limited           3\n",
      "Cloudflare, Inc.          1\n",
      "DigiCert Inc              1\n",
      "\n",
      "üåê Domain Analysis Stats\n",
      "  - dangerous_tld       : 84 domains\n",
      "  - short               : 11 domains\n",
      "  - random_pattern      : 2 domains\n",
      "\n",
      "üè∑Ô∏è  Brand Analysis Stats\n",
      "  Brand Detected: 19 domains\n",
      "  [Top Detected Brands]\n",
      "x(compound)        8\n",
      "x(substring)       3\n",
      "line(compound)     2\n",
      "line(substring)    1\n",
      "ntt(fuzzy)         1\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Verification Complete. Check CSV for per-domain details.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 6: „ÉÑ„Éº„É´Âà•Ë©≥Á¥∞Áµ±Ë®à„Çµ„Éû„É™„Éº\n",
    "# ============================================\n",
    "import numpy as np\n",
    "\n",
    "# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇôÔºà„Ç®„É©„Éº„Å™„Åó„ÅÆ„Éá„Éº„Çø„ÅÆ„ÅøÔºâ\n",
    "valid_df = results_df[results_df['error'].isna()].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîç DETAILED TOOL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. ÂÖ®‰ΩìÁµ±Ë®à\n",
    "phish_count = valid_df['ai_is_phishing'].sum()\n",
    "total = len(valid_df)\n",
    "print(f\"\\nüìä Overall Performance\")\n",
    "print(f\"  Total Domains: {total}\")\n",
    "print(f\"  Phishing Detected: {phish_count} ({phish_count/total*100:.1f}%)\")\n",
    "print(f\"  Avg Processing Time: {valid_df['processing_time'].mean():.2f}s\")\n",
    "\n",
    "# 2. Certificate Analysis Áµ±Ë®à (‰ªäÂõûÊ≥®ÁõÆ„ÅÆÊ©üËÉΩ)\n",
    "print(f\"\\nüîí Certificate Analysis Stats\")\n",
    "# Issue„Åî„Å®„ÅÆ„Ç´„Ç¶„É≥„Éà\n",
    "all_cert_issues = []\n",
    "for issues in valid_df['cert_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_cert_issues.extend(issues)\n",
    "    elif isinstance(issues, str) and issues: # ÊñáÂ≠óÂàó„ÅÆÂ†¥Âêà„ÅÆ„Ç±„Ç¢\n",
    "        import ast\n",
    "        try:\n",
    "            all_cert_issues.extend(ast.literal_eval(issues))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if all_cert_issues:\n",
    "    from collections import Counter\n",
    "    cert_counts = Counter(all_cert_issues)\n",
    "    for issue, count in cert_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "else:\n",
    "    print(\"  No certificate issues detected.\")\n",
    "\n",
    "# Áô∫Ë°åËÄÖ(Issuer)„ÅÆTop5 (Free CA„ÅÆÁ¢∫Ë™ç„Å™„Å©)\n",
    "issuers = valid_df[valid_df['cert_issuer'] != 'unknown']['cert_issuer']\n",
    "if not issuers.empty:\n",
    "    print(f\"  [Top Issuers]\")\n",
    "    print(issuers.value_counts().head(5).to_string(header=False))\n",
    "\n",
    "# 3. Domain Analysis Áµ±Ë®à\n",
    "print(f\"\\nüåê Domain Analysis Stats\")\n",
    "all_domain_issues = []\n",
    "for issues in valid_df['domain_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_domain_issues.extend(issues)\n",
    "\n",
    "if all_domain_issues:\n",
    "    dom_counts = Counter(all_domain_issues)\n",
    "    for issue, count in dom_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "\n",
    "# 4. Brand Analysis Áµ±Ë®à\n",
    "print(f\"\\nüè∑Ô∏è  Brand Analysis Stats\")\n",
    "brand_hits = valid_df[valid_df['brand_detected'] == True]\n",
    "print(f\"  Brand Detected: {len(brand_hits)} domains\")\n",
    "if not brand_hits.empty:\n",
    "    all_brands = []\n",
    "    for brands in brand_hits['brands']:\n",
    "        if isinstance(brands, list): all_brands.extend(brands)\n",
    "    print(f\"  [Top Detected Brands]\")\n",
    "    print(pd.Series(all_brands).value_counts().head(5).to_string(header=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ Verification Complete. Check CSV for per-domain details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0c0c2-c81e-44db-82bd-304d6fa60fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e40ed-3cc6-4c82-90d2-9bb658c259b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d210795e-365c-4a4d-a219-9562a409da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çª„É´1: ÂÖ±ÈÄö„Éò„É´„Éë\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "\n",
    "def find_result(results: List[Dict[str, Any]], domain: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ë©ï‰æ°ÁµêÊûú„É™„Çπ„Éà„Åã„ÇâÁâπÂÆö„Éâ„É°„Ç§„É≥„ÅÆ1‰ª∂„ÇíËøî„Åô„Éò„É´„Éë\n",
    "    \"\"\"\n",
    "    target = domain.strip().lower()\n",
    "    for r in results:\n",
    "        d = str(r.get(\"domain\", \"\")).strip().lower()\n",
    "        if d == target:\n",
    "            return r\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0759d15d-b6f9-47e7-8f10-78f4466b4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çª„É´2: 1„Éâ„É°„Ç§„É≥„ÅÆ‰∏≠Ë∫´„ÇíÂÖ®ÈÉ®Ë¶ã„Çã„Éá„Éê„ÉÉ„Ç¨\n",
    "from typing import Any, Dict\n",
    "\n",
    "def debug_single_result(results: List[Dict[str, Any]], domain: str) -> None:\n",
    "    res = find_result(results, domain)\n",
    "    if not res:\n",
    "        print(f\"[WARN] domain '{domain}' „Åå results „Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\")\n",
    "        return\n",
    "    \n",
    "    gs: Dict[str, Any] = res.get(\"graph_state\", {}) or {}\n",
    "    tr: Dict[str, Any] = gs.get(\"tool_results\", {}) or {}\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"DEBUG for domain: {res.get('domain')}  (ML={res.get('ml_probability')})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"ai_is_phishing: {res.get('ai_is_phishing')}  \"\n",
    "          f\"ai_confidence: {res.get('ai_confidence')}  \"\n",
    "          f\"ai_risk_level: {res.get('ai_risk_level')}\")\n",
    "    print()\n",
    "    \n",
    "    # --- precheck ---\n",
    "    print(\">>> PRECHECK HINTS\")\n",
    "    pre = gs.get(\"precheck_hints\", {}) or {}\n",
    "    print(json.dumps(pre, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # --- tools ---\n",
    "    print(\"\\n>>> TOOL RESULTS (brand / cert / domain / contextual_risk_assessment / contextual)\")\n",
    "    for key in (\"brand\", \"cert\", \"domain\", \"contextual_risk_assessment\", \"contextual\"):\n",
    "        data = tr.get(key)\n",
    "        if data is None:\n",
    "            continue\n",
    "        print(f\"\\n[{key}]\")\n",
    "        if isinstance(data, dict):\n",
    "            print(f\"  risk_score : {data.get('risk_score')}\")\n",
    "            print(f\"  issues     : {data.get('detected_issues')}\")\n",
    "            details = data.get(\"details\", {})\n",
    "            if details:\n",
    "                print(\"  details    :\")\n",
    "                print(json.dumps(details, indent=2, ensure_ascii=False))\n",
    "            if data.get(\"_fallback\"):\n",
    "                print(\"  *** _fallback=True (tool ÂÜÖ„Åß„Ç®„É©„Éº or „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ) ***\")\n",
    "        else:\n",
    "            print(\"  raw:\", data)\n",
    "    \n",
    "    # --- final_assessment ---\n",
    "    print(\"\\n>>> FINAL ASSESSMENT (Phase4/6)\")\n",
    "    asmt = gs.get(\"final_assessment\")\n",
    "    if asmt is None:\n",
    "        print(\"  <final_assessment „Åå„ÅÇ„Çä„Åæ„Åõ„Çì>\")\n",
    "    else:\n",
    "        try:\n",
    "            # Pydantic v2 BaseModel „ÅÆÂ†¥Âêà\n",
    "            asmt_dict = asmt.model_dump()\n",
    "        except Exception:\n",
    "            # „Åô„Åß„Å´ dict „ÅÆÂ†¥Âêà\n",
    "            asmt_dict = asmt if isinstance(asmt, dict) else {\"_raw\": str(asmt)}\n",
    "        print(json.dumps(asmt_dict, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # --- fallback / trace ---\n",
    "    print(\"\\n>>> FALLBACK / TRACE\")\n",
    "    print(\"fallback_locations:\", gs.get(\"fallback_locations\"))\n",
    "    if \"decision_trace\" in gs:\n",
    "        print(\"decision_trace:\")\n",
    "        print(json.dumps(gs[\"decision_trace\"], indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"decision_trace: <none>\")\n",
    "    \n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9feba2-e7b7-4723-a4c3-b32451b0d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çª„É´3: Phase6 „Éù„É™„Ç∑„Éº„Å´Ê∏°„ÇãÂÖ•Âäõ„ÅÆË¶ÅÁ¥Ñ\n",
    "from phishing_agent.llm_final_decision import _summarize_tool_signals  # type: ignore\n",
    "\n",
    "def debug_policy_inputs(results: List[Dict[str, Any]], domain: str) -> None:\n",
    "    res = find_result(results, domain)\n",
    "    if not res:\n",
    "        print(f\"[WARN] domain '{domain}' „Åå results „Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\")\n",
    "        return\n",
    "    \n",
    "    gs: Dict[str, Any] = res.get(\"graph_state\", {}) or {}\n",
    "    tr: Dict[str, Any] = gs.get(\"tool_results\", {}) or {}\n",
    "    pre: Dict[str, Any] = gs.get(\"precheck_hints\", {}) or {}\n",
    "    ml = float(res.get(\"ml_probability\", 0.0) or 0.0)\n",
    "    \n",
    "    tsum = _summarize_tool_signals(tr)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"POLICY INPUTS for domain: {res.get('domain')}  (ML={ml:.3f})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"precheck:\")\n",
    "    print(f\"  tld_category          : {pre.get('tld_category')}\")\n",
    "    print(f\"  domain_length_category: {pre.get('domain_length_category')}\")\n",
    "    print(f\"  quick_risk            : {pre.get('quick_risk')}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"brand:\")\n",
    "    print(f\"  risk_score : {tsum['brand']['risk_score']}\")\n",
    "    print(f\"  issues     : {tsum['brand']['issues']}\")\n",
    "    print(f\"  brands     : {tsum['brand']['brands']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"cert:\")\n",
    "    print(f\"  risk_score : {tsum['cert']['risk_score']}\")\n",
    "    print(f\"  issues     : {tsum['cert']['issues']}\")\n",
    "    print(f\"  details    : {tsum['cert']['details']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"domain:\")\n",
    "    print(f\"  risk_score : {tsum['domain']['risk_score']}\")\n",
    "    print(f\"  issues     : {tsum['domain']['issues']}\")\n",
    "    print(f\"  details    : {tsum['domain']['details']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"contextual (used by Phase6):\")\n",
    "    print(f\"  risk_score : {tsum['contextual']['risk_score']}\")\n",
    "    print(f\"  issues     : {tsum['contextual']['issues']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"baseline_risk (max of brand/cert/domain/contextual): {tsum['baseline_risk']}\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb5ad45b-3b36-4ba6-b071-0c725e99d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Çª„É´4: R1 ÂÄôË£ú‰∏ÄË¶ßÔºàml<0.2 „Åã„Å§ free_ca+no_orgÔºâ\n",
    "def list_r1_candidates(results: List[Dict[str, Any]], ml_th: float = 0.2, limit: int = 20) -> None:\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        gs = r.get(\"graph_state\", {}) or {}\n",
    "        tr = gs.get(\"tool_results\", {}) or {}\n",
    "        cert = tr.get(\"cert\", {}) or {}\n",
    "        issues = set(cert.get(\"detected_issues\", []) or [])\n",
    "        ml = float(r.get(\"ml_probability\", 0.0) or 0.0)\n",
    "        \n",
    "        if ml < ml_th and {\"free_ca\", \"no_org\"} <= issues:\n",
    "            ctx = tr.get(\"contextual_risk_assessment\") or tr.get(\"contextual\") or {}\n",
    "            rows.append({\n",
    "                \"domain\": r.get(\"domain\"),\n",
    "                \"ml\": ml,\n",
    "                \"cert_issues\": sorted(list(issues)),\n",
    "                \"ctx_score\": float(ctx.get(\"risk_score\", 0.0) or 0.0),\n",
    "                \"ctx_issues\": ctx.get(\"detected_issues\", []),\n",
    "                \"ai_is_phishing\": r.get(\"ai_is_phishing\"),\n",
    "                \"ai_confidence\": r.get(\"ai_confidence\"),\n",
    "            })\n",
    "    \n",
    "    rows = sorted(rows, key=lambda x: x[\"ml\"])\n",
    "    print(f\"R1ÂÄôË£ú (ml<{ml_th}, free_ca+no_org) ‰ª∂Êï∞: {len(rows)}\")\n",
    "    print(\"-\" * 80)\n",
    "    for row in rows[:limit]:\n",
    "        print(\n",
    "            f\"{row['domain']:<30s} \"\n",
    "            f\"ml={row['ml']:.3f}  \"\n",
    "            f\"cert={row['cert_issues']}  \"\n",
    "            f\"ctx={row['ctx_score']:.3f}  \"\n",
    "            f\"final={row['ai_is_phishing']} (conf={row['ai_confidence']:.2f})\"\n",
    "        )\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb72235e-62d2-46cd-9d92-c02d6ef368a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1ÂÄôË£ú (ml<0.2, free_ca+no_org) ‰ª∂Êï∞: 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "DEBUG for domain: internetku.id  (ML=0.12955579)\n",
      "--------------------------------------------------------------------------------\n",
      "ai_is_phishing: True  ai_confidence: 0.55  ai_risk_level: medium-high\n",
      "\n",
      ">>> PRECHECK HINTS\n",
      "{}\n",
      "\n",
      ">>> TOOL RESULTS (brand / cert / domain / contextual_risk_assessment / contextual)\n",
      "\n",
      ">>> FINAL ASSESSMENT (Phase4/6)\n",
      "  <final_assessment „Åå„ÅÇ„Çä„Åæ„Åõ„Çì>\n",
      "\n",
      ">>> FALLBACK / TRACE\n",
      "fallback_locations: None\n",
      "decision_trace: <none>\n",
      "================================================================================\n",
      "================================================================================\n",
      "POLICY INPUTS for domain: internetku.id  (ML=0.130)\n",
      "--------------------------------------------------------------------------------\n",
      "precheck:\n",
      "  tld_category          : None\n",
      "  domain_length_category: None\n",
      "  quick_risk            : None\n",
      "\n",
      "brand:\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  brands     : []\n",
      "\n",
      "cert:\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    : {}\n",
      "\n",
      "domain:\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    : {}\n",
      "\n",
      "contextual (used by Phase6):\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "\n",
      "baseline_risk (max of brand/cert/domain/contextual): 0.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 1) R1ÂÄôË£ú„Çí„Åñ„Å£„Å®Á¢∫Ë™ç\n",
    "list_r1_candidates(results)\n",
    "\n",
    "# 2) „Åù„ÅÆ‰∏≠„Åã„Çâ„ÄÅ‰æã„Åà„Å∞ \"internetku.id\" „Å™„Å©\n",
    "debug_single_result(results, \"internetku.id\")\n",
    "debug_policy_inputs(results, \"internetku.id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c33eeab-aed0-4bac-987c-9b57e47c9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Ç®„É©„ÉºË©≥Á¥∞„ÇíË¶ã„Çã„Éá„Éê„ÉÉ„Ç¨\n",
    "def debug_error_details(results, domain: str) -> None:\n",
    "    res = find_result(results, domain)\n",
    "    if not res:\n",
    "        print(f\"[WARN] domain '{domain}' „Åå results „Å´Ë¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ERROR DETAILS for domain: {res.get('domain')}  (ML={res.get('ml_probability')})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # „Éà„ÉÉ„Éó„É¨„Éô„É´„ÅÆ„Ç≠„Éº‰∏ÄË¶ß\n",
    "    print(\"[keys]\")\n",
    "    print(sorted(res.keys()))\n",
    "    print()\n",
    "    \n",
    "    # ÊàêÂäü/Â§±Êïó„Éï„É©„Ç∞„Å®„Ç®„É©„ÉºÊÉÖÂ†±\n",
    "    print(\"[status]\")\n",
    "    print(\"  success       :\", res.get(\"success\"))\n",
    "    print(\"  phase         :\", res.get(\"phase\"))\n",
    "    print(\"  error_category:\", res.get(\"error_category\"))\n",
    "    print(\"  error         :\", res.get(\"error\"))\n",
    "    print()\n",
    "    \n",
    "    # „Éà„É¨„Éº„Çπ„Éê„ÉÉ„ÇØÔºàÈï∑„ÅÑÂ†¥Âêà„ÅØÂÖàÈ†≠„Å†„ÅëÔºâ\n",
    "    tb = res.get(\"traceback\")\n",
    "    if tb:\n",
    "        print(\"[traceback]\")\n",
    "        # ÂøÖË¶Å„Å™„ÇâÂÖàÈ†≠„Å†„Åë„Å´„Åó„Å¶„ÇÇOK\n",
    "        print(tb)\n",
    "    else:\n",
    "        print(\"[traceback]\")\n",
    "        print(\"  <no traceback field>\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# ÂÖ®‰Ωì„ÅÆ„Ç®„É©„Éº‰ª∂Êï∞„ÇÇ„Åñ„Å£„Å®Ë¶ã„Çã\n",
    "def summarize_errors(results):\n",
    "    total = len(results)\n",
    "    errs = [r for r in results if r.get(\"success\") is False]\n",
    "    print(f\"total={total}, errors={len(errs)}\")\n",
    "    if errs:\n",
    "        print(\"  sample error domains:\", [e.get(\"domain\") for e in errs[:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21b6503a-9117-4a50-ae05-7846e1043b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total=100, errors=0\n",
      "================================================================================\n",
      "ERROR DETAILS for domain: internetku.id  (ML=0.12955579)\n",
      "--------------------------------------------------------------------------------\n",
      "[keys]\n",
      "['ai_confidence', 'ai_is_phishing', 'ai_risk_level', 'brand_detected', 'brands', 'cert_issuer', 'cert_issues', 'cert_score', 'ctx_issues', 'domain', 'domain_issues', 'error', 'ml_probability', 'processing_time', 'tld_category']\n",
      "\n",
      "[status]\n",
      "  success       : None\n",
      "  phase         : None\n",
      "  error_category: None\n",
      "  error         : None\n",
      "\n",
      "[traceback]\n",
      "  <no traceback field>\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ÂÖ®‰Ωì„Åß„Å©„Çå„Åè„Çâ„ÅÑ„Ç®„É©„Éº„Å´„Å™„Å£„Å¶„ÅÑ„Çã„Åã\n",
    "summarize_errors(results)\n",
    "\n",
    "# ÂïèÈ°å„ÅÆ internetku.id „ÅÆ„Ç®„É©„ÉºË©≥Á¥∞\n",
    "debug_error_details(results, \"internetku.id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba7f4bf-3591-412f-a2d0-f39c6d690e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell: agent.evaluate „ÅÆ‰∏≠Ë∫´„ÇíË¶ã„Çã„Éá„Éê„ÉÉ„Ç¨ ===\n",
    "from typing import Any, Dict\n",
    "import json\n",
    "\n",
    "def debug_agent_single(domain: str, ml_probability: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LangGraphPhishingAgent.evaluate(domain, ml_probability) „Çí1‰ª∂ÂÆüË°å„Åó„Å¶„ÄÅ\n",
    "    - precheck_hints\n",
    "    - tool_results (brand/cert/domain/contextual)\n",
    "    - final_assessment\n",
    "    „ÇíÂÖ®ÈÉ®„Éó„É™„É≥„Éà„Åô„Çã„ÄÇ\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"[DEBUG] agent.evaluate for {domain} (ML={ml_probability:.3f})\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. „Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË°åÔºàÂÖÉ„ÅÆ agent „Çí„Åù„ÅÆ„Åæ„Åæ‰Ωø„ÅÜÔºâ\n",
    "    res: Dict[str, Any] = agent.evaluate(domain, ml_probability)\n",
    "    print(\"\\n[TOP-LEVEL KEYS]\")\n",
    "    print(sorted(res.keys()))\n",
    "\n",
    "    # graph_state „ÅÆÂ≠òÂú®Á¢∫Ë™ç\n",
    "    gs: Dict[str, Any] = res.get(\"graph_state\", {}) or {}\n",
    "    print(\"\\n[GRAPH_STATE KEYS]\")\n",
    "    print(sorted(gs.keys()))\n",
    "\n",
    "    # 2. precheck_hints\n",
    "    print(\"\\n>>> PRECHECK HINTS\")\n",
    "    pre = gs.get(\"precheck_hints\", {}) or {}\n",
    "    print(json.dumps(pre, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # 3. tool_results „ÅÆÂêÑ„ÉÑ„Éº„É´\n",
    "    print(\"\\n>>> TOOL RESULTS\")\n",
    "    tr: Dict[str, Any] = gs.get(\"tool_results\", {}) or {}\n",
    "    print(\"tool keys:\", list(tr.keys()))\n",
    "\n",
    "    for key in (\"brand\", \"cert\", \"domain\", \"contextual_risk_assessment\", \"contextual\"):\n",
    "        data = tr.get(key)\n",
    "        if data is None:\n",
    "            continue\n",
    "        print(f\"\\n[{key}]\")\n",
    "        if isinstance(data, dict):\n",
    "            print(f\"  risk_score : {data.get('risk_score')}\")\n",
    "            print(f\"  issues     : {data.get('detected_issues')}\")\n",
    "            details = data.get(\"details\", {})\n",
    "            if details:\n",
    "                print(\"  details    :\")\n",
    "                print(json.dumps(details, indent=2, ensure_ascii=False))\n",
    "            if data.get(\"_fallback\"):\n",
    "                print(\"  *** _fallback=True (tool ÂÜÖ„Åß„Ç®„É©„Éº or „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ) ***\")\n",
    "        else:\n",
    "            print(\"  raw:\", data)\n",
    "\n",
    "    # 4. final_assessmentÔºàPhase6 + LLM „ÅÆÊúÄÁµÇÂà§ÂÆöÔºâ\n",
    "    print(\"\\n>>> FINAL ASSESSMENT\")\n",
    "    fa = gs.get(\"final_assessment\")\n",
    "    if fa is None:\n",
    "        print(\"  <None>\")\n",
    "    else:\n",
    "        try:\n",
    "            # Pydantic v2 BaseModel „ÅÆÂ†¥Âêà\n",
    "            fa_dict = fa.model_dump()\n",
    "        except Exception:\n",
    "            fa_dict = fa if isinstance(fa, dict) else {\"_raw\": str(fa)}\n",
    "        print(json.dumps(fa_dict, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # 5. decision_trace (R1/R2/R3„Å™„Å©)\n",
    "    if \"decision_trace\" in gs:\n",
    "        print(\"\\n>>> DECISION TRACE\")\n",
    "        print(json.dumps(gs[\"decision_trace\"], indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"\\n>>> DECISION TRACE\")\n",
    "        print(\"  <none>\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52619ba8-3687-401d-aaf8-c9340eb454a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DEBUG] agent.evaluate for internetku.id (ML=0.130)\n",
      "================================================================================\n",
      "\n",
      "[TOP-LEVEL KEYS]\n",
      "['ai_confidence', 'ai_is_phishing', 'ai_risk_level', 'detected_brands', 'domain', 'graph_state', 'llm_driven', 'ml_probability', 'module_version', 'phase', 'processing_time', 'reasoning', 'success', 'tools_used']\n",
      "\n",
      "[GRAPH_STATE KEYS]\n",
      "['current_step', 'domain', 'error', 'fallback_count', 'fallback_locations', 'final_assessment', 'ml_probability', 'precheck_hints', 'retry_count', 'selected_tools', 'tool_results']\n",
      "\n",
      ">>> PRECHECK HINTS\n",
      "{\n",
      "  \"ml_category\": \"very_low\",\n",
      "  \"ml_paradox\": false,\n",
      "  \"tld_category\": \"unknown\",\n",
      "  \"brand_detected\": false,\n",
      "  \"potential_brands\": [],\n",
      "  \"domain_length_category\": \"normal\",\n",
      "  \"quick_risk\": 0.05,\n",
      "  \"recommended_tools\": [\n",
      "    \"brand_impersonation_check\",\n",
      "    \"certificate_analysis\",\n",
      "    \"short_domain_analysis\"\n",
      "  ],\n",
      "  \"etld1\": {\n",
      "    \"registered_domain\": \"internetku.id\",\n",
      "    \"domain\": \"internetku\",\n",
      "    \"suffix\": \"id\",\n",
      "    \"subdomain\": \"\"\n",
      "  },\n",
      "  \"stats\": {\n",
      "    \"phishing_tld_weight\": 0.0,\n",
      "    \"high_risk_hits\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      ">>> TOOL RESULTS\n",
      "tool keys: ['brand', 'cert', 'domain', 'contextual_risk_assessment']\n",
      "\n",
      "[brand]\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    :\n",
      "{\n",
      "  \"detected_brands\": [],\n",
      "  \"method\": \"none\"\n",
      "}\n",
      "\n",
      "[cert]\n",
      "  risk_score : 0.35\n",
      "  issues     : ['free_ca', 'no_org']\n",
      "  details    :\n",
      "{\n",
      "  \"has_cert\": true,\n",
      "  \"issuer\": \"Sectigo Limited\",\n",
      "  \"is_free_ca\": true,\n",
      "  \"has_org\": false,\n",
      "  \"san_count\": 2,\n",
      "  \"is_domain_matched\": true\n",
      "}\n",
      "\n",
      "[domain]\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    :\n",
      "{\n",
      "  \"domain_length\": 10,\n",
      "  \"domain_length_category\": \"normal\",\n",
      "  \"base_domain\": \"internetku\",\n",
      "  \"tld\": \"id\",\n",
      "  \"tld_category\": \"unknown\",\n",
      "  \"entropy\": 2.72,\n",
      "  \"is_random_pattern\": false,\n",
      "  \"vowel_ratio\": 0.4,\n",
      "  \"digit_ratio\": 0.0,\n",
      "  \"tld_stat\": 0,\n",
      "  \"tld_stat_weight\": 0.0\n",
      "}\n",
      "\n",
      "[contextual_risk_assessment]\n",
      "  risk_score : 0.4149999999999999\n",
      "  issues     : ['ml_paradox', 'multiple_risk_factors', 'known_domain']\n",
      "  details    :\n",
      "{\n",
      "  \"ml_probability\": 0.12955579,\n",
      "  \"ml_category\": \"very_low\",\n",
      "  \"total_issues_count\": 2,\n",
      "  \"combined_risk_score\": 0.12,\n",
      "  \"tool_average_risk\": 0.12,\n",
      "  \"is_ml_paradox\": true,\n",
      "  \"all_detected_issues\": [\n",
      "    \"free_ca\",\n",
      "    \"no_org\"\n",
      "  ],\n",
      "  \"high_risk_hits\": 0,\n",
      "  \"known_domain\": {\n",
      "    \"is_known\": true,\n",
      "    \"label\": true,\n",
      "    \"mitigation\": 0.1\n",
      "  },\n",
      "  \"consistency_boost\": 0.0\n",
      "}\n",
      "\n",
      ">>> FINAL ASSESSMENT\n",
      "{\n",
      "  \"is_phishing\": true,\n",
      "  \"confidence\": 0.55,\n",
      "  \"risk_level\": \"medium-high\",\n",
      "  \"detected_brands\": [],\n",
      "  \"risk_factors\": [\n",
      "    \"policy:R1\"\n",
      "  ],\n",
      "  \"reasoning\": \"The domain internetku.id has a low risk level based on the analysis. The contextual risk score is 0.415, which is below the threshold of 0.5, and no significant risk factors were identified.\"\n",
      "}\n",
      "\n",
      ">>> DECISION TRACE\n",
      "  <none>\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === Cell: ÂÆüË°å‰æã ===\n",
    "\n",
    "# „Åï„Å£„Åç„ÅÆ„É≠„Ç∞„Å´Âêà„Çè„Åõ„Å¶ ML ÂÄ§„ÇíÂÖ•„Çå„Çã\n",
    "debug_result = debug_agent_single(\"internetku.id\", 0.12955579)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd9670d-0d90-4d3d-bad9-51f378e815af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[DEBUG] agent.evaluate for internetku.id (ML=0.130)\n",
      "================================================================================\n",
      "\n",
      "[TOP-LEVEL KEYS]\n",
      "['ai_confidence', 'ai_is_phishing', 'ai_risk_level', 'detected_brands', 'domain', 'graph_state', 'llm_driven', 'ml_probability', 'module_version', 'phase', 'processing_time', 'reasoning', 'success', 'tools_used']\n",
      "\n",
      "[GRAPH_STATE KEYS]\n",
      "['current_step', 'domain', 'error', 'fallback_count', 'fallback_locations', 'final_assessment', 'ml_probability', 'precheck_hints', 'retry_count', 'selected_tools', 'tool_results']\n",
      "\n",
      ">>> PRECHECK HINTS\n",
      "{\n",
      "  \"ml_category\": \"very_low\",\n",
      "  \"ml_paradox\": false,\n",
      "  \"tld_category\": \"unknown\",\n",
      "  \"brand_detected\": false,\n",
      "  \"potential_brands\": [],\n",
      "  \"domain_length_category\": \"normal\",\n",
      "  \"quick_risk\": 0.05,\n",
      "  \"recommended_tools\": [\n",
      "    \"brand_impersonation_check\",\n",
      "    \"certificate_analysis\",\n",
      "    \"short_domain_analysis\"\n",
      "  ],\n",
      "  \"etld1\": {\n",
      "    \"registered_domain\": \"internetku.id\",\n",
      "    \"domain\": \"internetku\",\n",
      "    \"suffix\": \"id\",\n",
      "    \"subdomain\": \"\"\n",
      "  },\n",
      "  \"stats\": {\n",
      "    \"phishing_tld_weight\": 0.0,\n",
      "    \"high_risk_hits\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      ">>> TOOL RESULTS\n",
      "tool keys: ['brand', 'cert', 'domain', 'contextual_risk_assessment']\n",
      "\n",
      "[brand]\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    :\n",
      "{\n",
      "  \"detected_brands\": [],\n",
      "  \"method\": \"none\"\n",
      "}\n",
      "\n",
      "[cert]\n",
      "  risk_score : 0.35\n",
      "  issues     : ['free_ca', 'no_org']\n",
      "  details    :\n",
      "{\n",
      "  \"has_cert\": true,\n",
      "  \"issuer\": \"Sectigo Limited\",\n",
      "  \"is_free_ca\": true,\n",
      "  \"has_org\": false,\n",
      "  \"san_count\": 2,\n",
      "  \"is_domain_matched\": true\n",
      "}\n",
      "\n",
      "[domain]\n",
      "  risk_score : 0.0\n",
      "  issues     : []\n",
      "  details    :\n",
      "{\n",
      "  \"domain_length\": 10,\n",
      "  \"domain_length_category\": \"normal\",\n",
      "  \"base_domain\": \"internetku\",\n",
      "  \"tld\": \"id\",\n",
      "  \"tld_category\": \"unknown\",\n",
      "  \"entropy\": 2.72,\n",
      "  \"is_random_pattern\": false,\n",
      "  \"vowel_ratio\": 0.4,\n",
      "  \"digit_ratio\": 0.0,\n",
      "  \"tld_stat\": 0,\n",
      "  \"tld_stat_weight\": 0.0\n",
      "}\n",
      "\n",
      "[contextual_risk_assessment]\n",
      "  risk_score : 0.4149999999999999\n",
      "  issues     : ['ml_paradox', 'multiple_risk_factors', 'known_domain']\n",
      "  details    :\n",
      "{\n",
      "  \"ml_probability\": 0.12955579,\n",
      "  \"ml_category\": \"very_low\",\n",
      "  \"total_issues_count\": 2,\n",
      "  \"combined_risk_score\": 0.12,\n",
      "  \"tool_average_risk\": 0.12,\n",
      "  \"is_ml_paradox\": true,\n",
      "  \"all_detected_issues\": [\n",
      "    \"free_ca\",\n",
      "    \"no_org\"\n",
      "  ],\n",
      "  \"high_risk_hits\": 0,\n",
      "  \"known_domain\": {\n",
      "    \"is_known\": true,\n",
      "    \"label\": true,\n",
      "    \"mitigation\": 0.1\n",
      "  },\n",
      "  \"consistency_boost\": 0.0\n",
      "}\n",
      "\n",
      ">>> FINAL ASSESSMENT\n",
      "{\n",
      "  \"is_phishing\": true,\n",
      "  \"confidence\": 0.55,\n",
      "  \"risk_level\": \"medium-high\",\n",
      "  \"detected_brands\": [],\n",
      "  \"risk_factors\": [\n",
      "    \"policy:R1\"\n",
      "  ],\n",
      "  \"reasoning\": \"The domain internetku.id has a low risk level based on the analysis. The contextual risk score is 0.415, which is below the threshold of 0.5, and no significant risk factors were identified.\"\n",
      "}\n",
      "\n",
      ">>> DECISION TRACE\n",
      "  <none>\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'domain': 'internetku.id',\n",
       " 'ml_probability': 0.12955579,\n",
       " 'ai_is_phishing': True,\n",
       " 'ai_confidence': 0.55,\n",
       " 'ai_risk_level': 'medium-high',\n",
       " 'detected_brands': [],\n",
       " 'reasoning': 'The domain internetku.id has a low risk level based on the analysis. The contextual risk score is 0.415, which is below the threshold of 0.5, and no significant risk factors were identified.',\n",
       " 'success': True,\n",
       " 'processing_time': 4.836447942070663,\n",
       " 'tools_used': ['brand', 'cert', 'domain', 'contextual_risk_assessment'],\n",
       " 'llm_driven': True,\n",
       " 'phase': 'phase4_v1.3',\n",
       " 'graph_state': {'domain': 'internetku.id',\n",
       "  'ml_probability': 0.12955579,\n",
       "  'current_step': 'completed',\n",
       "  'precheck_hints': {'ml_category': 'very_low',\n",
       "   'ml_paradox': False,\n",
       "   'tld_category': 'unknown',\n",
       "   'brand_detected': False,\n",
       "   'potential_brands': [],\n",
       "   'domain_length_category': 'normal',\n",
       "   'quick_risk': 0.05,\n",
       "   'recommended_tools': ['brand_impersonation_check',\n",
       "    'certificate_analysis',\n",
       "    'short_domain_analysis'],\n",
       "   'etld1': {'registered_domain': 'internetku.id',\n",
       "    'domain': 'internetku',\n",
       "    'suffix': 'id',\n",
       "    'subdomain': ''},\n",
       "   'stats': {'phishing_tld_weight': 0.0, 'high_risk_hits': 0}},\n",
       "  'selected_tools': ['brand_impersonation_check',\n",
       "   'certificate_analysis',\n",
       "   'short_domain_analysis'],\n",
       "  'tool_results': {'brand': {'detected_issues': [],\n",
       "    'risk_score': 0.0,\n",
       "    'details': {'detected_brands': [], 'method': 'none'}},\n",
       "   'cert': {'tool_name': 'certificate_analysis',\n",
       "    'detected_issues': ['free_ca', 'no_org'],\n",
       "    'risk_score': 0.35,\n",
       "    'details': {'has_cert': True,\n",
       "     'issuer': 'Sectigo Limited',\n",
       "     'is_free_ca': True,\n",
       "     'has_org': False,\n",
       "     'san_count': 2,\n",
       "     'is_domain_matched': True},\n",
       "    'reasoning': 'Issues: free_ca, no_org (Issuer: Sectigo Limited)'},\n",
       "   'domain': {'tool_name': 'short_domain_analysis',\n",
       "    'detected_issues': [],\n",
       "    'risk_score': 0.0,\n",
       "    'details': {'domain_length': 10,\n",
       "     'domain_length_category': 'normal',\n",
       "     'base_domain': 'internetku',\n",
       "     'tld': 'id',\n",
       "     'tld_category': 'unknown',\n",
       "     'entropy': 2.72,\n",
       "     'is_random_pattern': False,\n",
       "     'vowel_ratio': 0.4,\n",
       "     'digit_ratio': 0.0,\n",
       "     'tld_stat': 0,\n",
       "     'tld_stat_weight': 0.0},\n",
       "    'reasoning': 'Áü≠„ÅÑ„Éâ„É°„Ç§„É≥„ÅÆÈ°ïËëó„Å™ÂïèÈ°å„Å™„Åó'},\n",
       "   'contextual_risk_assessment': {'tool_name': 'contextual_risk_assessment',\n",
       "    'detected_issues': ['ml_paradox', 'multiple_risk_factors', 'known_domain'],\n",
       "    'risk_score': 0.4149999999999999,\n",
       "    'details': {'ml_probability': 0.12955579,\n",
       "     'ml_category': 'very_low',\n",
       "     'total_issues_count': 2,\n",
       "     'combined_risk_score': 0.12,\n",
       "     'tool_average_risk': 0.12,\n",
       "     'is_ml_paradox': True,\n",
       "     'all_detected_issues': ['free_ca', 'no_org'],\n",
       "     'high_risk_hits': 0,\n",
       "     'known_domain': {'is_known': True, 'label': True, 'mitigation': 0.1},\n",
       "     'consistency_boost': 0.0},\n",
       "    'reasoning': 'ML=0.13(very_low) / „ÉÑ„Éº„É´Âπ≥Âùá=0.12 / Êó¢Áü•„Éâ„É°„Ç§„É≥=internetku.id(True) / ML Paradox / Ë¶ÅÂõ†Êï∞=2'}},\n",
       "  'final_assessment': PhishingAssessment(is_phishing=True, confidence=0.55, risk_level='medium-high', detected_brands=[], risk_factors=['policy:R1'], reasoning='The domain internetku.id has a low risk level based on the analysis. The contextual risk score is 0.415, which is below the threshold of 0.5, and no significant risk factors were identified.'),\n",
       "  'error': None,\n",
       "  'retry_count': 0,\n",
       "  'fallback_count': 0,\n",
       "  'fallback_locations': []},\n",
       " 'module_version': '1.3.4-phase4-toolexec-fix-2025-11-08'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_agent_single(\"internetku.id\", 0.12955579)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b089aa-d6dd-4f1c-bcf5-3c97d1632424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a343181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[FULL] Building eval_df from artifacts (04-2 / 04-3)\n",
      "================================================================================\n",
      "[FULL] Loading pickle: /home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\n",
      "[FULL] Collected 4 DataFrame candidates from:\n",
      "  - /home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\n",
      "[FULL] Selected candidate idx=0 with score=7\n",
      "[FULL] Selected columns: ['domain', 'source', 'prediction_proba', 'confidence']\n",
      "[FULL] Selected rows: 4132\n",
      "[DEBUG][FULL] columns: ['domain', 'source', 'prediction_proba', 'confidence']\n",
      "[INFO][FULL] Source rows (normalized, FULL): 4132\n",
      "[INFO][FULL] Using FULL dataset for evaluation: 4132 domains\n",
      "[INFO][FULL] Full eval list saved to: /home/asomura/nextstep/artifacts/2025-11-22_020618/logs/eval_domains_full_latest.csv\n",
      "\n",
      "[FULL][ML Probability Distribution]\n",
      "  Min:    0.001\n",
      "  Max:    0.500\n",
      "  Mean:   0.209\n",
      "  Median: 0.176\n",
      "  High risk (>0.4): 576 domains\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell FULL-1: FULLË©ï‰æ°Áî® eval_df „Çí 04-2 / 04-3 „ÅÆ pickle „Åã„ÇâÊßãÁØâ\n",
    "# ============================================\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[FULL] Building eval_df from artifacts (04-2 / 04-3)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ÂÄôË£ú„Å®„Å™„Çãpickle„Éï„Ç°„Ç§„É´ÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶„Éë„Çπ„ÇíËøΩÂä†Ôºâ\n",
    "PICKLE_CANDIDATES = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "    HANDOFF_DIR / \"04-3_random_eval_context.pkl\",\n",
    "    Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-2_statistical_analysis.pkl\"),\n",
    "    Path(\"/home/asomura/nextstep/artifacts/20251030_004055/handoff/04-3_random_eval_context.pkl\"),\n",
    "]\n",
    "\n",
    "def _collect_dfs(obj, acc):\n",
    "    \"\"\"‰ªªÊÑè„ÅÆ„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Åã„ÇâÂÜçÂ∏∞ÁöÑ„Å´ DataFrame „ÇíÂèéÈõÜ\"\"\"\n",
    "    if obj is None:\n",
    "        return\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        acc.append(obj)\n",
    "        return\n",
    "    if isinstance(obj, dict):\n",
    "        for v in obj.values():\n",
    "            _collect_dfs(v, acc)\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            _collect_dfs(v, acc)\n",
    "\n",
    "def _score_candidate_df(df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Ë©ï‰æ°Áî®DF„Çí„Çπ„Ç≥„Ç¢„É™„É≥„Ç∞„Åô„ÇãÁ∞°ÊòìÈñ¢Êï∞„ÄÇ\n",
    "    - domain/fqdn/hostname/url Á≥ª„ÅÆÂàó„Åå„ÅÇ„Çå„Å∞ +2\n",
    "    - ml_probability/probability/score/proba Á≥ª„ÅÆÂàó„Åå„ÅÇ„Çå„Å∞ +2\n",
    "    - (tld,count)„Å†„Åë„ÅÆÁµ±Ë®à„ÉÜ„Éº„Éñ„É´„ÅØÂº∑„ÅèÊ∏õÁÇπ\n",
    "    - Ë°åÊï∞„ÅåÂ§ö„ÅÑ (>= 500) „ÇÇ„ÅÆ„ÇíÂº∑„ÅèÂÑ™ÂÖà\n",
    "    - 100‰ª∂ÂâçÂæå„ÅÆ„Çµ„É≥„Éó„É´DF„ÅØÊòéÁ§∫ÁöÑ„Å´Ê∏õÁÇπ\n",
    "    \"\"\"\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    has_domain = any(any(k in c for k in [\"domain\", \"fqdn\", \"hostname\", \"host\", \"requested_host\", \"url\"]) for c in cols)\n",
    "    has_ml = any(any(k in c for k in [\"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\", \"score\", \"pred_proba\", \"proba\", \"confidence\"]) for c in cols)\n",
    "    score = 0\n",
    "    if has_domain:\n",
    "        score += 2\n",
    "    if has_ml:\n",
    "        score += 2\n",
    "    # (tld, count) „Å†„Åë„ÅÆÁµ±Ë®à„ÉÜ„Éº„Éñ„É´„ÅØÊòéÁ§∫ÁöÑ„Å´Èô§Â§ñ„Åó„Åü„ÅÑ„ÅÆ„ÅßÊ∏õÁÇπ\n",
    "    if set(cols) == {\"tld\", \"count\"}:\n",
    "        score -= 5\n",
    "    # Ë°åÊï∞„Å´„Çà„ÇãÈáç„Åø‰ªò„Åë: Êú¨Áï™Áî®„ÅÆÂ§ß„Åç„Å™DF„ÇíÂÑ™ÂÖà\n",
    "    n_rows = len(df)\n",
    "    if n_rows >= 500:\n",
    "        score += 3  # ÊòéÁ¢∫„Å´„Éï„É´„Çª„ÉÉ„Éà„ÇíÂÑ™ÂÖà\n",
    "    elif n_rows >= 200:\n",
    "        score += 1\n",
    "    # 100‰ª∂ÂâçÂæå„ÅÆ„Çµ„É≥„Éó„É´ÔºàRandom100Áõ∏ÂΩìÔºâ„ÅØÂÄôË£ú„Å®„Åó„Å¶Âº±„ÅÑ\n",
    "    if 80 <= n_rows <= 150:\n",
    "        score -= 2\n",
    "    # Ë°åÊï∞„ÅåÊ•µÁ´Ø„Å´Â∞ë„Å™„ÅÑ„ÇÇ„ÅÆ„ÅØ„Åï„Çâ„Å´Ê∏õÁÇπ\n",
    "    if n_rows < 50:\n",
    "        score -= 2\n",
    "    return score\n",
    "def _normalize_eval_df_full(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"ÂàóÂêç„ÅÆÊè∫„Çå„Å´ÂØæÂøú„Åó„Å¶ domain, ml_probability „ÅÆ2Âàó„Å´Ê≠£Ë¶èÂåñ (FULLÁî®)\"\"\"\n",
    "    print(\"[DEBUG][FULL] columns:\", list(df.columns))\n",
    "\n",
    "    # lower ‚Üí ÂÖÉÂêç„ÅÆ„Éû„ÉÉ„Éó\n",
    "    lower2orig = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    # 1) domainÂÄôË£ú\n",
    "    domain_candidates = [\"domain\", \"fqdn\", \"domain_name\", \"hostname\", \"host\", \"requested_host\", \"url\"]\n",
    "    domain_key = None\n",
    "    for key in domain_candidates:\n",
    "        if key in lower2orig:\n",
    "            domain_key = lower2orig[key]\n",
    "            break\n",
    "    if domain_key is None:\n",
    "        # ÈÉ®ÂàÜ‰∏ÄËá¥„Åß fallback\n",
    "        for c in df.columns:\n",
    "            lc = c.lower()\n",
    "            if any(kw in lc for kw in [\"domain\", \"fqdn\", \"host\", \"url\"]):\n",
    "                domain_key = c\n",
    "                print(f\"[DEBUG][FULL] domain fallback: {c}\")\n",
    "                break\n",
    "\n",
    "    # 2) ml_probabilityÂÄôË£ú\n",
    "    ml_candidates = [\n",
    "        \"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\",\n",
    "        \"score\", \"pred_proba\", \"proba\", \"confidence\"\n",
    "    ]\n",
    "    mlp_key = None\n",
    "    for key in ml_candidates:\n",
    "        if key in lower2orig:\n",
    "            mlp_key = lower2orig[key]\n",
    "            break\n",
    "    if mlp_key is None:\n",
    "        float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "        for c in float_cols:\n",
    "            lc = c.lower()\n",
    "            if any(kw in lc for kw in [\"prob\", \"score\", \"pred\"]):\n",
    "                mlp_key = c\n",
    "                print(f\"[DEBUG][FULL] ml_probability fallback: {c}\")\n",
    "                break\n",
    "\n",
    "    if domain_key is None or mlp_key is None:\n",
    "        print(\"[ERROR][FULL] domain_key or mlp_key not found\")\n",
    "        return None\n",
    "\n",
    "    tmp = df[[domain_key, mlp_key]].copy()\n",
    "    tmp.columns = [\"domain\", \"ml_probability\"]\n",
    "\n",
    "    # URLÂΩ¢Âºè„ÅåÊ∑∑„Åñ„Å£„Å¶„ÅÑ„Åü„Çâ„Éâ„É°„Ç§„É≥ÈÉ®ÂàÜ„Å†„ÅëÊäΩÂá∫\n",
    "    if tmp[\"domain\"].astype(str).str.contains(\"://\").any():\n",
    "        def _to_domain(x: str) -> str:\n",
    "            if not isinstance(x, str):\n",
    "                return \"\"\n",
    "            if \"://\" in x:\n",
    "                netloc = urlparse(x).netloc\n",
    "            else:\n",
    "                netloc = x\n",
    "            # user@host:port ‚Üí host\n",
    "            netloc = netloc.split(\"@\")[-1].split(\":\")[0]\n",
    "            return netloc.lower()\n",
    "        tmp[\"domain\"] = tmp[\"domain\"].map(_to_domain)\n",
    "\n",
    "    # „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó\n",
    "    tmp[\"domain\"] = tmp[\"domain\"].astype(str).str.strip().str.lower()\n",
    "    tmp = tmp[tmp[\"domain\"].str.len() > 0]\n",
    "\n",
    "    tmp[\"ml_probability\"] = pd.to_numeric(tmp[\"ml_probability\"], errors=\"coerce\")\n",
    "    tmp = tmp[(tmp[\"ml_probability\"] >= 0.0) & (tmp[\"ml_probability\"] <= 1.0)]\n",
    "    tmp = tmp.dropna(subset=[\"ml_probability\"]).reset_index(drop=True)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "# === ÂÆüÈöõ„Å´ pickle „Åã„Çâ DataFrame „ÇíÂèéÈõÜ ===\n",
    "all_dfs = []\n",
    "used_paths = []\n",
    "for p in PICKLE_CANDIDATES:\n",
    "    try:\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        print(f\"[FULL] Loading pickle: {p}\")\n",
    "        with open(p, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "        _collect_dfs(obj, all_dfs)\n",
    "        used_paths.append(str(p))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN][FULL] Failed to load {p}: {e}\")\n",
    "\n",
    "if not all_dfs:\n",
    "    raise RuntimeError(\"04-2 / 04-3 „ÅÆpickle„Åã„Çâ DataFrame „ÇíÂèéÈõÜ„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\")\n",
    "\n",
    "print(f\"[FULL] Collected {len(all_dfs)} DataFrame candidates from:\")\n",
    "for p in used_paths:\n",
    "    print(f\"  - {p}\")\n",
    "\n",
    "# ÂêÑDF„Çí„Çπ„Ç≥„Ç¢„É™„É≥„Ç∞„Åó„Å¶ÊúÄ„ÇÇË©ï‰æ°Áî®„Çâ„Åó„ÅÑ„ÇÇ„ÅÆ„ÇíÈÅ∏Êäû\n",
    "scored = [(i, _score_candidate_df(df), df) for i, df in enumerate(all_dfs)]\n",
    "scored.sort(key=lambda x: x[1], reverse=True)\n",
    "best_idx, best_score, best_df = scored[0]\n",
    "\n",
    "print(f\"[FULL] Selected candidate idx={best_idx} with score={best_score}\")\n",
    "print(f\"[FULL] Selected columns: {list(best_df.columns)}\")\n",
    "print(f\"[FULL] Selected rows: {len(best_df)}\")\n",
    "\n",
    "if best_score <= 0:\n",
    "    raise RuntimeError(\"Ë©ï‰æ°Áî®„Å´ÈÅ©„Åó„Åü DataFrame „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì (score<=0)„ÄÇ\")\n",
    "\n",
    "# Ê≠£Ë¶èÂåñ„Åó„Å¶ eval_df „Å®„Åó„Å¶Âà©Áî®\n",
    "norm_df = _normalize_eval_df_full(best_df)\n",
    "if norm_df is None:\n",
    "    raise RuntimeError(\"[FULL] DataFrame„ÅÆÊ≠£Ë¶èÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü\")\n",
    "\n",
    "print(f\"[INFO][FULL] Source rows (normalized, FULL): {len(norm_df)}\")\n",
    "\n",
    "eval_df = norm_df.reset_index(drop=True)\n",
    "print(f\"[INFO][FULL] Using FULL dataset for evaluation: {len(eval_df)} domains\")\n",
    "\n",
    "# „É≠„Ç∞„Å®„Åó„Å¶CSV‰øùÂ≠ò\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = LOGS_DIR / \"eval_domains_full_latest.csv\"\n",
    "eval_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"[INFO][FULL] Full eval list saved to: {out_csv}\")\n",
    "\n",
    "# MLÁ¢∫Áéá„ÅÆÂàÜÂ∏É„ÇíÁ¢∫Ë™ç\n",
    "print(\"\\n[FULL][ML Probability Distribution]\")\n",
    "print(f\"  Min:    {eval_df['ml_probability'].min():.3f}\")\n",
    "print(f\"  Max:    {eval_df['ml_probability'].max():.3f}\")\n",
    "print(f\"  Mean:   {eval_df['ml_probability'].mean():.3f}\")\n",
    "print(f\"  Median: {eval_df['ml_probability'].median():.3f}\")\n",
    "\n",
    "high_risk_full = eval_df[eval_df['ml_probability'] > 0.4]\n",
    "print(f\"  High risk (>0.4): {len(high_risk_full)} domains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d671406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting FULL AGENT evaluation of 4132 domains...\n",
      "================================================================================\n",
      "[INFO] LLM initialized: Qwen/Qwen3-14B-FP8\n",
      "[    1/ 4132] üü¢ winrneteik.icu                      (ML: 0.324 / Time: 5.21s)\n",
      "    üèÅ Final : Conf=0.29 (low)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üìå Ctx   : multiple_risk_factors, known_domain\n",
      "------------------------------------------------------------\n",
      "[    2/ 4132] üî¥ mecano-normand.com                  (ML: 0.070 / Time: 3.96s)\n",
      "    üèÅ Final : Conf=0.55 (medium-high)\n",
      "    üîí Cert  : free_ca, no_org (Issuer: Let's Encrypt)\n",
      "    üåê Domain: dangerous_tld (TLD: dangerous)\n",
      "    üìå Ctx   : ml_paradox, multiple_risk_factors, known_domain\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell FULL-2: FULL AGENT evaluation for ALL domains in eval_df\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "if 'eval_df' not in globals():\n",
    "    raise RuntimeError(\"eval_df „ÅåÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇÂÖà„Å´ Cell FULL-1 „ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
    "\n",
    "print(f\"[INFO] Starting FULL AGENT evaluation of {len(eval_df)} domains...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLMË®≠ÂÆö„ÅÆÁ¢∫Ë™ç\n",
    "if 'agent' in globals() and hasattr(agent, 'llm_config'):\n",
    "    llm_config = agent.llm_config\n",
    "    if llm_config.enabled:\n",
    "        print(f\"[INFO] LLM initialized: {llm_config.model}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - results may be limited\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent not properly initialized\")\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "def _fmt_issues(issues):\n",
    "    return \", \".join(issues) if issues else \"None\"\n",
    "\n",
    "for idx, row in eval_df.iterrows():\n",
    "    domain = row['domain']\n",
    "    ml_prob = row['ml_probability']\n",
    "\n",
    "    try:\n",
    "        eval_start = time.time()\n",
    "        result = agent.evaluate(domain, ml_prob)\n",
    "        elapsed = time.time() - eval_start\n",
    "\n",
    "        is_phishing = result.get('ai_is_phishing', False)\n",
    "        confidence = result.get('ai_confidence', 0.0)\n",
    "        risk_level = result.get('ai_risk_level', 'unknown')\n",
    "\n",
    "        tool_res = {}\n",
    "        if 'graph_state' in result and 'tool_results' in result['graph_state']:\n",
    "            tool_res = result['graph_state']['tool_results']\n",
    "        elif 'tool_results' in result:\n",
    "            tool_res = result.get('tool_results', {})\n",
    "\n",
    "        brand_res = tool_res.get('brand', {})\n",
    "        brand_issues = brand_res.get('detected_issues', [])\n",
    "        brand_details = brand_res.get('details', {})\n",
    "        detected_brands = brand_details.get('detected_brands', [])\n",
    "\n",
    "        cert_res = tool_res.get('cert', {})\n",
    "        cert_issues = cert_res.get('detected_issues', [])\n",
    "        cert_score = cert_res.get('risk_score', 0.0)\n",
    "        cert_details = cert_res.get('details', {})\n",
    "        cert_issuer = cert_details.get('issuer', 'unknown')\n",
    "\n",
    "        domain_res = tool_res.get('domain', {})\n",
    "        domain_issues = domain_res.get('detected_issues', [])\n",
    "        domain_details = domain_res.get('details', {})\n",
    "        tld_cat = domain_details.get('tld_category', '-')\n",
    "\n",
    "        ctx_res = tool_res.get('contextual_risk_assessment', {})\n",
    "        ctx_issues = ctx_res.get('detected_issues', [])\n",
    "\n",
    "        mark = \"üî¥\" if is_phishing else \"üü¢\"\n",
    "        print(f\"[{idx+1:5}/{len(eval_df):5}] {mark} {domain:<35} (ML: {ml_prob:.3f} / Time: {elapsed:.2f}s)\")\n",
    "        print(f\"    üèÅ Final : Conf={confidence:.2f} ({risk_level})\")\n",
    "        if detected_brands:\n",
    "            print(f\"    üè∑Ô∏è  Brand : {detected_brands} (Issues: {_fmt_issues(brand_issues)})\")\n",
    "        if cert_issues:\n",
    "            print(f\"    üîí Cert  : {_fmt_issues(cert_issues)} (Issuer: {cert_issuer})\")\n",
    "        if domain_issues:\n",
    "            print(f\"    üåê Domain: {_fmt_issues(domain_issues)} (TLD: {tld_cat})\")\n",
    "        if ctx_issues:\n",
    "            print(f\"    üìå Ctx   : {_fmt_issues(ctx_issues)}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        results.append({\n",
    "            'domain': domain,\n",
    "            'ml_probability': ml_prob,\n",
    "            'ai_is_phishing': is_phishing,\n",
    "            'ai_confidence': confidence,\n",
    "            'ai_risk_level': risk_level,\n",
    "            'processing_time': elapsed,\n",
    "            'brand_detected': bool(detected_brands),\n",
    "            'brands': detected_brands,\n",
    "            'cert_issues': cert_issues,\n",
    "            'cert_issuer': cert_issuer,\n",
    "            'cert_score': cert_score,\n",
    "            'domain_issues': domain_issues,\n",
    "            'tld_category': tld_cat,\n",
    "            'ctx_issues': ctx_issues,\n",
    "            'error': None,\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{idx+1:5}/{len(eval_df):5}] ‚ùå ERROR: {domain} - {str(e)}\")\n",
    "        results.append({\n",
    "            'domain': domain,\n",
    "            'ml_probability': ml_prob,\n",
    "            'ai_is_phishing': False,\n",
    "            'ai_confidence': 0.0,\n",
    "            'ai_risk_level': 'error',\n",
    "            'processing_time': None,\n",
    "            'brand_detected': False,\n",
    "            'brands': [],\n",
    "            'cert_issues': [],\n",
    "            'cert_issuer': 'unknown',\n",
    "            'cert_score': 0.0,\n",
    "            'domain_issues': [],\n",
    "            'tld_category': '-',\n",
    "            'ctx_issues': [],\n",
    "            'error': str(e),\n",
    "        })\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] Full evaluation complete! Total time: {total_time:.2f}s\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "result_file = BASE_DIR / f\"full_eval_{timestamp}.csv\"\n",
    "results_df.to_csv(result_file, index=False)\n",
    "print(f\"[INFO] Detailed FULL results saved to: {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5cc51-03a6-4aeb-b09f-dc9e26c3d84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
