{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1c3e10",
   "metadata": {},
   "source": [
    "\n",
    "# 03_ai_agent_analysis_part3_fixed ‚Äî ConfigÊ©üËÉΩËøΩÂä† & Controller APIÔºàÊîπ‰øÆÁâàÔºâ\n",
    "- „Çª„É´1: `load_configuration()`ÔºàConfigË™≠„ÅøËæº„Åø„ÉªÊ§úË®º„Éª„Éû„Éº„Ç∏Ôºâ\n",
    "- „Çª„É´2: Robust handoff loaderÔºàPart2Âèó„ÅëÂèñ„ÇäÔºâ\n",
    "- „Çª„É´3: DBË®≠ÂÆöÁÆ°ÁêÜÔºàcfg/handoff/envÂÑ™ÂÖàÈ†Ü‰ΩçÔºâ\n",
    "- „Çª„É´4: HandoffÂ±ïÈñãÔºàÂøÖÈ†à„Ç≠„ÉºÊ§úË®ºÔºâ\n",
    "- „Çª„É´5: **TLDÂàÜÂ∏ÉÂàÜÊûê**Ôºà‰∏≠Ê†∏Ê©üËÉΩ„Çí‰øùÊåÅ„Åó„Åü„Åæ„ÅæConfigÂèçÊò†Ôºâ\n",
    "- „Çª„É´6: Handoff‰øùÂ≠òÔºàpkl + JSONÔºâ\n",
    "- „Çª„É´7: Controller API `explanation_quality()`Ôºà„Ç®„Ç§„É™„Ç¢„Çπ `tld_risk_analysis`Ôºâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2dc5d9-4915-4cc8-aef5-aac253386d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NX] RUN_ID = 2026-01-10_140940 | paths.RUN_ID = 2026-01-10_140940\n"
     ]
    }
   ],
   "source": [
    "# === Cell 0 (02‰ª•Èôç ÂÖ±ÈÄö): „É¨„Ç∏„Çπ„Éà„É™„Åã„ÇâËß£Ê±∫„Åó„Å¶ paths „ÇíË™≠„ÇÄ ===\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.bootstrap()  # env‚Üí„Éï„Ç°„Ç§„É´(artifacts/_current/run_id.txt)‚ÜíPart3‚Üílatest‚ÜíÊñ∞Ë¶è „ÅÆÈ†Ü„ÅßËß£Ê±∫\n",
    "\n",
    "import importlib\n",
    "import _compat.paths as paths\n",
    "importlib.reload(paths)\n",
    "importlib.reload(paths)\n",
    "print(\"[NX] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab47c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ IO guard ready -> artifacts/2026-01-10_140940\n",
      "üîß Config loaded (cert_only_mode=True, tld_analysis.enabled=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´1: Áí∞Â¢ÉÂàùÊúüÂåñ„Éª„Éë„ÇπË®≠ÂÆö + load_configuration ===\n",
    "import os, json, typing, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "try:\n",
    "    import yaml\n",
    "except Exception:\n",
    "    yaml = None\n",
    "\n",
    "if 'RUN_ID' not in globals():\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\") or datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "ARTIFACTS = Path(\"artifacts\") / RUN_ID\n",
    "for _p in [ARTIFACTS / d for d in [\"raw\",\"processed\",\"models\",\"results\",\"handoff\",\"logs\",\"traces\"]]:\n",
    "    _p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW, PROCESSED, MODELS, RESULTS, HANDOFF, LOGS, TRACES = [ARTIFACTS / d for d in [\"raw\",\"processed\",\"models\",\"results\",\"handoff\",\"logs\",\"traces\"]]\n",
    "RAW_DIR, PROCESSED_DIR, MODELS_DIR, RESULTS_DIR, HANDOFF_DIR, LOGS_DIR, TRACES_DIR = map(str, [RAW, PROCESSED, MODELS, RESULTS, HANDOFF, LOGS, TRACES])\n",
    "print(f\"‚úÖ IO guard ready -> artifacts/{RUN_ID}\")\n",
    "\n",
    "def _deep_update(base: dict, override: dict) -> dict:\n",
    "    base = dict(base or {})\n",
    "    for k, v in (override or {}).items():\n",
    "        if isinstance(v, dict) and isinstance(base.get(k), dict):\n",
    "            base[k] = _deep_update(base[k], v)\n",
    "        else:\n",
    "            base[k] = v\n",
    "    return base\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "def load_configuration(config_path: Optional[str] = None,\n",
    "                       cfg_override: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    defaults = {\n",
    "        \"system\": {\"cert_only_mode\": True, \"seed\": 42},\n",
    "        \"db\": {\"dbname\":\"rapids_data\",\"user\":\"postgres\",\"password\":\"asomura\",\"host\":\"localhost\",\"port\":\"5432\",\"timeout_s\":30,\"read_only\":True},\n",
    "        \"tld_analysis\": {\"enabled\":True,\"use_all_data\":True,\"balance_data\":True,\"sample_size\":None,\"min_sample_size\":10,\n",
    "                         \"max_dangerous_tlds\":30,\"max_legitimate_tlds\":30,\"percentile_thresholds\":[50,75,90],\"fn_weight\":1.5},\n",
    "        \"engine\": {\"max_concurrent\":20,\"max_retries\":3,\"batch_size\":10000},\n",
    "        \"paths\": {\"base_dir\":\"artifacts\"},\n",
    "        \"llm\": {\"enabled\":False}\n",
    "    }\n",
    "    cfg = dict(defaults)\n",
    "    if config_path and Path(config_path).exists():\n",
    "        try:\n",
    "            text = Path(config_path).read_text(encoding=\"utf-8\")\n",
    "            if Path(config_path).suffix.lower() in (\".yml\",\".yaml\") and yaml:\n",
    "                cfg = _deep_update(cfg, yaml.safe_load(text) or {})\n",
    "            else:\n",
    "                cfg = _deep_update(cfg, json.loads(text))\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠ËæºÂ§±Êïó: {e}\")\n",
    "    env_map = {\"USE_ALL_DATA\":(\"tld_analysis\",\"use_all_data\"),\n",
    "               \"BALANCE_DATA\":(\"tld_analysis\",\"balance_data\"),\n",
    "               \"PGDATABASE\":(\"db\",\"dbname\"),\n",
    "               \"PGUSER\":(\"db\",\"user\"),\n",
    "               \"PGPASSWORD\":(\"db\",\"password\")}\n",
    "    for env, path in env_map.items():\n",
    "        if env in os.environ and os.environ[env]!=\"\":\n",
    "            val = os.environ[env]\n",
    "            if isinstance(val,str) and val.lower() in (\"true\",\"false\"):\n",
    "                val = (val.lower()==\"true\")\n",
    "            node = cfg\n",
    "            for k in path[:-1]:\n",
    "                node = node.setdefault(k,{})\n",
    "            node[path[-1]] = val\n",
    "    if isinstance(cfg_override, dict):\n",
    "        cfg = _deep_update(cfg, cfg_override)\n",
    "    if not cfg[\"system\"].get(\"cert_only_mode\", False):\n",
    "        raise ValueError(\"system.cert_only_mode „ÅØ True ÂøÖÈ†à„Åß„Åô\")\n",
    "    if not cfg.get(\"tld_analysis\",{}).get(\"enabled\", False):\n",
    "        raise ValueError(\"tld_analysis.enabled „ÅØ True ÂøÖÈ†à„Åß„Åô\")\n",
    "    for k in (\"dbname\",\"user\",\"host\",\"port\"):\n",
    "        if not str(cfg[\"db\"].get(k,\"\")).strip():\n",
    "            raise ValueError(f\"DBÂøÖÈ†àÈ†ÖÁõÆ‰∏çË∂≥: db.{k}\")\n",
    "    globals()[\"cfg\"] = cfg\n",
    "    print(\"üîß Config loaded (cert_only_mode=True, tld_analysis.enabled=True)\")\n",
    "    return cfg\n",
    "\n",
    "cfg = load_configuration(os.getenv(\"CONFIG_PATH\"), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cd3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ handoff loaded: artifacts/2026-01-10_140940/handoff/03_ai_agent_analysis_part2.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´2: Robust handoff loader ===\n",
    "import joblib, glob\n",
    "Path(HANDOFF_DIR).mkdir(parents=True, exist_ok=True)\n",
    "cands = [str(Path(HANDOFF_DIR) / \"03_ai_agent_analysis_part2.pkl\")]\n",
    "if not any(Path(p).exists() for p in cands):\n",
    "    cands += sorted(glob.glob(\"artifacts/*/handoff/03_ai_agent_analysis_part2.pkl\"))\n",
    "src = next((p for p in cands if Path(p).exists()), None)\n",
    "if not src:\n",
    "    raise FileNotFoundError(\"Part2 handoff „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ\")\n",
    "handoff = joblib.load(src)\n",
    "print(f\"‚úÖ handoff loaded: {src}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e137611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß DB_CONFIG ready: {'dbname': 'rapids_data', 'host': 'localhost', 'port': '5432', 'user': 'postgres'} (timeout=30s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´3: DBË®≠ÂÆöÁÆ°ÁêÜ ===\n",
    "import os\n",
    "def _db_from_env():\n",
    "    return {'dbname':os.getenv('PGDATABASE','rapids_data'),\n",
    "            'user':os.getenv('PGUSER','postgres'),\n",
    "            'password':os.getenv('PGPASSWORD','asomura'),\n",
    "            'host':os.getenv('PGHOST','localhost'),\n",
    "            'port':os.getenv('PGPORT','5432')}\n",
    "def build_db_config(cfg: dict, handoff: dict) -> dict:\n",
    "    if isinstance(cfg, dict) and 'db' in cfg:\n",
    "        base = {k:str(cfg['db'].get(k)) for k in ['dbname','user','password','host','port']}\n",
    "    elif isinstance(handoff, dict) and 'DB_CONFIG' in handoff:\n",
    "        base = dict(handoff['DB_CONFIG'])\n",
    "    else:\n",
    "        base = _db_from_env()\n",
    "    base['connect_timeout'] = int((cfg.get('db',{}) or {}).get('timeout_s',30)) if isinstance(cfg,dict) else 30\n",
    "    base['_read_only'] = bool((cfg.get('db',{}) or {}).get('read_only',True)) if isinstance(cfg,dict) else True\n",
    "    return base\n",
    "DB_CONFIG = build_db_config(cfg, handoff)\n",
    "print(\"üîß DB_CONFIG ready:\", {k: DB_CONFIG[k] for k in ['dbname','host','port','user']}, f\"(timeout={DB_CONFIG['connect_timeout']}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9cd98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ unpack: fn_rows=55524, brand_keywords=109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´4: HandoffÂ±ïÈñã ===\n",
    "required = ['false_negatives_df','brand_keywords','cert_full_info_map','fn_features_df']\n",
    "miss = [k for k in required if k not in handoff]\n",
    "if miss: raise KeyError(f\"handoff keys missing: {miss}\")\n",
    "false_negatives_df = handoff['false_negatives_df']\n",
    "brand_keywords = handoff['brand_keywords']\n",
    "cert_full_info_map = handoff['cert_full_info_map']\n",
    "fn_features_df = handoff['fn_features_df']\n",
    "if 'DB_CONFIG' in handoff: DB_CONFIG = {**DB_CONFIG, **handoff['DB_CONFIG']}\n",
    "print(f\"‚úÖ unpack: fn_rows={getattr(false_negatives_df,'shape',[None,None])[0]}, brand_keywords={len(brand_keywords) if isinstance(brand_keywords,(list,dict,set,tuple)) else 'n/a'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f761a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DB connected\n",
      "  phishtank: 54,362‰ª∂ (Top5: .com(23196), .dev(5865), .ly(3191), .me(2732), .de(2705))\n",
      "  jpcert: 116,647‰ª∂ (Top5: .com(35795), .cn(34513), .top(6972), .org(5610), .shop(4572))\n",
      "  certificates: 196,392‰ª∂ (Top5: .org(102083), .com(30237), .cn(27498), .top(7450), .xyz(6099))\n",
      "‚úÖ TLDÂàÜÊûêÂÆå‰∫Ü: dangerous=23, legitimate=8, neutral=1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´5: TLDÂàÜÂ∏ÉÂàÜÊûêÔºà‰∏≠Ê†∏‰øùÊåÅ + ConfigÔºâ ===\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np, random\n",
    "\n",
    "ta = cfg.get('tld_analysis', {})\n",
    "use_all_data   = bool(ta.get('use_all_data', True))\n",
    "balance_data   = bool(ta.get('balance_data', True))\n",
    "sample_size    = ta.get('sample_size', None)\n",
    "min_sample     = int(ta.get('min_sample_size', 10))\n",
    "max_dangerous  = int(ta.get('max_dangerous_tlds', 30))\n",
    "max_legitimate = int(ta.get('max_legitimate_tlds', 30))\n",
    "pct_thresholds = list(ta.get('percentile_thresholds', [50,75,90]))\n",
    "fn_weight      = float(ta.get('fn_weight', 1.5))\n",
    "random.seed(cfg.get('system',{}).get('seed',42))\n",
    "\n",
    "def extract_tld(domain):\n",
    "    if not domain: return None\n",
    "    if '://' in domain:\n",
    "        try: domain = urlparse(domain).netloc\n",
    "        except Exception: pass\n",
    "    domain = domain.split(':')[0]\n",
    "    parts = domain.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        if len(parts) >= 3 and parts[-2] in ['co','ac','or','ne','go']:\n",
    "            return f'.{parts[-2]}.{parts[-1]}'\n",
    "        return f'.{parts[-1]}'\n",
    "    return None\n",
    "\n",
    "conn = psycopg2.connect(dbname=DB_CONFIG['dbname'], user=DB_CONFIG['user'], password=DB_CONFIG['password'],\n",
    "                        host=DB_CONFIG['host'], port=DB_CONFIG['port'],\n",
    "                        connect_timeout=int(DB_CONFIG.get('connect_timeout',30)))\n",
    "cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "print(\"‚úÖ DB connected\")\n",
    "\n",
    "phishing_queries = {\n",
    "    'phishtank': \"SELECT cert_domain as domain FROM phishtank_entries WHERE cert_status='SUCCESS' AND cert_data IS NOT NULL AND cert_domain IS NOT NULL\",\n",
    "    'jpcert':    \"SELECT domain FROM jpcert_phishing_urls WHERE status='SUCCESS' AND cert_data IS NOT NULL AND domain IS NOT NULL\",\n",
    "    'certificates': \"SELECT domain FROM certificates WHERE status='SUCCESS' AND cert_data IS NOT NULL AND domain IS NOT NULL\"\n",
    "}\n",
    "ph_dom = []; ph_tlds = Counter()\n",
    "for name, q in phishing_queries.items():\n",
    "    if not use_all_data and sample_size: q += f\" LIMIT {int(sample_size)}\"\n",
    "    cur.execute(q); rows = cur.fetchall()\n",
    "    st = Counter()\n",
    "    for r in rows:\n",
    "        d = r['domain']\n",
    "        if d:\n",
    "            ph_dom.append(d)\n",
    "            t = extract_tld(d)\n",
    "            if t:\n",
    "                st[t]+=1; ph_tlds[t]+=1\n",
    "    print(f\"  {name}: {len(rows):,}‰ª∂ (Top5: {', '.join([f'{t}({c})' for t,c in st.most_common(5)])})\")\n",
    "\n",
    "q = \"SELECT domain FROM trusted_certificates WHERE status='SUCCESS' AND cert_data IS NOT NULL AND domain IS NOT NULL\"\n",
    "if not use_all_data and sample_size: q += f\" LIMIT {int(sample_size)}\"\n",
    "cur.execute(q); rows = cur.fetchall()\n",
    "tr_dom = []; tr_tlds = Counter()\n",
    "for r in rows:\n",
    "    d = r['domain']\n",
    "    if d:\n",
    "        tr_dom.append(d)\n",
    "        t = extract_tld(d)\n",
    "        if t: tr_tlds[t]+=1\n",
    "\n",
    "if balance_data:\n",
    "    minc = min(len(set(ph_dom)), len(set(tr_dom)))\n",
    "    ph_u = list(set(ph_dom)); tr_u = list(set(tr_dom))\n",
    "    random.seed(cfg.get('system',{}).get('seed',42))\n",
    "    ph_bal = random.sample(ph_u, minc) if len(ph_u)>minc else ph_u\n",
    "    tr_bal = random.sample(tr_u, minc) if len(tr_u)>minc else tr_u\n",
    "else:\n",
    "    ph_bal, tr_bal = ph_dom, tr_dom\n",
    "\n",
    "ph_bal_t = Counter(extract_tld(d) for d in ph_bal if extract_tld(d))\n",
    "tr_bal_t = Counter(extract_tld(d) for d in tr_bal if extract_tld(d))\n",
    "\n",
    "from collections import Counter as _Ctr\n",
    "fn_tlds = _Ctr()\n",
    "if hasattr(false_negatives_df,'columns') and 'domain' in false_negatives_df.columns:\n",
    "    for d in false_negatives_df['domain']:\n",
    "        t = extract_tld(d)\n",
    "        if t: fn_tlds[t]+=1\n",
    "\n",
    "dangerous_ratio = {}\n",
    "for t in ph_bal_t:\n",
    "    ph = ph_bal_t[t]; tr = tr_bal_t.get(t,0)\n",
    "    if ph >= min_sample:\n",
    "        ratio = float('inf') if tr==0 else ph/(tr+1)\n",
    "        dangerous_ratio[t] = {'ratio':ratio,'phishing_count':ph,'trusted_count':tr,\n",
    "                              'phishing_pct': ph/max(len(ph_bal),1)*100}\n",
    "\n",
    "ratios = [s['ratio'] for s in dangerous_ratio.values() if s['ratio']!=float('inf')]\n",
    "if ratios:\n",
    "    pcts = np.percentile(ratios, pct_thresholds).tolist()\n",
    "else:\n",
    "    pcts = [10,10,10]\n",
    "p50,p75,p90 = (pcts+[10,10,10])[:3]\n",
    "\n",
    "DANGEROUS_TLDS = []\n",
    "for t,s in sorted(dangerous_ratio.items(), key=lambda x:x[1]['ratio'], reverse=True):\n",
    "    if ((s['ratio']==float('inf') and s['phishing_count']>=10) or\n",
    "        (s['ratio']>=p90 and s['phishing_pct']>=0.1) or\n",
    "        (s['ratio']>=10 and s['phishing_pct']>=1.0)):\n",
    "        DANGEROUS_TLDS.append(t)\n",
    "        if len(DANGEROUS_TLDS)>=max_dangerous: break\n",
    "\n",
    "LEGITIMATE_TLDS = []\n",
    "for t,c in tr_bal_t.most_common(max_legitimate*2):\n",
    "    tr_pct = c/max(len(tr_bal),1)*100\n",
    "    if tr_pct>=1.0 and c>=1000:\n",
    "        ph = ph_bal_t.get(t,0)\n",
    "        ratio = ph/c if c>0 else 0.0\n",
    "        if ratio<0.5:\n",
    "            LEGITIMATE_TLDS.append(t)\n",
    "    if len(LEGITIMATE_TLDS)>=max_legitimate: break\n",
    "\n",
    "if len(fn_tlds):\n",
    "    for t,c in fn_tlds.most_common():\n",
    "        fn_pct = c/max(len(false_negatives_df),1)*100\n",
    "        if fn_pct>=1.0 and t not in DANGEROUS_TLDS and t not in LEGITIMATE_TLDS:\n",
    "            if t in dangerous_ratio and dangerous_ratio[t]['ratio']>=5:\n",
    "                DANGEROUS_TLDS.append(t)\n",
    "\n",
    "NEUTRAL_TLDS = []\n",
    "for t in ['.com','.org','.net','.info','.biz']:\n",
    "    if t not in DANGEROUS_TLDS and t not in LEGITIMATE_TLDS:\n",
    "        if t in ph_bal_t and t in tr_bal_t:\n",
    "            ph_pct = ph_bal_t[t]/max(len(ph_bal),1)*100\n",
    "            tr_pct = tr_bal_t[t]/max(len(tr_bal),1)*100\n",
    "            if ph_pct>=0.5 or tr_pct>=0.5:\n",
    "                NEUTRAL_TLDS.append(t)\n",
    "\n",
    "globals().update({'DANGEROUS_TLDS':DANGEROUS_TLDS,'LEGITIMATE_TLDS':LEGITIMATE_TLDS,'NEUTRAL_TLDS':NEUTRAL_TLDS,\n",
    "                  'phishing_tld_stats':ph_bal_t,'trusted_tld_stats':tr_bal_t})\n",
    "cur.close(); conn.close()\n",
    "print(f\"‚úÖ TLDÂàÜÊûêÂÆå‰∫Ü: dangerous={len(DANGEROUS_TLDS)}, legitimate={len(LEGITIMATE_TLDS)}, neutral={len(NEUTRAL_TLDS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b19c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved handoff: artifacts/2026-01-10_140940/handoff/03_ai_agent_analysis_part3.pkl\n",
      "üíæ Saved JSON   : artifacts/2026-01-10_140940/results/tld_statistics.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´6: Handoff‰øùÂ≠òÔºàpkl + JSONÔºâ ===\n",
    "import joblib, json, time\n",
    "from pathlib import Path\n",
    "out_handoff = Path(HANDOFF_DIR) / \"03_ai_agent_analysis_part3.pkl\"\n",
    "payload = {\n",
    "    'false_negatives_df': false_negatives_df,\n",
    "    'brand_keywords': brand_keywords,\n",
    "    'cert_full_info_map': cert_full_info_map,\n",
    "    'fn_features_df': fn_features_df,\n",
    "    'DANGEROUS_TLDS': DANGEROUS_TLDS,\n",
    "    'LEGITIMATE_TLDS': LEGITIMATE_TLDS,\n",
    "    'NEUTRAL_TLDS': NEUTRAL_TLDS,\n",
    "    'phishing_tld_stats': phishing_tld_stats,\n",
    "    'trusted_tld_stats': trusted_tld_stats,\n",
    "    'DB_CONFIG': DB_CONFIG,\n",
    "    'cfg': cfg\n",
    "}\n",
    "joblib.dump(payload, str(out_handoff))\n",
    "\n",
    "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "with open(Path(RESULTS_DIR)/\"tld_statistics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({'ts': time.time(),\n",
    "               'dangerous_tlds': list(DANGEROUS_TLDS),\n",
    "               'legitimate_tlds': list(LEGITIMATE_TLDS),\n",
    "               'neutral_tlds': list(NEUTRAL_TLDS)}, f, ensure_ascii=False, indent=2)\n",
    "print(f\"üíæ Saved handoff: {out_handoff}\")\n",
    "print(f\"üíæ Saved JSON   : {Path(RESULTS_DIR)/'tld_statistics.json'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac0fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Controller API ready: explanation_quality() / tld_risk_analysis()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === „Çª„É´7: Controller APIÈñ¢Êï∞ ===\n",
    "from typing import Tuple, Dict, Any\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "def explanation_quality(session_id: str, cfg: Dict[str, Any]) -> Tuple[str, Dict[str, str]]:\n",
    "    try:\n",
    "        if not isinstance(cfg, dict):\n",
    "            return \"INVALID_INPUT\", {\"error\":\"cfg„ÅØËæûÊõ∏Âûã„ÅßÊåáÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ\"}\n",
    "        _ = load_configuration(cfg_override=cfg)\n",
    "        if not _.get('tld_analysis',{}).get('enabled', False):\n",
    "            return \"INVALID_INPUT\", {\"error\":\"tld_analysis.enabled „ÅåÁÑ°Âäπ\"}\n",
    "        if not Path(HANDOFF_DIR, \"03_ai_agent_analysis_part2.pkl\").exists():\n",
    "            return \"NOT_FOUND\", {\"error\":\"Part2 handoff „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì\"}\n",
    "        paths = {\n",
    "            \"dangerous_tlds\": str(Path(RESULTS_DIR)/\"tld_statistics.json\"),\n",
    "            \"legitimate_tlds\": str(Path(RESULTS_DIR)/\"tld_statistics.json\"),\n",
    "            \"neutral_tlds\": str(Path(RESULTS_DIR)/\"tld_statistics.json\"),\n",
    "            \"tld_statistics\": str(Path(RESULTS_DIR)/\"tld_statistics.json\"),\n",
    "            \"handoff\": str(Path(HANDOFF_DIR)/\"03_ai_agent_analysis_part3.pkl\"),\n",
    "            \"logs\": LOGS_DIR\n",
    "        }\n",
    "        if len(DANGEROUS_TLDS)==0 and len(LEGITIMATE_TLDS)==0:\n",
    "            return \"NOT_FOUND\", {\"error\":\"TLD„É™„Çπ„Éà„ÅåÁ©∫„Åß„Åô\", **paths}\n",
    "        return \"OK\", paths\n",
    "    except Exception as e:\n",
    "        return \"ERROR\", {\"error\": str(e), \"trace\": traceback.format_exc()}\n",
    "\n",
    "tld_risk_analysis = explanation_quality\n",
    "print(\"‚úÖ Controller API ready: explanation_quality() / tld_risk_analysis()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1a8f3-98d4-4469-b1a6-ee203bcbb9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74098ffc-0def-48ef-9c1b-d0f0d85d45b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
