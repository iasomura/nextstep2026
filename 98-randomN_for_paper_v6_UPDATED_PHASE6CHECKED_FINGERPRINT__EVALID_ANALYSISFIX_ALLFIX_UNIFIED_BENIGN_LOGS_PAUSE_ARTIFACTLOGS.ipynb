{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09461286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SET] N_SAMPLE= 10 N_BENIGN_SAMPLE= 10 N_BENIGN_HARD_SAMPLE= 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 0: å®Ÿé¨“ä»¶æ•°ã®è¨­å®šï¼ˆphish/random=100, benign=100, benign_hard=100ï¼‰\n",
    "# ============================================\n",
    "# [ChangeLog] 2025-12-15: N_* ã« ALL/0/-1 ã‚’æŒ‡å®šã™ã‚‹ã¨å…¨ä»¶å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µ\n",
    "\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# â–¼â–¼â–¼ ã“ã“ã ã‘ç·¨é›†ã™ã‚Œã°OKï¼ˆå„ªå…ˆåº¦: ç’°å¢ƒå¤‰æ•° > ã“ã“ï¼‰ â–¼â–¼â–¼\n",
    "#   - \"500\" ã®ã‚ˆã†ã«æ•°å€¤ â†’ ãã®ä»¶æ•°ã ã‘å‡¦ç†\n",
    "#   - \"ALL\" / 0 / -1     â†’ å…¨ä»¶å‡¦ç†ï¼ˆåˆ¶é™ãªã—ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "DEFAULT_N_SAMPLE = \"10\"\n",
    "DEFAULT_N_BENIGN_SAMPLE = DEFAULT_N_SAMPLE\n",
    "DEFAULT_N_BENIGN_HARD_SAMPLE = \"10\"\n",
    "\n",
    "def _normalize_n_env(key: str, default: str) -> str:\n",
    "    \"\"\"ç’°å¢ƒå¤‰æ•° N_* ã‚’æ­£è¦åŒ–ã—ã¦ os.environ ã«å…¥ã‚Œã‚‹ã€‚\n",
    "    - 1ä»¥ä¸Š: ãã®ä»¶æ•°ã‚’å‡¦ç†\n",
    "    - 0 / -1 / 'ALL' / '*' / 'FULL': å…¨ä»¶å‡¦ç†ï¼ˆåˆ¶é™ãªã—ï¼‰\n",
    "    \"\"\"\n",
    "    raw = os.getenv(key, default)\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # äººé–“å‘ã‘ã®æŒ‡å®šï¼ˆALL ç­‰ï¼‰â†’ æ•°å€¤ã‚»ãƒ³ãƒãƒãƒ«ã¸\n",
    "    if s.upper() in (\"ALL\", \"*\", \"FULL\"):\n",
    "        return \"-1\"\n",
    "\n",
    "    # æ•°å€¤åŒ–ï¼ˆå¤‰ãªå€¤ãªã‚‰ default ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "    try:\n",
    "        n = int(float(s))\n",
    "    except Exception:\n",
    "        try:\n",
    "            n = int(default)\n",
    "        except Exception:\n",
    "            n = -1\n",
    "    # â˜… 0 / è² å€¤ ã¯ ALL æ‰±ã„ï¼ˆ-1 ã«å¯„ã›ã‚‹ï¼‰\n",
    "    return \"-1\" if n <= 0 else str(n)\n",
    "def _n_label(n_str: str) -> str:\n",
    "    \"\"\"è¡¨ç¤ºç”¨: -1/0 ä»¥ä¸‹ã¯ ALL ã¨è¦‹ã›ã‚‹\"\"\"\n",
    "    try:\n",
    "        n = int(str(n_str).strip())\n",
    "    except Exception:\n",
    "        return str(n_str)\n",
    "    return \"ALL\" if n <= 0 else str(n)\n",
    "\n",
    "# 3ç¾¤ã®ä»¶æ•°\n",
    "os.environ[\"N_SAMPLE\"] = _normalize_n_env(\"N_SAMPLE\", DEFAULT_N_SAMPLE)\n",
    "os.environ[\"N_BENIGN_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_SAMPLE\", DEFAULT_N_BENIGN_SAMPLE)\n",
    "os.environ[\"N_BENIGN_HARD_SAMPLE\"] = _normalize_n_env(\"N_BENIGN_HARD_SAMPLE\", DEFAULT_N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "print(\"[SET] N_SAMPLE=\", _n_label(os.environ[\"N_SAMPLE\"]),\n",
    "      \"N_BENIGN_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_SAMPLE\"]),\n",
    "      \"N_BENIGN_HARD_SAMPLE=\", _n_label(os.environ[\"N_BENIGN_HARD_SAMPLE\"]),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed1e38e-e956-482d-b6f5-28796ade11b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N_SAMPLE=10, N_BENIGN_SAMPLE=10, RANDOM_STATE=42\n",
      "[NX] RUN_ID = 2025-12-07_143907 | paths.RUN_ID = 2025-12-07_143907\n",
      "[INFO] BASE_DIR      = /home/asomura/backup/nextstep\n",
      "[INFO] RUN_ID        = 2025-12-07_143907\n",
      "[INFO] ARTIFACTS_DIR = artifacts/2025-12-07_143907\n",
      "[INFO] HANDOFF_DIR   = artifacts/2025-12-07_143907/handoff\n",
      "[OK] Handoff directory found: artifacts/2025-12-07_143907/handoff\n",
      "[OK] Target pickle found: 04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] Current Timestamp: 2025-12-21_131402\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 1: ç’°å¢ƒè¨­å®šã¨åˆæœŸåŒ–ï¼ˆCell0æ–¹å¼ã§RUN_IDæ±ºå®šï¼‰\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "import datetime\n",
    "import run_id_registry as runreg\n",
    "import importlib\n",
    "import _compat.paths as paths\n",
    "# ---------------------------------------------------------\n",
    "# â–¼â–¼â–¼ Evaluation sample size (variable) â–¼â–¼â–¼\n",
    "# ---------------------------------------------------------\n",
    "N_SAMPLE = int(os.getenv(\"N_SAMPLE\", \"300\"))\n",
    "N_BENIGN_SAMPLE = int(os.getenv(\"N_BENIGN_SAMPLE\", str(N_SAMPLE)))\n",
    "RANDOM_STATE = int(os.getenv(\"RANDOM_STATE\", \"42\"))\n",
    "def _n_label(n: int) -> str:\n",
    "    return \"ALL\" if int(n) <= 0 else str(int(n))\n",
    "print(f\"[INFO] N_SAMPLE={_n_label(N_SAMPLE)}, N_BENIGN_SAMPLE={_n_label(N_BENIGN_SAMPLE)}, RANDOM_STATE={RANDOM_STATE}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæ¨å®š\n",
    "# ---------------------------------------------------------\n",
    "BASE_DIR = Path(os.environ.get(\"NEXTSTEP_BASE_DIR\", \".\")).resolve()\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# [ChangeLog] 2025-12-16: sys.path ã‹ã‚‰ BASE_DIR/phishing_agent ã‚’é™¤å»ï¼ˆé‡è¤‡ import ã‚’é˜²ãã€Phase6 wiring ã‚’ç¢ºå®ŸåŒ–ï¼‰\n",
    "# NOTE: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ import ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã€sys.path ã«ã¯ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ(BASE_DIR)ã€ã ã‘ã‚’å…¥ã‚Œã‚‹ã€‚\n",
    "#       BASE_DIR/phishing_agent ã‚’å…¥ã‚Œã‚‹ã¨ `langgraph_module` ãªã©ãŒãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ« import ã•ã‚Œã€\n",
    "#       `phishing_agent.langgraph_module` ã¨äºŒé‡ãƒ­ãƒ¼ãƒ‰ã«ãªã‚Š Phase6 ã®ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒãŒåŠ¹ã‹ãªã„ã“ã¨ãŒã‚ã‚‹ã€‚\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "# å¿µã®ãŸã‚èª¤ã£ãŸãƒ‘ã‚¹ã‚’æ¶ˆã™ï¼ˆå­˜åœ¨ã—ã¦ã„ã‚Œã°ï¼‰\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# â–¼â–¼â–¼ RUN_ID ã®æ±ºå®š: 02ä»¥é™å…±é€š Cell0 ã¨åŒã˜æ–¹å¼ â–¼â–¼â–¼\n",
    "#   rid = runreg.bootstrap()  # envâ†’run_id.txtâ†’Part3â†’latestâ†’æ–°è¦\n",
    "#   paths ã‚’ reload ã—ã¦ paths.RUN_ID ã‚’ç¢ºå®š\n",
    "#   rid ã¨ paths.RUN_ID ãŒã‚ºãƒ¬ãŸã‚‰å³æ¤œçŸ¥\n",
    "# ---------------------------------------------------------\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.bootstrap()  # ã“ã“ã§ env RUN_ID ã‚’ã‚»ãƒƒãƒˆã™ã‚‹æƒ³å®šï¼ˆå¿µã®ãŸã‚ä¸‹ã§æ˜ç¤ºä¸Šæ›¸ãï¼‰\n",
    "\n",
    "# å¿µã®ãŸã‚ env ã‚’ rid ã§å›ºå®šï¼ˆbootstrapãŒã‚»ãƒƒãƒˆã—ã¦ã„ã¦ã‚‚å®³ã¯ãªã„ï¼‰\n",
    "os.environ[\"RUN_ID\"] = rid\n",
    "\n",
    "# _compat.paths (ã¾ãŸã¯ paths) ã‚’èª­ã¿è¾¼ã¿ã€env(RUN_ID) ã‚’åæ˜ ã•ã›ã‚‹\n",
    "try:\n",
    "    import _compat.paths as paths\n",
    "except ImportError:\n",
    "    import paths as paths  # fallback\n",
    "\n",
    "importlib.reload(paths)  # Cell0æ–¹å¼ï¼ˆå¿…è¦ãªã‚‰2å›ã§ã‚‚å¯ã ãŒé€šå¸¸1å›ã§ååˆ†ï¼‰\n",
    "\n",
    "# ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼†ã‚ºãƒ¬æ¤œçŸ¥\n",
    "print(\"[NX] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n",
    "assert paths.RUN_ID == rid, f\"RUN_ID mismatch: rid={rid} paths.RUN_ID={paths.RUN_ID}\"\n",
    "\n",
    "# æœ€çµ‚æ¡ç”¨ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ±ºå®šã«ä½¿ã†ã®ã¯ paths.RUN_IDï¼‰\n",
    "RUN_ID = paths.RUN_ID\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# artifacts/<RUN_ID>/... é…ä¸‹ã®å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š\n",
    "# ---------------------------------------------------------\n",
    "ARTIFACTS_DIR = Path(paths.ARTIFACTS) if hasattr(paths, \"ARTIFACTS\") else (BASE_DIR / \"artifacts\" / RUN_ID)\n",
    "RAW_DIR       = Path(paths.compat_base_dirs[\"raw\"])\n",
    "PROCESSED_DIR = Path(paths.compat_base_dirs[\"data\"])\n",
    "MODELS_DIR    = Path(paths.compat_base_dirs[\"models\"])\n",
    "RESULTS_DIR   = Path(paths.compat_base_dirs[\"results\"])\n",
    "HANDOFF_DIR   = Path(paths.compat_base_dirs[\"handoff\"])\n",
    "LOGS_DIR      = Path(paths.compat_base_dirs[\"logs\"])\n",
    "TRACES_DIR    = Path(paths.compat_base_dirs[\"traces\"])\n",
    "\n",
    "print(f\"[INFO] BASE_DIR      = {BASE_DIR}\")\n",
    "print(f\"[INFO] RUN_ID        = {RUN_ID}\")\n",
    "print(f\"[INFO] ARTIFACTS_DIR = {ARTIFACTS_DIR}\")\n",
    "print(f\"[INFO] HANDOFF_DIR   = {HANDOFF_DIR}\")\n",
    "\n",
    "# Handoffãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª\n",
    "if HANDOFF_DIR.exists():\n",
    "    print(f\"[OK] Handoff directory found: {HANDOFF_DIR}\")\n",
    "    target_pkl = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "    if target_pkl.exists():\n",
    "        print(f\"[OK] Target pickle found: {target_pkl.name}\")\n",
    "    else:\n",
    "        print(f\"[WARN] Target pickle NOT found in this directory.\")\n",
    "else:\n",
    "    print(f\"[WARN] Handoff directory NOT found. Check RUN_ID logic.\")\n",
    "\n",
    "# å‡ºåŠ›ç”¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "print(f\"[INFO] Current Timestamp: {timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] external_data loaded from: artifacts/2025-12-07_143907/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
      "[INFO] Added 33 new brands\n",
      "[INFO] Total brand_keywords: 35\n",
      "\n",
      "[Brand Check]\n",
      "  mufg            âœ…\n",
      "  smbc            âœ…\n",
      "  amazon          âœ…\n",
      "  mercari         âœ…\n",
      "  rakuten         âœ…\n",
      "  metamask        âœ…\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2: External Dataã®èª­ã¿è¾¼ã¿ã¨Brand Keywordsè£œå¼·\n",
    "# ============================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "# handoffã‹ã‚‰external_dataã‚’èª­ã¿è¾¼ã¿\n",
    "handoff_path = HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\"\n",
    "\n",
    "if not handoff_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Handoff file not found: {handoff_path}\\n\"\n",
    "        \"04-3_llm_tools_setup_with_tools ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ã€artifacts/<RUN_ID>/handoff é…ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚\"\n",
    "    )\n",
    "\n",
    "with open(handoff_path, 'rb') as f:\n",
    "    external_data = pickle.load(f)\n",
    "\n",
    "print(f\"[INFO] external_data loaded from: {handoff_path}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Brand Keywords è£œå¼·ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå…ƒãƒãƒ¼ãƒˆã®å‹•ä½œã‚’è¸è¥²ï¼‰\n",
    "# --------------------------------------------------\n",
    "\n",
    "# æ—¢å­˜ã® brand_keywords ã‚’å–å¾—ï¼ˆç„¡ã‘ã‚Œã°ç©ºãƒªã‚¹ãƒˆï¼‰\n",
    "brand_keywords = external_data.get(\"brand_keywords\") or []\n",
    "brands_lower = [b.lower() for b in brand_keywords]\n",
    "\n",
    "# è«–æ–‡ãƒ»å®Ÿé¨“ã§é‡è¦–ã—ãŸã„ãƒ–ãƒ©ãƒ³ãƒ‰ï¼ˆä¸è¶³ã—ã¦ã„ãŸã‚‚ã®ã‚’è£œã†ï¼‰\n",
    "essential_brands = [\n",
    "    \"mufg\", \"mufg-card\", \"mitsubishi-ufj\", \"ä¸‰è±UFJ\", \"ä¸‰è±ï¼µï¼¦ï¼ª\",\n",
    "    \"smbc\", \"smbc-card\", \"ä¸‰äº•ä½å‹ã‚«ãƒ¼ãƒ‰\", \"ä¸‰äº•ä½å‹éŠ€è¡Œ\",\n",
    "    \"rakuten\", \"rakuten-card\", \"æ¥½å¤©ã‚«ãƒ¼ãƒ‰\", \"æ¥½å¤©éŠ€è¡Œ\",\n",
    "    \"amazon\", \"amazon-jp\", \"amazon.co.jp\",\n",
    "    \"mercari\", \"ãƒ¡ãƒ«ã‚«ãƒª\",\n",
    "    \"metamask\", \"binance\", \"bybit\",\n",
    "    # â–¼â–¼â–¼ è¿½åŠ åˆ† â–¼â–¼â–¼\n",
    "    \"sbi\", \"sbisec\", \"sumishin\", \"ä½ä¿¡SBI\",\n",
    "    \"telegram\", \"tg\",\n",
    "    \"makuake\",\n",
    "    \"aeon\", \"aeonbank\", \"ã‚¤ã‚ªãƒ³éŠ€è¡Œ\",\n",
    "    \"jcb\",\n",
    "    \"imad\"\n",
    "]\n",
    "\n",
    "added_brands = []\n",
    "for brand in essential_brands:\n",
    "    if brand.lower() not in brands_lower:\n",
    "        external_data.setdefault('brand_keywords', []).append(brand)\n",
    "        added_brands.append(brand)\n",
    "        brands_lower.append(brand.lower())\n",
    "\n",
    "print(f\"[INFO] Added {len(added_brands)} new brands\")\n",
    "print(f\"[INFO] Total brand_keywords: {len(external_data['brand_keywords'])}\")\n",
    "\n",
    "# ä¸»è¦ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç¢ºèªè¡¨ç¤º\n",
    "check_brands = [\"mufg\", \"smbc\", \"amazon\", \"mercari\", \"rakuten\", \"metamask\"]\n",
    "print(\"\\n[Brand Check]\")\n",
    "for brand in check_brands:\n",
    "    exists = brand in [b.lower() for b in external_data['brand_keywords']]\n",
    "    status = \"âœ…\" if exists else \"âŒ\"\n",
    "    print(f\"  {brand:15} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ed7391-2b52-48c6-8074-709de2e26a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] Loading additional data from 04-2\n",
      "================================================================================\n",
      "[INFO] Found 04-2 at: artifacts/2025-12-07_143907/handoff/04-2_statistical_analysis.pkl\n",
      "[INFO] 04-2 loaded successfully\n",
      "[INFO] 04-2 keys: ['cfg', 'RUN_ID', 'SESSION_ID', 'output_dirs', 'brand_keywords', 'cert_full_info_map', 'false_negatives_df', 'fn_features_df', 'HIGH_RISK_WORDS', 'suspicious_words_stats']...\n",
      "  âœ… Added dangerous_tlds: NoneType (len=N/A)\n",
      "  âœ… Added legitimate_tlds: NoneType (len=N/A)\n",
      "  âœ… Added neutral_tlds: NoneType (len=N/A)\n",
      "  âœ… Added phishing_tld_stats: DataFrame (len=177)\n",
      "  âœ… Added high_risk_words: list (len=2)\n",
      "  âœ… Added known_domains: dict (len=4148)\n",
      "\n",
      "[INFO] Added 6 data items from 04-2\n",
      "\n",
      "================================================================================\n",
      "[INFO] Final Data Availability Check\n",
      "================================================================================\n",
      "  âœ… Brand keywords list            (len=35)\n",
      "  âœ… Certificate information        (len=4148)\n",
      "  âœ… Dangerous TLDs                 (len=N/A)\n",
      "  âœ… Legitimate TLDs                (len=N/A)\n",
      "  âœ… Neutral TLDs                   (len=N/A)\n",
      "  âœ… TLD phishing statistics        (len=177)\n",
      "  âœ… High risk words                (len=2)\n",
      "  âœ… Known legitimate domains       (len=4148)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 2ã®æœ€å¾Œã«è¿½åŠ : 04-2ã‹ã‚‰ä¸è¶³ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œ\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Loading additional data from 04-2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 04-2ã®ãƒ‘ã‚¹ã‚’æ¢ç´¢\n",
    "pickle_04_2_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "]\n",
    "\n",
    "data_04_2 = None\n",
    "for path in pickle_04_2_paths:\n",
    "    if path.exists():\n",
    "        print(f\"[INFO] Found 04-2 at: {path}\")\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                data_04_2 = pickle.load(f)\n",
    "            print(f\"[INFO] 04-2 loaded successfully\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {path}: {e}\")\n",
    "\n",
    "if data_04_2 is None:\n",
    "    print(\"[WARN] 04-2 not found, continuing with available data\")\n",
    "else:\n",
    "    print(f\"[INFO] 04-2 keys: {list(data_04_2.keys())[:10]}...\")\n",
    "    \n",
    "    # TLDé–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "    tld_keys = [\n",
    "        'dangerous_tlds', 'DANGEROUS_TLDS',\n",
    "        'legitimate_tlds', 'LEGITIMATE_TLDS',\n",
    "        'neutral_tlds', 'NEUTRAL_TLDS',\n",
    "        'phishing_tld_stats', 'TLD_STATS', 'tld_stats'\n",
    "    ]\n",
    "    \n",
    "    added_count = 0\n",
    "    for key in tld_keys:\n",
    "        if key in data_04_2:\n",
    "            # æ¨™æº–åŒ–ã•ã‚ŒãŸã‚­ãƒ¼åã«ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "            standard_key = key.lower()\n",
    "            if 'dangerous' in standard_key:\n",
    "                target_key = 'dangerous_tlds'\n",
    "            elif 'legitimate' in standard_key:\n",
    "                target_key = 'legitimate_tlds'\n",
    "            elif 'neutral' in standard_key:\n",
    "                target_key = 'neutral_tlds'\n",
    "            elif 'tld' in standard_key and 'stat' in standard_key:\n",
    "                target_key = 'phishing_tld_stats'\n",
    "            else:\n",
    "                target_key = key\n",
    "            \n",
    "            if target_key not in external_data:\n",
    "                external_data[target_key] = data_04_2[key]\n",
    "                value = data_04_2[key]\n",
    "                size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "                print(f\"  âœ… Added {target_key}: {type(value).__name__} (len={size})\")\n",
    "                added_count += 1\n",
    "    \n",
    "    # High Risk Words ã‚’è¿½åŠ \n",
    "    hrw_keys = ['HIGH_RISK_WORDS', 'high_risk_words', 'high_risk']\n",
    "    for key in hrw_keys:\n",
    "        if key in data_04_2 and 'high_risk_words' not in external_data:\n",
    "            external_data['high_risk_words'] = data_04_2[key]\n",
    "            words = data_04_2[key]\n",
    "            print(f\"  âœ… Added high_risk_words: {type(words).__name__} (len={len(words)})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    # Known Domains ã‚’è¿½åŠ \n",
    "    kd_keys = ['KNOWN_DOMAINS', 'known_domains', 'legitimate_domains']\n",
    "    for key in kd_keys:\n",
    "        if key in data_04_2 and 'known_domains' not in external_data:\n",
    "            external_data['known_domains'] = data_04_2[key]\n",
    "            domains = data_04_2[key]\n",
    "            size = len(domains) if hasattr(domains, '__len__') else 'N/A'\n",
    "            print(f\"  âœ… Added known_domains: {type(domains).__name__} (len={size})\")\n",
    "            added_count += 1\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n[INFO] Added {added_count} data items from 04-2\")\n",
    "\n",
    "# æœ€çµ‚ç¢ºèª\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Final Data Availability Check\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "required_keys = {\n",
    "    'brand_keywords': 'Brand keywords list',\n",
    "    'cert_full_info_map': 'Certificate information',\n",
    "    'dangerous_tlds': 'Dangerous TLDs',\n",
    "    'legitimate_tlds': 'Legitimate TLDs',\n",
    "    'neutral_tlds': 'Neutral TLDs',\n",
    "    'phishing_tld_stats': 'TLD phishing statistics',\n",
    "    'high_risk_words': 'High risk words',\n",
    "    'known_domains': 'Known legitimate domains'\n",
    "}\n",
    "\n",
    "for key, description in required_keys.items():\n",
    "    if key in external_data:\n",
    "        value = external_data[key]\n",
    "        size = len(value) if hasattr(value, '__len__') else 'N/A'\n",
    "        print(f\"  âœ… {description:30} (len={size})\")\n",
    "    else:\n",
    "        print(f\"  âŒ {description:30} NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b765008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[External Data Summary]\n",
      "================================================================================\n",
      "[INFO] Expected sources:\n",
      "{'04-2': 'artifacts/2025-12-07_143907/handoff/04-2_statistical_analysis.pkl',\n",
      " '04-3': 'artifacts/2025-12-07_143907/handoff/04-3_llm_tools_setup_with_tools.pkl'}\n",
      "\n",
      "[OK] All required keys exist.\n",
      "\n",
      "[Counts]\n",
      "  brand_keywords     : list         len=35\n",
      "  cert_full_info_map : dict         len=4148\n",
      "  dangerous_tlds     : NoneType     len=N/A\n",
      "  legitimate_tlds    : NoneType     len=N/A\n",
      "  neutral_tlds       : NoneType     len=N/A\n",
      "  phishing_tld_stats : DataFrame    len=177\n",
      "  high_risk_words    : list         len=2\n",
      "  known_domains      : dict         len=4148\n",
      "\n",
      "[TLD Sanity]\n",
      "  âœ… OK: 'com' is NOT in dangerous_tlds.\n",
      "  âœ… OK: No overlaps between dangerous/legitimate/neutral TLD sets.\n",
      "\n",
      "[Known Domains Note]\n",
      "  known_domains type=dict, sample=[('ulnln.cn', True), ('iberoprint.com', True), ('libreriatinta.com', True), ('hilfe-debixapp.com', True), ('liberta-jikohasan.com', True)]\n",
      "  NOTE: If known_domains is a 'seen list' (not a strict whitelist), it should NOT be used for safety mitigation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell X: External Data ã®å–å¾—å…ƒã¨å†…å®¹ã‚µãƒãƒªï¼ˆå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼‰\n",
    "# ============================================\n",
    "\n",
    "# ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä½¿ã† external_data ã¯ã€åŸå‰‡ã“ã“ã¾ã§ã§ä»¥ä¸‹ã‹ã‚‰æ§‹ç¯‰ã•ã‚Œã¾ã™ï¼š\n",
    "#   1) artifacts/<RUN_ID>/handoff/04-3_llm_tools_setup_with_tools.pkl\n",
    "#   2) (ä¸è¶³åˆ†ãŒã‚ã‚‹å ´åˆ) artifacts/<RUN_ID>/handoff/04-2_statistical_analysis.pkl\n",
    "# ãã®å¾Œã€(å¿…è¦ã«å¿œã˜ã¦) brand_keywords ã‚’è£œå¼·ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[External Data Summary]\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "required = [\n",
    "    'brand_keywords',\n",
    "    'cert_full_info_map',\n",
    "    'dangerous_tlds',\n",
    "    'legitimate_tlds',\n",
    "    'neutral_tlds',\n",
    "    'phishing_tld_stats',\n",
    "    'high_risk_words',\n",
    "    'known_domains',\n",
    "]\n",
    "\n",
    "src_hint = {\n",
    "    '04-3': str(HANDOFF_DIR / '04-3_llm_tools_setup_with_tools.pkl'),\n",
    "    '04-2': str(HANDOFF_DIR / '04-2_statistical_analysis.pkl'),\n",
    "}\n",
    "print(\"[INFO] Expected sources:\")\n",
    "pprint(src_hint)\n",
    "\n",
    "missing = [k for k in required if k not in (external_data or {})]\n",
    "if missing:\n",
    "    print(\"\\n[WARN] Missing keys in external_data:\")\n",
    "    pprint(missing)\n",
    "else:\n",
    "    print(\"\\n[OK] All required keys exist.\")\n",
    "\n",
    "def _len(x):\n",
    "    try:\n",
    "        return len(x)\n",
    "    except Exception:\n",
    "        return 'N/A'\n",
    "\n",
    "print(\"\\n[Counts]\")\n",
    "for k in required:\n",
    "    v = (external_data or {}).get(k)\n",
    "    print(f\"  {k:18} : {type(v).__name__:<12} len={_len(v)}\")\n",
    "\n",
    "# None/å‹ã‚†ã‚‰ãå¯¾ç­–: external_data ã® *tlds ãŒ None ã®å ´åˆãŒã‚ã‚‹\n",
    "def _as_list(v):\n",
    "    if v is None:\n",
    "        return []\n",
    "    if isinstance(v, str):\n",
    "        return [v]\n",
    "    if isinstance(v, (list, tuple, set)):\n",
    "        return list(v)\n",
    "    # pandas Series / numpy array ç­‰\n",
    "    try:\n",
    "        return list(v)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# TLD ã‚»ãƒƒãƒˆã®äº¤å·®ãƒã‚§ãƒƒã‚¯ï¼ˆ.com ãŒ dangerous ã«æ··å…¥ã™ã‚‹ã¨ FP/FN åˆ†æãŒå£Šã‚Œã‚„ã™ã„ï¼‰\n",
    "D = {str(x).lower() for x in _as_list((external_data or {}).get('dangerous_tlds'))}\n",
    "L = {str(x).lower() for x in _as_list((external_data or {}).get('legitimate_tlds'))}\n",
    "N = {str(x).lower() for x in _as_list((external_data or {}).get('neutral_tlds'))}\n",
    "\n",
    "print(\"\\n[TLD Sanity]\")\n",
    "if 'com' in D:\n",
    "    print(\"  âŒ WARNING: 'com' is inside dangerous_tlds. This will over-fire dangerous_tld for normal domains.\")\n",
    "else:\n",
    "    print(\"  âœ… OK: 'com' is NOT in dangerous_tlds.\")\n",
    "\n",
    "overlap_DL = sorted(D & L)\n",
    "overlap_DN = sorted(D & N)\n",
    "overlap_LN = sorted(L & N)\n",
    "if overlap_DL or overlap_DN or overlap_LN:\n",
    "    print(\"  âš  Overlaps found (should ideally be empty):\")\n",
    "    if overlap_DL: print(\"    - dangerous âˆ© legitimate:\", overlap_DL[:20], \"...\" if len(overlap_DL)>20 else \"\")\n",
    "    if overlap_DN: print(\"    - dangerous âˆ© neutral   :\", overlap_DN[:20], \"...\" if len(overlap_DN)>20 else \"\")\n",
    "    if overlap_LN: print(\"    - legitimate âˆ© neutral  :\", overlap_LN[:20], \"...\" if len(overlap_LN)>20 else \"\")\n",
    "else:\n",
    "    print(\"  âœ… OK: No overlaps between dangerous/legitimate/neutral TLD sets.\")\n",
    "\n",
    "print(\"\\n[Known Domains Note]\")\n",
    "kd = (external_data or {}).get('known_domains', {})\n",
    "sample_items = list(kd.items())[:5] if isinstance(kd, dict) else []\n",
    "print(f\"  known_domains type={type(kd).__name__}, sample={sample_items}\")\n",
    "print(\"  NOTE: If known_domains is a 'seen list' (not a strict whitelist), it should NOT be used for safety mitigation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading existing CSV from: artifacts/2025-12-07_143907/logs/random_eval_domains_latest.csv\n",
      "[INFO] Target sample loaded: 10 domains (N_SAMPLE=10)\n",
      "                        domain  ml_probability\n",
      "0                  upsixdc.com        0.086927\n",
      "1                  buteegch.mn        0.273401\n",
      "2  westpac-security-verify.com        0.064026\n",
      "3                    42kmm.com        0.413152\n",
      "4          bdowefindway-ph.com        0.360522\n",
      "\n",
      "[ML Probability Distribution]\n",
      "  Min:    0.064\n",
      "  Max:    0.413\n",
      "  Mean:   0.219\n",
      "  Median: 0.193\n",
      "  High risk (>0.4): 1 domains\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 3: Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆä»¶æ•°=N_SAMPLEï¼‰\n",
    "# ============================================\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "def _search_eval_df(obj):\n",
    "    '''dict/list å†å¸°ã§ DataFrame ã‚’æ¢ã™'''\n",
    "    if obj is None:\n",
    "        return None\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        # ã‚ˆãã‚ã‚‹ã‚­ãƒ¼ç›´å‚ç…§\n",
    "        for k in (\"false_negatives_df\", \"fn_df\", \"eval_df\", \"random_eval_df\"):\n",
    "            v = obj.get(k)\n",
    "            if isinstance(v, pd.DataFrame):\n",
    "                return v\n",
    "        for v in obj.values():\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        for v in obj:\n",
    "            hit = _search_eval_df(v)\n",
    "            if hit is not None:\n",
    "                return hit\n",
    "    return None\n",
    "\n",
    "def _normalize_eval_df(df):\n",
    "    '''åˆ—åã®æºã‚Œã«å¯¾å¿œã—ã¦ domain, ml_probability ã®2åˆ—ã«æ­£è¦åŒ–'''\n",
    "    print(\"[DEBUG] columns:\", list(df.columns))\n",
    "    \n",
    "    # lower â†’ å…ƒåã®ãƒãƒƒãƒ—\n",
    "    lower2orig = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    # 1) domainå€™è£œ\n",
    "    domain_candidates = [\"domain\", \"fqdn\", \"domain_name\", \"hostname\", \"host\", \"requested_host\"]\n",
    "    domain_key = None\n",
    "    for key in domain_candidates:\n",
    "        if key in lower2orig:\n",
    "            domain_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if domain_key is None:\n",
    "        # éƒ¨åˆ†ä¸€è‡´\n",
    "        for c in df.columns:\n",
    "            if any(kw in c.lower() for kw in [\"domain\", \"fqdn\", \"host\", \"url\"]):\n",
    "                domain_key = c\n",
    "                print(f\"[DEBUG] domain fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    # 2) ml_probabilityå€™è£œ\n",
    "    ml_candidates = [\"ml_probability\", \"ml_prob\", \"probability\", \"prediction_proba\", \n",
    "                     \"score\", \"pred_proba\", \"proba\", \"confidence\"]\n",
    "    mlp_key = None\n",
    "    for key in ml_candidates:\n",
    "        if key in lower2orig:\n",
    "            mlp_key = lower2orig[key]\n",
    "            break\n",
    "    \n",
    "    if mlp_key is None:\n",
    "        # floatã‚«ãƒ©ãƒ ã‹ã‚‰æ¨æ¸¬\n",
    "        float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "        for c in float_cols:\n",
    "            if any(kw in c.lower() for kw in [\"prob\", \"score\", \"pred\"]):\n",
    "                mlp_key = c\n",
    "                print(f\"[DEBUG] ml_probability fallback: {c}\")\n",
    "                break\n",
    "    \n",
    "    if domain_key is None or mlp_key is None:\n",
    "        print(\"[ERROR] could not infer domain/ml_probability columns\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"[DEBUG] chosen columns: domain={domain_key}, ml_prob={mlp_key}\")\n",
    "    \n",
    "    tmp = df[[domain_key, mlp_key]].copy()\n",
    "    tmp.columns = [\"domain\", \"ml_probability\"]\n",
    "    \n",
    "    # urlâ†’domainã®æ­£è¦åŒ–\n",
    "    if \"url\" in domain_key.lower():\n",
    "        def _to_domain(x):\n",
    "            if not isinstance(x, str):\n",
    "                return \"\"\n",
    "            if \"://\" in x:\n",
    "                netloc = urlparse(x).netloc\n",
    "            else:\n",
    "                netloc = x\n",
    "            netloc = netloc.split(\"@\")[-1].split(\":\")[0]\n",
    "            return netloc.lower()\n",
    "        tmp[\"domain\"] = tmp[\"domain\"].map(_to_domain)\n",
    "    \n",
    "    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "    tmp[\"domain\"] = tmp[\"domain\"].astype(str).str.strip().str.lower()\n",
    "    tmp = tmp[tmp[\"domain\"].str.len() > 0]\n",
    "    tmp[\"ml_probability\"] = pd.to_numeric(tmp[\"ml_probability\"], errors=\"coerce\")\n",
    "    tmp = tmp[(tmp[\"ml_probability\"] >= 0.0) & (tmp[\"ml_probability\"] <= 1.0)]\n",
    "    tmp = tmp.dropna(subset=[\"ml_probability\"]).reset_index(drop=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "def get_random_domains(sample_size=None):\n",
    "    '''Randomã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆä»¶æ•°=sample_sizeï¼‰'''\n",
    "    if sample_size is None:\n",
    "        sample_size = N_SAMPLE\n",
    "    sample_size = int(sample_size)\n",
    "    \n",
    "    # æ–¹æ³•1: æ—¢å­˜ã®CSVã‹ã‚‰\n",
    "    csv_paths = [\n",
    "    LOGS_DIR / \"random_eval_domains_latest.csv\",\n",
    "]\n",
    "    \n",
    "    for csv_path in csv_paths:\n",
    "        if csv_path.exists():\n",
    "            print(f\"[INFO] Loading existing CSV from: {csv_path}\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "            # ALL æŒ‡å®šï¼ˆ0/-1ï¼‰ãªã‚‰ã€æ—¢å­˜CSVãŒéƒ¨åˆ†ã‚µãƒ³ãƒ—ãƒ«ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ pickle ã‹ã‚‰å†ç”Ÿæˆã™ã‚‹\n",
    "            if sample_size <= 0:\n",
    "                print(f\"[INFO] sample_size={sample_size} (ALL) requested; ignore cache and regenerate from pickle...\")\n",
    "                break\n",
    "            # æ—¢å­˜CSVãŒè¦æ±‚ä»¶æ•°ã¨ä¸€è‡´ã™ã‚‹ãªã‚‰ãã®ã¾ã¾ä½¿ã†ã€‚\n",
    "            # ã‚‚ã—ä»¶æ•°ãŒé•ã†å ´åˆã¯ã€pickle ã‹ã‚‰å†ç”Ÿæˆã™ã‚‹ï¼ˆå¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´ã¾ãªã„ãŸã‚ï¼‰ã€‚\n",
    "            if (sample_size > 0) and (len(df) == sample_size):\n",
    "                return df\n",
    "\n",
    "            if (sample_size > 0) and (len(df) > sample_size):\n",
    "                print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; downsampling.\")\n",
    "                return df.sample(n=sample_size, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "            print(f\"[INFO] Existing CSV has n={len(df)} but requested n={sample_size}; regenerating from pickle...\")\n",
    "            break\n",
    "    \n",
    "    # æ–¹æ³•2: pickleã‹ã‚‰ç”Ÿæˆï¼ˆå…ƒã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰\n",
    "    print(\"[INFO] CSV not found, generating from pickle...\")\n",
    "    \n",
    "    pickle_paths = [\n",
    "    HANDOFF_DIR / \"04-2_statistical_analysis.pkl\",\n",
    "    HANDOFF_DIR / \"04-3_llm_tools_setup_with_tools.pkl\",\n",
    "]\n",
    "    \n",
    "    eval_source_df = None\n",
    "    for pickle_path in pickle_paths:\n",
    "        if not pickle_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"[INFO] Trying: {pickle_path}\")\n",
    "        try:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                obj = pickle.load(f)\n",
    "            \n",
    "            # DataFrameã‚’æ¢ã™\n",
    "            raw_df = _search_eval_df(obj)\n",
    "            if raw_df is not None and len(raw_df) > 0:\n",
    "                print(f\"[INFO] Found DataFrame with {len(raw_df)} rows\")\n",
    "                eval_source_df = raw_df\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {pickle_path}: {e}\")\n",
    "    \n",
    "    if eval_source_df is None:\n",
    "        raise RuntimeError(\n",
    "            \"è©•ä¾¡ç”¨DataFrameãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\\n\"\n",
    "            \"04-2 ã¾ãŸã¯ 04-3 ã®pickleãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\"\n",
    "        )\n",
    "    \n",
    "    # æ­£è¦åŒ–\n",
    "    norm_df = _normalize_eval_df(eval_source_df)\n",
    "    if norm_df is None:\n",
    "        raise RuntimeError(\"DataFrameã®æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "    \n",
    "    print(f\"[INFO] Source rows (normalized): {len(norm_df)}\")\n",
    "    \n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå…ƒã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯å›ºå®šã‚·ãƒ¼ãƒ‰ãªã—ï¼‰\n",
    "    # [ChangeLog] 2025-12-15: sample_size<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’è¿”ã™\n",
    "    if sample_size <= 0:\n",
    "        sample_n = len(norm_df)\n",
    "        # å…¨ä»¶å‡¦ç†ã®ã¨ãã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã›ãšã€ãã®ã¾ã¾ï¼ˆå†ç¾æ€§ãƒ»é€Ÿåº¦å„ªå…ˆï¼‰\n",
    "        sample_df = norm_df.reset_index(drop=True)\n",
    "    else:\n",
    "        sample_n = min(sample_size, len(norm_df))\n",
    "        sample_df = norm_df.sample(n=sample_n).reset_index(drop=True)\n",
    "    \n",
    "    # CSVä¿å­˜\n",
    "    out_csv = LOGS_DIR / \"random_eval_domains_latest.csv\"\n",
    "    LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    sample_df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[INFO] Random sample saved to: {out_csv} (n={sample_n})\")\n",
    "    \n",
    "    return sample_df\n",
    "\n",
    "# Randomã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "target_df = get_random_domains(sample_size=N_SAMPLE)\n",
    "print(f\"[INFO] Target sample loaded: {len(target_df)} domains (N_SAMPLE={N_SAMPLE})\")\n",
    "print(target_df.head())\n",
    "\n",
    "# MLç¢ºç‡ã®åˆ†å¸ƒã‚’ç¢ºèª\n",
    "print(f\"\\n[ML Probability Distribution]\")\n",
    "print(f\"  Min:    {target_df['ml_probability'].min():.3f}\")\n",
    "print(f\"  Max:    {target_df['ml_probability'].max():.3f}\")\n",
    "print(f\"  Mean:   {target_df['ml_probability'].mean():.3f}\")\n",
    "print(f\"  Median: {target_df['ml_probability'].median():.3f}\")\n",
    "\n",
    "# é«˜ãƒªã‚¹ã‚¯ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆMLç¢ºç‡ > 0.4ï¼‰ã®æ•°\n",
    "high_risk = target_df[target_df['ml_probability'] > 0.4]\n",
    "print(f\"  High risk (>0.4): {len(high_risk)} domains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622fa712-5c77-4190-a7f1-0c13078b7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT INITIALIZATION WITH LLM (MANDATORY, READ-ONLY CONFIG)\n",
      "================================================================================\n",
      "\n",
      "[1] Loading LLM Configuration from _compat/config.json\n",
      "----------------------------------------\n",
      "âœ… Loaded config.json from /home/asomura/backup/nextstep/_compat/config.json\n",
      "LLM config overview:\n",
      "  enabled   : True\n",
      "  provider  : vllm\n",
      "  base_url  : http://localhost:8000/v1\n",
      "  model     : JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8\n",
      "  temperature: 0.1\n",
      "\n",
      "[2] Setting OPENAI_API_KEY (dummy for vLLM / Ollama)\n",
      "----------------------------------------\n",
      "âœ… OPENAI_API_KEY set (dummy or from config)\n",
      "\n",
      "[3] Clearing legacy 'phishpkg' modules (if any)\n",
      "----------------------------------------\n",
      "âœ… Removed 0 phishpkg modules from sys.modules\n",
      "\n",
      "[4] Wiring Phase6 (LLM required, using config.json)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asomura/waseda/phish-core/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase6 wired with real LLM (using config.json)\n",
      "  phase6_wiring.__file__      = /home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py\n",
      "  langgraph_module.__file__   = /home/asomura/backup/nextstep/phishing_agent/langgraph_module.py\n",
      "  final_decision_node.module  = phishing_agent.phase6_wiring\n",
      "  final_decision_node.file    = /home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py\n",
      "\n",
      "[5] Importing LangGraphPhishingAgent\n",
      "----------------------------------------\n",
      "âœ… LangGraphPhishingAgent imported\n",
      "\n",
      "[6] Initializing Agent (LLM mandatory, config-driven)\n",
      "----------------------------------------\n",
      "âœ… Agent initialized\n",
      "\n",
      "================================================================================\n",
      "AGENT READY FOR EVALUATION (LLM MANDATORY, CONFIG-DRIVEN)\n",
      "================================================================================\n",
      "âœ… LLM: Loaded from _compat/config.json\n",
      "âœ… Phase6: wired (LLMçµŒè·¯ã‚ã‚Šã€fallbackã¯phase6_wiringå´ãƒ­ã‚¸ãƒƒã‚¯ã«ä¾å­˜)\n",
      "âœ… Agent: Initialized\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4: LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚µãƒ³ãƒ—ãƒ«ç”¨ãƒ»LLMå¿…é ˆç‰ˆ, configèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰\n",
    "# ============================================\n",
    "#\n",
    "# [ChangeLog] 2025-12-21:\n",
    "#   - [7] Quick Verification Test (single domain) ã‚’å‰Šé™¤ï¼ˆPreflightã‚»ãƒ«ã«é›†ç´„ã™ã‚‹ãŸã‚ï¼‰\n",
    "# ============================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ç’°å¢ƒè¨­å®š\n",
    "os.chdir(BASE_DIR)\n",
    "# [ChangeLog] 2025-12-16: sys.path ã‚’æ•´ç†ï¼ˆPhase6 wiring ã®äºŒé‡ import å•é¡Œã‚’å›é¿ï¼‰\n",
    "# NOTE: sys.path ã«ã¯ BASE_DIR ã®ã¿ã‚’å…¥ã‚Œã¦ package import ã‚’çµ±ä¸€ã™ã‚‹ã€‚\n",
    "phishing_agent_path = BASE_DIR / \"phishing_agent\"\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "if str(phishing_agent_path) in sys.path:\n",
    "    sys.path.remove(str(phishing_agent_path))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGENT INITIALIZATION WITH LLM (MANDATORY, READ-ONLY CONFIG)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. _compat/config.json ã‹ã‚‰ LLM è¨­å®šã‚’èª­ã‚€ï¼ˆâ€»æ›¸ãæ›ãˆãªã„ï¼‰\n",
    "print(\"\\n[1] Loading LLM Configuration from _compat/config.json\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cfg_path = BASE_DIR / \"_compat\" / \"config.json\"\n",
    "cfg_json = {}\n",
    "llm_cfg = {}\n",
    "\n",
    "if not cfg_path.exists():\n",
    "    print(f\"âŒ config.json not found at {cfg_path}\")\n",
    "else:\n",
    "    try:\n",
    "        with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg_json = json.load(f)\n",
    "        llm_cfg = (cfg_json.get(\"llm\") or {})\n",
    "        print(f\"âœ… Loaded config.json from {cfg_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load config.json: {e}\")\n",
    "        cfg_json = {}\n",
    "        llm_cfg = {}\n",
    "\n",
    "# LLMè¨­å®šã®ã‚µãƒãƒªè¡¨ç¤º\n",
    "if not llm_cfg:\n",
    "    print(\"âŒ 'llm' section not found in config.json\")\n",
    "else:\n",
    "    provider   = llm_cfg.get(\"provider\")\n",
    "    base_url   = (\n",
    "        llm_cfg.get(\"base_url\")\n",
    "        or llm_cfg.get(\"vllm_base_url\")\n",
    "        or llm_cfg.get(\"ollama_base_url\")\n",
    "    )\n",
    "    model      = (\n",
    "        llm_cfg.get(\"model\")\n",
    "        or llm_cfg.get(\"vllm_model\")\n",
    "        or llm_cfg.get(\"ollama_model\")\n",
    "    )\n",
    "    enabled    = bool(llm_cfg.get(\"enabled\", False))\n",
    "    temperature = llm_cfg.get(\"temperature\", 0.1)\n",
    "\n",
    "    print(\"LLM config overview:\")\n",
    "    print(f\"  enabled   : {enabled}\")\n",
    "    print(f\"  provider  : {provider}\")\n",
    "    print(f\"  base_url  : {base_url}\")\n",
    "    print(f\"  model     : {model}\")\n",
    "    print(f\"  temperature: {temperature}\")\n",
    "\n",
    "    if not enabled:\n",
    "        print(\"âš  LLM is disabled in config.json (llm.enabled=False)\")\n",
    "    if not base_url:\n",
    "        print(\"âš  llm.base_url / vllm_base_url / ollama_base_url is not set\")\n",
    "    if not model:\n",
    "        print(\"âš  llm.model / vllm_model / ollama_model is not set\")\n",
    "\n",
    "# external_data ã«ã‚‚ cfg ã‚’å…¥ã‚Œã¦ãŠãï¼ˆèª­ã¿å–ã‚Šçµæœã ã‘åæ˜ ï¼‰\n",
    "if \"external_data\" not in globals():\n",
    "    external_data = {}\n",
    "external_data.setdefault(\"cfg\", {})\n",
    "external_data[\"cfg\"][\"llm\"] = llm_cfg\n",
    "\n",
    "# 2. OPENAI_API_KEY ã®è¨­å®šï¼ˆvLLMã®å ´åˆã¯ãƒ€ãƒŸãƒ¼ã§OKï¼‰\n",
    "print(\"\\n[2] Setting OPENAI_API_KEY (dummy for vLLM / Ollama)\")\n",
    "print(\"-\" * 40)\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = llm_cfg.get(\"api_key\") or \"dummy-key-for-local-llm\"\n",
    "    print(\"âœ… OPENAI_API_KEY set (dummy or from config)\")\n",
    "else:\n",
    "    print(\"â„¹ OPENAI_API_KEY already set in environment\")\n",
    "\n",
    "# 3. phishpkg/æ—§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚ã‚Œã°ï¼‰\n",
    "print(\"\\n[3] Clearing legacy 'phishpkg' modules (if any)\")\n",
    "print(\"-\" * 40)\n",
    "removed = 0\n",
    "for key in list(sys.modules.keys()):\n",
    "    if key.startswith(\"phishpkg\"):\n",
    "        del sys.modules[key]\n",
    "        removed += 1\n",
    "print(f\"âœ… Removed {removed} phishpkg modules from sys.modules\")\n",
    "\n",
    "# 4. Phase6 é…ç·šï¼ˆLLMå¿…é ˆãƒ¢ãƒ¼ãƒ‰ï¼fake_llm=Falseï¼‰\n",
    "print(\"\\n[4] Wiring Phase6 (LLM required, using config.json)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from phishing_agent.phase6_wiring import wire_phase6\n",
    "\n",
    "    # CONFIG_JSON ã‚’æ˜ç¤ºã—ã¦ãŠãã¨å®‰å…¨\n",
    "    cfg_env_path = str(cfg_path)\n",
    "    os.environ[\"CONFIG_JSON\"] = cfg_env_path\n",
    "\n",
    "    # prefer_compat=True: _compat/config.json ã‚’å„ªå…ˆ\n",
    "    # fake_llm=False    : å®Ÿéš›ã® LLM ã‚’ä½¿ã†å‰æï¼ˆå¤±æ•—æ™‚ã¯ä¾‹å¤– or ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯phase6_wiringå´ãƒ«ãƒ¼ãƒ«ï¼‰\n",
    "    wire_phase6(prefer_compat=True, fake_llm=False)\n",
    "    print(\"âœ… Phase6 wired with real LLM (using config.json)\")\n",
    "\n",
    "    # [ChangeLog] 2025-12-16: ã©ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹æ˜ç¤ºï¼ˆå–ã‚Šé•ãˆé˜²æ­¢ï¼‰\n",
    "    import phishing_agent.phase6_wiring as _p6w\n",
    "    import phishing_agent.langgraph_module as _l4\n",
    "    import inspect as _inspect\n",
    "    print(f\"  phase6_wiring.__file__      = {_p6w.__file__}\")\n",
    "    print(f\"  langgraph_module.__file__   = {_l4.__file__}\")\n",
    "    try:\n",
    "        _fd = _l4.LangGraphPhishingAgent._final_decision_node\n",
    "        print(f\"  final_decision_node.module  = {_fd.__module__}\")\n",
    "        print(f\"  final_decision_node.file    = {_inspect.getsourcefile(_fd)}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  (warn) could not introspect final_decision_node: {_e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Phase6 wiring failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# 5. LangGraph ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "print(\"\\n[5] Importing LangGraphPhishingAgent\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from phishing_agent.langgraph_module import LangGraphPhishingAgent\n",
    "\n",
    "print(\"âœ… LangGraphPhishingAgent imported\")\n",
    "\n",
    "# 6. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆuse_llm_decision=True ãŒè¶…é‡è¦ï¼‰\n",
    "print(\"\\n[6] Initializing Agent (LLM mandatory, config-driven)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "agent = LangGraphPhishingAgent(\n",
    "    strict_mode=True,              # Graphå…¨ä½“ã¨ã—ã¦ã¯ strict=Falseï¼ˆPhase6å´ã§SOã¯strictã«ã—ã¦OKï¼‰\n",
    "    use_llm_selection=True,\n",
    "    use_llm_decision=True,          # â˜… final_decision ã§å¿…ãš LLM çµŒè·¯ã‚’è©¦ã™\n",
    "    config_path=str(cfg_path),\n",
    "    external_data=external_data,\n",
    ")\n",
    "print(\"âœ… Agent initialized\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AGENT READY FOR EVALUATION (LLM MANDATORY, CONFIG-DRIVEN)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ… LLM: Loaded from _compat/config.json\")\n",
    "print(\"âœ… Phase6: wired (LLMçµŒè·¯ã‚ã‚Šã€fallbackã¯phase6_wiringå´ãƒ­ã‚¸ãƒƒã‚¯ã«ä¾å­˜)\")\n",
    "print(\"âœ… Agent: Initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b6dd56-b783-442f-a0d7-5178c741ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Generating TLD data from Database Analysis...\n",
      "  ğŸ”Œ Connecting to database: rapids_data at localhost...\n",
      "  âœ… Database connected successfully\n",
      "  ğŸ“Š Analyzing phishing domains...\n",
      "  ğŸ“Š Analyzing trusted domains...\n",
      "    - Phishing unique: 320409\n",
      "    - Trusted unique: 450656\n",
      "  âœ… Generated 30 dangerous TLDs\n",
      "  âœ… Generated 26 legitimate TLDs\n",
      "  âœ… Agent external_data updated\n",
      "âœ… TLD data patched via Database Analysis. Ready for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4.6: TLDãƒªã‚¹ãƒˆã®å‹•çš„ç”Ÿæˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æç‰ˆï¼‰\n",
    "# â€» DBæ¥ç¶šå¿…é ˆã€‚å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼çµ‚äº†ã—ã¾ã™ã€‚\n",
    "# ============================================\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ”§ Generating TLD data from Database Analysis...\")\n",
    "\n",
    "# 03_ai_agent_analysis.ipynb ã‹ã‚‰ã® DBè¨­å®š\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# TLDæŠ½å‡ºé–¢æ•° (03ã‹ã‚‰ã®ç§»æ¤)\n",
    "def extract_tld(domain):\n",
    "    \"\"\"ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰TLDã‚’æŠ½å‡º\"\"\"\n",
    "    if not domain:\n",
    "        return None\n",
    "    # URLã®å ´åˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†ã‚’æŠ½å‡º\n",
    "    if '://' in domain:\n",
    "        try:\n",
    "            parsed = urlparse(domain)\n",
    "            domain = parsed.netloc\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # ãƒãƒ¼ãƒˆç•ªå·ã‚’å‰Šé™¤\n",
    "    domain = str(domain).split(':')[0]\n",
    "    \n",
    "    parts = domain.split('.')\n",
    "    if len(parts) >= 2:\n",
    "        # .co.jp, .ac.jp ãªã©ã®è¤‡åˆTLDå¯¾å¿œ\n",
    "        if len(parts) >= 3 and parts[-2] in ['co', 'ac', 'or', 'ne', 'go']:\n",
    "            return f'.{parts[-2]}.{parts[-1]}'\n",
    "        else:\n",
    "            return f'.{parts[-1]}'\n",
    "    return None\n",
    "\n",
    "try:\n",
    "    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
    "    print(f\"  ğŸ”Œ Connecting to database: {DB_CONFIG['dbname']} at {DB_CONFIG['host']}...\")\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    print(\"  âœ… Database connected successfully\")\n",
    "\n",
    "    # 1. ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã‚µã‚¤ãƒˆã®å–å¾— (å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰)\n",
    "    print(\"  ğŸ“Š Analyzing phishing domains...\")\n",
    "    phishing_queries = [\n",
    "        \"SELECT cert_domain as domain FROM phishtank_entries WHERE cert_status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM jpcert_phishing_urls WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\",\n",
    "        \"SELECT domain FROM certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\"\n",
    "    ]\n",
    "    \n",
    "    phishing_domains = []\n",
    "    for query in phishing_queries:\n",
    "        cur.execute(query)\n",
    "        results = cur.fetchall()\n",
    "        for row in results:\n",
    "            if row['domain']: phishing_domains.append(row['domain'])\n",
    "            \n",
    "    if not phishing_domains:\n",
    "        raise ValueError(\"No phishing domains found in database. Analysis cannot proceed.\")\n",
    "\n",
    "    # 2. æ­£å¸¸ã‚µã‚¤ãƒˆã®å–å¾—\n",
    "    print(\"  ğŸ“Š Analyzing trusted domains...\")\n",
    "    cur.execute(\"SELECT domain FROM trusted_certificates WHERE status = 'SUCCESS' AND cert_data IS NOT NULL\")\n",
    "    results = cur.fetchall()\n",
    "    trusted_domains = [row['domain'] for row in results if row['domain']]\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    # 3. ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ (03ã¨åŒæ§˜ã®ãƒ­ã‚¸ãƒƒã‚¯)\n",
    "    # é‡è¤‡é™¤å»\n",
    "    phishing_domains_unique = list(set(phishing_domains))\n",
    "    trusted_domains_unique = list(set(trusted_domains))\n",
    "    \n",
    "    print(f\"    - Phishing unique: {len(phishing_domains_unique)}\")\n",
    "    print(f\"    - Trusted unique: {len(trusted_domains_unique)}\")\n",
    "    \n",
    "    # å°‘ãªã„æ–¹ã«åˆã‚ã›ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "    random.seed(42)\n",
    "    min_unique = min(len(phishing_domains_unique), len(trusted_domains_unique))\n",
    "    \n",
    "    if min_unique == 0:\n",
    "        raise ValueError(\"Insufficient data for analysis (one of the datasets is empty).\")\n",
    "        \n",
    "    phishing_balanced = random.sample(phishing_domains_unique, min(len(phishing_domains_unique), min_unique))\n",
    "    trusted_balanced = random.sample(trusted_domains_unique, min(len(trusted_domains_unique), min_unique))\n",
    "\n",
    "    # 4. TLDé›†è¨ˆ\n",
    "    phishing_tlds = Counter([extract_tld(d) for d in phishing_balanced if extract_tld(d)])\n",
    "    trusted_tlds = Counter([extract_tld(d) for d in trusted_balanced if extract_tld(d)])\n",
    "\n",
    "    # 5. å±é™ºåº¦åˆ†æã¨åˆ†é¡\n",
    "    dangerous_tlds = []\n",
    "    \n",
    "    for tld, phish_count in phishing_tlds.items():\n",
    "        trust_count = trusted_tlds.get(tld, 0)\n",
    "        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã‚‹ã‚‚ã®ã¯é™¤å¤–\n",
    "        if phish_count >= 10:\n",
    "            ratio = phish_count / (trust_count + 1)\n",
    "            phish_pct = phish_count / len(phishing_balanced) * 100\n",
    "            \n",
    "            # åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯:\n",
    "            # 1. æ­£å¸¸ã‚µã‚¤ãƒˆã§çš†ç„¡(0ä»¶) ã‹ã¤ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã§10ä»¶ä»¥ä¸Š\n",
    "            # 2. æ¯”ç‡ãŒ10å€ä»¥ä¸Š ã‹ã¤ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°å…¨ä½“ã®0.1%ä»¥ä¸Š\n",
    "            if (trust_count == 0) or (ratio >= 10 and phish_pct >= 0.1):\n",
    "                dangerous_tlds.append(tld)\n",
    "    \n",
    "    # ãƒ‰ãƒƒãƒˆã‚’é™¤å»ã—ã¦æ ¼ç´ (ä¾‹: '.xyz' -> 'xyz')\n",
    "    external_data['dangerous_tlds'] = [t.lstrip('.') for t in dangerous_tlds]\n",
    "\n",
    "    # æ­£å½“ãªTLD\n",
    "    legitimate_tlds = []\n",
    "    for tld, count in trusted_tlds.most_common():\n",
    "        if count >= 1000: # çµ±è¨ˆçš„ä¿¡é ¼æ€§\n",
    "            phish_count = phishing_tlds.get(tld, 0)\n",
    "            ratio = phish_count / count\n",
    "            if ratio < 0.5: # æ­£å¸¸ã‚µã‚¤ãƒˆã§ã®ä½¿ç”¨ãŒ2å€ä»¥ä¸Š\n",
    "                legitimate_tlds.append(tld)\n",
    "    external_data['legitimate_tlds'] = [t.lstrip('.') for t in legitimate_tlds]\n",
    "\n",
    "    # ä¸­ç«‹çš„ãªTLD (ä¸»è¦TLDã®ã†ã¡ã€ä¸Šè¨˜ã«å…¥ã‚‰ãªã‹ã£ãŸã‚‚ã®)\n",
    "    neutral_candidates = ['.com', '.org', '.net', '.info', '.biz']\n",
    "    neutral_tlds = []\n",
    "    for tld in neutral_candidates:\n",
    "        if tld not in dangerous_tlds and tld not in legitimate_tlds:\n",
    "            neutral_tlds.append(tld)\n",
    "    external_data['neutral_tlds'] = [t.lstrip('.') for t in neutral_tlds]\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜ (ç”Ÿã®Counterã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ)\n",
    "    external_data['phishing_tld_stats'] = phishing_tlds\n",
    "\n",
    "    print(f\"  âœ… Generated {len(external_data['dangerous_tlds'])} dangerous TLDs\")\n",
    "    print(f\"  âœ… Generated {len(external_data['legitimate_tlds'])} legitimate TLDs\")\n",
    "\n",
    "    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå†…ã®å‚ç…§æ›´æ–°\n",
    "    if 'agent' in globals():\n",
    "        agent.external_data = external_data\n",
    "        print(\"  âœ… Agent external_data updated\")\n",
    "        \n",
    "    print(\"âœ… TLD data patched via Database Analysis. Ready for evaluation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ DATABASE ANALYSIS FAILED: {e}\")\n",
    "    print(\"â›” Stopping execution to prevent inaccurate results using fallback data.\")\n",
    "    # æ˜ç¤ºçš„ã«ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã¦å‡¦ç†ã‚’æ­¢ã‚ã‚‹\n",
    "    raise RuntimeError(\"Database connection or analysis failed. Please check DB connection and rerun this cell.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22dbebfb-390f-43d8-87ef-3ccddec725d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Preflight (light) â€” Phase6 wiring / precheck safety\n",
      "================================================================================\n",
      "[INFO] LLM initialized: JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8\n",
      "[OK] external_data: required keys present\n",
      "[OK] phishing_tld_stats normalized type: <class 'collections.Counter'>\n",
      "[INFO] code_fingerprint: {'eval_id': '2025-12-21_131443', 'phase6_policy_version_code': 'v1.4.3-r4tweak2', 'phase6_wiring_file': '/home/asomura/backup/nextstep/phishing_agent/phase6_wiring.py', 'phase6_wiring_sha256': '95ac49aae1913c218e1028c966cff73cda81c7ececda392c8ebbfa5d897d65dc', 'llm_final_decision_file': '/home/asomura/backup/nextstep/phishing_agent/llm_final_decision.py', 'llm_final_decision_sha256': '598f6cc4437f6a4d6a2fd2a1b9542b0eb8fd1ac5792b4fcb21ffc3adff1c089e', 'langgraph_module_file': '/home/asomura/backup/nextstep/phishing_agent/langgraph_module.py', 'langgraph_module_sha256': 'b19f2c7f7ee2039be1a96e54b753d2c3236cd229604a99fd651a6720c11e58c3', 'dual_import_langgraph_module': False}\n",
      "[INFO] final_decision_node: name=_patched_final_decision_node, module=phishing_agent.phase6_wiring\n",
      "[INFO] Phase6 wiring (static) : OK\n",
      "--------------------------------------------------------------------------------\n",
      "[INFO] Quick run domain=upsixdc.com, ml=0.086926974\n",
      "  Time              : 7.44s\n",
      "  success           : True\n",
      "  ai_is_phishing    : True\n",
      "  ai_confidence     : 0.75\n",
      "  ai_risk_level     : high\n",
      "--------------------------------------------------------------------------------\n",
      "  [FinalDecision debug]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    phase6_version(derived): None\n",
      "[INFO] Phase6 node executed(runtime): YES\n",
      "[WARNING] phase6_version could not be derived (may be OK if so_fallback occurred).\n",
      "          If you want to enforce Phase6 LLM success, set env STRICT_PHASE6_PREFLIGHT=1\n",
      "================================================================================\n",
      "âœ… Preflight PASSED. Proceed to Cell 5 (big evaluation loop).\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 4.7: Preflight (light) â€” Phase6 wiring / precheck safety\n",
    "#   - DBãƒã‚§ãƒƒã‚¯ãªã—ï¼ˆCell4.6ã§æ‹…ä¿ï¼‰\n",
    "#   - vLLMç–é€šãƒã‚§ãƒƒã‚¯ãªã—ï¼ˆåˆ¥ç®‡æ‰€ã§æ‹…ä¿ï¼‰\n",
    "#   - Cell5 ã®å®Ÿè£…ï¼ˆphase6_version ã®å–ã‚Šæ–¹ / fingerprintæ€æƒ³ï¼‰ã«åˆã‚ã›ã¦æ¤œè¨¼\n",
    "#\n",
    "# [ChangeLog] 2025-12-21:\n",
    "#   - phase6_policy_version ãŒç„¡ã„ã ã‘ã§å¤±æ•—æ‰±ã„ã«ã—ãªã„ï¼ˆCell5ã¨åŒæ§˜ã« decision_trace ã‚‚å‚ç…§ï¼‰\n",
    "#   - wiring ãŒå½“ãŸã£ã¦ã„ã‚‹ã‹ï¼ˆé™çš„ï¼‰ï¼‹ Phase6ãƒãƒ¼ãƒ‰ãŒè¸ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼ˆå®Ÿè¡Œæ™‚ï¼‰ã§åˆ¤å®š\n",
    "#   - precheck ã® DataFrame çœŸå½å€¤äº‹æ•…ã‚’é¿ã‘ã‚‹ãŸã‚ phishing_tld_stats ã‚’ dict ã«æ­£è¦åŒ–ï¼ˆãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆï¼‰\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import hashlib\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ§ª Preflight (light) â€” Phase6 wiring / precheck safety\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) å‰æï¼ˆæœ€ä½é™ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "if \"agent\" not in globals():\n",
    "    raise RuntimeError(\"agent ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« Agent åˆæœŸåŒ–ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if \"external_data\" not in globals():\n",
    "    raise RuntimeError(\"external_data ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚external_data æ§‹ç¯‰ã‚»ãƒ«ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "if \"target_df\" not in globals():\n",
    "    print(\"[WARNING] target_df ãŒæœªå®šç¾©ã§ã™ï¼ˆCell5 ç›´å‰ã«ç½®ãæƒ³å®šï¼‰ã€‚test domain ã¯å›ºå®šå€¤ã‚’ä½¿ã„ã¾ã™ã€‚\")\n",
    "\n",
    "# LLMè¨­å®šã®ç¢ºèªï¼ˆCell5 ã¨åŒæ§˜ã®é›°å›²æ°—ï¼‰\n",
    "if hasattr(agent, \"llm_config\"):\n",
    "    llm_config = getattr(agent, \"llm_config\", None)\n",
    "    if llm_config and getattr(llm_config, \"enabled\", False):\n",
    "        print(f\"[INFO] LLM initialized: {getattr(llm_config, 'model', '(unknown)')}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - Phase6 LLM path may not run\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent has no llm_config attribute (check initialization)\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) external_data ã®æœ€ä½é™ãƒã‚§ãƒƒã‚¯ï¼ˆprecheck ãŒä¾å­˜ã—ã‚„ã™ã„ã‚­ãƒ¼ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "required_keys = [\"dangerous_tlds\", \"legitimate_tlds\", \"neutral_tlds\", \"phishing_tld_stats\"]\n",
    "missing = [k for k in required_keys if k not in external_data or external_data[k] is None]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"[ERROR] external_data missing keys: {missing}\")\n",
    "\n",
    "print(\"[OK] external_data: required keys present\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) precheck å®‰å®šåŒ–ï¼šphishing_tld_stats ã‚’ dict ã«æ­£è¦åŒ–ï¼ˆDataFrame çœŸå½å€¤äº‹æ•…ã®å›é¿ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "except Exception:\n",
    "    pd = None\n",
    "\n",
    "def _normalize_tld_stats_to_dict(stats_obj):\n",
    "    \"\"\"\n",
    "    precheck_module ã® 'if not stats:' ã§è½ã¡ãªã„å½¢ï¼ˆdictï¼‰ã¸å¯„ã›ã‚‹ã€‚\n",
    "    æ—¢ã« dict ãªã‚‰ãã®ã¾ã¾ã€‚\n",
    "    DataFrame/Series ã¯ã‚ˆãã‚ã‚‹å½¢ã‚’æ¨å®šã—ã¦ {tld: float} ã«å¤‰æ›ã€‚\n",
    "    å¤±æ•—ã—ã¦ã‚‚å£Šã•ãªã„ï¼ˆå…ƒã®å€¤ã‚’è¿”ã™ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    if stats_obj is None:\n",
    "        return {}\n",
    "\n",
    "    if isinstance(stats_obj, dict):\n",
    "        return stats_obj\n",
    "\n",
    "    if pd is not None and isinstance(stats_obj, pd.Series):\n",
    "        try:\n",
    "            return {str(k): float(v) for k, v in stats_obj.to_dict().items()}\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "    if pd is not None and isinstance(stats_obj, pd.DataFrame):\n",
    "        try:\n",
    "            if getattr(stats_obj, \"empty\", False):\n",
    "                return {}\n",
    "\n",
    "            df = stats_obj.copy()\n",
    "\n",
    "            cols = list(df.columns)\n",
    "            key_candidates = [\"tld\", \"suffix\", \"public_suffix\", \"zone\"]\n",
    "            val_candidates = [\"count\", \"freq\", \"ratio\", \"rate\", \"score\", \"n\"]\n",
    "\n",
    "            key_col = next((c for c in key_candidates if c in cols), None)\n",
    "\n",
    "            val_col = next((c for c in val_candidates if c in cols), None)\n",
    "            if val_col is None:\n",
    "                num_cols = list(df.select_dtypes(include=\"number\").columns)\n",
    "                if num_cols:\n",
    "                    val_col = num_cols[0]\n",
    "\n",
    "            # (key_col, val_col) ãŒå–ã‚Œã‚Œã°ãã‚Œã‚’ä½¿ã†\n",
    "            if key_col and val_col and key_col in cols and val_col in cols:\n",
    "                s = df.set_index(key_col)[val_col]\n",
    "                return {str(k): float(v) for k, v in s.to_dict().items()}\n",
    "\n",
    "            # index ã‚’ key ã«ã—ã¦ã€æ•°å€¤åˆ—ã‚’ value ã«ã™ã‚‹ï¼ˆindex=tld ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\n",
    "            if val_col and val_col in cols:\n",
    "                s = df[val_col]\n",
    "                return {str(k): float(v) for k, v in s.to_dict().items()}\n",
    "\n",
    "            # æœ€å¾Œã®æ‰‹æ®µï¼š2åˆ—ä»¥ä¸Šãªã‚‰å…ˆé ­2åˆ—ã‚’ key/value ã¨ã¿ãªã™\n",
    "            if len(cols) >= 2:\n",
    "                kcol, vcol = cols[0], cols[1]\n",
    "                s = df.set_index(kcol)[vcol]\n",
    "                out = {}\n",
    "                for k, v in s.to_dict().items():\n",
    "                    try:\n",
    "                        out[str(k)] = float(v)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                return out\n",
    "\n",
    "            return {}\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "    # æœªçŸ¥å‹ã¯è§¦ã‚‰ãªã„ï¼ˆãŸã ã— precheck ãŒ if not stats ã‚’ã™ã‚‹ãªã‚‰ã€ã“ã“ã¯å±é™ºãªã®ã§ç©ºdictã¸ï¼‰\n",
    "    try:\n",
    "        # list/tuple ç­‰ã¯ç©ºãªã‚‰ {} ã«ã™ã‚‹ï¼ˆå®‰å…¨å´ï¼‰\n",
    "        if hasattr(stats_obj, \"__len__\") and len(stats_obj) == 0:  # type: ignore[arg-type]\n",
    "            return {}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # å®‰å…¨å´ï¼šæœªçŸ¥å‹ã¯ {} ã«å€’ã™ï¼ˆprecheck å®‰å®šå„ªå…ˆï¼‰\n",
    "    return {}\n",
    "\n",
    "external_data[\"phishing_tld_stats\"] = _normalize_tld_stats_to_dict(external_data.get(\"phishing_tld_stats\"))\n",
    "print(f\"[OK] phishing_tld_stats normalized type: {type(external_data['phishing_tld_stats'])}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Code fingerprintï¼ˆCell5 ã¨åŒã˜æ€æƒ³ã§ã€wiringçŠ¶æ…‹ã‚‚è¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰\n",
    "#    â€» Cell5 ã§æœªå®šç¾©ãªã‚‰ã“ã“ã§ä½œã‚‹ï¼ˆCell5å´ãŒå†åˆ©ç”¨ã§ãã‚‹ï¼‰\n",
    "# ------------------------------------------------------------\n",
    "def _sha256_of_file(path: str, chunk_size: int = 1024 * 1024) -> str:\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "                h.update(chunk)\n",
    "        return h.hexdigest()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR:{type(e).__name__}\"\n",
    "\n",
    "def _module_file_and_sha(modname: str):\n",
    "    try:\n",
    "        mod = importlib.import_module(modname)\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if f:\n",
    "            f = str(Path(f).resolve())\n",
    "            sha = _sha256_of_file(f)\n",
    "        else:\n",
    "            sha = None\n",
    "        return f, sha, mod\n",
    "    except Exception as e:\n",
    "        return None, f\"IMPORT_ERROR:{type(e).__name__}\", None\n",
    "\n",
    "def _make_code_fingerprint() -> dict:\n",
    "    import datetime as _dt\n",
    "    fp = {}\n",
    "    fp[\"eval_id\"] = _dt.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "    p6_file, p6_sha, _p6_mod = _module_file_and_sha(\"phishing_agent.phase6_wiring\")\n",
    "    ld_file, ld_sha, ld_mod = _module_file_and_sha(\"phishing_agent.llm_final_decision\")\n",
    "    lg_file, lg_sha, _lg_mod = _module_file_and_sha(\"phishing_agent.langgraph_module\")\n",
    "\n",
    "    fp[\"phase6_wiring_file\"] = p6_file\n",
    "    fp[\"phase6_wiring_sha256\"] = p6_sha\n",
    "    fp[\"llm_final_decision_file\"] = ld_file\n",
    "    fp[\"llm_final_decision_sha256\"] = ld_sha\n",
    "    fp[\"langgraph_module_file\"] = lg_file\n",
    "    fp[\"langgraph_module_sha256\"] = lg_sha\n",
    "\n",
    "    fp[\"phase6_policy_version_code\"] = getattr(ld_mod, \"PHASE6_POLICY_VERSION\", None) if ld_mod else None\n",
    "    fp[\"python\"] = sys.version.split()[0]\n",
    "    fp[\"dual_import_langgraph_module\"] = (\"langgraph_module\" in sys.modules) and (\"phishing_agent.langgraph_module\" in sys.modules)\n",
    "\n",
    "    return fp\n",
    "\n",
    "if \"CODE_FINGERPRINT\" not in globals():\n",
    "    CODE_FINGERPRINT = _make_code_fingerprint()\n",
    "    CODE_FP_ROW = {\n",
    "        \"eval_id\": CODE_FINGERPRINT.get(\"eval_id\"),\n",
    "        \"phase6_policy_version_code\": CODE_FINGERPRINT.get(\"phase6_policy_version_code\"),\n",
    "        \"phase6_wiring_file\": CODE_FINGERPRINT.get(\"phase6_wiring_file\"),\n",
    "        \"phase6_wiring_sha256\": CODE_FINGERPRINT.get(\"phase6_wiring_sha256\"),\n",
    "        \"llm_final_decision_file\": CODE_FINGERPRINT.get(\"llm_final_decision_file\"),\n",
    "        \"llm_final_decision_sha256\": CODE_FINGERPRINT.get(\"llm_final_decision_sha256\"),\n",
    "        \"langgraph_module_file\": CODE_FINGERPRINT.get(\"langgraph_module_file\"),\n",
    "        \"langgraph_module_sha256\": CODE_FINGERPRINT.get(\"langgraph_module_sha256\"),\n",
    "        \"dual_import_langgraph_module\": CODE_FINGERPRINT.get(\"dual_import_langgraph_module\"),\n",
    "    }\n",
    "    print(\"[INFO] code_fingerprint:\", CODE_FP_ROW)\n",
    "else:\n",
    "    CODE_FP_ROW = globals().get(\"CODE_FP_ROW\", {})\n",
    "\n",
    "if CODE_FINGERPRINT.get(\"dual_import_langgraph_module\"):\n",
    "    print(\"[WARNING] dual import detected: 'langgraph_module' and 'phishing_agent.langgraph_module' both in sys.modules\")\n",
    "    print(\"          â†’ wiring ãŒåˆ¥åå´ã«å½“ãŸã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆè¦æ³¨æ„ï¼‰\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) é™çš„ãƒã‚§ãƒƒã‚¯ï¼šPhase6 wiring ãŒ class ã«å½“ãŸã£ã¦ã„ã‚‹ã‹\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    import phishing_agent.phase6_wiring as _p6w\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"[ERROR] cannot import phishing_agent.phase6_wiring: {e}\") from e\n",
    "\n",
    "fn = getattr(agent.__class__, \"_final_decision_node\", None)\n",
    "fn_name = getattr(fn, \"__name__\", None)\n",
    "fn_mod  = getattr(fn, \"__module__\", None)\n",
    "\n",
    "is_patched_static = (fn_name == \"_patched_final_decision_node\") and (fn_mod is not None and \"phase6_wiring\" in fn_mod)\n",
    "print(f\"[INFO] final_decision_node: name={fn_name}, module={fn_mod}\")\n",
    "print(f\"[INFO] Phase6 wiring (static) : {'OK' if is_patched_static else 'NG'}\")\n",
    "\n",
    "if not is_patched_static:\n",
    "    raise RuntimeError(\n",
    "        \"Preflight failed: Phase6 wiring ãŒ class ã«å½“ãŸã£ã¦ã„ã¾ã›ã‚“ã€‚\\n\"\n",
    "        \"  - wire_phase6() ãŒ agent åˆæœŸåŒ–ã‚ˆã‚Šå‰ã«å‘¼ã°ã‚Œã¦ã„ã‚‹ã‹\\n\"\n",
    "        \"  - import åã®å–ã‚Šé•ãˆï¼ˆdual importï¼‰ã§åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å½“ãŸã£ã¦ã„ãªã„ã‹\\n\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) å®Ÿè¡Œæ™‚ãƒã‚§ãƒƒã‚¯ï¼šPhase6 ãƒãƒ¼ãƒ‰ãŒå®Ÿéš›ã«è¸ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼ˆ1ä»¶ã ã‘ï¼‰\n",
    "#    - Cell5 ã¨åŒæ§˜ã« debug_llm_final / decision_trace ã‚’è¦‹ã‚‹\n",
    "# ------------------------------------------------------------\n",
    "STRICT_PHASE6_PREFLIGHT = str(os.getenv(\"STRICT_PHASE6_PREFLIGHT\", \"\")).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆå¯¾è±¡ï¼štarget_df å…ˆé ­ã‚’å„ªå…ˆï¼ˆCell5ã¨åŒã˜çµŒè·¯ã‚’è¸ã¿ã‚„ã™ã„ï¼‰\n",
    "test_domain = \"test-amazon.com\"\n",
    "test_ml = 0.35\n",
    "try:\n",
    "    if \"target_df\" in globals() and len(target_df) > 0:\n",
    "        test_domain = str(target_df.iloc[0][\"domain\"])\n",
    "        test_ml = float(target_df.iloc[0][\"ml_probability\"])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"[INFO] Quick run domain={test_domain}, ml={test_ml}\")\n",
    "\n",
    "t0 = time.time()\n",
    "result = agent.evaluate(test_domain, test_ml)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"  Time              : {elapsed:.2f}s\")\n",
    "print(f\"  success           : {result.get('success')}\")\n",
    "print(f\"  ai_is_phishing    : {result.get('ai_is_phishing')}\")\n",
    "print(f\"  ai_confidence     : {result.get('ai_confidence')}\")\n",
    "print(f\"  ai_risk_level     : {result.get('ai_risk_level')}\")\n",
    "\n",
    "if not result.get(\"success\"):\n",
    "    err = result.get(\"error\")\n",
    "    tb = result.get(\"traceback\")\n",
    "    print(\"  âŒ error:\", err)\n",
    "    if tb:\n",
    "        print(\"  âŒ traceback(head):\", str(tb)[:800])\n",
    "    raise RuntimeError(\"Preflight failed: agent.evaluate ãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆä¸Šã® error/traceback ã‚’ç¢ºèªï¼‰ã€‚\")\n",
    "\n",
    "graph_state = result.get(\"graph_state\") or {}\n",
    "dbg_final = graph_state.get(\"debug_llm_final\") or {}\n",
    "dt_list = graph_state.get(\"decision_trace\") or []\n",
    "\n",
    "# Cell5 ã¨åŒæ§˜ã® phase6 version æ¨å®š\n",
    "phase6_ver = None\n",
    "try:\n",
    "    if isinstance(graph_state, dict):\n",
    "        phase6_ver = graph_state.get(\"phase6_policy_version\")\n",
    "    if not phase6_ver and isinstance(dt_list, list) and dt_list:\n",
    "        last = dt_list[-1] if isinstance(dt_list[-1], dict) else {}\n",
    "        if isinstance(last, dict):\n",
    "            phase6_ver = last.get(\"phase6_version\") or last.get(\"phase6_policy_version\") or last.get(\"phase6_ver\")\n",
    "except Exception:\n",
    "    phase6_ver = None\n",
    "\n",
    "# debug_llm_final ä¸»è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆCell5ã® _log_final_decision ã«å¯„ã›ã‚‹ï¼‰\n",
    "if not isinstance(dbg_final, dict):\n",
    "    dbg_final = {}\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"  [FinalDecision debug]\")\n",
    "print(f\"    use_llm_decision      : {dbg_final.get('use_llm_decision')}\")\n",
    "print(f\"    llm_is_none           : {dbg_final.get('llm_is_none')}\")\n",
    "print(f\"    path                  : {dbg_final.get('path')}\")\n",
    "print(f\"    success               : {dbg_final.get('success')}\")\n",
    "if dbg_final.get(\"error\"):\n",
    "    print(f\"    error                 : {dbg_final.get('error')}\")\n",
    "print(f\"    phase6_version(derived): {phase6_ver}\")\n",
    "\n",
    "# å®Ÿè¡Œæ™‚ã« Phase6 ãƒãƒ¼ãƒ‰ãŒè¸ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã®åˆ¤å®šï¼š\n",
    "# - phase6_wiring ã® patched node ã¯ debug_llm_final ã« use_llm_decision/llm_is_none/path ã‚’å…¥ã‚Œã‚‹\n",
    "ran_phase6_node = all(k in dbg_final for k in (\"use_llm_decision\", \"llm_is_none\", \"path\"))\n",
    "print(f\"[INFO] Phase6 node executed(runtime): {'YES' if ran_phase6_node else 'NO'}\")\n",
    "\n",
    "if not ran_phase6_node:\n",
    "    raise RuntimeError(\n",
    "        \"Preflight failed: Phase6 wiring ã¯ class ã«å½“ãŸã£ã¦ã„ã‚‹ãŒã€å®Ÿè¡Œæ™‚ state ã« Phase6 ãƒãƒ¼ãƒ‰ã®ç—•è·¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\\n\"\n",
    "        \"  - graph ãŒ wiring å‰ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§\\n\"\n",
    "        \"  - import/ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å–ã‚Šé•ãˆã®å¯èƒ½æ€§\\n\"\n",
    "    )\n",
    "\n",
    "# STRICT ãƒ¢ãƒ¼ãƒ‰ï¼šPhase6 ã® LLM çµŒè·¯ã§ version ãŒå–ã‚Œã‚‹ã“ã¨ã¾ã§è¦æ±‚\n",
    "# ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è­¦å‘Šã«ç•™ã‚ã‚‹ï¼šso_fallback ã§ã‚‚è©•ä¾¡ã¯ç¶™ç¶šã§ãã‚‹è¨­è¨ˆã®ãŸã‚ï¼‰\n",
    "if STRICT_PHASE6_PREFLIGHT:\n",
    "    if dbg_final.get(\"path\") != \"llm\" or dbg_final.get(\"success\") is not True:\n",
    "        raise RuntimeError(\n",
    "            \"Preflight failed (STRICT_PHASE6_PREFLIGHT=1): Phase6 LLM path ãŒæˆåŠŸã—ã¦ã„ã¾ã›ã‚“ã€‚\\n\"\n",
    "            f\"  path={dbg_final.get('path')}, success={dbg_final.get('success')}, error={dbg_final.get('error')}\\n\"\n",
    "        )\n",
    "    if not phase6_ver:\n",
    "        raise RuntimeError(\n",
    "            \"Preflight failed (STRICT_PHASE6_PREFLIGHT=1): phase6_version ãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚\\n\"\n",
    "            \"  ï¼ˆllm_final_decision ãŒ state ã« version ã‚’æ›¸ã‘ã¦ã„ãªã„å¯èƒ½æ€§ï¼‰\"\n",
    "        )\n",
    "else:\n",
    "    # éSTRICTï¼šversion ãŒç„¡ã„å ´åˆã¯è­¦å‘Šï¼ˆso_fallback ç­‰ã§ã¯èµ·ã“ã‚Šå¾—ã‚‹ï¼‰\n",
    "    if not phase6_ver:\n",
    "        print(\"[WARNING] phase6_version could not be derived (may be OK if so_fallback occurred).\")\n",
    "        print(\"          If you want to enforce Phase6 LLM success, set env STRICT_PHASE6_PREFLIGHT=1\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ… Preflight PASSED. Proceed to Cell 5 (big evaluation loop).\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df24f810-779a-4f5e-9f76-2cff549f577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting FULL AGENT evaluation of 10 domains (N_SAMPLE=10)...\n",
      "================================================================================\n",
      "[INFO] LLM initialized: JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8\n",
      "[INFO] Console output mode: VERBOSE (PROGRESS_EVERY=1, clear_output=False)\n",
      "--------------------------------------------------------------------------------\n",
      "[  1/10] ğŸ”´ upsixdc.com                         (ML: 0.087 / Time: 7.33s)\n",
      "ğŸ” Domain: upsixdc.com (ml_probability=0.087)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.087 (category=very_low)\n",
      "    tld_category        : legitimate  quick_risk=0.05\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : False\n",
      "    llm_confidence       : None\n",
      "    llm_reasoning (head) : None\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : CLOUDFLARE, INC.\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : upsixdc\n",
      "    domain_length         : 7 (category=normal)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 2.81\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.49\n",
      "    detected_issues       : ['ml_paradox', 'multiple_risk_factors', 'low_ml_safety_cap']\n",
      "    ml_probability        : 0.086926974 (category=very_low)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'upsixdc.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': True, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain 'upsixdc.com' has a low ML probability (0.0869) and a contextual risk score of 0.49, which is below the 0.5 threshold for automatic phishing detectio\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.086926974 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.086926974\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  2/10] ğŸ”´ buteegch.mn                         (ML: 0.273 / Time: 3.89s)\n",
      "ğŸ” Domain: buteegch.mn (ml_probability=0.273)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.273 (category=low)\n",
      "    tld_category        : unknown  quick_risk=0.046\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.2734\n",
      "    llm_reasoning (head) : The domain 'buteegch.mn' does not contain any known brand keywords from the provided list. The domain labels 'buteegch' and 'mn' do not match any brand names in the sample list. The ML probability is low (0.2734), indicating low confidence in impersonation.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.04640082484329303\n",
      "    detected_issues       : []\n",
      "    base_domain           : buteegch\n",
      "    domain_length         : 8 (category=normal)\n",
      "    tld / tld_category    : mn / unknown\n",
      "    entropy               : 2.75\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.47208009623171754\n",
      "    detected_issues       : ['ml_paradox_medium', 'multiple_risk_factors']\n",
      "    ml_probability        : 0.27340078 (category=low)\n",
      "    tool_average_risk     : 0.15\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'buteegch.mn', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': False, 'is_paradox_weak': True}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain 'buteegch.mn' has a low ML probability (0.27) and a contextual risk score of 0.47, which is below the 0.5 threshold for automatic phishing detection.\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.04640082484329303 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.04640082484329303 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.04640082484329303 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.27340078 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.04640082484329303 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.27340078\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  3/10] ğŸ”´ westpac-security-verify.com         (ML: 0.064 / Time: 4.41s)\n",
      "ğŸ” Domain: westpac-security-verify.com (ml_probability=0.064)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.064 (category=very_low)\n",
      "    tld_category        : legitimate  quick_risk=0.05\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.0\n",
      "    llm_reasoning (head) : The domain 'westpac-security-verify.com' contains 'westpac' which is a legitimate brand (Westpac Bank), but the domain includes 'security-verify' which is a common suffix for verification services. Since the domain is a legitimate service for Westpac's security verification, it does not constitute brand impersonation. \n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : True\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : westpac-security-verify\n",
      "    domain_length         : 23 (category=long)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 3.71\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.49\n",
      "    detected_issues       : ['ml_paradox', 'multiple_risk_factors', 'low_ml_safety_cap']\n",
      "    ml_probability        : 0.06402593 (category=very_low)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'westpac-security-verify.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': True, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain 'westpac-security-verify.com' has a low ML probability (0.064) and a contextual risk score of 0.49, which is below the 0.5 threshold for automatic ph\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.06402593 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.06402593\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  4/10] ğŸ”´ 42kmm.com                           (ML: 0.413 / Time: 3.97s)\n",
      "ğŸ” Domain: 42kmm.com (ml_probability=0.413)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.413 (category=medium)\n",
      "    tld_category        : legitimate  quick_risk=0.15\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.413151\n",
      "    llm_reasoning (head) : The domain '42kmm.com' does not contain any known brand keywords from the provided list. The domain name is unique and does not match any brand patterns or common typosquatting patterns.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Sectigo Limited\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.30000000000000004\n",
      "    detected_issues       : ['short', 'random_pattern']\n",
      "    base_domain           : 42kmm\n",
      "    domain_length         : 5 (category=short)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 1.92\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.42\n",
      "    detected_issues       : ['multiple_risk_factors', 'dv_suspicious_combo']\n",
      "    ml_probability        : 0.41315198 (category=medium)\n",
      "    tool_average_risk     : 0.23\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': '42kmm.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': False, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=medium-high, conf=0.65)\n",
      "    final_reasoning(head) : The domain 42kmm.com has a short length (5 characters) and a random pattern with low vowel ratio (0.0) and high entropy (1.92), which are indicators of potentia\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.30000000000000004 issues=['short', 'random_pattern']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.30000000000000004 issues=['short', 'random_pattern']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.30000000000000004 issues=['short', 'random_pattern']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.41315198 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.30000000000000004 issues=['short', 'random_pattern']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.41315198\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  5/10] ğŸ”´ bdowefindway-ph.com                 (ML: 0.361 / Time: 3.91s)\n",
      "ğŸ” Domain: bdowefindway-ph.com (ml_probability=0.361)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.361 (category=low)\n",
      "    tld_category        : legitimate  quick_risk=0.0\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.360521\n",
      "    llm_reasoning (head) : The domain 'bdowefindway-ph.com' does not contain any known brand keywords from the provided list. The domain appears to be a random string with 'ph' (possibly indicating Philippines) and no clear brand imitation patterns.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : True\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : bdowefindway-ph\n",
      "    domain_length         : 15 (category=long)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 3.64\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.3589013641666667\n",
      "    detected_issues       : ['multiple_risk_factors']\n",
      "    ml_probability        : 0.36052155 (category=medium)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'bdowefindway-ph.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': False, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain bdowefindway-ph.com has a legitimate TLD (com) and a low ML probability (0.36) which is below the threshold for automatic phishing detection. The con\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.36052155 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.36052155\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  6/10] ğŸ”´ allmendoit.com                      (ML: 0.107 / Time: 3.82s)\n",
      "ğŸ” Domain: allmendoit.com (ml_probability=0.107)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.107 (category=very_low)\n",
      "    tld_category        : legitimate  quick_risk=0.05\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.106596\n",
      "    llm_reasoning (head) : The domain 'allmendoit.com' does not contain any known brand keywords from the provided list. The domain name is unique and does not match any brand names or their common variations. The ML probability is low (0.106), indicating low likelihood of impersonation.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 4\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : allmendoit\n",
      "    domain_length         : 10 (category=normal)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 3.12\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.5566666666666668\n",
      "    detected_issues       : ['ml_paradox', 'multiple_risk_factors']\n",
      "    ml_probability        : 0.10659688 (category=very_low)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'allmendoit.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': True, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain 'allmendoit.com' has a contextual_risk_assessment.risk_score of 0.5567, which is above 0.5 but the ML probability is low (0.1066) and the domain is l\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.10659688 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.10659688\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  7/10] ğŸ”´ freedomappapkdownload.com           (ML: 0.111 / Time: 4.14s)\n",
      "ğŸ” Domain: freedomappapkdownload.com (ml_probability=0.111)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.111 (category=very_low)\n",
      "    tld_category        : legitimate  quick_risk=0.05\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.111065\n",
      "    llm_reasoning (head) : The domain 'freedomappapkdownload.com' contains no exact substring matching any brand keywords from the provided list. The domain name is a generic string with 'app' and 'download' which are common in phishing domains but not indicative of specific brand impersonation.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : freedomappapkdownload\n",
      "    domain_length         : 21 (category=long)\n",
      "    tld / tld_category    : com / legitimate\n",
      "    entropy               : 3.39\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.5566666666666668\n",
      "    detected_issues       : ['ml_paradox', 'multiple_risk_factors']\n",
      "    ml_probability        : 0.11106553 (category=very_low)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'freedomappapkdownload.com', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': True, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain 'freedomappapkdownload.com' has a contextual_risk_assessment.risk_score of 0.5567, which is above the 0.5 threshold but the ML probability is low (0.\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.11106553 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.11106553\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  8/10] ğŸ”´ i5s.top                             (ML: 0.156 / Time: 7.48s)\n",
      "ğŸ” Domain: i5s.top (ml_probability=0.156)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.156 (category=very_low)\n",
      "    tld_category        : dangerous  quick_risk=0.849\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : False\n",
      "    llm_confidence       : None\n",
      "    llm_reasoning (head) : None\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Google Trust Services\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.7986936521545276\n",
      "    detected_issues       : ['very_short', 'dangerous_tld', 'very_short_dangerous_combo']\n",
      "    base_domain           : i5s\n",
      "    domain_length         : 3 (category=very_short)\n",
      "    tld / tld_category    : top / dangerous\n",
      "    entropy               : 1.58\n",
      "    combo_flags           : ['very_short_dangerous_combo']\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.6498475927513616\n",
      "    detected_issues       : ['ml_paradox', 'multiple_risk_factors', 'dv_suspicious_combo']\n",
      "    ml_probability        : 0.15602536 (category=very_low)\n",
      "    tool_average_risk     : 0.4\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'i5s.top', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 2, 'is_paradox_strong': True, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain i5s.top has a very short domain length (3 characters) and a dangerous TLD (.top), which are strong risk indicators. However, the contextual_risk_asse\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.7986936521545276 issues=['very_short', 'dangerous_tld', 'very_short_dangerous_combo']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.7986936521545276 issues=['very_short', 'dangerous_tld', 'very_short_dangerous_combo']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.7986936521545276 issues=['very_short', 'dangerous_tld', 'very_short_dangerous_combo']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.15602536 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.7986936521545276 issues=['very_short', 'dangerous_tld', 'very_short_dangerous_combo']\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.15602536\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[  9/10] ğŸ”´ eki.liuzhouxqasgq.co                (ML: 0.393 / Time: 7.64s)\n",
      "ğŸ” Domain: eki.liuzhouxqasgq.co (ml_probability=0.393)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.393 (category=low)\n",
      "    tld_category        : unknown  quick_risk=0.177\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : False\n",
      "    llm_confidence       : None\n",
      "    llm_reasoning (head) : None\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 1\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : False\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.17678563146622409\n",
      "    detected_issues       : []\n",
      "    base_domain           : liuzhouxqasgq\n",
      "    domain_length         : 13 (category=long)\n",
      "    tld / tld_category    : co / unknown\n",
      "    entropy               : 3.39\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.3943280605043928\n",
      "    detected_issues       : ['multiple_risk_factors']\n",
      "    ml_probability        : 0.39341423 (category=medium)\n",
      "    tool_average_risk     : 0.19\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': False, 'is_known_legit': False, 'label': None, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'liuzhouxqasgq.co', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': False, 'is_paradox_weak': False}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=medium-high, conf=0.65)\n",
      "    final_reasoning(head) : The domain 'eki.liuzhouxqasgq.co' has a low ML probability (0.393) and a contextual risk score of 0.394, both below 0.5. The domain is long (13 characters) with\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.17678563146622409 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.17678563146622409 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.17678563146622409 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.39341423 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.17678563146622409 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.39341423\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "--------------------------------------------------------------------------------\n",
      "[ 10/10] ğŸ”´ camarasciervo.com.mx                (ML: 0.229 / Time: 3.69s)\n",
      "ğŸ” Domain: camarasciervo.com.mx (ml_probability=0.229)\n",
      "  [ToolSelection]\n",
      "    ml_probability      : 0.229 (category=low)\n",
      "    tld_category        : unknown  quick_risk=0.0\n",
      "    selected_tools      : ['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    tool_execution_flags: {}\n",
      "    llm_used_selection  : True\n",
      "    selection_strategy  : llm_structured_output\n",
      "  [BrandTool]\n",
      "    risk_score           : 0.0\n",
      "    detected_issues      : []\n",
      "    detected_brands      : []\n",
      "    used_llm             : True\n",
      "    llm_confidence       : 0.229165\n",
      "    llm_reasoning (head) : The domain 'camarasciervo.com.mx' does not contain any known brand keywords from the provided list. The domain name is unique and does not match any brand patterns or common impersonation tactics.\n",
      "    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\n",
      "  [CertTool]\n",
      "    risk_score      : 0.4\n",
      "    detected_issues : ['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    issuer          : Let's Encrypt\n",
      "    is_free_ca      : True\n",
      "    has_org         : False\n",
      "    valid_days      : 0\n",
      "    is_short_term   : False\n",
      "    san_count       : 2\n",
      "    is_self_signed  : False\n",
      "    is_wildcard     : True\n",
      "  [DomainTool]\n",
      "    risk_score            : 0.0\n",
      "    detected_issues       : []\n",
      "    base_domain           : camarasciervo\n",
      "    domain_length         : 13 (category=long)\n",
      "    tld / tld_category    : com.mx / unknown\n",
      "    entropy               : 3.03\n",
      "    combo_flags           : []\n",
      "    legitimate_check      : is_legit=False, brand=None, conf=0.0\n",
      "  [Contextual]\n",
      "    risk_score            : 0.4666666666666667\n",
      "    detected_issues       : ['ml_paradox_medium', 'multiple_risk_factors']\n",
      "    ml_probability        : 0.2291658 (category=low)\n",
      "    tool_average_risk     : 0.13\n",
      "    high_risk_hits        : 0\n",
      "    known_domain          : {'is_known_seen': True, 'is_known_legit': False, 'label': True, 'mitigation': 0.0, 'legit_info': {'is_legitimate': False, 'brand': None, 'confidence': 0.0, 'reason': 'not_in_whitelist', 'normalized_domain': 'com.mx', 'trust_level': 'none'}}\n",
      "    paradox_info          : {'risk_signal_count': 1, 'is_paradox_strong': False, 'is_paradox_weak': True}\n",
      "  [FinalDecision]\n",
      "    use_llm_decision      : True\n",
      "    llm_is_none           : False\n",
      "    path                  : llm\n",
      "    success               : True\n",
      "    ai_is_phishing        : True (risk_level=high, conf=0.75)\n",
      "    final_reasoning(head) : The domain camarasciervo.com.mx has a low ML probability (0.229) and a contextual risk score of 0.467, which is below the 0.5 threshold for automatic phishing d\n",
      "  [GraphMessages] (tool_selection / tool_execution / final_decision only)\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_selection] start ml=0.2291658 use_llm_selection=True so_available=True\n",
      "    [msg] [tool_selection] LLM selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] start selected_tools=['brand_impersonation_check', 'certificate_analysis', 'short_domain_analysis']\n",
      "    [msg] [tool_execution] brand risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] cert risk=0.4 issues=['free_ca', 'no_org', 'wildcard', 'free_ca_no_org']\n",
      "    [msg] [tool_execution] domain risk=0.0 issues=[]\n",
      "    [msg] [tool_execution] done tools=['brand', 'cert', 'domain']\n",
      "    [msg] [final_decision] LLM path ml=0.2291658\n",
      "    [msg] [final_decision] LLM done success=True (Phase6, strict)\n",
      "================================================================================\n",
      "[INFO] Full evaluation complete! Total time: 50.30s\n",
      "[INFO] Results saved to: /home/asomura/backup/nextstep/random10_full_eval__evalid_2025-12-21_131443__ts_2025-12-21_131541.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 5: ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡å®Ÿè¡Œï¼ˆä»¶æ•°=len(target_df), è¶…è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ç‰ˆï¼‰\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io, sys, json, os\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "print(f\"[INFO] Starting FULL AGENT evaluation of {len(target_df)} domains (N_SAMPLE={N_SAMPLE})...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# LLMè¨­å®šã®ç¢ºèª\n",
    "if 'agent' in globals() and hasattr(agent, 'llm_config'):\n",
    "    llm_config = agent.llm_config\n",
    "    if getattr(llm_config, \"enabled\", False):\n",
    "        print(f\"[INFO] LLM initialized: {llm_config.model}\")\n",
    "    else:\n",
    "        print(\"[WARNING] LLM is disabled - results may be limited\")\n",
    "else:\n",
    "    print(\"[WARNING] Agent not properly initialized\")\n",
    "\n",
    "# --- Code fingerprint (reproducibility / verification) ------------------------\n",
    "# [ChangeLog] 2025-12-17: Add code fingerprint (module __file__ + sha256) to each output row.\n",
    "import hashlib\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import datetime as _dt\n",
    "\n",
    "def _sha256_of_file(path: str, chunk_size: int = 1024 * 1024) -> str:\n",
    "    \"\"\"Return sha256 hex digest for a local file. Never raises.\"\"\"\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "                h.update(chunk)\n",
    "        return h.hexdigest()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR:{type(e).__name__}\"\n",
    "\n",
    "def _module_file_and_sha(modname: str):\n",
    "    \"\"\"Import module and return (file_path, sha256, module_obj).\"\"\"\n",
    "    try:\n",
    "        mod = importlib.import_module(modname)\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if f:\n",
    "            f = str(Path(f).resolve())\n",
    "            sha = _sha256_of_file(f)\n",
    "        else:\n",
    "            sha = None\n",
    "        return f, sha, mod\n",
    "    except Exception as e:\n",
    "        return None, f\"IMPORT_ERROR:{type(e).__name__}\", None\n",
    "\n",
    "def make_code_fingerprint() -> dict:\n",
    "    fp = {}\n",
    "    fp[\"eval_id\"] = _dt.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "    # Core modules used by final decision path\n",
    "    p6_file, p6_sha, _p6_mod = _module_file_and_sha(\"phishing_agent.phase6_wiring\")\n",
    "    ld_file, ld_sha, ld_mod = _module_file_and_sha(\"phishing_agent.llm_final_decision\")\n",
    "    lg_file, lg_sha, _lg_mod = _module_file_and_sha(\"phishing_agent.langgraph_module\")\n",
    "\n",
    "    fp[\"phase6_wiring_file\"] = p6_file\n",
    "    fp[\"phase6_wiring_sha256\"] = p6_sha\n",
    "    fp[\"llm_final_decision_file\"] = ld_file\n",
    "    fp[\"llm_final_decision_sha256\"] = ld_sha\n",
    "    fp[\"langgraph_module_file\"] = lg_file\n",
    "    fp[\"langgraph_module_sha256\"] = lg_sha\n",
    "\n",
    "    fp[\"phase6_policy_version_code\"] = getattr(ld_mod, \"PHASE6_POLICY_VERSION\", None) if ld_mod else None\n",
    "    fp[\"python\"] = sys.version.split()[0]\n",
    "    fp[\"dual_import_langgraph_module\"] = (\"langgraph_module\" in sys.modules) and (\"phishing_agent.langgraph_module\" in sys.modules)\n",
    "\n",
    "    return fp\n",
    "\n",
    "# Compute once per notebook run (avoid per-domain overhead)\n",
    "if \"CODE_FINGERPRINT\" not in globals():\n",
    "    CODE_FINGERPRINT = make_code_fingerprint()\n",
    "    CODE_FP_ROW = {\n",
    "        \"eval_id\": CODE_FINGERPRINT.get(\"eval_id\"),\n",
    "        \"phase6_policy_version_code\": CODE_FINGERPRINT.get(\"phase6_policy_version_code\"),\n",
    "        \"phase6_wiring_file\": CODE_FINGERPRINT.get(\"phase6_wiring_file\"),\n",
    "        \"phase6_wiring_sha256\": CODE_FINGERPRINT.get(\"phase6_wiring_sha256\"),\n",
    "        \"llm_final_decision_file\": CODE_FINGERPRINT.get(\"llm_final_decision_file\"),\n",
    "        \"llm_final_decision_sha256\": CODE_FINGERPRINT.get(\"llm_final_decision_sha256\"),\n",
    "        \"langgraph_module_file\": CODE_FINGERPRINT.get(\"langgraph_module_file\"),\n",
    "        \"langgraph_module_sha256\": CODE_FINGERPRINT.get(\"langgraph_module_sha256\"),\n",
    "        \"dual_import_langgraph_module\": CODE_FINGERPRINT.get(\"dual_import_langgraph_module\"),\n",
    "    }\n",
    "    print(\"[INFO] code_fingerprint:\", CODE_FP_ROW)\n",
    "else:\n",
    "    # Reuse existing in case notebook cells are re-run\n",
    "    CODE_FP_ROW = globals().get(\"CODE_FP_ROW\", {})\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "# --- Notebookç”»é¢å‡ºåŠ›ã®åˆ¶å¾¡ï¼ˆdebug_log ã®æƒ…å ±é‡ã¯ç¶­æŒï¼‰ -----------------\n",
    "# [ChangeLog] 2025-12-15: å¤§é‡ä»¶æ•°ã§ã‚‚Jupyterã®å‡ºåŠ›ãŒé‡ããªã‚‰ãªã„ã‚ˆã†ã€ç”»é¢å‡ºåŠ›ã‚’é–“å¼•ã\n",
    "TOTAL_N = len(target_df)\n",
    "\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å°‘æ•°ä»¶ã¯å¾“æ¥ã©ãŠã‚Šè©³ç´°è¡¨ç¤º / å¤šæ•°ä»¶ã¯ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆè¡¨ç¤º\n",
    "SHOW_DOMAIN_LOG_ON_SCREEN = (TOTAL_N <= 20)\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯: 1/true/yes/on ã§è©³ç´°è¡¨ç¤º\n",
    "_env = os.getenv(\"SHOW_DOMAIN_LOG_ON_SCREEN\")\n",
    "if _env is not None:\n",
    "    SHOW_DOMAIN_LOG_ON_SCREEN = str(_env).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# é€²æ—è¡¨ç¤ºã®æ›´æ–°é »åº¦ï¼ˆç”»é¢ã‚’è»½ãã™ã‚‹ãŸã‚ã€ä»¶æ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ï¼‰\n",
    "if TOTAL_N <= 30:\n",
    "    PROGRESS_EVERY = 1\n",
    "elif TOTAL_N <= 300:\n",
    "    PROGRESS_EVERY = 10\n",
    "elif TOTAL_N <= 3000:\n",
    "    PROGRESS_EVERY = 25\n",
    "else:\n",
    "    PROGRESS_EVERY = 50\n",
    "\n",
    "# Jupyterãªã‚‰ clear_output ã§è¡¨ç¤ºã‚’ç½®ãæ›ãˆï¼ˆãƒ­ã‚°ã¯CSVå´ã«æ®‹ã‚‹ï¼‰\n",
    "_USE_CLEAR_OUTPUT = (not SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "try:\n",
    "    from IPython.display import clear_output  # type: ignore\n",
    "    _HAS_CLEAR_OUTPUT = True\n",
    "except Exception:\n",
    "    _HAS_CLEAR_OUTPUT = False\n",
    "\n",
    "print(f\"[INFO] Console output mode: {'VERBOSE' if SHOW_DOMAIN_LOG_ON_SCREEN else 'COMPACT'} \"\n",
    "      f\"(PROGRESS_EVERY={PROGRESS_EVERY}, clear_output={_USE_CLEAR_OUTPUT and _HAS_CLEAR_OUTPUT})\")\n",
    "\n",
    "# é€²æ—ã‚«ã‚¦ãƒ³ã‚¿ï¼ˆç”»é¢è¡¨ç¤ºç”¨ï¼‰\n",
    "_screen_counts = {\"phish\": 0, \"benign\": 0, \"error\": 0}\n",
    "\n",
    "# --- è¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ ----------------------------------------------------\n",
    "def _fmt_issues(issues):\n",
    "    return \", \".join(issues) if issues else \"None\"\n",
    "\n",
    "def _safe_dict(d):\n",
    "    return d if isinstance(d, dict) else {}\n",
    "\n",
    "def _log_tool_selection(graph_state, ml_probability):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    pre = _safe_dict(gs.get(\"precheck_hints\"))\n",
    "    ml_cat   = pre.get(\"ml_category\", \"-\")\n",
    "    tld_cat  = pre.get(\"tld_category\", \"-\")\n",
    "    quick_risk = pre.get(\"quick_risk\", \"-\")\n",
    "    known_info = _safe_dict(pre.get(\"known_domain_info\"))\n",
    "    known_label = known_info.get(\"label\") or known_info.get(\"kind\") or known_info.get(\"brand\")\n",
    "\n",
    "    selected_tools = gs.get(\"selected_tools\", [])\n",
    "    flags = _safe_dict(gs.get(\"tool_execution_flags\"))\n",
    "    llm_used = gs.get(\"llm_used_selection\")\n",
    "    llm_err  = gs.get(\"llm_selection_error\")\n",
    "\n",
    "    print(\"  [ToolSelection]\")\n",
    "    print(f\"    ml_probability      : {ml_probability:.3f} (category={ml_cat})\")\n",
    "    print(f\"    tld_category        : {tld_cat}  quick_risk={quick_risk}\")\n",
    "    if known_label:\n",
    "        print(f\"    known_domain_info   : {known_label}\")\n",
    "    print(f\"    selected_tools      : {selected_tools}\")\n",
    "    print(f\"    tool_execution_flags: {flags}\")\n",
    "    print(f\"    llm_used_selection  : {llm_used}\")\n",
    "    if llm_err:\n",
    "        print(f\"    llm_selection_error : {llm_err}\")\n",
    "\n",
    "    if llm_used:\n",
    "        strategy = \"llm_structured_output\"\n",
    "    else:\n",
    "        strategy = \"ml_bucket_fallback\"\n",
    "    print(f\"    selection_strategy  : {strategy}\")\n",
    "\n",
    "    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã¯ã€ã©ã®ãƒã‚±ãƒƒãƒˆãƒãƒªã‚·ãƒ¼ã«ãªã£ãŸã‹ã‚‚è¡¨ç¤º\n",
    "    if not llm_used:\n",
    "        if ml_probability < 0.2:\n",
    "            policy = \"ML<0.2 â†’ brand+cert+domain (3 tools)\"\n",
    "        elif ml_probability < 0.5:\n",
    "            policy = \"0.2â‰¦ML<0.5 â†’ brand+cert+domain (3 tools)\"\n",
    "        else:\n",
    "            policy = \"MLâ‰§0.5 â†’ brand+cert (2 tools)\"\n",
    "        print(f\"    selection_policy    : {policy}\")\n",
    "\n",
    "def _log_brand_tool(brand_res):\n",
    "    br = _safe_dict(brand_res)\n",
    "    if not br:\n",
    "        print(\"  [BrandTool] not executed\")\n",
    "        return\n",
    "\n",
    "    details = _safe_dict(br.get(\"details\"))\n",
    "    issues  = br.get(\"detected_issues\") or []\n",
    "    # â€» brand_impersonation_check ã®æ§‹é€ ã«åˆã‚ã›ã¦ details å´ã‚’å„ªå…ˆ\n",
    "    brands  = details.get(\"detected_brands\") or br.get(\"detected_brands\") or []\n",
    "    used_llm    = details.get(\"used_llm\")\n",
    "    llm_conf    = details.get(\"llm_confidence\")\n",
    "    llm_reason  = details.get(\"llm_reasoning\")\n",
    "    #llm_reason  = (details.get(\"llm_reasoning\") or \"\")[:160]\n",
    "\n",
    "    print(\"  [BrandTool]\")\n",
    "    if br.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback           : True (brand tool exception or disabled)\")\n",
    "    print(f\"    risk_score           : {br.get('risk_score')}\")\n",
    "    print(f\"    detected_issues      : {issues}\")\n",
    "    print(f\"    detected_brands      : {brands}\")\n",
    "    print(f\"    used_llm             : {used_llm}\")\n",
    "    print(f\"    llm_confidence       : {llm_conf}\")\n",
    "    print(f\"    llm_reasoning (head) : {llm_reason}\")\n",
    "    if used_llm:\n",
    "        print(\"    âœ… LLM ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (used_llm=True)\")\n",
    "    if brands:\n",
    "        print(f\"    âœ… ãƒ–ãƒ©ãƒ³ãƒ‰æ¤œå‡ºãŒã‚ã‚Šã¾ã™: {brands}\")\n",
    "\n",
    "def _log_cert_tool(cert_res):\n",
    "    cr = _safe_dict(cert_res)\n",
    "    if not cr:\n",
    "        print(\"  [CertTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cr.get(\"details\"))\n",
    "    print(\"  [CertTool]\")\n",
    "    if cr.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback      : True (cert tool exception or disabled)\")\n",
    "    print(f\"    risk_score      : {cr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues : {cr.get('detected_issues') or []}\")\n",
    "    print(f\"    issuer          : {details.get('issuer')}\")\n",
    "    print(f\"    is_free_ca      : {details.get('is_free_ca')}\")\n",
    "    print(f\"    has_org         : {details.get('has_org')}\")\n",
    "    print(f\"    valid_days      : {details.get('valid_days')}\")\n",
    "    print(f\"    is_short_term   : {details.get('is_short_term')}\")\n",
    "    print(f\"    san_count       : {details.get('san_count')}\")\n",
    "    print(f\"    is_self_signed  : {details.get('is_self_signed')}\")\n",
    "    print(f\"    is_wildcard     : {details.get('is_wildcard')}\")\n",
    "\n",
    "def _log_domain_tool(domain_res):\n",
    "    dr = _safe_dict(domain_res)\n",
    "    if not dr:\n",
    "        print(\"  [DomainTool] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(dr.get(\"details\"))\n",
    "    print(\"  [DomainTool]\")\n",
    "    if dr.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback            : True (domain tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {dr.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {dr.get('detected_issues') or []}\")\n",
    "    print(f\"    base_domain           : {details.get('base_domain')}\")\n",
    "    print(f\"    domain_length         : {details.get('domain_length')}\"\n",
    "          f\" (category={details.get('domain_length_category')})\")\n",
    "    print(f\"    tld / tld_category    : {details.get('tld')} / {details.get('tld_category')}\")\n",
    "    print(f\"    entropy               : {details.get('entropy')}\")\n",
    "    print(f\"    combo_flags           : {details.get('combo_flags')}\")\n",
    "    legit = _safe_dict(details.get('legitimate_check'))\n",
    "    if legit:\n",
    "        print(f\"    legitimate_check      : is_legit={legit.get('is_legitimate')}\"\n",
    "              f\", brand={legit.get('brand')}, conf={legit.get('confidence')}\")\n",
    "\n",
    "def _log_contextual_tool(ctx_res):\n",
    "    cx = _safe_dict(ctx_res)\n",
    "    if not cx:\n",
    "        print(\"  [Contextual] not executed\")\n",
    "        return\n",
    "    details = _safe_dict(cx.get(\"details\"))\n",
    "    print(\"  [Contextual]\")\n",
    "    if cx.get(\"_fallback\"):\n",
    "        print(\"    âš  fallback            : True (contextual tool exception or disabled)\")\n",
    "    print(f\"    risk_score            : {cx.get('risk_score')}\")\n",
    "    print(f\"    detected_issues       : {cx.get('detected_issues') or []}\")\n",
    "    print(f\"    ml_probability        : {details.get('ml_probability')}\"\n",
    "          f\" (category={details.get('ml_category')})\")\n",
    "    print(f\"    tool_average_risk     : {details.get('tool_average_risk')}\")\n",
    "    print(f\"    high_risk_hits        : {details.get('high_risk_hits')}\")\n",
    "    known = _safe_dict(details.get('known_domain'))\n",
    "    if known:\n",
    "        print(f\"    known_domain          : {known}\")\n",
    "    paradox = _safe_dict(details.get('paradox'))\n",
    "    if paradox:\n",
    "        print(f\"    paradox_info          : {paradox}\")\n",
    "\n",
    "def _log_final_decision(graph_state, result):\n",
    "    gs = _safe_dict(graph_state)\n",
    "    dbg = _safe_dict(gs.get(\"debug_llm_final\"))\n",
    "    dt_list = gs.get(\"decision_trace\") or []\n",
    "    print(\"  [FinalDecision]\")\n",
    "    print(f\"    use_llm_decision      : {dbg.get('use_llm_decision')}\")\n",
    "    print(f\"    llm_is_none           : {dbg.get('llm_is_none')}\")\n",
    "    print(f\"    path                  : {dbg.get('path')}\")\n",
    "    print(f\"    success               : {dbg.get('success')}\")\n",
    "    if dbg.get(\"error\"):\n",
    "        print(f\"    error                 : {dbg.get('error')}\")\n",
    "\n",
    "    if dt_list:\n",
    "        last = _safe_dict(dt_list[-1])\n",
    "        print(f\"    phase6_policy_version : {gs.get('phase6_policy_version', last.get('phase6_version'))}\")\n",
    "        print(f\"    ctx_risk_score        : {last.get('ctx_score')}\")\n",
    "        rules = [s.get(\"rule\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"rule\" in s]\n",
    "        notes = [s.get(\"note\") for s in last.get(\"policy_trace\", []) if isinstance(s, dict) and \"note\" in s]\n",
    "        if rules:\n",
    "            print(f\"    policy_rules          : {rules}\")\n",
    "        if notes:\n",
    "            print(f\"    policy_notes          : {notes}\")\n",
    "\n",
    "    print(f\"    ai_is_phishing        : {result.get('ai_is_phishing')} \"\n",
    "          f\"(risk_level={result.get('ai_risk_level')}, conf={result.get('ai_confidence'):.2f})\")\n",
    "    print(f\"    final_reasoning(head) : {(result.get('reasoning') or '')[:160]}\")\n",
    "\n",
    "def _log_graph_messages(graph_state, prefix=\"    \"):\n",
    "    \"\"\"LangGraph ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã€é‡è¦ãã†ãªã‚‚ã®ã ã‘æŠœç²‹è¡¨ç¤º\"\"\"\n",
    "    gs = _safe_dict(graph_state)\n",
    "    msgs = gs.get(\"messages\") or []\n",
    "    if not msgs:\n",
    "        return\n",
    "    print(\"  [GraphMessages] (tool_selection / tool_execution / final_decision only)\")\n",
    "    for m in msgs:\n",
    "        if isinstance(m, dict):\n",
    "            content = m.get(\"content\", \"\")\n",
    "            role = m.get(\"role\", \"msg\")\n",
    "        else:\n",
    "            content = getattr(m, \"content\", \"\")\n",
    "            role = getattr(m, \"role\", \"msg\")\n",
    "        if not isinstance(content, str):\n",
    "            content = str(content)\n",
    "        if any(tag in content for tag in [\"[tool_selection]\", \"[tool_execution]\", \"[final_decision]\"]):\n",
    "            print(f\"{prefix}[{role}] {content}\")\n",
    "\n",
    "\n",
    "# --- ãƒ­ã‚°ã‚’CSVã«æ®‹ã™ãŸã‚ã®æ¨™æº–å‡ºåŠ›/æ¨™æº–ã‚¨ãƒ©ãƒ¼ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆprint/loggingä¸¡å¯¾å¿œï¼‰ ---\n",
    "class _TeeIO:\n",
    "    def __init__(self, primary, buffer, *, enable_primary: bool = True):\n",
    "        self.primary = primary\n",
    "        self.buffer = buffer\n",
    "        self.enable_primary = bool(enable_primary)\n",
    "    def write(self, s):\n",
    "        if self.enable_primary:\n",
    "            self.primary.write(s)\n",
    "        self.buffer.write(s)\n",
    "        return len(s)\n",
    "    def flush(self):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.flush()\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            self.buffer.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _json_dumps(obj):\n",
    "    \"\"\"CSVã«å®‰å…¨ã«è¼‰ã›ã‚‹ãŸã‚ã®JSONåŒ–ï¼ˆå¤±æ•—ã—ã¦ã‚‚è½ã¨ã•ãªã„ï¼‰\"\"\"\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return json.dumps(str(obj), ensure_ascii=False, default=str)\n",
    "\n",
    "# --- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è©•ä¾¡ ---------------------------------------------------\n",
    "for idx, row in target_df.iterrows():\n",
    "    domain = row['domain']\n",
    "    ml_prob = row['ml_probability']\n",
    "    _buf = io.StringIO()\n",
    "    _tee_out = _TeeIO(sys.stdout, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    _tee_err = _TeeIO(sys.stderr, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    with redirect_stdout(_tee_out), redirect_stderr(_tee_err):\n",
    "\n",
    "        try:\n",
    "            eval_start = time.time()\n",
    "            result = agent.evaluate(domain, ml_prob)\n",
    "            elapsed = time.time() - eval_start\n",
    "\n",
    "            # --- åŸºæœ¬æƒ…å ± ---\n",
    "            is_phishing = result.get('ai_is_phishing', False)\n",
    "            confidence  = result.get('ai_confidence', 0.0)\n",
    "            risk_level  = result.get('ai_risk_level', 'unknown')\n",
    "\n",
    "            graph_state = _safe_dict(result.get(\"graph_state\"))\n",
    "            tool_res = _safe_dict(graph_state.get(\"tool_results\")) or _safe_dict(result.get(\"tool_results\"))\n",
    "\n",
    "            # Phase4 ä»•æ§˜: brand/cert/domain/contextual_risk_assessment ã¯ data æœ¬ä½“ãŒå…¥ã£ã¦ã„ã‚‹æƒ³å®š\n",
    "            brand_res  = _safe_dict(tool_res.get('brand'))\n",
    "            cert_res   = _safe_dict(tool_res.get('cert'))\n",
    "            domain_res = _safe_dict(tool_res.get('domain'))\n",
    "            ctx_res    = _safe_dict(tool_res.get('contextual_risk_assessment') or tool_res.get('contextual'))\n",
    "\n",
    "            # Brand details\n",
    "            brand_details   = _safe_dict(brand_res.get('details'))\n",
    "            detected_brands = brand_details.get('detected_brands', [])\n",
    "\n",
    "            # brand_detected / brand_suspected ã‚’ tool å´ã®ãƒ•ãƒ©ã‚°ã‹ã‚‰å–å¾—ï¼ˆbrandsé…åˆ—ã®æœ‰ç„¡ã§æ±ºã‚ãªã„ï¼‰\n",
    "            _b_issues = brand_res.get('detected_issues', []) if isinstance(brand_res, dict) else []\n",
    "            brand_detected_flag = bool(brand_details.get('brand_detected')) or ('brand_detected' in (_b_issues or []))\n",
    "            brand_suspected_flag = bool(brand_details.get('brand_suspected')) or ('brand_suspected' in (_b_issues or [])) or ('brand_llm_candidate' in (_b_issues or []))\n",
    "\n",
    "\n",
    "            # Cert details\n",
    "            cert_details = _safe_dict(cert_res.get('details'))\n",
    "            cert_issuer  = cert_details.get('issuer', 'unknown')\n",
    "\n",
    "            # Domain details\n",
    "            domain_details = _safe_dict(domain_res.get('details'))\n",
    "            tld_cat        = domain_details.get('tld_category', '-')\n",
    "\n",
    "            # Contextual issues\n",
    "            ctx_issues = ctx_res.get('detected_issues', []) if ctx_res else []\n",
    "\n",
    "            mark = \"ğŸ”´\" if is_phishing else \"ğŸŸ¢\"\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] {mark} {domain:<35} (ML: {ml_prob:.3f} / Time: {elapsed:.2f}s)\")\n",
    "            print(f\"ğŸ” Domain: {domain} (ml_probability={ml_prob:.3f})\")\n",
    "\n",
    "            # --- Tool Selection è©³ç´° ---\n",
    "            _log_tool_selection(graph_state, ml_prob)\n",
    "\n",
    "            # --- å„ãƒ„ãƒ¼ãƒ«è©³ç´° ---\n",
    "            _log_brand_tool(brand_res)\n",
    "            _log_cert_tool(cert_res)\n",
    "            _log_domain_tool(domain_res)\n",
    "            if ctx_res:\n",
    "                _log_contextual_tool(ctx_res)\n",
    "\n",
    "            # --- Final Decision è©³ç´° ---\n",
    "            _log_final_decision(graph_state, result)\n",
    "\n",
    "            # --- LangGraph ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠœç²‹ ---\n",
    "            _log_graph_messages(graph_state)\n",
    "\n",
    "            # --- ä¿å­˜ç”¨ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ ---\n",
    "            dbg_final = _safe_dict(graph_state.get(\"debug_llm_final\"))\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': is_phishing,\n",
    "                'ai_confidence': confidence,\n",
    "                'ai_risk_level': risk_level,\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps(graph_state),\n",
    "                'tool_results_json': _json_dumps(tool_res),\n",
    "                # Brand\n",
    "                'brand_detected': brand_detected_flag,\n",
    "                'brand_suspected': brand_suspected_flag,\n",
    "                'brands': detected_brands,\n",
    "                'brand_used_llm': brand_details.get('used_llm'),\n",
    "                'brand_llm_quality': brand_details.get('llm_candidate_quality'),\n",
    "                'brand_llm_evidence_token': brand_details.get('llm_evidence_token'),\n",
    "                'brand_llm_detected_brand': brand_details.get('llm_detected_brand'),\n",
    "                'brand_llm_confidence': brand_details.get('llm_confidence'),\n",
    "                'brand_risk_score': brand_res.get('risk_score'),\n",
    "                'brand_issues': brand_res.get('detected_issues', []),\n",
    "                # Cert\n",
    "                'cert_issues': cert_res.get('detected_issues', []),\n",
    "                'cert_issuer': cert_issuer,\n",
    "                'cert_score': cert_res.get('risk_score', 0.0),\n",
    "                # Domain\n",
    "                'domain_issues': domain_res.get('detected_issues', []),\n",
    "                'domain_score': domain_res.get('risk_score', 0.0),\n",
    "                'tld_category': tld_cat,\n",
    "                # Contextual\n",
    "                'ctx_issues': ctx_issues,\n",
    "                'ctx_score': ctx_res.get('risk_score', None) if ctx_res else None,\n",
    "                # Tool Selection / Final LLM debug\n",
    "                'tool_selection_llm_used': graph_state.get('llm_used_selection'),\n",
    "                'tool_selection_llm_error': graph_state.get('llm_selection_error'),\n",
    "                'final_llm_path': dbg_final.get('path'),\n",
    "                'final_llm_success': dbg_final.get('success'),\n",
    "                'phase6_policy_version': graph_state.get('phase6_policy_version'),\n",
    "                'module_version': result.get('module_version'),\n",
    "                'error': None,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - eval_start\n",
    "            print(f\"[{idx+1:3}/{len(target_df)}] âŒ ERROR: {domain} - {str(e)}\")\n",
    "            results.append({\n",
    "                **CODE_FP_ROW,\n",
    "                'domain': domain,\n",
    "                'ml_probability': ml_prob,\n",
    "                'ai_is_phishing': False,\n",
    "                'ai_confidence': 0.0,\n",
    "                'ai_risk_level': 'error',\n",
    "                'processing_time': elapsed,\n",
    "                'debug_log': _buf.getvalue(),\n",
    "                'graph_state_json': _json_dumps({}),\n",
    "                'tool_results_json': _json_dumps({}),\n",
    "                'error': str(e),\n",
    "            })\n",
    "\n",
    "    # --- ç”»é¢è¡¨ç¤ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆé€²æ—ï¼‰ ---------------------------------------\n",
    "    # NOTE: è©³ç´°ãƒ­ã‚°ã¯ _buf ã«å…¨é‡ä¿å­˜ã—ã¦ã„ã‚‹ã®ã§ã€ç”»é¢å´ã¯è»½ãã™ã‚‹\n",
    "    try:\n",
    "        _last = results[-1] if results else None\n",
    "    except Exception:\n",
    "        _last = None\n",
    "\n",
    "    if _last is not None:\n",
    "        if _last.get(\"error\"):\n",
    "            _screen_counts[\"error\"] += 1\n",
    "        else:\n",
    "            if bool(_last.get(\"ai_is_phishing\")):\n",
    "                _screen_counts[\"phish\"] += 1\n",
    "            else:\n",
    "                _screen_counts[\"benign\"] += 1\n",
    "\n",
    "        # è©³ç´°ãƒ­ã‚°ã‚’ç”»é¢ã«å‡ºã•ãªã„ãƒ¢ãƒ¼ãƒ‰ã®ã¨ãã ã‘ã€é€²æ—ã‚’é–“å¼•ã„ã¦è¡¨ç¤º\n",
    "        if (not SHOW_DOMAIN_LOG_ON_SCREEN) and (\n",
    "            ((idx + 1) % PROGRESS_EVERY == 0) or (idx == (len(target_df) - 1)) or _last.get(\"error\")\n",
    "        ):\n",
    "            if _HAS_CLEAR_OUTPUT and _USE_CLEAR_OUTPUT:\n",
    "                try:\n",
    "                    clear_output(wait=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            elapsed_total = time.time() - start_time\n",
    "            mark = \"âŒ\" if _last.get(\"error\") else (\"ğŸ”´\" if _last.get(\"ai_is_phishing\") else \"ğŸŸ¢\")\n",
    "            dom  = _last.get(\"domain\", \"-\")\n",
    "            mlp  = float(_last.get(\"ml_probability\") or 0.0)\n",
    "            conf = float(_last.get(\"ai_confidence\") or 0.0)\n",
    "            rl   = _last.get(\"ai_risk_level\", \"-\")\n",
    "            tsec = float(_last.get(\"processing_time\") or 0.0)\n",
    "\n",
    "            print(f\"[PROGRESS] {idx+1}/{len(target_df)}  phishing={_screen_counts['phish']}  benign={_screen_counts['benign']}  error={_screen_counts['error']}  elapsed={elapsed_total:.1f}s\")\n",
    "            print(f\"          last: {mark} {dom} (ML={mlp:.3f} risk={rl} conf={conf:.2f} t={tsec:.2f}s)\")\n",
    "            if _last.get(\"error\"):\n",
    "                print(f\"          last_error: {_last.get('error')}\")\n",
    "\n",
    "# --- å®Œäº†å‡¦ç† ------------------------------------------------------------\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] Full evaluation complete! Total time: {total_time:.2f}s\")\n",
    "\n",
    "# DataFrameåŒ–ã¨ä¿å­˜\n",
    "results_df = pd.DataFrame(results)\n",
    "# --- ä¿å­˜ ------------------------------------------------------------\n",
    "# eval_id ã¯å®Ÿé¨“IDï¼ˆåŒä¸€Notebookå®Ÿè¡Œå†…ã§ä¸€å®šï¼‰ã€ts ã¯ä¿å­˜æ™‚åˆ»ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«è¡çªå›é¿ï¼‰\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "# full_eval ã‚’ \"eval_id ä»˜ã\" ã§ä¿å­˜ï¼ˆå¾Œç¶šã®åˆ†æCSVãŒã‚ºãƒ¬ãªã„ã‚ˆã†ã«ï¼‰\n",
    "full_eval_path = BASE_DIR / f\"random{len(target_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "results_df.to_csv(full_eval_path, index=False)\n",
    "\n",
    "print(f\"[INFO] Results saved to: {full_eval_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c3149a-01ec-4b2b-8c47-437626986896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” DETAILED TOOL ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Overall Performance\n",
      "  Total Domains: 10\n",
      "  Phishing Detected: 10 (100.0%)\n",
      "  Avg Processing Time: 5.03s\n",
      "\n",
      "ğŸ”’ Certificate Analysis Stats\n",
      "  - free_ca             : 10 domains\n",
      "  - no_org              : 10 domains\n",
      "  - free_ca_no_org      : 10 domains\n",
      "  - wildcard            : 3 domains\n",
      "  [Top Issuers]\n",
      "Let's Encrypt            7\n",
      "CLOUDFLARE, INC.         1\n",
      "Sectigo Limited          1\n",
      "Google Trust Services    1\n",
      "\n",
      "ğŸŒ Domain Analysis Stats\n",
      "  - short               : 1 domains\n",
      "  - random_pattern      : 1 domains\n",
      "  - very_short          : 1 domains\n",
      "  - dangerous_tld       : 1 domains\n",
      "  - very_short_dangerous_combo: 1 domains\n",
      "\n",
      "ğŸ·ï¸  Brand Analysis Stats\n",
      "  Brand Detected: 0 domains\n",
      "\n",
      "================================================================================\n",
      "âœ… Verification Complete. Check CSV for per-domain details.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 6: ãƒ„ãƒ¼ãƒ«åˆ¥è©³ç´°çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "# ============================================\n",
    "import numpy as np\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰\n",
    "valid_df = results_df[results_df['error'].isna()].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” DETAILED TOOL ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. å…¨ä½“çµ±è¨ˆ\n",
    "phish_count = valid_df['ai_is_phishing'].sum()\n",
    "total = len(valid_df)\n",
    "print(f\"\\nğŸ“Š Overall Performance\")\n",
    "print(f\"  Total Domains: {total}\")\n",
    "print(f\"  Phishing Detected: {phish_count} ({phish_count/total*100:.1f}%)\")\n",
    "print(f\"  Avg Processing Time: {valid_df['processing_time'].mean():.2f}s\")\n",
    "\n",
    "# 2. Certificate Analysis çµ±è¨ˆ (ä»Šå›æ³¨ç›®ã®æ©Ÿèƒ½)\n",
    "print(f\"\\nğŸ”’ Certificate Analysis Stats\")\n",
    "# Issueã”ã¨ã®ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "all_cert_issues = []\n",
    "for issues in valid_df['cert_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_cert_issues.extend(issues)\n",
    "    elif isinstance(issues, str) and issues: # æ–‡å­—åˆ—ã®å ´åˆã®ã‚±ã‚¢\n",
    "        import ast\n",
    "        try:\n",
    "            all_cert_issues.extend(ast.literal_eval(issues))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if all_cert_issues:\n",
    "    from collections import Counter\n",
    "    cert_counts = Counter(all_cert_issues)\n",
    "    for issue, count in cert_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "else:\n",
    "    print(\"  No certificate issues detected.\")\n",
    "\n",
    "# ç™ºè¡Œè€…(Issuer)ã®Top5 (Free CAã®ç¢ºèªãªã©)\n",
    "issuers = valid_df[valid_df['cert_issuer'] != 'unknown']['cert_issuer']\n",
    "if not issuers.empty:\n",
    "    print(f\"  [Top Issuers]\")\n",
    "    print(issuers.value_counts().head(5).to_string(header=False))\n",
    "\n",
    "# 3. Domain Analysis çµ±è¨ˆ\n",
    "print(f\"\\nğŸŒ Domain Analysis Stats\")\n",
    "all_domain_issues = []\n",
    "for issues in valid_df['domain_issues']:\n",
    "    if isinstance(issues, list):\n",
    "        all_domain_issues.extend(issues)\n",
    "\n",
    "if all_domain_issues:\n",
    "    dom_counts = Counter(all_domain_issues)\n",
    "    for issue, count in dom_counts.most_common():\n",
    "        print(f\"  - {issue:20}: {count} domains\")\n",
    "\n",
    "# 4. Brand Analysis çµ±è¨ˆ\n",
    "print(f\"\\nğŸ·ï¸  Brand Analysis Stats\")\n",
    "brand_hits = valid_df[valid_df['brand_detected'] == True]\n",
    "print(f\"  Brand Detected: {len(brand_hits)} domains\")\n",
    "if not brand_hits.empty:\n",
    "    all_brands = []\n",
    "    for brands in brand_hits['brands']:\n",
    "        if isinstance(brands, list): all_brands.extend(brands)\n",
    "    print(f\"  [Top Detected Brands]\")\n",
    "    print(pd.Series(all_brands).value_counts().head(5).to_string(header=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Verification Complete. Check CSV for per-domain details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35e40ed-3cc6-4c82-90d2-9bb658c259b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_DATA_PKL : artifacts/2025-12-07_143907/processed/test_data.pkl\n",
      "XGB_MODEL_PKL : artifacts/2025-12-07_143907/models/xgboost_model.pkl\n",
      "SCALER_PKL    : artifacts/2025-12-07_143907/models/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# === ã‚»ãƒ«1: ãƒ‘ã‚¹è¨­å®š & test_data / ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆartifacts/<RUN_ID>/... ã«çµ±ä¸€ï¼‰ ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cell 1 ã§å®šç¾©ã•ã‚ŒãŸ PROCESSED_DIR / MODELS_DIR / RUN_ID ã‚’åˆ©ç”¨\n",
    "if \"PROCESSED_DIR\" not in globals() or \"MODELS_DIR\" not in globals():\n",
    "    raise RuntimeError(\"PROCESSED_DIR / MODELS_DIR ãŒæœªå®šç¾©ã§ã™ã€‚å…ˆã« Cell 1 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "DATA_DIR = Path(PROCESSED_DIR)\n",
    "MODELS_DIR = Path(MODELS_DIR)  # ã™ã§ã« Path ã®ã¯ãšã ãŒå¿µã®ãŸã‚\n",
    "\n",
    "# 02_xgboost_training_evaluation_... ã®æ–°ä»•æ§˜ã«åˆã‚ã›ã¦:\n",
    "#   - test_data.pkl: artifacts/<RUN_ID>/processed/test_data.pkl\n",
    "#   - xgboost_model.pkl, scaler.pkl: artifacts/<RUN_ID>/models/...\n",
    "TEST_DATA_PKL = DATA_DIR / \"test_data.pkl\"\n",
    "XGB_MODEL_PKL = MODELS_DIR / \"xgboost_model.pkl\"\n",
    "SCALER_PKL    = MODELS_DIR / \"scaler.pkl\"\n",
    "\n",
    "print(\"TEST_DATA_PKL :\", TEST_DATA_PKL)\n",
    "print(\"XGB_MODEL_PKL :\", XGB_MODEL_PKL)\n",
    "print(\"SCALER_PKL    :\", SCALER_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53ae907-89e0-44a1-95f0-01377fce73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asomura/waseda/phish-core/lib/python3.12/site-packages/xgboost/core.py:774: UserWarning: [13:15:42] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>ml_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winrneteik.icu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.mcacsceeri.icu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sellsy.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turbohire.co</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3217.tmdjmze.name.na</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 domain  label  ml_probability\n",
       "0        winrneteik.icu      1        0.302355\n",
       "1    www.mcacsceeri.icu      1        0.999970\n",
       "2            sellsy.com      0        0.519350\n",
       "3          turbohire.co      0        0.009194\n",
       "4  3217.tmdjmze.name.na      1        0.999481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === ã‚»ãƒ«2: test_data + XGBoost ã§ ml_probability ã‚’å†è¨ˆç®— ===\n",
    "\n",
    "# 02 ã§ joblib.dump ã—ã¦ã„ã‚Œã° joblib.load ã§ãã®ã¾ã¾èª­ã‚ã¾ã™\n",
    "test_data = joblib.load(TEST_DATA_PKL)\n",
    "\n",
    "X_test = np.asarray(test_data[\"X\"])\n",
    "y_test = np.asarray(test_data[\"y\"]).astype(int)\n",
    "domains_test = np.asarray(test_data[\"domains\"])\n",
    "\n",
    "xgb_model = joblib.load(XGB_MODEL_PKL)\n",
    "try:\n",
    "    scaler = joblib.load(SCALER_PKL)\n",
    "except FileNotFoundError:\n",
    "    scaler = None\n",
    "    print(\"âš  scaler.pkl ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã®ã§ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç„¡ã—ã§æ¨è«–ã—ã¾ã™ã€‚\")\n",
    "\n",
    "def compute_ml_probabilities(model, X, scaler=None):\n",
    "    \"\"\"XGBoost ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ P(phish) ã‚’æ¨å®šã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼\"\"\"\n",
    "    X_in = scaler.transform(X) if scaler is not None else X\n",
    "\n",
    "    # sklearn API (XGBClassifier) ã®å ´åˆ\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = np.asarray(model.predict_proba(X_in))\n",
    "        if proba.ndim == 2 and proba.shape[1] >= 2:\n",
    "            return proba[:, 1]\n",
    "        return proba.ravel()\n",
    "\n",
    "    # Booster API ã®å ´åˆ\n",
    "    if hasattr(model, \"predict\"):\n",
    "        dtest = xgb.DMatrix(X_in)\n",
    "        proba = np.asarray(model.predict(dtest))\n",
    "        return proba.ravel()\n",
    "\n",
    "    raise RuntimeError(\"äºˆæœŸã—ãªã„ XGBoost ãƒ¢ãƒ‡ãƒ«å‹ã§ã™ (predict_proba/predict ãŒè¦‹ã¤ã‹ã‚‰ãªã„)ã€‚\")\n",
    "\n",
    "ml_probs_test = compute_ml_probabilities(xgb_model, X_test, scaler=scaler)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"domain\": domains_test,\n",
    "    \"label\": y_test,\n",
    "    \"ml_probability\": ml_probs_test,\n",
    "})\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8951945a-58e4-4610-b2cd-f9e4fed7ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign candidates (label==0 & ml_prob<0.5): 62727\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "      <th>ml_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cp2k.org</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>galloglassgames.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flocksocial.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clubdeparis.org</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nyxcosmetics.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain  label  ml_probability\n",
       "0             cp2k.org      0        0.130495\n",
       "1  galloglassgames.com      0        0.028086\n",
       "2      flocksocial.com      0        0.009096\n",
       "3      clubdeparis.org      0        0.110794\n",
       "4     nyxcosmetics.com      0        0.011676"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === ã‚»ãƒ«3: æ­£å¸¸ (label==0) ã‹ã‚‰ N_BENIGN_SAMPLE ä»¶ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ===\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_SAMPLE<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’ä½¿ã†\n",
    "\n",
    "# N_BENIGN_SAMPLE ã¯ Cell 1 ã®è¨­å®šã«å¾“ã†ï¼ˆå¿…è¦ãªã‚‰ç’°å¢ƒå¤‰æ•° N_BENIGN_SAMPLE ã§ä¸Šæ›¸ãï¼‰\n",
    "# RANDOM_STATE ã¯ Cell 1 ã§å®šç¾©ï¼ˆç’°å¢ƒå¤‰æ•° RANDOM_STATE ã§ã‚‚ä¸Šæ›¸ãå¯ï¼‰\n",
    "\n",
    "benign_candidates = test_df.query(\"label == 0 and ml_probability < 0.5\").copy()\n",
    "print(\"benign candidates (label==0 & ml_prob<0.5):\", len(benign_candidates))\n",
    "\n",
    "# N_BENIGN_SAMPLE <= 0 ã®å ´åˆã¯ã€Œå…¨ä»¶å‡¦ç†ã€\n",
    "if (N_BENIGN_SAMPLE <= 0) or (len(benign_candidates) <= N_BENIGN_SAMPLE):\n",
    "    print(f\"å€™è£œãŒ {len(benign_candidates)} ä»¶ãªã®ã§ã€ãã®ã¾ã¾å…¨ä»¶ä½¿ã„ã¾ã™ã€‚\")\n",
    "    benign_sample_df = benign_candidates.reset_index(drop=True)\n",
    "else:\n",
    "    benign_sample_df = benign_candidates.sample(N_BENIGN_SAMPLE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "benign_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22bdddae-6ae3-4940-a755-9a4eb919a4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2033571464.py, line 76)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexcept Exception:\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Cell 6.1: benign ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ï¼ˆé€²æ— / ä¸€æ™‚åœæ­¢ / debug_logåˆ†å‰²ä¿å­˜ å¯¾å¿œç‰ˆï¼‰\n",
    "# ============================================\n",
    "#\n",
    "# ç›®çš„:\n",
    "#   - benign_sample_df ã®å…¨è¡Œã«å¯¾ã—ã¦ agent.evaluate ã‚’å®Ÿè¡Œ\n",
    "#   - é€²æ—è¡¨ç¤ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰\n",
    "#   - ä¸€æ™‚åœæ­¢ï¼ˆpauseãƒ•ã‚¡ã‚¤ãƒ«ãŒç½®ã‹ã‚ŒãŸã‚‰å®‰å…¨åœæ­¢ + partialä¿å­˜ï¼‰\n",
    "#   - debug_log ã¯ CSV ã«å…¨æ–‡ã‚’è¼‰ã›ãšã€ãƒ•ã‚¡ã‚¤ãƒ«ã¸åˆ†å‰²ä¿å­˜ï¼ˆCSVã«ã¯ãƒ‘ã‚¹ã‚’æ ¼ç´ï¼‰\n",
    "#\n",
    "# ä¾å­˜:\n",
    "#   - agent ãŒåˆæœŸåŒ–æ¸ˆã¿ï¼ˆCell 4ï¼‰\n",
    "#   - benign_sample_df ãŒä½œæˆæ¸ˆã¿\n",
    "#   - CODE_FP_ROW ãŒã‚ã‚Œã° eval_id ã‚’ãã“ã‹ã‚‰ä½¿ã†ï¼ˆç„¡ã‘ã‚Œã°ç”Ÿæˆï¼‰\n",
    "#\n",
    "# [ChangeLog] 2025-12-21:\n",
    "#   - Cell 5 ã¨åŒç­‰ã®é‹ç”¨æ€§ï¼ˆé€²æ—/åœæ­¢/ãƒ­ã‚°åˆ†å‰²ï¼‰ã«å¯„ã›ã‚‹ãŸã‚ã€è©•ä¾¡ãƒ«ãƒ¼ãƒ—ã‚’æ‹¡å¼µ\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "def _safe_dict(d):\n",
    "    return d if isinstance(d, dict) else {}\n",
    "\n",
    "# --- è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ï¼‰ ---------------------------------------\n",
    "TOTAL_N = len(benign_sample_df)\n",
    "print(f\"[INFO] Starting BENIGN AGENT evaluation of {TOTAL_N} domains ...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ç”»é¢å‡ºåŠ›ï¼ˆå¤§é‡ä»¶æ•°ã§é‡ãã—ãªã„ï¼‰\n",
    "SHOW_DOMAIN_LOG_ON_SCREEN = (TOTAL_N <= 20)\n",
    "_env = os.getenv(\"SHOW_DOMAIN_LOG_ON_SCREEN\")\n",
    "if _env is not None:\n",
    "    SHOW_DOMAIN_LOG_ON_SCREEN = str(_env).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# é€²æ—è¡¨ç¤ºã®æ›´æ–°é »åº¦ï¼ˆä»¶æ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ï¼‰\n",
    "if TOTAL_N <= 30:\n",
    "    PROGRESS_EVERY = 1\n",
    "elif TOTAL_N <= 300:\n",
    "    PROGRESS_EVERY = 10\n",
    "elif TOTAL_N <= 3000:\n",
    "    PROGRESS_EVERY = 25\n",
    "else:\n",
    "    PROGRESS_EVERY = 50\n",
    "\n",
    "# pause ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå­˜åœ¨ã—ãŸã‚‰å®‰å…¨åœæ­¢ï¼‰\n",
    "# datasetã”ã¨ã«å€‹åˆ¥æŒ‡å®šå¯èƒ½: PAUSE_EVAL_FILE_BENIGN / PAUSE_EVAL_FILE_BENIGN_HARD\n",
    "# â€»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ artifacts/<RUN_ID>/logs é…ä¸‹ã«ç½®ãï¼ˆãƒ­ã‚°ãŒæ•£ã‚‰ã‹ã‚‰ãªã„ã‚ˆã†ã«ï¼‰\n",
    "_pause_env_key = \"PAUSE_EVAL_FILE_BENIGN\"\n",
    "_LOG_BASE = globals().get(\"LOGS_DIR\", BASE_DIR)\n",
    "_LOG_BASE = Path(str(_LOG_BASE))\n",
    "\n",
    "_pause_default = str(_LOG_BASE / \".PAUSE_EVAL\")\n",
    "PAUSE_FILE = Path(os.getenv(_pause_env_key, os.getenv(\"PAUSE_EVAL_FILE\", _pause_default)))\n",
    "\n",
    "# debug_log ã®ä¿å­˜å…ˆï¼ˆåˆ†å‰²ï¼‰\n",
    "# ä¾‹: artifacts/<RUN_ID>/logs/debug_logs/<eval_id>/benign/xxxxx_domain.txt\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "_dataset_tag = \"benign\"\n",
    "_debug_default = str(_LOG_BASE / \"debug_logs\" / eval_id / _dataset_tag)\n",
    "DEBUG_DIR = Path(os.getenv(\"DEBUG_LOG_DIR\", _debug_default))\n",
    "except Exception:\n",
    "    DEBUG_LOG_INLINE_CHARS = 0\n",
    "\n",
    "# å†é–‹ï¼ˆresumeï¼‰ï¼šå‡¦ç†æ¸ˆã¿ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
    "# datasetã”ã¨ã«å€‹åˆ¥æŒ‡å®šå¯èƒ½: RESUME_FROM_CSV_BENIGN / RESUME_FROM_CSV_BENIGN_HARD\n",
    "_resume_env_key = \"RESUME_FROM_CSV_BENIGN\"\n",
    "RESUME_FROM_CSV = os.getenv(_resume_env_key, os.getenv(\"RESUME_FROM_CSV\", \"\"))\n",
    "processed = set()\n",
    "if RESUME_FROM_CSV:\n",
    "    try:\n",
    "        _df_resume = pd.read_csv(RESUME_FROM_CSV)\n",
    "        if \"domain\" in _df_resume.columns:\n",
    "            processed = set(_df_resume[\"domain\"].astype(str).tolist())\n",
    "            print(f\"[INFO] Resume enabled: loaded {len(processed)} processed domains from {RESUME_FROM_CSV}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] Resume CSV has no 'domain' column: {RESUME_FROM_CSV}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to load RESUME_FROM_CSV={RESUME_FROM_CSV}: {e}\")\n",
    "\n",
    "# Jupyterãªã‚‰ clear_output ã§è¡¨ç¤ºã‚’ç½®ãæ›ãˆ\n",
    "_USE_CLEAR_OUTPUT = (not SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "try:\n",
    "    from IPython.display import clear_output  # type: ignore\n",
    "    _HAS_CLEAR_OUTPUT = True\n",
    "except Exception:\n",
    "    _HAS_CLEAR_OUTPUT = False\n",
    "\n",
    "print(f\"[INFO] Console output mode: {'VERBOSE' if SHOW_DOMAIN_LOG_ON_SCREEN else 'COMPACT'} \"\n",
    "      f\"(PROGRESS_EVERY={PROGRESS_EVERY}, clear_output={_USE_CLEAR_OUTPUT and _HAS_CLEAR_OUTPUT})\")\n",
    "print(f\"[INFO] pause_file: {PAUSE_FILE}\")\n",
    "print(f\"[INFO] debug_dir : {DEBUG_DIR}\")\n",
    "print(f\"[INFO] debug_inline_chars: {DEBUG_LOG_INLINE_CHARS}\")\n",
    "if RESUME_FROM_CSV:\n",
    "    print(f\"[INFO] resume_csv: {RESUME_FROM_CSV}\")\n",
    "\n",
    "# --- ãƒ­ã‚°ç”¨ -----------------------------------------------------------\n",
    "class _TeeIO:\n",
    "    def __init__(self, primary, buffer, *, enable_primary: bool = True):\n",
    "        self.primary = primary\n",
    "        self.buffer = buffer\n",
    "        self.enable_primary = bool(enable_primary)\n",
    "    def write(self, s):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.write(s)\n",
    "            except Exception:\n",
    "                pass\n",
    "        self.buffer.write(s)\n",
    "        return len(s)\n",
    "    def flush(self):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.flush()\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            self.buffer.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _json_dumps(obj):\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return json.dumps(str(obj), ensure_ascii=False, default=str)\n",
    "\n",
    "def _safe_filename(s: str, max_len: int = 120) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = s.replace(\"/\", \"_\").replace(\":\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = \"\".join(ch if ch.isalnum() or ch in \"._-@\" else \"_\" for ch in s)\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len]\n",
    "    return s\n",
    "\n",
    "def _save_partial(df: pd.DataFrame, suffix: str = \"partial\"):\n",
    "    try:\n",
    "        _ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "        path = BASE_DIR / f\"benign{TOTAL_N}_full_eval__evalid_{eval_id}__{suffix}__ts_{_ts}.csv\"\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[INFO] Saved {suffix} results to: {path}\")\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to save {suffix} results: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- è©•ä¾¡ãƒ«ãƒ¼ãƒ— -------------------------------------------------------\n",
    "results = []\n",
    "start_time = time.time()\n",
    "counts = {\"phish\": 0, \"benign\": 0, \"error\": 0}\n",
    "skipped = 0\n",
    "\n",
    "for i, row in enumerate(benign_sample_df.itertuples(index=False), start=1):\n",
    "    domain = str(row.domain)\n",
    "    ml_prob = float(row.ml_probability)\n",
    "\n",
    "    if processed and domain in processed:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if PAUSE_FILE.exists():\n",
    "        print(f\"[PAUSE] Detected pause file: {PAUSE_FILE} â†’ stopping safely at {i-1}/{TOTAL_N}.\")\n",
    "        try:\n",
    "            benign_agent_df = pd.DataFrame(results) if results else pd.DataFrame([])\n",
    "            _save_partial(benign_agent_df, suffix=\"partial_pause\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        break\n",
    "\n",
    "    _buf = io.StringIO()\n",
    "    _tee_out = _TeeIO(sys.stdout, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    _tee_err = _TeeIO(sys.stderr, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "\n",
    "    with redirect_stdout(_tee_out), redirect_stderr(_tee_err):\n",
    "        try:\n",
    "            eval_start = time.time()\n",
    "            res = agent.evaluate(domain=domain, ml_probability=ml_prob)\n",
    "            elapsed = time.time() - eval_start\n",
    "\n",
    "            is_phishing = bool(res.get(\"ai_is_phishing\", False)) if isinstance(res, dict) else False\n",
    "            confidence = float(res.get(\"ai_confidence\") or 0.0) if isinstance(res, dict) else 0.0\n",
    "            risk_level = (res.get(\"ai_risk_level\") if isinstance(res, dict) else \"unknown\") or \"unknown\"\n",
    "\n",
    "            graph_state = res.get(\"graph_state\") if isinstance(res, dict) else {}\n",
    "            tool_res = {}\n",
    "            if isinstance(graph_state, dict):\n",
    "                tool_res = _safe_dict(graph_state.get(\"tool_results\")) or _safe_dict(res.get(\"tool_results\") if isinstance(res, dict) else {})\n",
    "\n",
    "            log_text = _buf.getvalue()\n",
    "            safe_dom = _safe_filename(domain)\n",
    "            log_path = DEBUG_DIR / f\"{i:05d}_{safe_dom}.log.txt\"\n",
    "            try:\n",
    "                log_path.write_text(log_text, encoding=\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                log_path = None\n",
    "\n",
    "            if DEBUG_LOG_INLINE_CHARS == 0:\n",
    "                inline_log = None\n",
    "            elif DEBUG_LOG_INLINE_CHARS < 0:\n",
    "                inline_log = log_text\n",
    "            else:\n",
    "                inline_log = log_text[:DEBUG_LOG_INLINE_CHARS]\n",
    "\n",
    "            row_out = {}\n",
    "            if isinstance(res, dict):\n",
    "                row_out.update(res)\n",
    "\n",
    "            if isinstance(row_out, dict) and \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "                row_out.update(CODE_FP_ROW)\n",
    "\n",
    "            row_out.update({\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": ml_prob,\n",
    "                \"processing_time\": elapsed,\n",
    "                \"debug_log_path\": str(log_path) if log_path else None,\n",
    "                \"debug_log\": inline_log,\n",
    "                \"graph_state_json\": _json_dumps(_safe_dict(graph_state)),\n",
    "                \"tool_results_json\": _json_dumps(_safe_dict(tool_res)),\n",
    "                \"error\": None,\n",
    "            })\n",
    "\n",
    "            # å¿µã®ãŸã‚ã€ä¸»è¦åˆ—ã‚’æ˜ç¤º\n",
    "            row_out.setdefault(\"ai_is_phishing\", is_phishing)\n",
    "            row_out.setdefault(\"ai_confidence\", confidence)\n",
    "            row_out.setdefault(\"ai_risk_level\", risk_level)\n",
    "\n",
    "            results.append(row_out)\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - eval_start if \"eval_start\" in locals() else 0.0\n",
    "            log_text = _buf.getvalue()\n",
    "            safe_dom = _safe_filename(domain)\n",
    "            log_path = DEBUG_DIR / f\"{i:05d}_{safe_dom}.log.txt\"\n",
    "            try:\n",
    "                log_path.write_text(log_text, encoding=\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                log_path = None\n",
    "\n",
    "            results.append({\n",
    "                **(CODE_FP_ROW if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict) else {}),\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": ml_prob,\n",
    "                \"ai_is_phishing\": False,\n",
    "                \"ai_confidence\": 0.0,\n",
    "                \"ai_risk_level\": \"error\",\n",
    "                \"processing_time\": elapsed,\n",
    "                \"debug_log_path\": str(log_path) if log_path else None,\n",
    "                \"debug_log\": None,\n",
    "                \"graph_state_json\": _json_dumps({}),\n",
    "                \"tool_results_json\": _json_dumps({}),\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "\n",
    "    last = results[-1] if results else None\n",
    "    if last is not None:\n",
    "        if last.get(\"error\"):\n",
    "            counts[\"error\"] += 1\n",
    "        else:\n",
    "            if bool(last.get(\"ai_is_phishing\")):\n",
    "                counts[\"phish\"] += 1\n",
    "            else:\n",
    "                counts[\"benign\"] += 1\n",
    "\n",
    "    if (not SHOW_DOMAIN_LOG_ON_SCREEN) and (\n",
    "        (i % PROGRESS_EVERY == 0) or (i == TOTAL_N) or (last and last.get(\"error\"))\n",
    "    ):\n",
    "        if _HAS_CLEAR_OUTPUT and _USE_CLEAR_OUTPUT:\n",
    "            try:\n",
    "                clear_output(wait=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        elapsed_total = time.time() - start_time\n",
    "        mark = \"âŒ\" if (last and last.get(\"error\")) else (\"ğŸ”´\" if (last and last.get(\"ai_is_phishing\")) else \"ğŸŸ¢\")\n",
    "        dom  = last.get(\"domain\", \"-\") if last else \"-\"\n",
    "        mlp  = float(last.get(\"ml_probability\") or 0.0) if last else 0.0\n",
    "        conf = float(last.get(\"ai_confidence\") or 0.0) if last else 0.0\n",
    "        rl   = last.get(\"ai_risk_level\", \"-\") if last else \"-\"\n",
    "        tsec = float(last.get(\"processing_time\") or 0.0) if last else 0.0\n",
    "\n",
    "        print(f\"[PROGRESS] {i}/{TOTAL_N}  phishing={counts['phish']}  benign={counts['benign']}  error={counts['error']}  skipped={skipped}  elapsed={elapsed_total:.1f}s\")\n",
    "        print(f\"          last: {mark} {dom} (ML={mlp:.3f} risk={rl} conf={conf:.2f} t={tsec:.2f}s)\")\n",
    "        if last and last.get(\"error\"):\n",
    "            print(f\"          last_error: {last.get('error')}\")\n",
    "\n",
    "        # autosaveï¼ˆå®‰å…¨ã®ãŸã‚ï¼‰\n",
    "        try:\n",
    "            benign_agent_df = pd.DataFrame(results) if results else pd.DataFrame([])\n",
    "            _save_partial(benign_agent_df, suffix=\"partial_auto\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] BENIGN evaluation complete! Total time: {total_time:.2f}s\")\n",
    "if skipped:\n",
    "    print(f\"[INFO] skipped (resume): {skipped} domains\")\n",
    "\n",
    "benign_agent_df = pd.DataFrame(results)\n",
    "\n",
    "benign_eval_df = benign_sample_df.merge(\n",
    "    benign_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_eval_df[\"label\"] = 0  # ground truth\n",
    "\n",
    "benign_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: benign è©•ä¾¡çµæœã‚’CSVã¸ä¿å­˜ï¼ˆå…±æœ‰ç”¨ï¼‰ ===\n",
    "import datetime\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ãƒ©ãƒ™ãƒ«ä»˜ãç°¡æ˜“ã‚µãƒãƒª\n",
    "eval_path = BASE_DIR / f\"benign{len(benign_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) ãƒ•ãƒ«ãƒ­ã‚°ï¼ˆagent.evaluate ã®ç”Ÿå‡ºåŠ›ã‚’å«ã‚€ï¼‰\n",
    "full_path = BASE_DIR / f\"benign{len(benign_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: hard-negative benign ã‚’ä½œæˆï¼ˆMLãŒé«˜ã„æ­£å¸¸ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ ===\n",
    "# ç›®çš„: ã€ŒMLãŒé«˜ã„æ­£å¸¸ã€ã‚’é›†ã‚ã¦ã€FPãŒå¢—ãˆãªã„ã‹æ¤œè¨¼ã™ã‚‹ï¼ˆhard negativesï¼‰\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 200 ä»¶ã€‚å¿…è¦ãªã‚‰ç’°å¢ƒå¤‰æ•° N_BENIGN_HARD_SAMPLE ã§ä¸Šæ›¸ãã§ãã¾ã™ã€‚\n",
    "# [ChangeLog] 2025-12-15: N_BENIGN_HARD_SAMPLE<=0(ALL) ã®å ´åˆã¯å…¨ä»¶ã‚’ä½¿ã†\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "N_BENIGN_HARD_SAMPLE = int(os.getenv(\"N_BENIGN_HARD_SAMPLE\", \"200\"))\n",
    "\n",
    "# label==0 å…¨ä½“ã‹ã‚‰ ML ã®é«˜ã„é †ã«ä¸¦ã¹ã‚‹\n",
    "benign_all = test_df.query(\"label == 0\").copy()\n",
    "benign_all = benign_all.sort_values(\"ml_probability\", ascending=False)\n",
    "\n",
    "# ã™ã§ã« benign_sample_df ã‚’ä½œã£ã¦ã„ã‚‹å ´åˆã¯é‡è¤‡ã‚’é¿ã‘ã‚‹ï¼ˆä»»æ„ï¼‰\n",
    "try:\n",
    "    used = set(benign_sample_df[\"domain\"].astype(str))\n",
    "    benign_all = benign_all[~benign_all[\"domain\"].astype(str).isin(used)]\n",
    "    print(\"removed overlap with benign_sample_df:\", len(used), \"used\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# å…¨ä»¶å‡¦ç†ï¼ˆN<=0ï¼‰ or å€™è£œä¸è¶³ãªã‚‰å…¨ä»¶\n",
    "if (N_BENIGN_HARD_SAMPLE <= 0) or (len(benign_all) <= N_BENIGN_HARD_SAMPLE):\n",
    "    print(f\"hard benign candidates are only {len(benign_all)}; using all.\")\n",
    "    benign_hard_sample_df = benign_all\n",
    "else:\n",
    "    benign_hard_sample_df = benign_all.head(N_BENIGN_HARD_SAMPLE)\n",
    "\n",
    "benign_hard_sample_df = benign_hard_sample_df.reset_index(drop=True)\n",
    "\n",
    "print(\"hard benign sample size:\", len(benign_hard_sample_df))\n",
    "if len(benign_hard_sample_df):\n",
    "    print(\"ml_probability (hard benign) min/mean/max:\",\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].min()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].mean()),\n",
    "          float(benign_hard_sample_df[\"ml_probability\"].max()))\n",
    "benign_hard_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Cell 6.2: benign_hard ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ï¼ˆé€²æ— / ä¸€æ™‚åœæ­¢ / debug_logåˆ†å‰²ä¿å­˜ å¯¾å¿œç‰ˆï¼‰\n",
    "# ============================================\n",
    "#\n",
    "# ç›®çš„:\n",
    "#   - benign_hard_sample_df ã®å…¨è¡Œã«å¯¾ã—ã¦ agent.evaluate ã‚’å®Ÿè¡Œ\n",
    "#   - é€²æ—è¡¨ç¤ºï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆï¼‰\n",
    "#   - ä¸€æ™‚åœæ­¢ï¼ˆpauseãƒ•ã‚¡ã‚¤ãƒ«ãŒç½®ã‹ã‚ŒãŸã‚‰å®‰å…¨åœæ­¢ + partialä¿å­˜ï¼‰\n",
    "#   - debug_log ã¯ CSV ã«å…¨æ–‡ã‚’è¼‰ã›ãšã€ãƒ•ã‚¡ã‚¤ãƒ«ã¸åˆ†å‰²ä¿å­˜ï¼ˆCSVã«ã¯ãƒ‘ã‚¹ã‚’æ ¼ç´ï¼‰\n",
    "#\n",
    "# ä¾å­˜:\n",
    "#   - agent ãŒåˆæœŸåŒ–æ¸ˆã¿ï¼ˆCell 4ï¼‰\n",
    "#   - benign_hard_sample_df ãŒä½œæˆæ¸ˆã¿\n",
    "#   - CODE_FP_ROW ãŒã‚ã‚Œã° eval_id ã‚’ãã“ã‹ã‚‰ä½¿ã†ï¼ˆç„¡ã‘ã‚Œã°ç”Ÿæˆï¼‰\n",
    "#\n",
    "# [ChangeLog] 2025-12-21:\n",
    "#   - Cell 5 ã¨åŒç­‰ã®é‹ç”¨æ€§ï¼ˆé€²æ—/åœæ­¢/ãƒ­ã‚°åˆ†å‰²ï¼‰ã«å¯„ã›ã‚‹ãŸã‚ã€è©•ä¾¡ãƒ«ãƒ¼ãƒ—ã‚’æ‹¡å¼µ\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "def _safe_dict(d):\n",
    "    return d if isinstance(d, dict) else {}\n",
    "\n",
    "# --- è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ï¼‰ ---------------------------------------\n",
    "TOTAL_N = len(benign_hard_sample_df)\n",
    "print(f\"[INFO] Starting BENIGN_HARD AGENT evaluation of {TOTAL_N} domains ...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ç”»é¢å‡ºåŠ›ï¼ˆå¤§é‡ä»¶æ•°ã§é‡ãã—ãªã„ï¼‰\n",
    "SHOW_DOMAIN_LOG_ON_SCREEN = (TOTAL_N <= 20)\n",
    "_env = os.getenv(\"SHOW_DOMAIN_LOG_ON_SCREEN\")\n",
    "if _env is not None:\n",
    "    SHOW_DOMAIN_LOG_ON_SCREEN = str(_env).strip().lower() in (\"1\", \"true\", \"yes\", \"y\", \"on\")\n",
    "\n",
    "# é€²æ—è¡¨ç¤ºã®æ›´æ–°é »åº¦ï¼ˆä»¶æ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ï¼‰\n",
    "if TOTAL_N <= 30:\n",
    "    PROGRESS_EVERY = 1\n",
    "elif TOTAL_N <= 300:\n",
    "    PROGRESS_EVERY = 10\n",
    "elif TOTAL_N <= 3000:\n",
    "    PROGRESS_EVERY = 25\n",
    "else:\n",
    "    PROGRESS_EVERY = 50\n",
    "\n",
    "# pause ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå­˜åœ¨ã—ãŸã‚‰å®‰å…¨åœæ­¢ï¼‰\n",
    "# datasetã”ã¨ã«å€‹åˆ¥æŒ‡å®šå¯èƒ½: PAUSE_EVAL_FILE_BENIGN / PAUSE_EVAL_FILE_BENIGN_HARD\n",
    "# â€»ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ artifacts/<RUN_ID>/logs é…ä¸‹ã«ç½®ãï¼ˆãƒ­ã‚°ãŒæ•£ã‚‰ã‹ã‚‰ãªã„ã‚ˆã†ã«ï¼‰\n",
    "_pause_env_key = \"PAUSE_EVAL_FILE_BENIGN_HARD\"\n",
    "_LOG_BASE = globals().get(\"LOGS_DIR\", BASE_DIR)\n",
    "_LOG_BASE = Path(str(_LOG_BASE))\n",
    "\n",
    "_pause_default = str(_LOG_BASE / \".PAUSE_EVAL\")\n",
    "PAUSE_FILE = Path(os.getenv(_pause_env_key, os.getenv(\"PAUSE_EVAL_FILE\", _pause_default)))\n",
    "\n",
    "# debug_log ã®ä¿å­˜å…ˆï¼ˆåˆ†å‰²ï¼‰\n",
    "# ä¾‹: artifacts/<RUN_ID>/logs/debug_logs/<eval_id>/benign_hard/xxxxx_domain.txt\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "_dataset_tag = \"benign_hard\"\n",
    "_debug_default = str(_LOG_BASE / \"debug_logs\" / eval_id / _dataset_tag)\n",
    "DEBUG_DIR = Path(os.getenv(\"DEBUG_LOG_DIR\", _debug_default))\n",
    "except Exception:\n",
    "    DEBUG_LOG_INLINE_CHARS = 0\n",
    "\n",
    "# å†é–‹ï¼ˆresumeï¼‰ï¼šå‡¦ç†æ¸ˆã¿ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—\n",
    "# datasetã”ã¨ã«å€‹åˆ¥æŒ‡å®šå¯èƒ½: RESUME_FROM_CSV_BENIGN / RESUME_FROM_CSV_BENIGN_HARD\n",
    "_resume_env_key = \"RESUME_FROM_CSV_BENIGN_HARD\"\n",
    "RESUME_FROM_CSV = os.getenv(_resume_env_key, os.getenv(\"RESUME_FROM_CSV\", \"\"))\n",
    "processed = set()\n",
    "if RESUME_FROM_CSV:\n",
    "    try:\n",
    "        _df_resume = pd.read_csv(RESUME_FROM_CSV)\n",
    "        if \"domain\" in _df_resume.columns:\n",
    "            processed = set(_df_resume[\"domain\"].astype(str).tolist())\n",
    "            print(f\"[INFO] Resume enabled: loaded {len(processed)} processed domains from {RESUME_FROM_CSV}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] Resume CSV has no 'domain' column: {RESUME_FROM_CSV}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to load RESUME_FROM_CSV={RESUME_FROM_CSV}: {e}\")\n",
    "\n",
    "# Jupyterãªã‚‰ clear_output ã§è¡¨ç¤ºã‚’ç½®ãæ›ãˆ\n",
    "_USE_CLEAR_OUTPUT = (not SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "try:\n",
    "    from IPython.display import clear_output  # type: ignore\n",
    "    _HAS_CLEAR_OUTPUT = True\n",
    "except Exception:\n",
    "    _HAS_CLEAR_OUTPUT = False\n",
    "\n",
    "print(f\"[INFO] Console output mode: {'VERBOSE' if SHOW_DOMAIN_LOG_ON_SCREEN else 'COMPACT'} \"\n",
    "      f\"(PROGRESS_EVERY={PROGRESS_EVERY}, clear_output={_USE_CLEAR_OUTPUT and _HAS_CLEAR_OUTPUT})\")\n",
    "print(f\"[INFO] pause_file: {PAUSE_FILE}\")\n",
    "print(f\"[INFO] debug_dir : {DEBUG_DIR}\")\n",
    "print(f\"[INFO] debug_inline_chars: {DEBUG_LOG_INLINE_CHARS}\")\n",
    "if RESUME_FROM_CSV:\n",
    "    print(f\"[INFO] resume_csv: {RESUME_FROM_CSV}\")\n",
    "\n",
    "# --- ãƒ­ã‚°ç”¨ -----------------------------------------------------------\n",
    "class _TeeIO:\n",
    "    def __init__(self, primary, buffer, *, enable_primary: bool = True):\n",
    "        self.primary = primary\n",
    "        self.buffer = buffer\n",
    "        self.enable_primary = bool(enable_primary)\n",
    "    def write(self, s):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.write(s)\n",
    "            except Exception:\n",
    "                pass\n",
    "        self.buffer.write(s)\n",
    "        return len(s)\n",
    "    def flush(self):\n",
    "        if self.enable_primary:\n",
    "            try:\n",
    "                self.primary.flush()\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            self.buffer.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _json_dumps(obj):\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return json.dumps(str(obj), ensure_ascii=False, default=str)\n",
    "\n",
    "def _safe_filename(s: str, max_len: int = 120) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = s.replace(\"/\", \"_\").replace(\":\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = \"\".join(ch if ch.isalnum() or ch in \"._-@\" else \"_\" for ch in s)\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len]\n",
    "    return s\n",
    "\n",
    "def _save_partial(df: pd.DataFrame, suffix: str = \"partial\"):\n",
    "    try:\n",
    "        _ts = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "        path = BASE_DIR / f\"benign_hard{TOTAL_N}_full_eval__evalid_{eval_id}__{suffix}__ts_{_ts}.csv\"\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"[INFO] Saved {suffix} results to: {path}\")\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Failed to save {suffix} results: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- è©•ä¾¡ãƒ«ãƒ¼ãƒ— -------------------------------------------------------\n",
    "results = []\n",
    "start_time = time.time()\n",
    "counts = {\"phish\": 0, \"benign\": 0, \"error\": 0}\n",
    "skipped = 0\n",
    "\n",
    "for i, row in enumerate(benign_hard_sample_df.itertuples(index=False), start=1):\n",
    "    domain = str(row.domain)\n",
    "    ml_prob = float(row.ml_probability)\n",
    "\n",
    "    if processed and domain in processed:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    if PAUSE_FILE.exists():\n",
    "        print(f\"[PAUSE] Detected pause file: {PAUSE_FILE} â†’ stopping safely at {i-1}/{TOTAL_N}.\")\n",
    "        try:\n",
    "            benign_hard_agent_df = pd.DataFrame(results) if results else pd.DataFrame([])\n",
    "            _save_partial(benign_hard_agent_df, suffix=\"partial_pause\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        break\n",
    "\n",
    "    _buf = io.StringIO()\n",
    "    _tee_out = _TeeIO(sys.stdout, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "    _tee_err = _TeeIO(sys.stderr, _buf, enable_primary=SHOW_DOMAIN_LOG_ON_SCREEN)\n",
    "\n",
    "    with redirect_stdout(_tee_out), redirect_stderr(_tee_err):\n",
    "        try:\n",
    "            eval_start = time.time()\n",
    "            res = agent.evaluate(domain=domain, ml_probability=ml_prob)\n",
    "            elapsed = time.time() - eval_start\n",
    "\n",
    "            is_phishing = bool(res.get(\"ai_is_phishing\", False)) if isinstance(res, dict) else False\n",
    "            confidence = float(res.get(\"ai_confidence\") or 0.0) if isinstance(res, dict) else 0.0\n",
    "            risk_level = (res.get(\"ai_risk_level\") if isinstance(res, dict) else \"unknown\") or \"unknown\"\n",
    "\n",
    "            graph_state = res.get(\"graph_state\") if isinstance(res, dict) else {}\n",
    "            tool_res = {}\n",
    "            if isinstance(graph_state, dict):\n",
    "                tool_res = _safe_dict(graph_state.get(\"tool_results\")) or _safe_dict(res.get(\"tool_results\") if isinstance(res, dict) else {})\n",
    "\n",
    "            log_text = _buf.getvalue()\n",
    "            safe_dom = _safe_filename(domain)\n",
    "            log_path = DEBUG_DIR / f\"{i:05d}_{safe_dom}.log.txt\"\n",
    "            try:\n",
    "                log_path.write_text(log_text, encoding=\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                log_path = None\n",
    "\n",
    "            if DEBUG_LOG_INLINE_CHARS == 0:\n",
    "                inline_log = None\n",
    "            elif DEBUG_LOG_INLINE_CHARS < 0:\n",
    "                inline_log = log_text\n",
    "            else:\n",
    "                inline_log = log_text[:DEBUG_LOG_INLINE_CHARS]\n",
    "\n",
    "            row_out = {}\n",
    "            if isinstance(res, dict):\n",
    "                row_out.update(res)\n",
    "\n",
    "            if isinstance(row_out, dict) and \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "                row_out.update(CODE_FP_ROW)\n",
    "\n",
    "            row_out.update({\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": ml_prob,\n",
    "                \"processing_time\": elapsed,\n",
    "                \"debug_log_path\": str(log_path) if log_path else None,\n",
    "                \"debug_log\": inline_log,\n",
    "                \"graph_state_json\": _json_dumps(_safe_dict(graph_state)),\n",
    "                \"tool_results_json\": _json_dumps(_safe_dict(tool_res)),\n",
    "                \"error\": None,\n",
    "            })\n",
    "\n",
    "            # å¿µã®ãŸã‚ã€ä¸»è¦åˆ—ã‚’æ˜ç¤º\n",
    "            row_out.setdefault(\"ai_is_phishing\", is_phishing)\n",
    "            row_out.setdefault(\"ai_confidence\", confidence)\n",
    "            row_out.setdefault(\"ai_risk_level\", risk_level)\n",
    "\n",
    "            results.append(row_out)\n",
    "\n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - eval_start if \"eval_start\" in locals() else 0.0\n",
    "            log_text = _buf.getvalue()\n",
    "            safe_dom = _safe_filename(domain)\n",
    "            log_path = DEBUG_DIR / f\"{i:05d}_{safe_dom}.log.txt\"\n",
    "            try:\n",
    "                log_path.write_text(log_text, encoding=\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                log_path = None\n",
    "\n",
    "            results.append({\n",
    "                **(CODE_FP_ROW if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict) else {}),\n",
    "                \"domain\": domain,\n",
    "                \"ml_probability\": ml_prob,\n",
    "                \"ai_is_phishing\": False,\n",
    "                \"ai_confidence\": 0.0,\n",
    "                \"ai_risk_level\": \"error\",\n",
    "                \"processing_time\": elapsed,\n",
    "                \"debug_log_path\": str(log_path) if log_path else None,\n",
    "                \"debug_log\": None,\n",
    "                \"graph_state_json\": _json_dumps({}),\n",
    "                \"tool_results_json\": _json_dumps({}),\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "\n",
    "    last = results[-1] if results else None\n",
    "    if last is not None:\n",
    "        if last.get(\"error\"):\n",
    "            counts[\"error\"] += 1\n",
    "        else:\n",
    "            if bool(last.get(\"ai_is_phishing\")):\n",
    "                counts[\"phish\"] += 1\n",
    "            else:\n",
    "                counts[\"benign\"] += 1\n",
    "\n",
    "    if (not SHOW_DOMAIN_LOG_ON_SCREEN) and (\n",
    "        (i % PROGRESS_EVERY == 0) or (i == TOTAL_N) or (last and last.get(\"error\"))\n",
    "    ):\n",
    "        if _HAS_CLEAR_OUTPUT and _USE_CLEAR_OUTPUT:\n",
    "            try:\n",
    "                clear_output(wait=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        elapsed_total = time.time() - start_time\n",
    "        mark = \"âŒ\" if (last and last.get(\"error\")) else (\"ğŸ”´\" if (last and last.get(\"ai_is_phishing\")) else \"ğŸŸ¢\")\n",
    "        dom  = last.get(\"domain\", \"-\") if last else \"-\"\n",
    "        mlp  = float(last.get(\"ml_probability\") or 0.0) if last else 0.0\n",
    "        conf = float(last.get(\"ai_confidence\") or 0.0) if last else 0.0\n",
    "        rl   = last.get(\"ai_risk_level\", \"-\") if last else \"-\"\n",
    "        tsec = float(last.get(\"processing_time\") or 0.0) if last else 0.0\n",
    "\n",
    "        print(f\"[PROGRESS] {i}/{TOTAL_N}  phishing={counts['phish']}  benign={counts['benign']}  error={counts['error']}  skipped={skipped}  elapsed={elapsed_total:.1f}s\")\n",
    "        print(f\"          last: {mark} {dom} (ML={mlp:.3f} risk={rl} conf={conf:.2f} t={tsec:.2f}s)\")\n",
    "        if last and last.get(\"error\"):\n",
    "            print(f\"          last_error: {last.get('error')}\")\n",
    "\n",
    "        # autosaveï¼ˆå®‰å…¨ã®ãŸã‚ï¼‰\n",
    "        try:\n",
    "            benign_hard_agent_df = pd.DataFrame(results) if results else pd.DataFrame([])\n",
    "            _save_partial(benign_hard_agent_df, suffix=\"partial_auto\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 80)\n",
    "print(f\"[INFO] BENIGN_HARD evaluation complete! Total time: {total_time:.2f}s\")\n",
    "if skipped:\n",
    "    print(f\"[INFO] skipped (resume): {skipped} domains\")\n",
    "\n",
    "benign_hard_agent_df = pd.DataFrame(results)\n",
    "\n",
    "benign_hard_eval_df = benign_hard_sample_df.merge(\n",
    "    benign_hard_agent_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "    on=\"domain\",\n",
    "    how=\"left\",\n",
    ")\n",
    "benign_hard_eval_df[\"label\"] = 0  # ground truth\n",
    "\n",
    "benign_hard_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dafa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === è¿½åŠ ã‚»ãƒ«: benign_hard è©•ä¾¡çµæœã‚’CSVã¸ä¿å­˜ï¼ˆå…±æœ‰ç”¨ï¼‰ ===\n",
    "import datetime\n",
    "\n",
    "ts = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "eval_id = None\n",
    "if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "    eval_id = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "if not eval_id:\n",
    "    eval_id = ts\n",
    "\n",
    "# 1) ãƒ©ãƒ™ãƒ«ä»˜ãç°¡æ˜“ã‚µãƒãƒª\n",
    "eval_path = BASE_DIR / f\"benign_hard{len(benign_hard_eval_df)}_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_eval_df.to_csv(eval_path, index=False)\n",
    "\n",
    "# 2) ãƒ•ãƒ«ãƒ­ã‚°ï¼ˆagent.evaluate ã®ç”Ÿå‡ºåŠ›ã‚’å«ã‚€ï¼‰\n",
    "full_path = BASE_DIR / f\"benign_hard{len(benign_hard_agent_df)}_full_eval__evalid_{eval_id}__ts_{ts}.csv\"\n",
    "benign_hard_agent_df.to_csv(full_path, index=False)\n",
    "\n",
    "print('saved:', eval_path)\n",
    "print('saved:', full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c9e08-5d3c-4a3d-9f0d-c48022b7fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«5: FN ã‚µãƒ³ãƒ—ãƒ«å´ã®æ•´å½¢ (å…¨éƒ¨ label=1) ===\n",
    "\n",
    "# target_df: FN ã‚µãƒ³ãƒ—ãƒ«ï¼ˆn=len(target_df), å…¨éƒ¨ phishæƒ³å®šï¼‰\n",
    "# results_df: target_df ã«å¯¾ã—ã¦ agent.evaluate() æ¸ˆã¿ã® DataFrame\n",
    "fn_eval_df = (\n",
    "    target_df[[\"domain\", \"ml_probability\"]]\n",
    "    .merge(\n",
    "        results_df[[\"domain\", \"ai_is_phishing\", \"ai_confidence\", \"ai_risk_level\"]],\n",
    "        on=\"domain\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "fn_eval_df[\"label\"] = 1  # ground truth = phishing\n",
    "fn_eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be900d16-c5ac-4bc3-8904-ef2a600e3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«6: phishN + benignN ã‚’çµåˆ ===\n",
    "\n",
    "eval_df = pd.concat(\n",
    "    [fn_eval_df, benign_eval_df],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "print(eval_df[[\"label\", \"ai_is_phishing\"]].value_counts())\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7d6dc-f7e2-4a35-a37c-6dcacb8f8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ã‚»ãƒ«7: Agent å˜ä½“ã®æ··åŒè¡Œåˆ—ã¨å„ç¨®æŒ‡æ¨™ã‚’è¨ˆç®— ===\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ConfusionResult:\n",
    "    TP: int\n",
    "    FP: int\n",
    "    TN: int\n",
    "    FN: int\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    fbeta: float\n",
    "    fpr: float\n",
    "\n",
    "def compute_confusion_and_scores(\n",
    "    df: pd.DataFrame,\n",
    "    label_col: str = \"label\",\n",
    "    pred_col: str = \"ai_is_phishing\",\n",
    "    beta: float = 2.0,\n",
    ") -> ConfusionResult:\n",
    "    y_true = df[label_col].astype(int).to_numpy()\n",
    "    y_pred = df[pred_col].astype(int).to_numpy()\n",
    "\n",
    "    tp = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    fp = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    tn = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    fn = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    beta2 = beta ** 2\n",
    "    denom = beta2 * precision + recall\n",
    "    fbeta = ((1 + beta2) * precision * recall) / denom if denom > 0 else 0.0\n",
    "\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "    return ConfusionResult(tp, fp, tn, fn, precision, recall, f1, fbeta, fpr)\n",
    "\n",
    "metrics_agent = compute_confusion_and_scores(eval_df, beta=2.0)\n",
    "metrics_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5c681-d436-4ad3-acd0-5b1ad993a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã„ã¾ã®ã¾ã¾ã§ã‚‚OKãª FP/FN ã®æŠ½å‡º\n",
    "is_tp = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_fp = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 1)\n",
    "is_tn = (eval_df[\"label\"] == 0) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "is_fn = (eval_df[\"label\"] == 1) & (eval_df[\"ai_is_phishing\"] == 0)\n",
    "\n",
    "tp_df = eval_df[is_tp].copy()\n",
    "fp_df = eval_df[is_fp].copy()\n",
    "tn_df = eval_df[is_tn].copy()\n",
    "fn_df = eval_df[is_fn].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2aaf4-1e46-4285-85a6-81e94b0479cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å€™è£œã«ã™ã‚‹åˆ—ï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦å¢—æ¸›OKï¼‰\n",
    "candidate_cols = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "    \"error\",\n",
    "    \"phase\",\n",
    "    \"graph_state\",\n",
    "    # \"tools_used\",  # â† ä»Šã¯ç„¡ã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ\n",
    "]\n",
    "\n",
    "# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã ã‘ã‚’ä½¿ã†\n",
    "fp_cols = [c for c in candidate_cols if c in fp_df.columns]\n",
    "fn_cols = [c for c in candidate_cols if c in fn_df.columns]\n",
    "\n",
    "print(\"FP columns:\", fp_cols)\n",
    "display(fp_df[fp_cols].head(20))\n",
    "\n",
    "print(\"FN columns:\", fn_cols)\n",
    "display(fn_df[fn_cols].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dce5d-19e9-45a0-9850-d39b9a2baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# FP / FN åˆ†æCSVã®ç”Ÿæˆï¼ˆeval_id å›ºå®šãƒ»å‚ç…§å…ƒå›ºå®šç‰ˆï¼‰\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== Export FP/FN analysis CSVs (eval_id-fixed) ===\")\n",
    "\n",
    "# è¿½è·¡ç”¨ã®æŒ‡ç´‹åˆ—ï¼ˆå­˜åœ¨ã™ã‚‹åˆ†ã ã‘ä½¿ã†ï¼‰\n",
    "FINGERPRINT_COLS = [\n",
    "    \"eval_id\",\n",
    "    \"phase6_policy_version_code\",\n",
    "    \"phase6_wiring_file\",\n",
    "    \"phase6_wiring_sha256\",\n",
    "    \"llm_final_decision_file\",\n",
    "    \"llm_final_decision_sha256\",\n",
    "    \"langgraph_module_file\",\n",
    "    \"langgraph_module_sha256\",\n",
    "    \"dual_import_langgraph_module\",\n",
    "]\n",
    "\n",
    "BASE_CASE_COLS = [\n",
    "    \"domain\",\n",
    "    \"label\",\n",
    "    \"ml_probability\",\n",
    "    \"ai_is_phishing\",\n",
    "    \"ai_confidence\",\n",
    "    \"ai_risk_level\",\n",
    "]\n",
    "\n",
    "def _infer_eval_id(*dfs) -> str:\n",
    "    # 1) CODE_FP_ROW ã‚’æœ€å„ªå…ˆï¼ˆNotebookå®Ÿè¡Œå˜ä½ã§å›ºå®šã•ã‚Œã‚‹æƒ³å®šï¼‰\n",
    "    if \"CODE_FP_ROW\" in globals() and isinstance(globals().get(\"CODE_FP_ROW\"), dict):\n",
    "        _eid = globals()[\"CODE_FP_ROW\"].get(\"eval_id\")\n",
    "        if _eid:\n",
    "            return str(_eid)\n",
    "\n",
    "    # 2) å„DFã® eval_id ãŒå˜ä¸€ãªã‚‰ãã‚Œã‚’æ¡ç”¨\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame) and \"eval_id\" in df.columns:\n",
    "            vals = df[\"eval_id\"].dropna().astype(str).unique()\n",
    "            if len(vals) == 1:\n",
    "                return vals[0]\n",
    "\n",
    "    # 3) æœ€å¾Œã®æ‰‹æ®µ\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "def _existing(cols, df):\n",
    "    return [c for c in cols if isinstance(df, pd.DataFrame) and c in df.columns]\n",
    "\n",
    "def _export_cases_and_details(*, full_df: pd.DataFrame, label: int, dataset_tag: str, out_dir: Path):\n",
    "    \"\"\"full_dfï¼ˆï¼ãã®å®Ÿè¡Œã§ä½œã£ãŸfull_eval DFï¼‰ã ã‘ã‚’å‚ç…§ã—ã¦ FN/FP ã‚’ä½œã‚‹\"\"\"\n",
    "    assert isinstance(full_df, pd.DataFrame)\n",
    "\n",
    "    eval_id = _infer_eval_id(full_df)\n",
    "    fp_cols = _existing(FINGERPRINT_COLS, full_df)\n",
    "\n",
    "    # ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ï¼ˆdetails / cases ä¸¡æ–¹ã«å…¥ã‚Œã‚‹ï¼‰\n",
    "    df = full_df.copy()\n",
    "    df[\"label\"] = label\n",
    "\n",
    "    if label == 1:\n",
    "        # FN: phishing(1) ãªã®ã« ai_is_phishing=False\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == False)\n",
    "        kind = \"fn\"\n",
    "    else:\n",
    "        # FP: benign(0) ãªã®ã« ai_is_phishing=True\n",
    "        cases_mask = (df[\"ai_is_phishing\"] == True)\n",
    "        kind = \"fp\"\n",
    "\n",
    "    cases_df = df.loc[cases_mask, _existing(BASE_CASE_COLS, df) + fp_cols].copy()\n",
    "    details_df = df.loc[cases_mask].copy()\n",
    "\n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«åã¯å¿…ãš eval_id ã‚’å«ã‚ã‚‹ï¼ˆrun_id ç”±æ¥ã®èª¤èªé˜²æ­¢ï¼‰\n",
    "    cases_path = out_dir / f\"{kind}_cases_full_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "    details_path = out_dir / f\"{kind}_details_for_analysis__{dataset_tag}__evalid_{eval_id}.csv\"\n",
    "\n",
    "    cases_df.to_csv(cases_path, index=False)\n",
    "    details_df.to_csv(details_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": dataset_tag,\n",
    "        \"label\": label,\n",
    "        \"kind\": kind,\n",
    "        \"eval_id\": eval_id,\n",
    "        \"n_total\": int(len(full_df)),\n",
    "        \"n_cases\": int(len(cases_df)),\n",
    "        \"cases_path\": str(cases_path),\n",
    "        \"details_path\": str(details_path),\n",
    "        \"fingerprint_cols\": \",\".join(fp_cols),\n",
    "    }\n",
    "\n",
    "# å‡ºåŠ›å…ˆï¼ˆLOGS_DIR ãŒã‚ã‚Œã°ãã“ã€ãªã‘ã‚Œã°ã‚«ãƒ¬ãƒ³ãƒˆ/BASE_DIRï¼‰\n",
    "out_dir = None\n",
    "if \"LOGS_DIR\" in globals() and globals().get(\"LOGS_DIR\"):\n",
    "    out_dir = Path(globals()[\"LOGS_DIR\"])\n",
    "elif \"BASE_DIR\" in globals() and globals().get(\"BASE_DIR\"):\n",
    "    out_dir = Path(globals()[\"BASE_DIR\"])\n",
    "else:\n",
    "    out_dir = Path(\".\")\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "manifest = []\n",
    "\n",
    "# --- randomï¼ˆphishæƒ³å®šï¼‰: results_df ãŒ full_eval ---\n",
    "if \"results_df\" in globals() and isinstance(globals().get(\"results_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"results_df\"],\n",
    "            label=1,\n",
    "            dataset_tag=f\"random{len(globals()['results_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) results_df not found -> random FN export skipped\")\n",
    "\n",
    "# --- benign: benign_agent_df ãŒ full_eval ---\n",
    "if \"benign_agent_df\" in globals() and isinstance(globals().get(\"benign_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign{len(globals()['benign_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_agent_df not found -> benign FP export skipped\")\n",
    "\n",
    "# --- benign_hard: benign_hard_agent_df ãŒ full_eval ---\n",
    "if \"benign_hard_agent_df\" in globals() and isinstance(globals().get(\"benign_hard_agent_df\"), pd.DataFrame):\n",
    "    manifest.append(\n",
    "        _export_cases_and_details(\n",
    "            full_df=globals()[\"benign_hard_agent_df\"],\n",
    "            label=0,\n",
    "            dataset_tag=f\"benign_hard{len(globals()['benign_hard_agent_df'])}\",\n",
    "            out_dir=out_dir,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"  (skip) benign_hard_agent_df not found -> hard FP export skipped\")\n",
    "\n",
    "manifest_df = pd.DataFrame(manifest)\n",
    "manifest_path = out_dir / f\"analysis_manifest__evalid_{_infer_eval_id(*(globals().get(n) for n in ['results_df','benign_agent_df','benign_hard_agent_df']))}.csv\"\n",
    "manifest_df.to_csv(manifest_path, index=False)\n",
    "\n",
    "print(\"\\nSaved analysis CSVs to:\")\n",
    "for r in manifest:\n",
    "    print(f\"  - {r['kind'].upper()} {r['dataset']}: {r['n_cases']}/{r['n_total']}\")\n",
    "    print(f\"      cases  : {r['cases_path']}\")\n",
    "    print(f\"      details: {r['details_path']}\")\n",
    "print(f\"  - manifest : {manifest_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa2916-6315-4f1c-867b-cfe9f42252d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === ConfusionResult ã‹ã‚‰æ··åŒè¡Œåˆ—ã‚’ä½œæˆ ===\n",
    "cm = np.array([\n",
    "    [metrics_agent.TN, metrics_agent.FP],\n",
    "    [metrics_agent.FN, metrics_agent.TP],\n",
    "])\n",
    "\n",
    "labels = [\"benign (0)\", \"phish (1)\"]\n",
    "\n",
    "# å¯è¦–åŒ–ã—ãŸã„æŒ‡æ¨™ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¢—æ¸›ã•ã›ã¦ãã ã•ã„ï¼‰\n",
    "score_names = [\"precision\", \"recall\", \"f1\", \"fbeta\", \"fpr\"]\n",
    "score_values = [\n",
    "    metrics_agent.precision,\n",
    "    metrics_agent.recall,\n",
    "    metrics_agent.f1,\n",
    "    metrics_agent.fbeta,\n",
    "    metrics_agent.fpr,\n",
    "]\n",
    "\n",
    "# === æç”» ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# 1) æ··åŒè¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "ax = axes[0]\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "# è»¸ãƒ©ãƒ™ãƒ«\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
    "ax.set_yticklabels([\"True 0\", \"True 1\"])\n",
    "ax.set_xlabel(\"Predicted label\")\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_title(\"Confusion Matrix (Agent)\")\n",
    "\n",
    "# å€¤ã‚’ãƒã‚¹ã®ä¸Šã«è¡¨ç¤º\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(\n",
    "            j, i,\n",
    "            cm[i, j],\n",
    "            ha=\"center\", va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# 2) Precision / Recall / F1 / Fbeta / FPR ã®æ£’ã‚°ãƒ©ãƒ•\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(score_names))\n",
    "ax2.bar(x, score_values)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(score_names, rotation=30)\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "ax2.set_ylabel(\"Score\")\n",
    "ax2.set_title(\"Agent Metrics (eval_df)\")\n",
    "\n",
    "# å€¤ã‚’æ£’ã®ä¸Šã«è¡¨ç¤ºï¼ˆå°æ•°3æ¡ï¼‰\n",
    "for i, v in enumerate(score_values):\n",
    "    ax2.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18807a01-7020-4be8-99b7-771d86c83f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43616881-c74e-4902-a2c0-41b7e67af685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7035e94-c14a-43d2-9439-7ea533b6cbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
