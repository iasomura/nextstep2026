{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b485f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4498c517-74f2-4df5-b3b5-fde10e9e6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] RUN_ID = 2025-10-27_082036 | paths.RUN_ID = 2025-10-27_082036\n"
     ]
    }
   ],
   "source": [
    "# === Cell 0 (01_* Áî®): Êñ∞„Åó„ÅÑRUN„ÇíÁô∫Ë°å„Åó„Å¶„Åã„Çâ paths „ÇíË™≠„ÇÄ ===\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.new_run()  # „Çø„Ç§„É†„Çπ„Çø„É≥„Éó„ÅßÊñ∞Ë¶è RUN_ID Áô∫Ë°å‚Üí„Éï„Ç°„Ç§„É´ & Áí∞Â¢ÉÂ§âÊï∞„Å´‰øùÂ≠ò\n",
    "\n",
    "import importlib  # ‚Üê „Åì„Åì„ÅßÂàù„ÇÅ„Å¶ paths „Çí import\n",
    "import _compat.paths as paths\n",
    "importlib.reload(paths)\n",
    "print(\"[01] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea90a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ IO guard ready -> artifacts/2025-10-27_082036\n"
     ]
    }
   ],
   "source": [
    "# === IO PATHS (auto-added guard) ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "if 'RUN_ID' not in globals():\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\") or datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "ARTIFACTS = Path(\"artifacts\") / RUN_ID\n",
    "RAW = ARTIFACTS / \"raw\"\n",
    "PROCESSED = ARTIFACTS / \"processed\"\n",
    "MODELS = ARTIFACTS / \"models\"\n",
    "RESULTS = ARTIFACTS / \"results\"\n",
    "HANDOFF = ARTIFACTS / \"handoff\"\n",
    "LOGS = ARTIFACTS / \"logs\"\n",
    "TRACES = ARTIFACTS / \"traces\"\n",
    "for _p in [RAW, PROCESSED, MODELS, RESULTS, HANDOFF, LOGS, TRACES]:\n",
    "    _p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# string shortcuts (compat)\n",
    "RAW_DIR = str(RAW); PROCESSED_DIR = str(PROCESSED); MODELS_DIR = str(MODELS)\n",
    "RESULTS_DIR = str(RESULTS); HANDOFF_DIR = str(HANDOFF); LOGS_DIR = str(LOGS); TRACES_DIR = str(TRACES)\n",
    "\n",
    "base_dirs = {'raw': RAW_DIR, 'data': PROCESSED_DIR, 'models': MODELS_DIR,\n",
    "             'results': RESULTS_DIR, 'handoff': HANDOFF_DIR, 'logs': LOGS_DIR, 'traces': TRACES_DIR}\n",
    "def resolve(p): p = Path(p); p.mkdir(parents=True, exist_ok=True); return str(p)\n",
    "def ensure_roots(): pass\n",
    "def load_config(): return {\"root\": str(ARTIFACTS), \"run_id\": RUN_ID}\n",
    "\n",
    "print(f\"‚úÖ IO guard ready -> artifacts/{RUN_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1dcc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, \"./\")\n",
    "from _compat.paths import resolve, ensure_roots, load_config, compat_base_dirs\n",
    "ensure_roots()\n",
    "CFG = load_config()\n",
    "base_dirs = dict(compat_base_dirs)  # Êó¢Â≠ò„Ç≥„Éº„Éâ‰∫íÊèõ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7d6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- RUN_ID „Çí‰∏ÄÂ∫¶„Å†„ÅëÊ±∫„ÇÅ„Å¶Âõ∫ÂÆöÔºàÂêå‰∏Ä„Éé„Éº„ÉàÔºèÂêå‰∏ÄÂÆüË°å„Åß„Éñ„É¨„Å™„ÅÑÔºâ----\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if \"RUN_ID\" not in globals():\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\") or datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    os.environ[\"RUN_ID\"] = RUN_ID  # Âêå‰∏Ä„Ç´„Éº„Éç„É´ÂÜÖ„Åß‰ªñ„Éé„Éº„Éà„Å´„ÇÇÂÖ±Êúâ„Åó„Åü„ÅÑÂ†¥Âêà„ÅÆ„Åø\n",
    "\n",
    "# Êó¢Â≠ò„ÅÆ base_dirs „ÅÆÊµÅÂÑÄ„ÅØ„Åù„ÅÆ„Åæ„ÅæÔºàÔºùÊ©üËÉΩ‰∏çÂ§âÔºâ\n",
    "base_dirs['results'] = f\"results/{RUN_ID}\"\n",
    "\n",
    "# Ôºà‰ªªÊÑèÔºâ‰Ωø„ÅÜ„Å™„ÇâËß£Ê±∫Ê∏à„Åø„Éë„Çπ„Çí1„Å§„Å†„Åë‰Ωú„Å£„Å¶„Åä„Åè\n",
    "RESULTS_DIR = resolve(base_dirs['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1904a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_ID = 2025-10-27_082036\n",
      "RESULTS_DIR = results/2025-10-27_082036\n"
     ]
    }
   ],
   "source": [
    "print(\"RUN_ID =\", RUN_ID)\n",
    "print(\"RESULTS_DIR =\", RESULTS_DIR)   # ‰æã: .../artifacts/2025-10-12_080143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9256ef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Ë®≠ÂÆöË™≠„ÅøËæº„ÅøÂÆå‰∫Ü: DEVELOPMENT_MODE=False, CERT_ONLY(optional)=False\n",
      "   DB: rapids_data@localhost:5432 (read_only=True)\n",
      "‚úÖ Êú¨Áï™„É¢„Éº„ÉâÔºöÂÖ®„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Åæ„Åô\n",
      "‚úÖ Êú¨Áï™„É¢„Éº„ÉâÔºöÂÖ®„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Åæ„Åô\n",
      "üìÅ Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™: data/raw/2025-10-27_082037\n",
      "üÜî „Çª„ÉÉ„Ç∑„Éß„É≥ID: 2025-10-27_082037\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "„Éó„É≠„Ç∞„É©„É†Âêç: 01_data_preparation.py\n",
    "Ê¶ÇË¶Å: „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ê§úÁü•„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„ÇøÊ∫ñÂÇôÔºà„É©„Éô„É´‰ªò„Åç„Éá„Éº„Çø„ÅÆÂèñÂæóÔºâ\n",
    "ÁõÆÁöÑ: ÂõΩÈöõÂ≠¶‰ºöË´ñÊñá„Åß„ÅÆÁô∫Ë°®ÔºàML„Å®LLM„ÅÆ„Éè„Ç§„Éñ„É™„ÉÉ„Éâ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅÆÂÆüË®ºÔºâ\n",
    "‰ΩúÊàêÊó•: 2025-07-20\n",
    "‰æùÂ≠òÈñ¢‰øÇ: PostgreSQL„Éá„Éº„Çø„Éô„Éº„ÇπÔºàrapids_dataÔºâ\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "„Çª„É´Áï™Âè∑: 1\n",
    "Ê¶ÇË¶Å: „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà„Å®„Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öË®≠ÂÆö\n",
    "ÂÖ•Âäõ: „Å™„Åó\n",
    "Âá∫Âäõ: DBÊé•Á∂öË®≠ÂÆö„ÄÅÂü∫Êú¨Ë®≠ÂÆöÂ§âÊï∞\n",
    "\"\"\"\n",
    "\n",
    "# === CONFIG (ËøΩÂä†) ===\n",
    "import os, json, yaml\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "cfg: Dict[str, Any] = {}\n",
    "\n",
    "def _deep_update(base: dict, override: dict) -> dict:\n",
    "    for k, v in (override or {}).items():\n",
    "        if isinstance(v, dict) and isinstance(base.get(k), dict):\n",
    "            base[k] = _deep_update(base[k], v)\n",
    "        else:\n",
    "            base[k] = v\n",
    "    return base\n",
    "\n",
    "def load_configuration(config_path: Optional[str] = None,\n",
    "                       cfg_override: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    01_data_preparation_fixed.py Áî®„ÅÆConfigË™≠„ÅøËæº„ÅøÁµ±ÂêàÈñ¢Êï∞\n",
    "    ÂÑ™ÂÖàÈ†Ü‰Ωç: APIÂºïÊï∞(cfg_override) > Áí∞Â¢ÉÂ§âÊï∞ > Ë®≠ÂÆö„Éï„Ç°„Ç§„É´ > „Éá„Éï„Ç©„É´„Éà\n",
    "    Êàª„ÇäÂÄ§: Áµ±ÂêàÊ∏à„ÅøcfgËæûÊõ∏\n",
    "    \"\"\"\n",
    "    default = {\n",
    "        \"system\": {\n",
    "            \"cert_only_mode\": False,   # CERT-ONLYÂªÉÊ≠¢Ôºà‰ªªÊÑèÔºâ\n",
    "            \"seed\": 42,\n",
    "            \"development_mode\": False\n",
    "        },\n",
    "        \"db\": {\n",
    "            \"dbname\": \"rapids_data\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"asomura\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": \"5432\",\n",
    "            \"read_only\": True,\n",
    "            \"timeout_s\": 30\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"dev_limit\": 1000,\n",
    "            \"balance_data\": True,\n",
    "            \"remove_duplicates\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cfg_all = dict(default)\n",
    "\n",
    "    def _load_file(path: str):\n",
    "        try:\n",
    "            if path and os.path.exists(path):\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    if path.endswith((\".yml\", \".yaml\")):\n",
    "                        return yaml.safe_load(f) or {}\n",
    "                    return json.load(f) or {}\n",
    "        except Exception:\n",
    "            pass\n",
    "        return {}\n",
    "\n",
    "    if config_path:\n",
    "        cfg_all = _deep_update(cfg_all, _load_file(config_path))\n",
    "\n",
    "    env_map = {\n",
    "        \"CERT_ONLY_MODE\": (\"system\", \"cert_only_mode\"),\n",
    "        \"DEV_MODE\": (\"system\", \"development_mode\"),\n",
    "        \"PGDATABASE\": (\"db\", \"dbname\"),\n",
    "        \"PGUSER\": (\"db\", \"user\"),\n",
    "        \"PGPASSWORD\": (\"db\", \"password\"),\n",
    "        \"PGHOST\": (\"db\", \"host\"),\n",
    "        \"PGPORT\": (\"db\", \"port\"),\n",
    "    }\n",
    "    for env_key, path in env_map.items():\n",
    "        val = os.getenv(env_key, None)\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, str) and val.lower() in (\"true\", \"false\"):\n",
    "            val = val.lower() == \"true\"\n",
    "        node = cfg_all\n",
    "        for k in path[:-1]:\n",
    "            node = node.setdefault(k, {})\n",
    "        node[path[-1]] = val\n",
    "\n",
    "    if cfg_override:\n",
    "        cfg_all = _deep_update(cfg_all, cfg_override)\n",
    "\n",
    "    # CERT-ONLY Âº∑Âà∂„ÉÅ„Çß„ÉÉ„ÇØ„ÅØÂâäÈô§\n",
    "    db = cfg_all.get(\"db\", {})\n",
    "    for key in [\"dbname\", \"user\", \"host\", \"port\"]:\n",
    "        if not db.get(key):\n",
    "            raise ValueError(f\"DBË®≠ÂÆö„Å´ÂøÖÈ†àÈ†ÖÁõÆ„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„Åæ„Åô: db.{key}\")\n",
    "\n",
    "    global cfg, DB_CONFIG, DEVELOPMENT_MODE, DATA_LIMIT\n",
    "    cfg = cfg_all\n",
    "    DB_CONFIG = {\n",
    "        \"dbname\": str(cfg_all[\"db\"][\"dbname\"]),\n",
    "        \"user\": str(cfg_all[\"db\"][\"user\"]),\n",
    "        \"password\": str(cfg_all[\"db\"].get(\"password\", \"\")),\n",
    "        \"host\": str(cfg_all[\"db\"][\"host\"]),\n",
    "        \"port\": str(cfg_all[\"db\"][\"port\"]),\n",
    "    }\n",
    "    DEVELOPMENT_MODE = bool(cfg_all[\"system\"].get(\"development_mode\", False))\n",
    "    DATA_LIMIT = int(cfg_all[\"data\"].get(\"dev_limit\", 1000)) if DEVELOPMENT_MODE else None\n",
    "    print(f\"üîß Ë®≠ÂÆöË™≠„ÅøËæº„ÅøÂÆå‰∫Ü: DEVELOPMENT_MODE={DEVELOPMENT_MODE}, CERT_ONLY(optional)={cfg_all['system'].get('cert_only_mode', False)}\")\n",
    "    print(f\"   DB: {DB_CONFIG['dbname']}@{DB_CONFIG['host']}:{DB_CONFIG['port']} (read_only={cfg_all['db'].get('read_only', True)})\")\n",
    "    return cfg_all\n",
    "\n",
    "if 'cfg' not in globals() or not cfg:\n",
    "    try:\n",
    "        load_configuration(os.getenv(\"CONFIG_PATH\", None))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ConfigË™≠„ÅøËæº„ÅøË≠¶Âëä: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öË®≠ÂÆö\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# ÈñãÁô∫„É¢„Éº„Éâ„ÅÆË®≠ÂÆöÔºàÁí∞Â¢ÉÂ§âÊï∞„ÅßÂà∂Âæ°Ôºâ\n",
    "DEVELOPMENT_MODE = bool(cfg['system'].get('development_mode', False))\n",
    "if DEVELOPMENT_MODE:\n",
    "    DATA_LIMIT = int(cfg['data'].get('dev_limit', 1000))\n",
    "    print(f\"‚ö†Ô∏è Ë≠¶ÂëäÔºöÈñãÁô∫„É¢„Éº„Éâ„Åß„Éá„Éº„Çø„Çí{DATA_LIMIT}‰ª∂„Å´Âà∂Èôê„Åó„Å¶„ÅÑ„Åæ„Åô\")\n",
    "    print(\"‚ö†Ô∏è Êú¨Áï™ÂÆüË°åÊôÇ„ÅØÈñãÁô∫„É¢„Éº„Éâ„ÇíÁÑ°ÂäπÂåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºàcfg.system.development_mode=falseÔºâ\")\n",
    "else:\n",
    "    DATA_LIMIT = None  # ÂÖ®„Éá„Éº„Çø‰ΩøÁî®\n",
    "    print(\"‚úÖ Êú¨Áï™„É¢„Éº„ÉâÔºöÂÖ®„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Åæ„Åô\")\n",
    "    print(\"‚úÖ Êú¨Áï™„É¢„Éº„ÉâÔºöÂÖ®„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Åæ„Åô\")\n",
    "\n",
    "# „Çª„ÉÉ„Ç∑„Éß„É≥ID„ÅÆÁîüÊàê\n",
    "session_id = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "output_dir = Path(f\"data/raw/{session_id}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™: {output_dir}\")\n",
    "print(f\"üÜî „Çª„ÉÉ„Ç∑„Éß„É≥ID: {session_id}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b245501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîå „Éá„Éº„Çø„Éô„Éº„Çπ„Å´Êé•Á∂ö‰∏≠...\n",
      "‚úÖ „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öÊàêÂäü\n",
      "üìä „Éá„Éº„ÇøÂèñÂæó„ÇíÈñãÂßã„Åó„Åæ„Åô...\n",
      "\n",
      "üé£ PHISHTANK„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3851014/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ ÂèñÂæóÊàêÂäü: 54,362‰ª∂\n",
      "\n",
      "üé£ JPCERT„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3851014/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ ÂèñÂæóÊàêÂäü: 116,647‰ª∂\n",
      "\n",
      "üé£ CERTIFICATES„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3851014/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ ÂèñÂæóÊàêÂäü: 196,392‰ª∂\n",
      "\n",
      "‚úÖ Ê≠£Â∏∏„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3851014/2411644574.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  trusted_df = pd.read_sql(trusted_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ ÂèñÂæóÊàêÂäü: 450,656‰ª∂\n",
      "\n",
      "üìä „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„ÇøÁµ±ÂêàÂÆå‰∫Ü: 367,401‰ª∂\n",
      "\n",
      "‚úÖ „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„ÇíÈñâ„Åò„Åæ„Åó„Åü\n",
      "\n",
      "================================================================================\n",
      "üìä „Éá„Éº„ÇøÂèñÂæóÁµêÊûú„Çµ„Éû„É™„Éº\n",
      "================================================================================\n",
      "\n",
      "üé£ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø:\n",
      "  - Á∑è‰ª∂Êï∞: 367,401‰ª∂\n",
      "  - „ÇΩ„Éº„ÇπÂà•ÂÜÖË®≥:\n",
      "    - certificates: 196,392‰ª∂\n",
      "    - jpcert: 116,647‰ª∂\n",
      "    - phishtank: 54,362‰ª∂\n",
      "\n",
      "‚úÖ Ê≠£Â∏∏„Éá„Éº„Çø:\n",
      "  - Á∑è‰ª∂Êï∞: 450,656‰ª∂\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "„Çª„É´Áï™Âè∑: 2\n",
    "Ê¶ÇË¶Å: „Éá„Éº„Çø„Éô„Éº„Çπ„Åã„ÇâÂêÑ„ÉÜ„Éº„Éñ„É´„ÅÆ„É©„Éô„É´‰ªò„Åç„Éá„Éº„Çø„ÇíÂèñÂæó\n",
    "ÂÖ•Âäõ: DB_CONFIG, DATA_LIMIT\n",
    "Âá∫Âäõ: phishing_data_list, trusted_data\n",
    "\"\"\"\n",
    "\n",
    "def fetch_labeled_data(conn, limit: Optional[int] = None) -> Tuple[List[pd.DataFrame], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    „É©„Éô„É´‰ªò„Åç„Éá„Éº„Çø„ÇíÂèñÂæó„Åô„ÇãÈñ¢Êï∞\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[pd.DataFrame], pd.DataFrame]: („Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„ÅÆ„É™„Çπ„Éà, Ê≠£Â∏∏„Éá„Éº„Çø)\n",
    "    \"\"\"\n",
    "    \n",
    "    # LIMIT„ÅÆË®≠ÂÆö\n",
    "    limit_clause = f\"LIMIT {limit}\" if limit else \"\"\n",
    "    \n",
    "    # „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„ÅÆ„ÇØ„Ç®„É™ÂÆöÁæ©\n",
    "    phishing_queries = {\n",
    "        'phishtank': f\"\"\"\n",
    "            SELECT \n",
    "                cert_domain as domain,\n",
    "                cert_data,\n",
    "                'phishtank' as source,\n",
    "                1 as label\n",
    "            FROM phishtank_entries\n",
    "            WHERE cert_status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND cert_domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\",\n",
    "        'jpcert': f\"\"\"\n",
    "            SELECT \n",
    "                domain,\n",
    "                cert_data,\n",
    "                'jpcert' as source,\n",
    "                1 as label\n",
    "            FROM jpcert_phishing_urls\n",
    "            WHERE status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\",\n",
    "        'certificates': f\"\"\"\n",
    "            SELECT \n",
    "                domain,\n",
    "                cert_data,\n",
    "                'certificates' as source,\n",
    "                1 as label\n",
    "            FROM certificates\n",
    "            WHERE status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # Ê≠£Â∏∏„Éá„Éº„Çø„ÅÆ„ÇØ„Ç®„É™\n",
    "    trusted_query = f\"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            cert_data,\n",
    "            'trusted' as source,\n",
    "            0 as label\n",
    "        FROM trusted_certificates\n",
    "        WHERE status = 'SUCCESS' \n",
    "        AND cert_data IS NOT NULL\n",
    "        AND domain IS NOT NULL\n",
    "        {limit_clause}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä „Éá„Éº„ÇøÂèñÂæó„ÇíÈñãÂßã„Åó„Åæ„Åô...\")\n",
    "    \n",
    "    # „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„ÅÆÂèñÂæó\n",
    "    phishing_data_list = []\n",
    "    \n",
    "    for source, query in phishing_queries.items():\n",
    "        print(f\"\\nüé£ {source.upper()}„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\")\n",
    "        try:\n",
    "            df = pd.read_sql(query, conn)\n",
    "            print(f\"  ‚úÖ ÂèñÂæóÊàêÂäü: {len(df):,}‰ª∂\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                # „Éá„Éº„ÇøÂûã„ÅÆÁ¢∫Ë™ç„Å®‰øÆÊ≠£\n",
    "                df['label'] = df['label'].astype(int)\n",
    "                df['source'] = df['source'].astype(str)\n",
    "                phishing_data_list.append(df)\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è {source}„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå „Ç®„É©„Éº: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Ê≠£Â∏∏„Éá„Éº„Çø„ÅÆÂèñÂæó\n",
    "    print(f\"\\n‚úÖ Ê≠£Â∏∏„Éá„Éº„Çø„ÇíÂèñÂæó‰∏≠...\")\n",
    "    try:\n",
    "        trusted_df = pd.read_sql(trusted_query, conn)\n",
    "        print(f\"  ‚úÖ ÂèñÂæóÊàêÂäü: {len(trusted_df):,}‰ª∂\")\n",
    "        \n",
    "        if len(trusted_df) > 0:\n",
    "            # „Éá„Éº„ÇøÂûã„ÅÆÁ¢∫Ë™ç„Å®‰øÆÊ≠£\n",
    "            trusted_df['label'] = trusted_df['label'].astype(int)\n",
    "            trusted_df['source'] = trusted_df['source'].astype(str)\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Ê≠£Â∏∏„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü\")\n",
    "            trusted_df = pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå „Ç®„É©„Éº: {str(e)}\")\n",
    "        trusted_df = pd.DataFrame()\n",
    "    \n",
    "    return phishing_data_list, trusted_df\n",
    "\n",
    "\n",
    "# „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„Å®„Éá„Éº„ÇøÂèñÂæó\n",
    "print(\"\\nüîå „Éá„Éº„Çø„Éô„Éº„Çπ„Å´Êé•Á∂ö‰∏≠...\")\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    print(\"‚úÖ „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öÊàêÂäü\")\n",
    "    \n",
    "    # „Éá„Éº„ÇøÂèñÂæó\n",
    "    phishing_data_list, trusted_data = fetch_labeled_data(conn, DATA_LIMIT)\n",
    "    \n",
    "    # „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„ÅÆÁµ±Âêà\n",
    "    if phishing_data_list:\n",
    "        phishing_data = pd.concat(phishing_data_list, ignore_index=True)\n",
    "        print(f\"\\nüìä „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„ÇøÁµ±ÂêàÂÆå‰∫Ü: {len(phishing_data):,}‰ª∂\")\n",
    "    else:\n",
    "        phishing_data = pd.DataFrame()\n",
    "        print(\"\\n‚ö†Ô∏è „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„ÅåÂèñÂæó„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n‚úÖ „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„ÇíÈñâ„Åò„Åæ„Åó„Åü\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„Ç®„É©„Éº: {str(e)}\")\n",
    "    phishing_data = pd.DataFrame()\n",
    "    trusted_data = pd.DataFrame()\n",
    "\n",
    "# „Éá„Éº„ÇøÂèñÂæóÁµêÊûú„ÅÆ„Çµ„Éû„É™„Éº\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä „Éá„Éº„ÇøÂèñÂæóÁµêÊûú„Çµ„Éû„É™„Éº\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not phishing_data.empty:\n",
    "    print(f\"\\nüé£ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø:\")\n",
    "    print(f\"  - Á∑è‰ª∂Êï∞: {len(phishing_data):,}‰ª∂\")\n",
    "    print(f\"  - „ÇΩ„Éº„ÇπÂà•ÂÜÖË®≥:\")\n",
    "    for source, count in phishing_data['source'].value_counts().items():\n",
    "        print(f\"    - {source}: {count:,}‰ª∂\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„Å™„Åó\")\n",
    "\n",
    "if not trusted_data.empty:\n",
    "    print(f\"\\n‚úÖ Ê≠£Â∏∏„Éá„Éº„Çø:\")\n",
    "    print(f\"  - Á∑è‰ª∂Êï∞: {len(trusted_data):,}‰ª∂\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Ê≠£Â∏∏„Éá„Éº„Çø„Å™„Åó\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701de590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç „Éá„Éº„ÇøÊ§úË®º„Å®„Éê„É©„É≥„ÇπË™øÊï¥„ÇíÈñãÂßã...\n",
      "\n",
      "üîÑ cert_dataÂûã„ÅÆÂ§âÊèõ...\n",
      "  ‚úÖ memoryview„Çíbytes„Å´Â§âÊèõÂÆå‰∫Ü\n",
      "\n",
      "üìã NULLÂÄ§„ÅÆÂá¶ÁêÜ...\n",
      "  - „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: 367,401 ‚Üí 367,401 (0‰ª∂ÂâäÈô§)\n",
      "  - Ê≠£Â∏∏: 450,656 ‚Üí 450,656 (0‰ª∂ÂâäÈô§)\n",
      "\n",
      "üîÑ „Éá„Éº„Çø„ÇΩ„Éº„ÇπÈñì„ÅÆÈáçË§áÂá¶ÁêÜ...\n",
      "  „Éá„Éº„Çø„ÇΩ„Éº„ÇπÂà•„ÅÆÈáçË§áÂâäÈô§ÁµêÊûú:\n",
      "    - phishtank: 54,362 ‚Üí 17,691 (36,671‰ª∂ÂâäÈô§)\n",
      "    - jpcert: 116,647 ‚Üí 112,422 (4,225‰ª∂ÂâäÈô§)\n",
      "    - certificates: 196,392 ‚Üí 190,296 (6,096‰ª∂ÂâäÈô§)\n",
      "\n",
      "üîÑ Âêå‰∏Ä„Éá„Éº„Çø„Éï„É¨„Éº„É†ÂÜÖ„ÅÆÈáçË§á„Éâ„É°„Ç§„É≥Âá¶ÁêÜ...\n",
      "  - „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: 320,409 ‚Üí 320,409 (0‰ª∂ÂâäÈô§)\n",
      "  - Ê≠£Â∏∏: 450,656 ‚Üí 450,656 (0‰ª∂ÂâäÈô§)\n",
      "\n",
      "üîç „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Å®Ê≠£Â∏∏„Éá„Éº„ÇøÈñì„ÅÆÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØ...\n",
      "  ‚ö†Ô∏è 243‰ª∂„ÅÆÈáçË§á„Éâ„É°„Ç§„É≥„ÇíÊ§úÂá∫\n",
      "  ‚Üí „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„Åã„ÇâÂâäÈô§„Åó„Åæ„Åô\n",
      "\n",
      "‚öñÔ∏è „Éá„Éº„Çø„Éê„É©„É≥„Çπ„ÅÆË™øÊï¥...\n",
      "  - ÊúÄÂ∞è‰ª∂Êï∞: 320,166‰ª∂\n",
      "  - Ë™øÊï¥Âæå„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: 320,166‰ª∂\n",
      "  - Ë™øÊï¥ÂæåÊ≠£Â∏∏: 320,166‰ª∂\n",
      "\n",
      "================================================================================\n",
      "üíæ „Éá„Éº„Çø‰øùÂ≠òÂá¶ÁêÜ\n",
      "================================================================================\n",
      "‚úÖ „Éá„Éº„Çø„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: data/raw/2025-10-27_082037/prepared_data.pkl\n",
      "üìä „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫: 1092.74 MB\n",
      "\n",
      "üìã ‰øùÂ≠ò„Éá„Éº„Çø„Çµ„Éû„É™„Éº:\n",
      "‚îú‚îÄ „Çª„ÉÉ„Ç∑„Éß„É≥ID: 2025-10-27_082037\n",
      "‚îú‚îÄ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø: 320,166‰ª∂\n",
      "‚îú‚îÄ Ê≠£Â∏∏„Éá„Éº„Çø: 320,166‰ª∂\n",
      "‚îú‚îÄ „Éá„Éº„Çø„ÇΩ„Éº„Çπ: phishtank, jpcert, certificates, trusted_certificates\n",
      "‚îî‚îÄ ÈñãÁô∫„É¢„Éº„Éâ: ÁÑ°Âäπ\n",
      "\n",
      "‚ú® 01_data_preparation.py „ÅÆÂá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "„Çª„É´Áï™Âè∑: 3\n",
    "Ê¶ÇË¶Å: „Éá„Éº„Çø„ÅÆÊ§úË®º„ÄÅ„Éê„É©„É≥„ÇπË™øÊï¥„ÄÅ„Åä„Çà„Å≥‰øùÂ≠ò\n",
    "ÂÖ•Âäõ: phishing_data, trusted_data\n",
    "Âá∫Âäõ: data/raw/{session_id}/prepared_data.pkl\n",
    "\"\"\"\n",
    "\n",
    "def validate_and_balance_data(phishing_df: pd.DataFrame, trusted_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    „Éá„Éº„Çø„ÅÆÊ§úË®º„Å®„Éê„É©„É≥„ÇπË™øÊï¥\n",
    "    \n",
    "    Args:\n",
    "        phishing_df: „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø\n",
    "        trusted_df: Ê≠£Â∏∏„Éá„Éº„Çø\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: „Éê„É©„É≥„ÇπË™øÊï¥Âæå„ÅÆ(„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø, Ê≠£Â∏∏„Éá„Éº„Çø)\n",
    "    \"\"\"\n",
    "    print(\"üîç „Éá„Éº„ÇøÊ§úË®º„Å®„Éê„É©„É≥„ÇπË™øÊï¥„ÇíÈñãÂßã...\")\n",
    "    \n",
    "    # Á©∫„ÅÆ„Éá„Éº„Çø„Éï„É¨„Éº„É†„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "    if phishing_df.empty or trusted_df.empty:\n",
    "        print(\"‚ùå „Ç®„É©„Éº: „Éá„Éº„Çø„ÅåÁ©∫„Åß„Åô\")\n",
    "        return phishing_df, trusted_df\n",
    "    \n",
    "    # ÂøÖÈ†à„Ç´„É©„É†„ÅÆÁ¢∫Ë™ç\n",
    "    required_columns = ['domain', 'cert_data', 'source', 'label']\n",
    "    \n",
    "    for df_name, df in [('phishing', phishing_df), ('trusted', trusted_df)]:\n",
    "        missing_cols = set(required_columns) - set(df.columns)\n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå {df_name}„Éá„Éº„Çø„Å´ÂøÖÈ†à„Ç´„É©„É†„Åå„ÅÇ„Çä„Åæ„Åõ„Çì: {missing_cols}\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # memoryview„Çíbytes„Å´Â§âÊèõ\n",
    "    print(\"\\nüîÑ cert_dataÂûã„ÅÆÂ§âÊèõ...\")\n",
    "    phishing_df = phishing_df.copy()\n",
    "    trusted_df = trusted_df.copy()\n",
    "    \n",
    "    phishing_df['cert_data'] = phishing_df['cert_data'].apply(\n",
    "        lambda x: bytes(x) if isinstance(x, memoryview) else x\n",
    "    )\n",
    "    trusted_df['cert_data'] = trusted_df['cert_data'].apply(\n",
    "        lambda x: bytes(x) if isinstance(x, memoryview) else x\n",
    "    )\n",
    "    print(\"  ‚úÖ memoryview„Çíbytes„Å´Â§âÊèõÂÆå‰∫Ü\")\n",
    "    \n",
    "    # NULL„Éá„Éº„Çø„ÅÆÈô§Âéª\n",
    "    print(\"\\nüìã NULLÂÄ§„ÅÆÂá¶ÁêÜ...\")\n",
    "    \n",
    "    phishing_before = len(phishing_df)\n",
    "    trusted_before = len(trusted_df)\n",
    "    \n",
    "    phishing_df = phishing_df.dropna(subset=['domain', 'cert_data'])\n",
    "    trusted_df = trusted_df.dropna(subset=['domain', 'cert_data'])\n",
    "    \n",
    "    print(f\"  - „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: {phishing_before:,} ‚Üí {len(phishing_df):,} ({phishing_before - len(phishing_df):,}‰ª∂ÂâäÈô§)\")\n",
    "    print(f\"  - Ê≠£Â∏∏: {trusted_before:,} ‚Üí {len(trusted_df):,} ({trusted_before - len(trusted_df):,}‰ª∂ÂâäÈô§)\")\n",
    "    \n",
    "    # „Éá„Éº„Çø„ÇΩ„Éº„ÇπÈñì„ÅÆÈáçË§áÈô§ÂéªÔºàÂÑ™ÂÖàÈ†Ü‰Ωç: phishtank > jpcert > certificatesÔºâ\n",
    "    print(\"\\nüîÑ „Éá„Éº„Çø„ÇΩ„Éº„ÇπÈñì„ÅÆÈáçË§áÂá¶ÁêÜ...\")\n",
    "    \n",
    "    # ÂêÑ„ÇΩ„Éº„Çπ„ÅÆ„Éá„Éº„ÇøÊï∞„ÇíË®òÈå≤\n",
    "    source_counts_before = phishing_df['source'].value_counts().to_dict()\n",
    "    \n",
    "    # „Éâ„É°„Ç§„É≥„Éô„Éº„Çπ„ÅßÈáçË§á„ÇíÁ¢∫Ë™ç„Åó„ÄÅÂÑ™ÂÖàÈ†Ü‰Ωç„Å´Âæì„Å£„Å¶‰øùÊåÅ\n",
    "    # „ÇΩ„Éº„Çπ„ÅÆÂÑ™ÂÖàÈ†Ü‰Ωç„ÇíÂÆöÁæ©\n",
    "    source_priority = {'phishtank': 1, 'jpcert': 2, 'certificates': 3}\n",
    "    phishing_df['priority'] = phishing_df['source'].map(source_priority)\n",
    "    \n",
    "    # ÂÑ™ÂÖàÈ†Ü‰Ωç„Åß„ÇΩ„Éº„Éà„Åó„Å¶„Åã„ÇâÈáçË§áÂâäÈô§ÔºàÂÑ™ÂÖàÂ∫¶„ÅÆÈ´ò„ÅÑ„ÇÇ„ÅÆ„ÇíÊÆã„ÅôÔºâ\n",
    "    phishing_df = phishing_df.sort_values('priority').drop_duplicates(subset=['domain'], keep='first')\n",
    "    phishing_df = phishing_df.drop(columns=['priority'])\n",
    "    \n",
    "    # ÂêÑ„ÇΩ„Éº„Çπ„ÅÆÊÆãÂ≠ò„Éá„Éº„ÇøÊï∞„ÇíÁ¢∫Ë™ç\n",
    "    source_counts_after = phishing_df['source'].value_counts().to_dict()\n",
    "    \n",
    "    print(\"  „Éá„Éº„Çø„ÇΩ„Éº„ÇπÂà•„ÅÆÈáçË§áÂâäÈô§ÁµêÊûú:\")\n",
    "    for source in ['phishtank', 'jpcert', 'certificates']:\n",
    "        before = source_counts_before.get(source, 0)\n",
    "        after = source_counts_after.get(source, 0)\n",
    "        removed = before - after\n",
    "        print(f\"    - {source}: {before:,} ‚Üí {after:,} ({removed:,}‰ª∂ÂâäÈô§)\")\n",
    "    \n",
    "    # Âêå‰∏Ä„Éá„Éº„Çø„Éï„É¨„Éº„É†ÂÜÖ„ÅÆÈáçË§á„Éâ„É°„Ç§„É≥„ÅÆÂâäÈô§\n",
    "    print(\"\\nüîÑ Âêå‰∏Ä„Éá„Éº„Çø„Éï„É¨„Éº„É†ÂÜÖ„ÅÆÈáçË§á„Éâ„É°„Ç§„É≥Âá¶ÁêÜ...\")\n",
    "    \n",
    "    phishing_before = len(phishing_df)\n",
    "    trusted_before = len(trusted_df)\n",
    "    \n",
    "    phishing_df = phishing_df.drop_duplicates(subset=['domain'], keep='first')\n",
    "    trusted_df = trusted_df.drop_duplicates(subset=['domain'], keep='first')\n",
    "    \n",
    "    print(f\"  - „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: {phishing_before:,} ‚Üí {len(phishing_df):,} ({phishing_before - len(phishing_df):,}‰ª∂ÂâäÈô§)\")\n",
    "    print(f\"  - Ê≠£Â∏∏: {trusted_before:,} ‚Üí {len(trusted_df):,} ({trusted_before - len(trusted_df):,}‰ª∂ÂâäÈô§)\")\n",
    "    \n",
    "    # „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Å®Ê≠£Â∏∏„Éá„Éº„ÇøÈñì„ÅÆÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "    print(\"\\nüîç „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Å®Ê≠£Â∏∏„Éá„Éº„ÇøÈñì„ÅÆÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØ...\")\n",
    "    \n",
    "    overlapping_domains = set(phishing_df['domain']) & set(trusted_df['domain'])\n",
    "    if overlapping_domains:\n",
    "        print(f\"  ‚ö†Ô∏è {len(overlapping_domains):,}‰ª∂„ÅÆÈáçË§á„Éâ„É°„Ç§„É≥„ÇíÊ§úÂá∫\")\n",
    "        print(f\"  ‚Üí „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„Åã„ÇâÂâäÈô§„Åó„Åæ„Åô\")\n",
    "        phishing_df = phishing_df[~phishing_df['domain'].isin(overlapping_domains)]\n",
    "    else:\n",
    "        print(\"  ‚úÖ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Å®Ê≠£Â∏∏„Éá„Éº„ÇøÈñì„Å´ÈáçË§á„Å™„Åó\")\n",
    "    \n",
    "    # „Éá„Éº„Çø„Éê„É©„É≥„Çπ„ÅÆË™øÊï¥ÔºàÂ∞ë„Å™„ÅÑÊñπ„Å´Âêà„Çè„Åõ„ÇãÔºâ\n",
    "    print(\"\\n‚öñÔ∏è „Éá„Éº„Çø„Éê„É©„É≥„Çπ„ÅÆË™øÊï¥...\")\n",
    "    \n",
    "    min_count = min(len(phishing_df), len(trusted_df))\n",
    "    print(f\"  - ÊúÄÂ∞è‰ª∂Êï∞: {min_count:,}‰ª∂\")\n",
    "    \n",
    "    if len(phishing_df) > min_count:\n",
    "        # „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºà„ÇΩ„Éº„Çπ„Åî„Å®„ÅÆÊØîÁéá„ÇíÁ∂≠ÊåÅÔºâ\n",
    "        phishing_df = phishing_df.groupby('source', group_keys=False).apply(\n",
    "            lambda x: x.sample(n=int(len(x) * min_count / len(phishing_df)), random_state=42)\n",
    "        )\n",
    "    \n",
    "    if len(trusted_df) > min_count:\n",
    "        # Ê≠£Â∏∏„Éá„Éº„Çø„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞\n",
    "        trusted_df = trusted_df.sample(n=min_count, random_state=42)\n",
    "    \n",
    "    print(f\"  - Ë™øÊï¥Âæå„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞: {len(phishing_df):,}‰ª∂\")\n",
    "    print(f\"  - Ë™øÊï¥ÂæåÊ≠£Â∏∏: {len(trusted_df):,}‰ª∂\")\n",
    "    \n",
    "    return phishing_df, trusted_df\n",
    "\n",
    "\n",
    "# „Éá„Éº„Çø„ÅÆÊ§úË®º„Å®„Éê„É©„É≥„ÇπË™øÊï¥\n",
    "if not phishing_data.empty and not trusted_data.empty:\n",
    "    phishing_data_balanced, trusted_data_balanced = validate_and_balance_data(phishing_data, trusted_data)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è „Éá„Éº„Çø„Åå‰∏çË∂≥„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ„Éê„É©„É≥„ÇπË™øÊï¥„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô\")\n",
    "    phishing_data_balanced = phishing_data\n",
    "    trusted_data_balanced = trusted_data\n",
    "\n",
    "# „Éá„Éº„Çø‰øùÂ≠ò„ÅÆÊ∫ñÂÇô\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üíæ „Éá„Éº„Çø‰øùÂ≠òÂá¶ÁêÜ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ‰øùÂ≠ò„Åô„Çã„Éá„Éº„ÇøÊßãÈÄ†„ÅÆ‰ΩúÊàê\n",
    "data_to_save = {\n",
    "    'phishing_data': phishing_data_balanced,\n",
    "    'trusted_data': trusted_data_balanced,\n",
    "    'metadata': {\n",
    "        'session_id': session_id,\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'phishing_count': len(phishing_data_balanced),\n",
    "        'trusted_count': len(trusted_data_balanced),\n",
    "        'data_sources': ['phishtank', 'jpcert', 'certificates', 'trusted_certificates'],\n",
    "        'development_mode': DEVELOPMENT_MODE,\n",
    "        'data_limit': DATA_LIMIT,\n",
    "        'preprocessing': {\n",
    "            'null_removed': True,\n",
    "            'duplicates_removed': True,\n",
    "            'balanced': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# PickleÂΩ¢Âºè„Åß‰øùÂ≠ò\n",
    "output_file = output_dir / 'prepared_data.pkl'\n",
    "try:\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "    print(f\"‚úÖ „Éá„Éº„Çø„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: {output_file}\")\n",
    "    \n",
    "    # „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„ÅÆÁ¢∫Ë™ç\n",
    "    file_size_mb = output_file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"üìä „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ‰øùÂ≠ò„Ç®„É©„Éº: {str(e)}\")\n",
    "\n",
    "# ‰øùÂ≠ò„Éá„Éº„Çø„ÅÆ„Çµ„Éû„É™„ÉºË°®Á§∫\n",
    "if 'data_to_save' in locals():\n",
    "    print(\"\\nüìã ‰øùÂ≠ò„Éá„Éº„Çø„Çµ„Éû„É™„Éº:\")\n",
    "    print(f\"‚îú‚îÄ „Çª„ÉÉ„Ç∑„Éß„É≥ID: {data_to_save['metadata']['session_id']}\")\n",
    "    print(f\"‚îú‚îÄ „Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Éá„Éº„Çø: {data_to_save['metadata']['phishing_count']:,}‰ª∂\")\n",
    "    print(f\"‚îú‚îÄ Ê≠£Â∏∏„Éá„Éº„Çø: {data_to_save['metadata']['trusted_count']:,}‰ª∂\")\n",
    "    print(f\"‚îú‚îÄ „Éá„Éº„Çø„ÇΩ„Éº„Çπ: {', '.join(data_to_save['metadata']['data_sources'])}\")\n",
    "    print(f\"‚îî‚îÄ ÈñãÁô∫„É¢„Éº„Éâ: {'ÊúâÂäπ' if data_to_save['metadata']['development_mode'] else 'ÁÑ°Âäπ'}\")\n",
    "\n",
    "print(\"\\n‚ú® 01_data_preparation.py „ÅÆÂá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü\")\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf7e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Controller APIÈñ¢Êï∞ ===\n",
    "from typing import Tuple, Dict, Any\n",
    "import json, hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def _safe_bytes(x):\n",
    "    if isinstance(x, memoryview): return bytes(x)\n",
    "    return x\n",
    "\n",
    "def _quick_cert_parse_error_rate(df: pd.DataFrame, sample_n: int = 200) -> float:\n",
    "    try:\n",
    "        from cryptography import x509\n",
    "        from cryptography.hazmat.backends import default_backend\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "    if df.empty: return 0.0\n",
    "    sub = df.sample(n=min(sample_n, len(df)), random_state=42)\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for b in sub['cert_data']:\n",
    "        b = _safe_bytes(b)\n",
    "        if b is None:\n",
    "            continue\n",
    "        total += 1\n",
    "        try:\n",
    "            x509.load_der_x509_certificate(b, default_backend())\n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    return (errors / max(total, 1)) if total > 0 else 0.0\n",
    "\n",
    "def _save_evidence_store(ph_df: pd.DataFrame, tr_df: pd.DataFrame, out_path: Path) -> Path:\n",
    "    cols = ['domain', 'cert_data', 'source', 'label']\n",
    "    df = pd.concat([ph_df[cols], tr_df[cols]], ignore_index=True) if (not ph_df.empty and not tr_df.empty) else \\\n",
    "         (ph_df[cols] if not ph_df.empty else tr_df[cols] if not tr_df.empty else pd.DataFrame(columns=cols))\n",
    "    def _sha256(b):\n",
    "        b = _safe_bytes(b)\n",
    "        if not isinstance(b, (bytes, bytearray)): return None\n",
    "        return hashlib.sha256(b).hexdigest()\n",
    "    df = df.copy()\n",
    "    df['cert_hash'] = df['cert_data'].map(_sha256)\n",
    "    df.drop(columns=['cert_data'], inplace=True)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "def prepare_data(session_id: str, cfg: Dict[str, Any]) -> Tuple[str, Dict[str, str]]:\n",
    "    try:\n",
    "        if not isinstance(cfg, dict):\n",
    "            return \"INVALID_INPUT\", {\"error\": \"cfg„ÅØËæûÊõ∏Âûã„ÅßÊåáÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ\"}\n",
    "\n",
    "        load_configuration(cfg_override=cfg)\n",
    "\n",
    "        out_base = Path(RESULTS_DIR) / str(session_id)\n",
    "        logs_dir = Path(LOGS_DIR) / \"preparation\"\n",
    "        out_base.mkdir(parents=True, exist_ok=True)\n",
    "        logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        import psycopg2\n",
    "        try:\n",
    "            conn = psycopg2.connect(**DB_CONFIG, connect_timeout=int(cfg['db'].get('timeout_s', 30)))\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"DBÊé•Á∂ö„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        try:\n",
    "            phishing_list, trusted_df = fetch_labeled_data(conn, DATA_LIMIT)\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"„Éá„Éº„ÇøÂèñÂæó„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        phishing_df = pd.concat(phishing_list, ignore_index=True) if phishing_list else pd.DataFrame(columns=['domain','cert_data','source','label'])\n",
    "\n",
    "        total_records = len(phishing_df) + len(trusted_df)\n",
    "        if total_records < 100:\n",
    "            return \"NOT_FOUND\", {\"error\": f\"„Éá„Éº„Çø‰∏çË∂≥: ÂêàË®à{total_records}‰ª∂ (<100)\",\n",
    "                                  \"phishing\": str(len(phishing_df)), \"trusted\": str(len(trusted_df))}\n",
    "\n",
    "        parse_err_rate = _quick_cert_parse_error_rate(phishing_df.append(trusted_df, ignore_index=True) if not trusted_df.empty else phishing_df)\n",
    "        if parse_err_rate > 0.10:\n",
    "            return \"INVALID_INPUT\", {\"error\": f\"Ë®ºÊòéÊõ∏„Éë„Éº„ÇπÂ§±ÊïóÁéá„ÅåÈ´ò„Åô„Åé„Åæ„Åô: {parse_err_rate:.1%} (>10%)\"}\n",
    "\n",
    "        try:\n",
    "            ph_bal, tr_bal = validate_and_balance_data(phishing_df, trusted_df)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"„Éá„Éº„ÇøÊ§úË®º/„Éê„É©„É≥„Ç∑„É≥„Ç∞„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        prepared_path = out_base / \"prepared_data.pkl\"\n",
    "        try:\n",
    "            data_to_save = {\n",
    "                'phishing_data': ph_bal,\n",
    "                'trusted_data': tr_bal,\n",
    "                'metadata': {\n",
    "                    'session_id': session_id,\n",
    "                    'created_at': datetime.now().isoformat(),\n",
    "                    'phishing_count': len(ph_bal),\n",
    "                    'trusted_count': len(tr_bal),\n",
    "                    'data_sources': ['phishtank', 'jpcert', 'certificates', 'trusted_certificates'],\n",
    "                    'development_mode': DEVELOPMENT_MODE,\n",
    "                    'data_limit': DATA_LIMIT,\n",
    "                    'preprocessing': {\n",
    "                        'null_removed': True,\n",
    "                        'duplicates_removed': True,\n",
    "                        'balanced': True\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            with open(prepared_path, \"wb\") as f:\n",
    "                import pickle\n",
    "                pickle.dump(data_to_save, f)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"prepared_data‰øùÂ≠ò„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        evidence_path = out_base / \"evidence_store.parquet\"\n",
    "        try:\n",
    "            _save_evidence_store(ph_bal, tr_bal, evidence_path)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"evidence_store‰øùÂ≠ò„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        split_manifest = out_base / \"split_manifest.json\"\n",
    "        prov_manifest = out_base / \"data_provenance.json\"\n",
    "        try:\n",
    "            split = {\n",
    "                \"phishing_count\": len(ph_bal),\n",
    "                \"trusted_count\": len(tr_bal),\n",
    "                \"balanced\": True\n",
    "            }\n",
    "            split_manifest.write_text(json.dumps(split, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "            provenance = {\n",
    "                \"session_id\": session_id,\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"cfg\": cfg,\n",
    "                \"source_tables\": [\"phishtank_entries\", \"jpcert_phishing_urls\", \"certificates\", \"trusted_certificates\"]\n",
    "            }\n",
    "            prov_manifest.write_text(json.dumps(provenance, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"„É°„Çø„Éá„Éº„Çø‰øùÂ≠ò„Å´Â§±Êïó: {e}\"}\n",
    "\n",
    "        paths = {\n",
    "            \"prepared_data\": str(prepared_path),\n",
    "            \"evidence_store\": str(evidence_path),\n",
    "            \"split_manifest\": str(split_manifest),\n",
    "            \"data_provenance\": str(prov_manifest),\n",
    "            \"logs\": str(logs_dir / \"preparation.log\")\n",
    "        }\n",
    "        return \"OK\", paths\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"ERROR\", {\"error\": f\"Êú™Âá¶ÁêÜ‰æãÂ§ñ: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60439a-633c-4a1c-8358-eca735c30433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
