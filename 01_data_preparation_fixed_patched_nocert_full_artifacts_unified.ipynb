{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a92f937-89f8-4f5b-bc4a-892c855bd469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.438365Z",
     "iopub.status.busy": "2026-02-02T13:04:31.438254Z",
     "iopub.status.idle": "2026-02-02T13:04:31.448662Z",
     "shell.execute_reply": "2026-02-02T13:04:31.448006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asomura/waseda/phish-core/bin/python\n",
      "3.12.3 (main, Jan  8 2026, 11:30:50) [GCC 13.3.0]\n",
      "2.9.11 (dt dec pq3 ext lo64)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "import psycopg2\n",
    "print(psycopg2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245c2c3f-0508-421a-8658-1c720d99401c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.450919Z",
     "iopub.status.busy": "2026-02-02T13:04:31.450801Z",
     "iopub.status.idle": "2026-02-02T13:04:31.454723Z",
     "shell.execute_reply": "2026-02-02T13:04:31.454160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ghpc3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "socket.gethostname()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b485f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.456664Z",
     "iopub.status.busy": "2026-02-02T13:04:31.456552Z",
     "iopub.status.idle": "2026-02-02T13:04:31.458628Z",
     "shell.execute_reply": "2026-02-02T13:04:31.458052Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4498c517-74f2-4df5-b3b5-fde10e9e6191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.460276Z",
     "iopub.status.busy": "2026-02-02T13:04:31.460165Z",
     "iopub.status.idle": "2026-02-02T13:04:31.614480Z",
     "shell.execute_reply": "2026-02-02T13:04:31.613631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] RUN_ID = 2026-02-02_220431 | paths.RUN_ID = 2026-02-02_220431\n"
     ]
    }
   ],
   "source": [
    "# === Cell 0 (01_* ç”¨): æ–°ã—ã„RUNã‚’ç™ºè¡Œã—ã¦ã‹ã‚‰ paths ã‚’èª­ã‚€ ===\n",
    "import run_id_registry as runreg\n",
    "rid = runreg.new_run()  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§æ–°è¦ RUN_ID ç™ºè¡Œâ†’ãƒ•ã‚¡ã‚¤ãƒ« & ç’°å¢ƒå¤‰æ•°ã«ä¿å­˜\n",
    "\n",
    "import importlib  # â† ã“ã“ã§åˆã‚ã¦ paths ã‚’ import\n",
    "import _compat.paths as paths\n",
    "importlib.reload(paths)\n",
    "print(\"[01] RUN_ID =\", rid, \"| paths.RUN_ID =\", paths.RUN_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea90a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.616896Z",
     "iopub.status.busy": "2026-02-02T13:04:31.616559Z",
     "iopub.status.idle": "2026-02-02T13:04:31.622907Z",
     "shell.execute_reply": "2026-02-02T13:04:31.622160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IO guard ready -> artifacts/2026-02-02_220431\n"
     ]
    }
   ],
   "source": [
    "# === IO PATHS (auto-added guard) ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "if 'RUN_ID' not in globals():\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\") or datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "ARTIFACTS = Path(\"artifacts\") / RUN_ID\n",
    "RAW = ARTIFACTS / \"raw\"\n",
    "PROCESSED = ARTIFACTS / \"processed\"\n",
    "MODELS = ARTIFACTS / \"models\"\n",
    "RESULTS = ARTIFACTS / \"results\"\n",
    "HANDOFF = ARTIFACTS / \"handoff\"\n",
    "LOGS = ARTIFACTS / \"logs\"\n",
    "TRACES = ARTIFACTS / \"traces\"\n",
    "for _p in [RAW, PROCESSED, MODELS, RESULTS, HANDOFF, LOGS, TRACES]:\n",
    "    _p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# string shortcuts (compat)\n",
    "RAW_DIR = str(RAW); PROCESSED_DIR = str(PROCESSED); MODELS_DIR = str(MODELS)\n",
    "RESULTS_DIR = str(RESULTS); HANDOFF_DIR = str(HANDOFF); LOGS_DIR = str(LOGS); TRACES_DIR = str(TRACES)\n",
    "\n",
    "base_dirs = {'raw': RAW_DIR, 'data': PROCESSED_DIR, 'models': MODELS_DIR,\n",
    "             'results': RESULTS_DIR, 'handoff': HANDOFF_DIR, 'logs': LOGS_DIR, 'traces': TRACES_DIR}\n",
    "def resolve(p): p = Path(p); p.mkdir(parents=True, exist_ok=True); return str(p)\n",
    "def ensure_roots(): pass\n",
    "def load_config(): return {\"root\": str(ARTIFACTS), \"run_id\": RUN_ID}\n",
    "\n",
    "print(f\"âœ… IO guard ready -> artifacts/{RUN_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1dcc01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.624886Z",
     "iopub.status.busy": "2026-02-02T13:04:31.624720Z",
     "iopub.status.idle": "2026-02-02T13:04:31.627984Z",
     "shell.execute_reply": "2026-02-02T13:04:31.627403Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, \"./\")\n",
    "from _compat.paths import resolve, ensure_roots, load_config, compat_base_dirs\n",
    "ensure_roots()\n",
    "CFG = load_config()\n",
    "base_dirs = dict(compat_base_dirs)  # æ—¢å­˜ã‚³ãƒ¼ãƒ‰äº’æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7d6c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.630179Z",
     "iopub.status.busy": "2026-02-02T13:04:31.630017Z",
     "iopub.status.idle": "2026-02-02T13:04:31.633531Z",
     "shell.execute_reply": "2026-02-02T13:04:31.632695Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- RUN_ID ã‚’ä¸€åº¦ã ã‘æ±ºã‚ã¦å›ºå®šï¼ˆåŒä¸€ãƒãƒ¼ãƒˆï¼åŒä¸€å®Ÿè¡Œã§ãƒ–ãƒ¬ãªã„ï¼‰----\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "if \"RUN_ID\" not in globals():\n",
    "    RUN_ID = os.environ.get(\"RUN_ID\") or datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "    os.environ[\"RUN_ID\"] = RUN_ID  # åŒä¸€ã‚«ãƒ¼ãƒãƒ«å†…ã§ä»–ãƒãƒ¼ãƒˆã«ã‚‚å…±æœ‰ã—ãŸã„å ´åˆã®ã¿\n",
    "\n",
    "# æ—¢å­˜ã® base_dirs ã®æµå„€ã¯ãã®ã¾ã¾ï¼ˆï¼æ©Ÿèƒ½ä¸å¤‰ï¼‰\n",
    "# base_dirs['results'] = f\"results/{RUN_ID}\"  # artifactsé…ä¸‹ã«çµ±ä¸€ã™ã‚‹ãŸã‚æ—§ä»•æ§˜ã‚’ç„¡åŠ¹åŒ–\n",
    "\n",
    "# ï¼ˆä»»æ„ï¼‰ä½¿ã†ãªã‚‰è§£æ±ºæ¸ˆã¿ãƒ‘ã‚¹ã‚’1ã¤ã ã‘ä½œã£ã¦ãŠã\n",
    "RESULTS_DIR = resolve(base_dirs['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1904a375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.635186Z",
     "iopub.status.busy": "2026-02-02T13:04:31.635016Z",
     "iopub.status.idle": "2026-02-02T13:04:31.637724Z",
     "shell.execute_reply": "2026-02-02T13:04:31.637282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_ID = 2026-02-02_220431\n",
      "RESULTS_DIR = artifacts/2026-02-02_220431/results\n"
     ]
    }
   ],
   "source": [
    "print(\"RUN_ID =\", RUN_ID)\n",
    "print(\"RESULTS_DIR =\", RESULTS_DIR)   # ä¾‹: .../artifacts/2025-10-12_080143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9256ef58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.639745Z",
     "iopub.status.busy": "2026-02-02T13:04:31.639573Z",
     "iopub.status.idle": "2026-02-02T13:04:31.916485Z",
     "shell.execute_reply": "2026-02-02T13:04:31.915778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†: DEVELOPMENT_MODE=False, CERT_ONLY(optional)=False\n",
      "   DB: rapids_data@localhost:5432 (read_only=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™\n",
      "âœ… æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™\n",
      "ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: artifacts/2026-02-02_220431/raw\n",
      "ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID (RUN_ID): 2026-02-02_220431\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "ãƒ—ãƒ­ã‚°ãƒ©ãƒ å: 01_data_preparation.py\n",
    "æ¦‚è¦: ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼‰\n",
    "ç›®çš„: å›½éš›å­¦ä¼šè«–æ–‡ã§ã®ç™ºè¡¨ï¼ˆMLã¨LLMã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å®Ÿè¨¼ï¼‰\n",
    "ä½œæˆæ—¥: 2025-07-20\n",
    "ä¾å­˜é–¢ä¿‚: PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆrapids_dataï¼‰\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "ã‚»ãƒ«ç•ªå·: 1\n",
    "æ¦‚è¦: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š\n",
    "å…¥åŠ›: ãªã—\n",
    "å‡ºåŠ›: DBæ¥ç¶šè¨­å®šã€åŸºæœ¬è¨­å®šå¤‰æ•°\n",
    "\"\"\"\n",
    "\n",
    "# === CONFIG (è¿½åŠ ) ===\n",
    "import os, json, yaml\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "cfg: Dict[str, Any] = {}\n",
    "\n",
    "def _deep_update(base: dict, override: dict) -> dict:\n",
    "    for k, v in (override or {}).items():\n",
    "        if isinstance(v, dict) and isinstance(base.get(k), dict):\n",
    "            base[k] = _deep_update(base[k], v)\n",
    "        else:\n",
    "            base[k] = v\n",
    "    return base\n",
    "\n",
    "def load_configuration(config_path: Optional[str] = None,\n",
    "                       cfg_override: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    01_data_preparation_fixed.py ç”¨ã®Configèª­ã¿è¾¼ã¿çµ±åˆé–¢æ•°\n",
    "    å„ªå…ˆé †ä½: APIå¼•æ•°(cfg_override) > ç’°å¢ƒå¤‰æ•° > è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\n",
    "    æˆ»ã‚Šå€¤: çµ±åˆæ¸ˆã¿cfgè¾æ›¸\n",
    "    \"\"\"\n",
    "    default = {\n",
    "        \"system\": {\n",
    "            \"cert_only_mode\": False,   # CERT-ONLYå»ƒæ­¢ï¼ˆä»»æ„ï¼‰\n",
    "            \"seed\": 42,\n",
    "            \"development_mode\": False\n",
    "        },\n",
    "        \"db\": {\n",
    "            \"dbname\": \"rapids_data\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"asomura\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": \"5432\",\n",
    "            \"read_only\": True,\n",
    "            \"timeout_s\": 30\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"dev_limit\": 1000,\n",
    "            \"balance_data\": True,\n",
    "            \"remove_duplicates\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cfg_all = dict(default)\n",
    "\n",
    "    def _load_file(path: str):\n",
    "        try:\n",
    "            if path and os.path.exists(path):\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    if path.endswith((\".yml\", \".yaml\")):\n",
    "                        return yaml.safe_load(f) or {}\n",
    "                    return json.load(f) or {}\n",
    "        except Exception:\n",
    "            pass\n",
    "        return {}\n",
    "\n",
    "    if config_path:\n",
    "        cfg_all = _deep_update(cfg_all, _load_file(config_path))\n",
    "\n",
    "    env_map = {\n",
    "        \"CERT_ONLY_MODE\": (\"system\", \"cert_only_mode\"),\n",
    "        \"DEV_MODE\": (\"system\", \"development_mode\"),\n",
    "        \"PGDATABASE\": (\"db\", \"dbname\"),\n",
    "        \"PGUSER\": (\"db\", \"user\"),\n",
    "        \"PGPASSWORD\": (\"db\", \"password\"),\n",
    "        \"PGHOST\": (\"db\", \"host\"),\n",
    "        \"PGPORT\": (\"db\", \"port\"),\n",
    "    }\n",
    "    for env_key, path in env_map.items():\n",
    "        val = os.getenv(env_key, None)\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, str) and val.lower() in (\"true\", \"false\"):\n",
    "            val = val.lower() == \"true\"\n",
    "        node = cfg_all\n",
    "        for k in path[:-1]:\n",
    "            node = node.setdefault(k, {})\n",
    "        node[path[-1]] = val\n",
    "\n",
    "    if cfg_override:\n",
    "        cfg_all = _deep_update(cfg_all, cfg_override)\n",
    "\n",
    "    # CERT-ONLY å¼·åˆ¶ãƒã‚§ãƒƒã‚¯ã¯å‰Šé™¤\n",
    "    db = cfg_all.get(\"db\", {})\n",
    "    for key in [\"dbname\", \"user\", \"host\", \"port\"]:\n",
    "        if not db.get(key):\n",
    "            raise ValueError(f\"DBè¨­å®šã«å¿…é ˆé …ç›®ãŒä¸è¶³ã—ã¦ã„ã¾ã™: db.{key}\")\n",
    "\n",
    "    global cfg, DB_CONFIG, DEVELOPMENT_MODE, DATA_LIMIT\n",
    "    cfg = cfg_all\n",
    "    DB_CONFIG = {\n",
    "        \"dbname\": str(cfg_all[\"db\"][\"dbname\"]),\n",
    "        \"user\": str(cfg_all[\"db\"][\"user\"]),\n",
    "        \"password\": str(cfg_all[\"db\"].get(\"password\", \"\")),\n",
    "        \"host\": str(cfg_all[\"db\"][\"host\"]),\n",
    "        \"port\": str(cfg_all[\"db\"][\"port\"]),\n",
    "    }\n",
    "    DEVELOPMENT_MODE = bool(cfg_all[\"system\"].get(\"development_mode\", False))\n",
    "    DATA_LIMIT = int(cfg_all[\"data\"].get(\"dev_limit\", 1000)) if DEVELOPMENT_MODE else None\n",
    "    print(f\"ğŸ”§ è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†: DEVELOPMENT_MODE={DEVELOPMENT_MODE}, CERT_ONLY(optional)={cfg_all['system'].get('cert_only_mode', False)}\")\n",
    "    print(f\"   DB: {DB_CONFIG['dbname']}@{DB_CONFIG['host']}:{DB_CONFIG['port']} (read_only={cfg_all['db'].get('read_only', True)})\")\n",
    "    return cfg_all\n",
    "\n",
    "if 'cfg' not in globals() or not cfg:\n",
    "    try:\n",
    "        load_configuration(os.getenv(\"CONFIG_PATH\", None))\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Configèª­ã¿è¾¼ã¿è­¦å‘Š: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'rapids_data',\n",
    "    'user': 'postgres',\n",
    "    'password': 'asomura',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡ï¼‰\n",
    "DEVELOPMENT_MODE = bool(cfg['system'].get('development_mode', False))\n",
    "if DEVELOPMENT_MODE:\n",
    "    DATA_LIMIT = int(cfg['data'].get('dev_limit', 1000))\n",
    "    print(f\"âš ï¸ è­¦å‘Šï¼šé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’{DATA_LIMIT}ä»¶ã«åˆ¶é™ã—ã¦ã„ã¾ã™\")\n",
    "    print(\"âš ï¸ æœ¬ç•ªå®Ÿè¡Œæ™‚ã¯é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ï¼ˆcfg.system.development_mode=falseï¼‰\")\n",
    "else:\n",
    "    DATA_LIMIT = None  # å…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨\n",
    "    print(\"âœ… æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "    print(\"âœ… æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆ\n",
    "# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆ (RUN_ID ã«çµ±ä¸€)\n",
    "session_id = RUN_ID\n",
    "output_dir = Path(RAW_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}\")\n",
    "print(f\"ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID (RUN_ID): {session_id}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b245501e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:04:31.920303Z",
     "iopub.status.busy": "2026-02-02T13:04:31.920053Z",
     "iopub.status.idle": "2026-02-02T13:08:16.843690Z",
     "shell.execute_reply": "2026-02-02T13:08:16.842445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šä¸­...\n",
      "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ\n",
      "ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’é–‹å§‹ã—ã¾ã™...\n",
      "\n",
      "ğŸ£ PHISHTANKãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258549/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… å–å¾—æˆåŠŸ: 53,327ä»¶\n",
      "\n",
      "ğŸ£ JPCERTãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258549/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… å–å¾—æˆåŠŸ: 115,866ä»¶\n",
      "\n",
      "ğŸ£ CERTIFICATESãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258549/2411644574.py:81: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… å–å¾—æˆåŠŸ: 196,158ä»¶\n",
      "\n",
      "âœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258549/2411644574.py:99: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  trusted_df = pd.read_sql(trusted_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… å–å¾—æˆåŠŸ: 450,545ä»¶\n",
      "\n",
      "ğŸ“Š ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†: 365,351ä»¶\n",
      "\n",
      "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœã‚µãƒãƒªãƒ¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ£ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿:\n",
      "  - ç·ä»¶æ•°: 365,351ä»¶\n",
      "  - ã‚½ãƒ¼ã‚¹åˆ¥å†…è¨³:\n",
      "    - certificates: 196,158ä»¶\n",
      "    - jpcert: 115,866ä»¶\n",
      "    - phishtank: 53,327ä»¶\n",
      "\n",
      "âœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿:\n",
      "  - ç·ä»¶æ•°: 450,545ä»¶\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ã‚»ãƒ«ç•ªå·: 2\n",
    "æ¦‚è¦: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "å…¥åŠ›: DB_CONFIG, DATA_LIMIT\n",
    "å‡ºåŠ›: phishing_data_list, trusted_data\n",
    "\"\"\"\n",
    "\n",
    "def fetch_labeled_data(conn, limit: Optional[int] = None) -> Tuple[List[pd.DataFrame], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹é–¢æ•°\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[List[pd.DataFrame], pd.DataFrame]: (ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ, æ­£å¸¸ãƒ‡ãƒ¼ã‚¿)\n",
    "    \"\"\"\n",
    "    \n",
    "    # LIMITã®è¨­å®š\n",
    "    limit_clause = f\"LIMIT {limit}\" if limit else \"\"\n",
    "    \n",
    "    # ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒªå®šç¾©\n",
    "    phishing_queries = {\n",
    "        'phishtank': f\"\"\"\n",
    "            SELECT \n",
    "                cert_domain as domain,\n",
    "                cert_data,\n",
    "                'phishtank' as source,\n",
    "                1 as label\n",
    "            FROM phishtank_entries\n",
    "            WHERE cert_status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND cert_domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\",\n",
    "        'jpcert': f\"\"\"\n",
    "            SELECT \n",
    "                domain,\n",
    "                cert_data,\n",
    "                'jpcert' as source,\n",
    "                1 as label\n",
    "            FROM jpcert_phishing_urls\n",
    "            WHERE status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\",\n",
    "        'certificates': f\"\"\"\n",
    "            SELECT \n",
    "                domain,\n",
    "                cert_data,\n",
    "                'certificates' as source,\n",
    "                1 as label\n",
    "            FROM certificates\n",
    "            WHERE status = 'SUCCESS' \n",
    "            AND cert_data IS NOT NULL\n",
    "            AND domain IS NOT NULL\n",
    "            {limit_clause}\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒª\n",
    "    trusted_query = f\"\"\"\n",
    "        SELECT \n",
    "            domain,\n",
    "            cert_data,\n",
    "            'trusted' as source,\n",
    "            0 as label\n",
    "        FROM trusted_certificates\n",
    "        WHERE status = 'SUCCESS' \n",
    "        AND cert_data IS NOT NULL\n",
    "        AND domain IS NOT NULL\n",
    "        {limit_clause}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    \n",
    "    # ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å–å¾—\n",
    "    phishing_data_list = []\n",
    "    \n",
    "    for source, query in phishing_queries.items():\n",
    "        print(f\"\\nğŸ£ {source.upper()}ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\")\n",
    "        try:\n",
    "            df = pd.read_sql(query, conn)\n",
    "            print(f\"  âœ… å–å¾—æˆåŠŸ: {len(df):,}ä»¶\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨ä¿®æ­£\n",
    "                df['label'] = df['label'].astype(int)\n",
    "                df['source'] = df['source'].astype(str)\n",
    "                phishing_data_list.append(df)\n",
    "            else:\n",
    "                print(f\"  âš ï¸ {source}ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®å–å¾—\n",
    "    print(f\"\\nâœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\")\n",
    "    try:\n",
    "        trusted_df = pd.read_sql(trusted_query, conn)\n",
    "        print(f\"  âœ… å–å¾—æˆåŠŸ: {len(trusted_df):,}ä»¶\")\n",
    "        \n",
    "        if len(trusted_df) > 0:\n",
    "            # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèªã¨ä¿®æ­£\n",
    "            trusted_df['label'] = trusted_df['label'].astype(int)\n",
    "            trusted_df['source'] = trusted_df['source'].astype(str)\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "            trusted_df = pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "        trusted_df = pd.DataFrame()\n",
    "    \n",
    "    return phishing_data_list, trusted_df\n",
    "\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "print(\"\\nğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šä¸­...\")\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "    phishing_data_list, trusted_data = fetch_labeled_data(conn, DATA_LIMIT)\n",
    "    \n",
    "    # ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ\n",
    "    if phishing_data_list:\n",
    "        phishing_data = pd.concat(phishing_data_list, ignore_index=True)\n",
    "        print(f\"\\nğŸ“Š ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†: {len(phishing_data):,}ä»¶\")\n",
    "    else:\n",
    "        phishing_data = pd.DataFrame()\n",
    "        print(\"\\nâš ï¸ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "    phishing_data = pd.DataFrame()\n",
    "    trusted_data = pd.DataFrame()\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœã®ã‚µãƒãƒªãƒ¼\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—çµæœã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not phishing_data.empty:\n",
    "    print(f\"\\nğŸ£ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿:\")\n",
    "    print(f\"  - ç·ä»¶æ•°: {len(phishing_data):,}ä»¶\")\n",
    "    print(f\"  - ã‚½ãƒ¼ã‚¹åˆ¥å†…è¨³:\")\n",
    "    for source, count in phishing_data['source'].value_counts().items():\n",
    "        print(f\"    - {source}: {count:,}ä»¶\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "\n",
    "if not trusted_data.empty:\n",
    "    print(f\"\\nâœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿:\")\n",
    "    print(f\"  - ç·ä»¶æ•°: {len(trusted_data):,}ä»¶\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701de590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:08:16.846641Z",
     "iopub.status.busy": "2026-02-02T13:08:16.846463Z",
     "iopub.status.idle": "2026-02-02T13:08:19.186815Z",
     "shell.execute_reply": "2026-02-02T13:08:19.185956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã‚’é–‹å§‹...\n",
      "\n",
      "ğŸ”„ cert_dataå‹ã®å¤‰æ›...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… memoryviewã‚’bytesã«å¤‰æ›å®Œäº†\n",
      "\n",
      "ğŸ“‹ NULLå€¤ã®å‡¦ç†...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: 365,351 â†’ 365,351 (0ä»¶å‰Šé™¤)\n",
      "  - æ­£å¸¸: 450,545 â†’ 450,545 (0ä»¶å‰Šé™¤)\n",
      "\n",
      "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é–“ã®é‡è¤‡å‡¦ç†...\n",
      "  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã®é‡è¤‡å‰Šé™¤çµæœ:\n",
      "    - phishtank: 53,327 â†’ 17,140 (36,187ä»¶å‰Šé™¤)\n",
      "    - jpcert: 115,866 â†’ 111,755 (4,111ä»¶å‰Šé™¤)\n",
      "    - certificates: 196,158 â†’ 190,075 (6,083ä»¶å‰Šé™¤)\n",
      "\n",
      "ğŸ”„ åŒä¸€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®é‡è¤‡ãƒ‰ãƒ¡ã‚¤ãƒ³å‡¦ç†...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: 318,970 â†’ 318,970 (0ä»¶å‰Šé™¤)\n",
      "  - æ­£å¸¸: 450,545 â†’ 450,545 (0ä»¶å‰Šé™¤)\n",
      "\n",
      "ğŸ” ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿é–“ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯...\n",
      "  âš ï¸ 243ä»¶ã®é‡è¤‡ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æ¤œå‡º\n",
      "  â†’ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤ã—ã¾ã™\n",
      "\n",
      "âš–ï¸ ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹ã®èª¿æ•´...\n",
      "  - æœ€å°ä»¶æ•°: 318,727ä»¶\n",
      "  - èª¿æ•´å¾Œãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: 318,727ä»¶\n",
      "  - èª¿æ•´å¾Œæ­£å¸¸: 318,727ä»¶\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å‡¦ç†\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: artifacts/2026-02-02_220431/raw/prepared_data.pkl\n",
      "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 1089.21 MB\n",
      "\n",
      "ğŸ“‹ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼:\n",
      "â”œâ”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: 2026-02-02_220431\n",
      "â”œâ”€ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿: 318,727ä»¶\n",
      "â”œâ”€ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: 318,727ä»¶\n",
      "â”œâ”€ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: phishtank, jpcert, certificates, trusted_certificates\n",
      "â””â”€ é–‹ç™ºãƒ¢ãƒ¼ãƒ‰: ç„¡åŠ¹\n",
      "\n",
      "âœ¨ 01_data_preparation.py ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ã‚»ãƒ«ç•ªå·: 3\n",
    "æ¦‚è¦: ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã€ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã€ãŠã‚ˆã³ä¿å­˜\n",
    "å…¥åŠ›: phishing_data, trusted_data\n",
    "å‡ºåŠ›: artifacts/<RUN_ID>/raw/prepared_data.pkl (RAW_DIRé…ä¸‹)\n",
    "\"\"\"\n",
    "\n",
    "def validate_and_balance_data(phishing_df: pd.DataFrame, trusted_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ãƒãƒ©ãƒ³ã‚¹èª¿æ•´\n",
    "    \n",
    "    Args:\n",
    "        phishing_df: ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿\n",
    "        trusted_df: æ­£å¸¸ãƒ‡ãƒ¼ã‚¿\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: ãƒãƒ©ãƒ³ã‚¹èª¿æ•´å¾Œã®(ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿, æ­£å¸¸ãƒ‡ãƒ¼ã‚¿)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã‚’é–‹å§‹...\")\n",
    "    \n",
    "    # ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãƒã‚§ãƒƒã‚¯\n",
    "    if phishing_df.empty or trusted_df.empty:\n",
    "        print(\"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™\")\n",
    "        return phishing_df, trusted_df\n",
    "    \n",
    "    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª\n",
    "    required_columns = ['domain', 'cert_data', 'source', 'label']\n",
    "    \n",
    "    for df_name, df in [('phishing', phishing_df), ('trusted', trusted_df)]:\n",
    "        missing_cols = set(required_columns) - set(df.columns)\n",
    "        if missing_cols:\n",
    "            print(f\"âŒ {df_name}ãƒ‡ãƒ¼ã‚¿ã«å¿…é ˆã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {missing_cols}\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # memoryviewã‚’bytesã«å¤‰æ›\n",
    "    print(\"\\nğŸ”„ cert_dataå‹ã®å¤‰æ›...\")\n",
    "    phishing_df = phishing_df.copy()\n",
    "    trusted_df = trusted_df.copy()\n",
    "    \n",
    "    phishing_df['cert_data'] = phishing_df['cert_data'].apply(\n",
    "        lambda x: bytes(x) if isinstance(x, memoryview) else x\n",
    "    )\n",
    "    trusted_df['cert_data'] = trusted_df['cert_data'].apply(\n",
    "        lambda x: bytes(x) if isinstance(x, memoryview) else x\n",
    "    )\n",
    "    print(\"  âœ… memoryviewã‚’bytesã«å¤‰æ›å®Œäº†\")\n",
    "    \n",
    "    # NULLãƒ‡ãƒ¼ã‚¿ã®é™¤å»\n",
    "    print(\"\\nğŸ“‹ NULLå€¤ã®å‡¦ç†...\")\n",
    "    \n",
    "    phishing_before = len(phishing_df)\n",
    "    trusted_before = len(trusted_df)\n",
    "    \n",
    "    phishing_df = phishing_df.dropna(subset=['domain', 'cert_data'])\n",
    "    trusted_df = trusted_df.dropna(subset=['domain', 'cert_data'])\n",
    "    \n",
    "    print(f\"  - ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: {phishing_before:,} â†’ {len(phishing_df):,} ({phishing_before - len(phishing_df):,}ä»¶å‰Šé™¤)\")\n",
    "    print(f\"  - æ­£å¸¸: {trusted_before:,} â†’ {len(trusted_df):,} ({trusted_before - len(trusted_df):,}ä»¶å‰Šé™¤)\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é–“ã®é‡è¤‡é™¤å»ï¼ˆå„ªå…ˆé †ä½: phishtank > jpcert > certificatesï¼‰\n",
    "    print(\"\\nğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é–“ã®é‡è¤‡å‡¦ç†...\")\n",
    "    \n",
    "    # å„ã‚½ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¨˜éŒ²\n",
    "    source_counts_before = phishing_df['source'].value_counts().to_dict()\n",
    "    \n",
    "    # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹ã§é‡è¤‡ã‚’ç¢ºèªã—ã€å„ªå…ˆé †ä½ã«å¾“ã£ã¦ä¿æŒ\n",
    "    # ã‚½ãƒ¼ã‚¹ã®å„ªå…ˆé †ä½ã‚’å®šç¾©\n",
    "    source_priority = {'phishtank': 1, 'jpcert': 2, 'certificates': 3}\n",
    "    phishing_df['priority'] = phishing_df['source'].map(source_priority)\n",
    "    \n",
    "    # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰é‡è¤‡å‰Šé™¤ï¼ˆå„ªå…ˆåº¦ã®é«˜ã„ã‚‚ã®ã‚’æ®‹ã™ï¼‰\n",
    "    phishing_df = phishing_df.sort_values('priority').drop_duplicates(subset=['domain'], keep='first')\n",
    "    phishing_df = phishing_df.drop(columns=['priority'])\n",
    "    \n",
    "    # å„ã‚½ãƒ¼ã‚¹ã®æ®‹å­˜ãƒ‡ãƒ¼ã‚¿æ•°ã‚’ç¢ºèª\n",
    "    source_counts_after = phishing_df['source'].value_counts().to_dict()\n",
    "    \n",
    "    print(\"  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ã®é‡è¤‡å‰Šé™¤çµæœ:\")\n",
    "    for source in ['phishtank', 'jpcert', 'certificates']:\n",
    "        before = source_counts_before.get(source, 0)\n",
    "        after = source_counts_after.get(source, 0)\n",
    "        removed = before - after\n",
    "        print(f\"    - {source}: {before:,} â†’ {after:,} ({removed:,}ä»¶å‰Šé™¤)\")\n",
    "    \n",
    "    # åŒä¸€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®é‡è¤‡ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å‰Šé™¤\n",
    "    print(\"\\nğŸ”„ åŒä¸€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®é‡è¤‡ãƒ‰ãƒ¡ã‚¤ãƒ³å‡¦ç†...\")\n",
    "    \n",
    "    phishing_before = len(phishing_df)\n",
    "    trusted_before = len(trusted_df)\n",
    "    \n",
    "    phishing_df = phishing_df.drop_duplicates(subset=['domain'], keep='first')\n",
    "    trusted_df = trusted_df.drop_duplicates(subset=['domain'], keep='first')\n",
    "    \n",
    "    print(f\"  - ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: {phishing_before:,} â†’ {len(phishing_df):,} ({phishing_before - len(phishing_df):,}ä»¶å‰Šé™¤)\")\n",
    "    print(f\"  - æ­£å¸¸: {trusted_before:,} â†’ {len(trusted_df):,} ({trusted_before - len(trusted_df):,}ä»¶å‰Šé™¤)\")\n",
    "    \n",
    "    # ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿é–“ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯\n",
    "    print(\"\\nğŸ” ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿é–“ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯...\")\n",
    "    \n",
    "    overlapping_domains = set(phishing_df['domain']) & set(trusted_df['domain'])\n",
    "    if overlapping_domains:\n",
    "        print(f\"  âš ï¸ {len(overlapping_domains):,}ä»¶ã®é‡è¤‡ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æ¤œå‡º\")\n",
    "        print(f\"  â†’ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤ã—ã¾ã™\")\n",
    "        phishing_df = phishing_df[~phishing_df['domain'].isin(overlapping_domains)]\n",
    "    else:\n",
    "        print(\"  âœ… ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿é–“ã«é‡è¤‡ãªã—\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹ã®èª¿æ•´ï¼ˆå°‘ãªã„æ–¹ã«åˆã‚ã›ã‚‹ï¼‰\n",
    "    print(\"\\nâš–ï¸ ãƒ‡ãƒ¼ã‚¿ãƒãƒ©ãƒ³ã‚¹ã®èª¿æ•´...\")\n",
    "    \n",
    "    min_count = min(len(phishing_df), len(trusted_df))\n",
    "    print(f\"  - æœ€å°ä»¶æ•°: {min_count:,}ä»¶\")\n",
    "    \n",
    "    if len(phishing_df) > min_count:\n",
    "        # ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆã‚½ãƒ¼ã‚¹ã”ã¨ã®æ¯”ç‡ã‚’ç¶­æŒï¼‰\n",
    "        phishing_df = phishing_df.groupby('source', group_keys=False).apply(\n",
    "            lambda x: x.sample(n=int(len(x) * min_count / len(phishing_df)), random_state=42)\n",
    "        )\n",
    "    \n",
    "    if len(trusted_df) > min_count:\n",
    "        # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "        trusted_df = trusted_df.sample(n=min_count, random_state=42)\n",
    "    \n",
    "    print(f\"  - èª¿æ•´å¾Œãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°: {len(phishing_df):,}ä»¶\")\n",
    "    print(f\"  - èª¿æ•´å¾Œæ­£å¸¸: {len(trusted_df):,}ä»¶\")\n",
    "    \n",
    "    return phishing_df, trusted_df\n",
    "\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ãƒãƒ©ãƒ³ã‚¹èª¿æ•´\n",
    "if not phishing_data.empty and not trusted_data.empty:\n",
    "    phishing_data_balanced, trusted_data_balanced = validate_and_balance_data(phishing_data, trusted_data)\n",
    "else:\n",
    "    print(\"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "    phishing_data_balanced = phishing_data\n",
    "    trusted_data_balanced = trusted_data\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã®æº–å‚™\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å‡¦ç†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ä½œæˆ\n",
    "data_to_save = {\n",
    "    'phishing_data': phishing_data_balanced,\n",
    "    'trusted_data': trusted_data_balanced,\n",
    "    'metadata': {\n",
    "        'session_id': session_id,\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'phishing_count': len(phishing_data_balanced),\n",
    "        'trusted_count': len(trusted_data_balanced),\n",
    "        'data_sources': ['phishtank', 'jpcert', 'certificates', 'trusted_certificates'],\n",
    "        'development_mode': DEVELOPMENT_MODE,\n",
    "        'data_limit': DATA_LIMIT,\n",
    "        'preprocessing': {\n",
    "            'null_removed': True,\n",
    "            'duplicates_removed': True,\n",
    "            'balanced': True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pickleå½¢å¼ã§ä¿å­˜\n",
    "output_file = output_dir / 'prepared_data.pkl'\n",
    "try:\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "    print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª\n",
    "    file_size_mb = output_file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "\n",
    "# ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
    "if 'data_to_save' in locals():\n",
    "    print(\"\\nğŸ“‹ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼:\")\n",
    "    print(f\"â”œâ”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {data_to_save['metadata']['session_id']}\")\n",
    "    print(f\"â”œâ”€ ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿: {data_to_save['metadata']['phishing_count']:,}ä»¶\")\n",
    "    print(f\"â”œâ”€ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: {data_to_save['metadata']['trusted_count']:,}ä»¶\")\n",
    "    print(f\"â”œâ”€ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {', '.join(data_to_save['metadata']['data_sources'])}\")\n",
    "    print(f\"â””â”€ é–‹ç™ºãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if data_to_save['metadata']['development_mode'] else 'ç„¡åŠ¹'}\")\n",
    "\n",
    "print(\"\\nâœ¨ 01_data_preparation.py ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf7e4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:08:19.189196Z",
     "iopub.status.busy": "2026-02-02T13:08:19.189045Z",
     "iopub.status.idle": "2026-02-02T13:08:19.200265Z",
     "shell.execute_reply": "2026-02-02T13:08:19.199597Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Controller APIé–¢æ•° ===\n",
    "from typing import Tuple, Dict, Any\n",
    "import json, hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def _safe_bytes(x):\n",
    "    if isinstance(x, memoryview): return bytes(x)\n",
    "    return x\n",
    "\n",
    "def _quick_cert_parse_error_rate(df: pd.DataFrame, sample_n: int = 200) -> float:\n",
    "    try:\n",
    "        from cryptography import x509\n",
    "        from cryptography.hazmat.backends import default_backend\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "    if df.empty: return 0.0\n",
    "    sub = df.sample(n=min(sample_n, len(df)), random_state=42)\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for b in sub['cert_data']:\n",
    "        b = _safe_bytes(b)\n",
    "        if b is None:\n",
    "            continue\n",
    "        total += 1\n",
    "        try:\n",
    "            x509.load_der_x509_certificate(b, default_backend())\n",
    "        except Exception:\n",
    "            errors += 1\n",
    "    return (errors / max(total, 1)) if total > 0 else 0.0\n",
    "\n",
    "def _save_evidence_store(ph_df: pd.DataFrame, tr_df: pd.DataFrame, out_path: Path) -> Path:\n",
    "    cols = ['domain', 'cert_data', 'source', 'label']\n",
    "    df = pd.concat([ph_df[cols], tr_df[cols]], ignore_index=True) if (not ph_df.empty and not tr_df.empty) else \\\n",
    "         (ph_df[cols] if not ph_df.empty else tr_df[cols] if not tr_df.empty else pd.DataFrame(columns=cols))\n",
    "    def _sha256(b):\n",
    "        b = _safe_bytes(b)\n",
    "        if not isinstance(b, (bytes, bytearray)): return None\n",
    "        return hashlib.sha256(b).hexdigest()\n",
    "    df = df.copy()\n",
    "    df['cert_hash'] = df['cert_data'].map(_sha256)\n",
    "    df.drop(columns=['cert_data'], inplace=True)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "def prepare_data(session_id: str, cfg: Dict[str, Any]) -> Tuple[str, Dict[str, str]]:\n",
    "    try:\n",
    "        if not isinstance(cfg, dict):\n",
    "            return \"INVALID_INPUT\", {\"error\": \"cfgã¯è¾æ›¸å‹ã§æŒ‡å®šã—ã¦ãã ã•ã„\"}\n",
    "\n",
    "        load_configuration(cfg_override=cfg)\n",
    "\n",
    "        out_base = Path(RAW_DIR)  # results â†’ raw ã«çµ±ä¸€\n",
    "        logs_dir = Path(LOGS_DIR) / \"preparation\"\n",
    "        out_base.mkdir(parents=True, exist_ok=True)\n",
    "        logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        import psycopg2\n",
    "        try:\n",
    "            conn = psycopg2.connect(**DB_CONFIG, connect_timeout=int(cfg['db'].get('timeout_s', 30)))\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"DBæ¥ç¶šã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        try:\n",
    "            phishing_list, trusted_df = fetch_labeled_data(conn, DATA_LIMIT)\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        phishing_df = pd.concat(phishing_list, ignore_index=True) if phishing_list else pd.DataFrame(columns=['domain','cert_data','source','label'])\n",
    "\n",
    "        total_records = len(phishing_df) + len(trusted_df)\n",
    "        if total_records < 100:\n",
    "            return \"NOT_FOUND\", {\"error\": f\"ãƒ‡ãƒ¼ã‚¿ä¸è¶³: åˆè¨ˆ{total_records}ä»¶ (<100)\",\n",
    "                                  \"phishing\": str(len(phishing_df)), \"trusted\": str(len(trusted_df))}\n",
    "\n",
    "        parse_err_rate = _quick_cert_parse_error_rate(phishing_df.append(trusted_df, ignore_index=True) if not trusted_df.empty else phishing_df)\n",
    "        if parse_err_rate > 0.10:\n",
    "            return \"INVALID_INPUT\", {\"error\": f\"è¨¼æ˜æ›¸ãƒ‘ãƒ¼ã‚¹å¤±æ•—ç‡ãŒé«˜ã™ãã¾ã™: {parse_err_rate:.1%} (>10%)\"}\n",
    "\n",
    "        try:\n",
    "            ph_bal, tr_bal = validate_and_balance_data(phishing_df, trusted_df)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼/ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        prepared_path = out_base / \"prepared_data.pkl\"\n",
    "        try:\n",
    "            data_to_save = {\n",
    "                'phishing_data': ph_bal,\n",
    "                'trusted_data': tr_bal,\n",
    "                'metadata': {\n",
    "                    'session_id': session_id,\n",
    "                    'created_at': datetime.now().isoformat(),\n",
    "                    'phishing_count': len(ph_bal),\n",
    "                    'trusted_count': len(tr_bal),\n",
    "                    'data_sources': ['phishtank', 'jpcert', 'certificates', 'trusted_certificates'],\n",
    "                    'development_mode': DEVELOPMENT_MODE,\n",
    "                    'data_limit': DATA_LIMIT,\n",
    "                    'preprocessing': {\n",
    "                        'null_removed': True,\n",
    "                        'duplicates_removed': True,\n",
    "                        'balanced': True\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            with open(prepared_path, \"wb\") as f:\n",
    "                import pickle\n",
    "                pickle.dump(data_to_save, f)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"prepared_dataä¿å­˜ã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        evidence_path = out_base / \"evidence_store.parquet\"\n",
    "        try:\n",
    "            _save_evidence_store(ph_bal, tr_bal, evidence_path)\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"evidence_storeä¿å­˜ã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        split_manifest = out_base / \"split_manifest.json\"\n",
    "        prov_manifest = out_base / \"data_provenance.json\"\n",
    "        try:\n",
    "            split = {\n",
    "                \"phishing_count\": len(ph_bal),\n",
    "                \"trusted_count\": len(tr_bal),\n",
    "                \"balanced\": True\n",
    "            }\n",
    "            split_manifest.write_text(json.dumps(split, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "            provenance = {\n",
    "                \"session_id\": session_id,\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"cfg\": cfg,\n",
    "                \"source_tables\": [\"phishtank_entries\", \"jpcert_phishing_urls\", \"certificates\", \"trusted_certificates\"]\n",
    "            }\n",
    "            prov_manifest.write_text(json.dumps(provenance, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            return \"ERROR\", {\"error\": f\"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«å¤±æ•—: {e}\"}\n",
    "\n",
    "        paths = {\n",
    "            \"prepared_data\": str(prepared_path),\n",
    "            \"evidence_store\": str(evidence_path),\n",
    "            \"split_manifest\": str(split_manifest),\n",
    "            \"data_provenance\": str(prov_manifest),\n",
    "            \"logs\": str(logs_dir / \"preparation.log\")\n",
    "        }\n",
    "        return \"OK\", paths\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"ERROR\", {\"error\": f\"æœªå‡¦ç†ä¾‹å¤–: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60439a-633c-4a1c-8358-eca735c30433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61981e-4cd3-49d3-8592-20801ac7b7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f3541-b6f1-4ae2-9c96-0a082515a4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116d22d-6335-4b69-9b9d-a72a95172918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7405dd-be42-446b-91ca-7adc29ca45de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
