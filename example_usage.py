#!/usr/bin/env python3
"""
Phase 2.0 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿä½¿ç”¨ä¾‹

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Phase 2.0ã§ä½œæˆã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦
å®Ÿéš›ã«ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°æ¤œå‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "02_stage1_stage2"))

import numpy as np
import pandas as pd
import json
import joblib

from src.config import load_config
from src.features import FeatureEngineer
from src.train_xgb import Stage1Trainer
from src.route1 import Route1ThresholdSelector
from src.stage2_gate import Stage2Gate

print("="*80)
print("Phase 2.0 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ä¾‹")
print("="*80)

# ========================================
# Step 1: è¨­å®šã¨ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®èª­ã¿è¾¼ã¿
# ========================================
print("\nğŸ“‹ Step 1: è¨­å®šã®èª­ã¿è¾¼ã¿")

# YAMLã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
config_path = "02_stage1_stage2/configs/default.yaml"
cfg = load_config(config_path)
print(f"âœ… Config loaded from: {config_path}")

# æ—¢å­˜ã®artifactsã‚’ä½¿ç”¨ï¼ˆã¾ãŸã¯æ–°ã—ã„RUN_IDã‚’æŒ‡å®šï¼‰
RUN_ID = "2026-01-10_140940"  # æœ€æ–°ã®RUN_IDã«å¤‰æ›´å¯èƒ½
artifacts_dir = Path("artifacts") / RUN_ID

# ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿
brand_keywords_path = artifacts_dir / "models" / "brand_keywords.json"
with open(brand_keywords_path) as f:
    brand_keywords = json.load(f)
print(f"âœ… Brand keywords loaded: {len(brand_keywords)} keywords")

# ========================================
# Step 2: Feature Engineerã®åˆæœŸåŒ–
# ========================================
print("\nğŸ”§ Step 2: Feature Engineerã®åˆæœŸåŒ–")

engineer = FeatureEngineer(brand_keywords=brand_keywords)
print(f"âœ… FeatureEngineer created")
print(f"   Total features: {len(engineer.get_feature_names())}")

# ========================================
# Step 3: æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
# ========================================
print("\nğŸ¯ Step 3: ç‰¹å¾´é‡æŠ½å‡ºã®ä¾‹")

# ä¾‹: æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒªã‚¹ãƒˆ
new_domains = [
    'google.com',
    'paypal-secure.tk',
    'amazon-verify.ml',
    'microsoft-login.xyz',
    'legitimate-site.org'
]

# ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆå®Ÿéš›ã«ã¯CSVã‚„DBã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ãŒå¤šã„ï¼‰
features_list = []
for domain in new_domains:
    features = engineer.extract_features(domain, cert_data=None)
    features_list.append(features)

# DataFrameã«å¤‰æ›
df_new = pd.DataFrame(
    features_list,
    columns=engineer.get_feature_names()
)
df_new['domain'] = new_domains

print(f"âœ… ç‰¹å¾´é‡æŠ½å‡ºå®Œäº†: {len(df_new)} domains")
print(f"\n   ã‚µãƒ³ãƒ—ãƒ«:")
print(df_new[['domain', 'domain_length', 'contains_brand', 'tld_length']].head())

# ========================================
# Step 4: Stage1 XGBoostãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
# ========================================
print("\nğŸ¤– Step 4: Stage1 äºˆæ¸¬")

# ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
model_path = artifacts_dir / "models" / "xgboost_model_baseline.pkl"
trainer = Stage1Trainer(cfg.xgboost)
trainer.load_model(model_path)

# ç‰¹å¾´é‡ã®é †åºã‚’èª­ã¿è¾¼ã¿
feature_order_path = artifacts_dir / "models" / "feature_order.json"
with open(feature_order_path) as f:
    feature_order = json.load(f)

# äºˆæ¸¬
p1 = trainer.predict_proba(df_new, feature_order)
df_new['p1_score'] = p1

print(f"âœ… Stage1 predictions:")
for idx, row in df_new.iterrows():
    print(f"   {row['domain']:30s} â†’ {row['p1_score']:.4f}")

# ========================================
# Step 5: Route1 é–¾å€¤ã§åˆ†é¡
# ========================================
print("\nğŸš¦ Step 5: Route1 é–¾å€¤é©ç”¨")

# æ—¢å­˜ã®é–¾å€¤ã‚’èª­ã¿è¾¼ã¿ï¼ˆã¾ãŸã¯æ–°ã—ãé¸æŠï¼‰
route1_path = artifacts_dir / "results" / "route1_thresholds.json"
if route1_path.exists():
    with open(route1_path) as f:
        thresholds = json.load(f)

    selector = Route1ThresholdSelector(cfg.route1)
    selector.t_low = thresholds['t_low']
    selector.t_high = thresholds['t_high']
    selector.selection_meta = thresholds

    print(f"âœ… Thresholds loaded:")
    print(f"   t_low:  {selector.t_low:.6f}")
    print(f"   t_high: {selector.t_high:.6f}")
else:
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    print("â„¹ï¸  é–¾å€¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    selector = Route1ThresholdSelector(cfg.route1)
    selector.t_low = 0.2
    selector.t_high = 0.8
    selector.selection_meta = {'t_low': 0.2, 't_high': 0.8}

# é–¾å€¤ã‚’é©ç”¨ã—ã¦åˆ†é¡
decisions = selector.apply_thresholds(p1)
df_new['route1_decision'] = decisions

# åˆ†é¡çµæœã‚’ãƒ©ãƒ™ãƒ«ã«å¤‰æ›
decision_map = {0: 'AUTO_BENIGN', 1: 'DEFER', 2: 'AUTO_PHISH'}
df_new['route1_label'] = df_new['route1_decision'].map(decision_map)

print(f"\nâœ… Route1 åˆ†é¡çµæœ:")
print(f"   AUTO_BENIGN: {(decisions == 0).sum()}")
print(f"   DEFER:       {(decisions == 1).sum()}")
print(f"   AUTO_PHISH:  {(decisions == 2).sum()}")

print(f"\n   è©³ç´°:")
for idx, row in df_new.iterrows():
    print(f"   {row['domain']:30s} â†’ {row['route1_label']:12s} (p={row['p1_score']:.4f})")

# ========================================
# Step 6: DEFERé ˜åŸŸã‚’Stage2ã§é¸åˆ¥
# ========================================
print("\nğŸšª Step 6: Stage2 Gateé©ç”¨")

# DEFERé ˜åŸŸã®ã¿ã‚’æŠ½å‡º
df_defer = df_new[df_new['route1_decision'] == 1].copy()

if len(df_defer) > 0:
    print(f"âœ… DEFER candidates: {len(df_defer)}")

    # Stage2 Gateã‚’é©ç”¨
    gate = Stage2Gate(cfg.stage2, brand_keywords)

    # DEFERé ˜åŸŸã®äºˆæ¸¬ã‚¹ã‚³ã‚¢ï¼ˆStage1ã‚’å†åˆ©ç”¨ï¼‰
    p2 = df_defer['p1_score'].values

    # segment_priorityé¸æŠã‚’é©ç”¨
    df_defer = gate.select_segment_priority(df_defer, p2)

    # çµæœã‚’ãƒãƒ¼ã‚¸
    df_new.loc[df_defer.index, 'stage2_decision'] = df_defer['stage2_decision']

    # æœ€çµ‚æ±ºå®šã‚’ä½œæˆ
    df_new['final_decision'] = df_new['route1_label'].copy()
    handoff_mask = df_new['stage2_decision'] == 'handoff'
    df_new.loc[handoff_mask, 'final_decision'] = 'HANDOFF_TO_STAGE3'

    print(f"\nâœ… Stage2 é¸æŠçµæœ:")
    print(f"   Handoff to Stage3: {handoff_mask.sum()}")
    print(f"   PENDING: {(df_new['stage2_decision'] == 'drop_to_auto').sum()}")
else:
    print(f"â„¹ï¸  DEFER candidates: 0 (å…¨ã¦AUTOåˆ†é¡)")
    df_new['stage2_decision'] = None
    df_new['final_decision'] = df_new['route1_label'].copy()

# ========================================
# Step 7: æœ€çµ‚çµæœã®è¡¨ç¤º
# ========================================
print("\n" + "="*80)
print("ğŸ“Š æœ€çµ‚çµæœ")
print("="*80)

print("\nå„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æœ€çµ‚åˆ¤å®š:")
for idx, row in df_new.iterrows():
    print(f"{row['domain']:30s} â†’ {row['final_decision']:20s} (Stage1: {row['p1_score']:.4f})")

print(f"\nå…¨ä½“ã®çµ±è¨ˆ:")
print(df_new['final_decision'].value_counts().to_string())

# ========================================
# Step 8: çµæœã®ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# ========================================
print("\nğŸ’¾ çµæœã®ä¿å­˜")

output_dir = Path("results") / "manual_run"
output_dir.mkdir(parents=True, exist_ok=True)

# CSVã§ä¿å­˜
output_path = output_dir / "predictions.csv"
df_new.to_csv(output_path, index=False)
print(f"âœ… Results saved to: {output_path}")

# çµ±è¨ˆã‚’JSONã§ä¿å­˜
stats = {
    'total_domains': len(df_new),
    'auto_benign': int((df_new['route1_decision'] == 0).sum()),
    'auto_phish': int((df_new['route1_decision'] == 2).sum()),
    'defer': int((df_new['route1_decision'] == 1).sum()),
    'handoff_to_stage3': int((df_new.get('stage2_decision') == 'handoff').sum()),
    'pending': int((df_new.get('stage2_decision') == 'drop_to_auto').sum())
}

stats_path = output_dir / "stats.json"
with open(stats_path, 'w') as f:
    json.dump(stats, f, indent=2)
print(f"âœ… Statistics saved to: {stats_path}")

print("\n" + "="*80)
print("âœ¨ å®Œäº†!")
print("="*80)
print("\nä½¿ã„æ–¹:")
print("  1. new_domainsãƒªã‚¹ãƒˆã‚’å®Ÿéš›ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¤‰æ›´")
print("  2. å¿…è¦ã«å¿œã˜ã¦RUN_IDã‚’æœ€æ–°ã®ã‚‚ã®ã«å¤‰æ›´")
print("  3. python example_usage.py ã§å®Ÿè¡Œ")
print("="*80)
