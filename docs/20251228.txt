教授との打ち合わせ結果を共有します。
私(阿曽村)の研究と論文を感性させるために、next actionを一緒に考えてください。
1. XGBoostを採用するのか、それとも別のモデルにするべきなのか
2. XGBoostをチューニングしていくほうが良さそうなのか
3. XGBoostをチューニングするなら、どのような方針でチューニングすればよいのか
3. 別のモデルなら実現できるのか
4. もっと良い方法をあなたが知っていたらおしえてほしい。

以下、会話記録="""
ご提示いただいた話者情報（話者A＝阿曽村様、話者B＝森先生）を反映し、再度文字起こしを整理しました。

**再生時間:** 35:17
**話者構成:**
*   **阿曽村:** 報告者（学生/エンジニア）
*   **森先生:** 指導者

---

**00:00 阿曽村：**
まず、12月4日にお打ち合わせさせていただいて、その時にXGBoostの箇所のスレッショルド（閾値）をちょっとずつ動かしながら、要するにエージェントに回すFN（False Negative）の数を調整してみましょうという課題がありました。

**00:30 阿曽村：**
そもそもこの研究は何でしたっけというと、第一層はXGBoostを使ってフィッシングサイトと正常サイトを寄り分けて、第二層がエージェントで精査していくという二段構えのシステムです。

**01:09 阿曽村：**
やってみましたというところで、そもそも前提とするデータなんですが、学習に使った後のテストに使う分は12万8000件です。

**01:40 阿曽村：**
閾値0.45の場合は、見逃し（FN）が3843件で、過検知（FP）が1664件ということになります。

**02:03 阿曽村：**
元々は閾値0.5でやっていたので、見逃しが4148件、過検知が1312件というところで、バランス重視というところでした。ちょっとずつずらしてみましょうというところなので、色々試して0.45ぐらいがちょうどいいのかなと思いました。見逃しは3843件、FPが1664件というのが、やや見逃しが削減できると。大胆に0.2まで落とすと、見逃しはすごく減るんですが、逆に過検知が結構出てきます。

**03:07 阿曽村：**
この前見たこの図ですけれども、0.5から0.45なので真ん中の図を左にずらしたような感じです。4148件から3843件に減りました。そして右側の検知できている部分の内訳が、こういう図で表せて、縦軸は数、横軸はプロバビリティ（確率）なんですけれども、ここの0.2から右あたりに、追加シグナルを出して精査を尽くしてみてもいいのかなという風には思えます。AIエージェントの実装方針ですけれども。

**04:19 阿曽村：**
0.45あたりがバランスいいのかなという風には思います。

**04:30 森先生：**
ちょっとマウスのポインタの場所を探しているということでよくわかりました。最初のパイプラインといいますか、最初のマシンラーニングと、その次にエージェントが来るという図があったと思うんですけど。

**04:50 阿曽村：**
これですか？

**04:52 森先生：**
もうちょい前で、あ、そうですね、3ページ目ですね。今回やっているのは、全部やった後にエージェントもやった上での話なんでしょうか？

**05:07 阿曽村：**
CSS（※実験対象の名称等）は全部やっていますね。今日のご報告もちょっと続きがあって、一旦はXGBoostで宿題のところがありますというご報告です。続きがあります。

**05:28 森先生：**
今のはあくまで最初の段階のところだけなんですね。わかりました。

**05:35 阿曽村：**
前回の話は第一層のところで、ここでエージェントに渡すフォールスネガティブ（FN）のデータの数を減らすことができるんじゃないか、というのが話題になったんです。そうすると、AIエージェントというのは計算コストが高いので、そこを減らすことによって全体の性能も上げられるんじゃないですか、というのが話の趣旨でした。

**06:24 森先生：**
その時にフォールスネガティブが減るというのはそうなんですけど、実際、第二層に渡すデータというのは、どういうものを渡すんでしたっけ？

**06:40 阿曽村：**
第二層に渡すデータの種類ですか？

**06:45 森先生：**
数が減るということなんですけど。

**06:50 阿曽村：**
減るというのは、XGBoostでこの閾値をずらすことによって、0.5だと4148件、4000件なんですけれども、0.45にすると3800件になりますねというところですね。

**07:14 森先生：**
答えを知っているとそのフォールスネガティブって言えるんですけど、実際にはわからないわけですよね。

**07:19 阿曽村：**
実際にはわかりませんね。

**07:25 阿曽村：**
わからない場合は、答えは確かに知っているからというところはあるんですが、XGBoostで選り分けていった結果、確信を持ってNGになったものは全部NGとするんだけれども、そうじゃないものはもう一回エージェントに渡すという形になるかなと思います。

**08:21 森先生：**
具体的にはどういう閾値でどれぐらいの数があるっていうのはわかりますかね？

**08:31 阿曽村：**
具体的にはフォールスネガティブの話ですか？ それとも全体？

**08:35 森先生：**
確信を持てないというのは、どういう定義で確信を持てないとして、その数がどれぐらいあるのかと。そこが大事だと思うんですよね。結局そこの部分の数を減らしたいということだと思いますので。

**08:58 阿曽村：**
一旦は、このシステムそのものは、まず一旦、伝統的な機械学習で選り分けて、FNになったものをエージェントで見つけられますかというところをやってみたというのがまず最初にあります。

**09:17 森先生：**
FNになったかどうかっていうのは、わからない場合にどうするかというところが多分肝なんですよね。実際のデータだとそこがわからないので。フォールスネガティブだとわかっている時点で、もう選り分けができちゃっているということなんですよね。

**09:35 阿曽村：**
あとは、説明つくかつかないかというところは、エージェントを使うと説明がつくようになりますというところが一つあります。

**09:54 森先生：**
ご指摘の通り、じゃあ実際、現実世界ではどうやってやっていくんですかというのは考えないといけません。

**10:13 阿曽村：**
じゃあエージェントの性能はどうなんですかというところがあると思うので。まず、さっき言ったフォールスネガティブのところですね。これだけを渡した場合は95%検知できるようになりましたというのが、12月頑張ったところではあります。
内訳は、リスクスコアが全体に低いものと、明確な不正の根拠が少ないもの、正規の認証局を利用しているものというような感じで。正直、人間が見てもちょっと難しいようなものかなとは思います。

**11:05 阿曽村：**
あとは、フォールスネガティブだけじゃなくて全体ですね。フィッシングサイトとフィッシングサイトじゃないデータを混ぜて、ちゃんと選り分けられますかというテストをしました。これは全体の母数を8000件として、フィッシングと普通のサイトを半々でやった結果、まあまあ選り分けられたのかなというところです。True Positiveが4124で、FNが214で、誤検知が24件と。まあまあいい値が出ましたというところですね。

**12:10 森先生：**
ここは非常に良いと思うんですね。エージェント単体でもそれなりの精度が出ますと。これぐらい出て、じゃあ第一層と第二層をどう繋げるかというところが鍵になるのかなと思うんですよね。

**12:25 阿曽村：**
ここですよね。今は、元々の発想が「じゃあこのFNの中身どうなってるんだっけ？ちゃんとこれもっと選り分けられるんだっけ？」というところから入ってしまったので、こういう設計になっているんですよね、最初は。ただ、いろいろ作り直して多少柔軟性は持っているので、ここのデータの与え方を変えればいいのかなという気はしています。

**13:04 森先生：**
確信が持てないものを次に回すというのは正しいと思うんですが、その「確信が持てない」というのを上手く定義できるといいと思うんですよね。さっきの、もうちょっと先のデータで分布があったと思うんですけど、スコアの。青と赤のやつですね。おそらくこういう、0とか1に張り付いているのは確信度が高いと思っていいと思うんですけど、その中間にあるやつっていうのは、ややグレーなところかもしれない。0.5ぐらいが一番曖昧なんですけど、あんまり数はないので、割とどちらかに寄っていると思うんですけど、多分この辺が怪しいと思うんですよね。ここには入らないんですけど。
確信を持ってノーマルと答えた、確信を持ってフィッシングと答えた、それぞれあると思うんですけど、確信を持って…

**14:38 阿曽村：**
あ、これはXGBoostの結果なんで、正解がわかった上での値だから、ここは正しいのかな？ 確信を持って間違えているところは、やっぱりフォールスネガティブのところだけに入っている。

**14:55 森先生：**
あ、そっか、そうですね。どういうのかな、似たような図を書くとわかりやすいかもしれない。

**15:03 阿曽村：**
すみません、ちょっと似たような図を…

**15:05 森先生：**
いやいや、そうじゃなくて私が単純に勘違いしただけで。さっきのこの図で、スコアとしては0か1に張り付いているやつがあって、それは本当はどっちがどっちか実はわかんなくて、正規なのか悪性なのかどちらかを確信を持って出しているんですが、実際には正規だと思っていても本当はフィッシングだったりとか、逆もあるということですよね。

**15:35 阿曽村：**
だから、このフォールスネガティブの中で、さらに自信を持って間違えているところは数値で出ているので、それを拾って特徴を見ていってチューニングするみたいな感じかな。できるのかな、わかんないけど。

**15:52 森先生：**
そうできるといいですね。アイデアとしては、0とか1っていうのは確信度が高いものなんですけど、その確信度が高いやつは絶対に合っててほしいんですね。確信度が高くないやつ、グレーはグレーにしてほしいと。そういう戦略にするといいと思うんですよね。多分ちょっと調べると出てくると思うんですけど。今って無理やりどちらかに抑えていて、ここの曖昧なものを減らしているような訓練になっていると思うんですね。割とこう0か1に寄ってますと。

**16:26 阿曽村：**
そうですね。

**16:28 森先生：**
だけど0と1、もうちょっと増えてもいいよということにすればいいと思うんですよね。

**16:32 阿曽村：**
つまり、今はこれ無理やり0か1って書いてますけど、もうちょっと確信度は減ってもよくて、その代わり真ん中の部分は少し増えてもいいですと。

**16:48 森先生：**
無理やり0か1に頑張って抑えようとしなくてもよくて、本当に確信を持てたやつだけ0か1にすると。

**16:55 阿曽村：**
なるほど。その場合はXGBoostでの性能がちょっと落ちていく可能性がある。

**17:01 森先生：**
それでいいと思います。その代わり、ここが増えすぎちゃいけないんですけども。要はここが多分多いだろうと、ある程度減らすんですけど。

**17:15 阿曽村：**
今6万件とかあるやつが例えば5万件になるかもしれないですと。こっちの6万件が5万件。なので曖昧なのが2万件増えるんですけども、この2万件を第二層でやればいいんじゃないかな。

**17:33 森先生：**
そうですね。確信度を持てないのを第二層に渡したいということだと思いますので、確信度を持てないというのは確率が0とか1ではない、真ん中のやつですと。

**17:49 阿曽村：**
まあ、今これ正解がわかってテストをしていますと。で、次チューニングした後に、正解がわからない状態でこのモデルを使って選り分けた結果を、要するにAIエージェントに渡していけばいいという理解で正しいですかね。

**18:13 森先生：**
はい。もう一回言うと、第一層で、今は0か1って分けようとしていますと。で、目指したいのは、0と判定したのは本当に0、1と判定したのは本当に1。で、真ん中の中間のやつっていうのは、まあ確信度なし。低確信度ですと。その低確信度のものだけ第二層に渡したいので、第一層で目指すのは、0と判定したのは本当に正しく0になっててほしいし、1と判定したのは絶対1になってほしいと。その代わり中間のやつをちょっと増やしてもいいですよ、っていうそういう考え方ですね。グレーな、その、判定保留。

**19:10 阿曽村：**
わかりました。自信を持って間違えているところはまず減らしましょうと。で、そうするとグレー判定が増えるので、それをAIエージェントに渡していきましょうというところですね。自信を持って間違えているところを減らせばいいというのは本当にその通りで、それをもうちょっとさらに言うと、最初のマシンラーニングのところで中間を許容するような訓練をするというか。確信度が、ある程度こう中間のものも許容すると。

**20:11 阿曽村：**
そうですね。本当にできるかよくわかんないんですが。

**20:13 森先生：**
XGBoostじゃなくてモデルを変えるっていうのもあるかもしれない。

**20:16 阿曽村：**
ああ、なるほど、そうか。

**20:19 森先生：**
例えば単純なロジスティック回帰とかでもいいのかもしれないですけど。2値分類って大体0か1のどっちかに寄せようとする訓練をするんですけども、そうじゃなくて予知としては、怪しいものっていうのは無理やり0か1にしないというような最適化の方法もあるはずなんですね。それはAIに聞いてもらえば色々出てくると思うんですけど。中間層が増えすぎても困るんですが、多分そうはならないんじゃないかなっていうのが私の予想なんですね。ある程度この時点でそれなりの精度出てますので、正規は正規、悪性は悪性って多分確固たる特徴があるものはありますと。で、それ以外の微妙に間違っているやつっていうのは、無理やり0か1にせずにグレー判定してほしいという。グレー判定のやつだけAIエージェントに渡すと。

**21:28 阿曽村：**
グレーですね。意図としてはこういう感じ。自信を持って間違えているところはまず減らしましょうと。そうするとグレー判定が増えるので、それをAIエージェントに渡していきましょうという。

**21:49 森先生：**
自信を持って間違えているところを減らせばいいというのは本当にその通りで、それをもうちょっとさらに言うと、最初のマシンラーニングのところで中間を許容するような訓練をするというか。

**22:18 阿曽村：**
今はXGBoostにこだわらずにあれこれやってみれば、もうバシッと出る気がします。

**22:25 森先生：**
最近のLLMで聞きながらやれば、割といいヒント出してくれると思いますし、ローコードとかいいんじゃないかなと思いますので是非。

**22:35 阿曽村：**
戸田さんにLLMなんか使ってコード書くなみたいな感じでちょっとお叱り受けたんで（笑）。

**22:42 森先生：**
いやいやいいですよ。結果わかってれば。見てわかればいいので。コード書く前の設計の部分に関しても、まあ自分は下手に知ってるよりはよく知ってますので。例えばこういう問題設定だったらこういうマシンラーニングモデルがいいよとか。いくつか出してみて、それを戸田君に聞いてみてもいいと思うんですけども。実際にやってしまえば一目瞭然ですので。

**23:16 阿曽村：**
わかりました。ちょっとClaude、実は一回解約しちゃったんですけど、もう一回契約してみようかな。

**23:22 森先生：**
Geminiでもどちらでも。最近、CLIベースのLLMすごくいいので、私も使って結構これに近いようなことやってたりするんですけども、非常に良い精度が出ますね、やっぱり。

**23:42 阿曽村：**
職人技で作ってましたけど、エージェントとか。ちょっとそこはやっておいた方がいい話で、それができた上では後はAIも併用しつつということでいいんじゃないかなと思いますね。

**24:00 阿曽村：**
わかりました。ありがとうございます。時間もありませんので、ちょっと頑張ってやっていきたいと思います。

**24:09 森先生：**
了解しました。

**24:11 阿曽村：**
ありがとうございます。良いお年を。そしてメリークリスマス。

**24:15 森先生：**
はい、良いお年を。ご家族ともお買いください。

**24:18 阿曽村：**
ありがとうございます。また来年も引き続きよろしくお願いします。

**24:22 森先生：**
そうですね、ちょっと結果をまたチャットにちょっとずつ送りつつ、またやっていきたいと思います。

**24:28 阿曽村：**
はい、あの、年末年始は逆に結構時間があって研究に集中できる時期でもありますので、適宜時間があるときにお願いします。

**24:39 森先生：**
はい、ありがとうございます。

**24:41 阿曽村：**
はい、では失礼します。

**24:43 森先生：**
はい、失礼します。お疲れ様です。"""
