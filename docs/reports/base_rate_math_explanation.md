# Base-rate sensitivity の数学 — 教授報告用の予習メモ

作成日: 2026-02-08
目的: prior shift analysis の数式を、直感的に理解できるように解説する

---

## 0. この分析が何をしているか（一言で）

「テストデータの比率を変えたら、Precision はどうなる？」を、
**実験をやり直さずに計算だけで求める**方法。

---

## 1. 出発点: 混同行列から得られる2つのレート

50:50テストの結果:

```
                 予測=フィッシング   予測=正規
実際=フィッシング    TP=62,453        FN=1,158     → 合計 63,611
実際=正規           FP=532           TN=63,079    → 合計 63,611
```

ここから2つの「率」を計算する:

```
TPR = TP / (TP + FN) = 62,453 / 63,611 = 0.9818  （98.18%）
FPR = FP / (FP + TN) = 532 / 63,611   = 0.00836  （0.84%）
```

### これが何を意味するか

- **TPR（真陽性率）**: 「本物のフィッシングを見せたとき、正しく検知する確率」
  - 100件のフィッシングを見せたら、98件を見つけて、2件を見逃す
- **FPR（偽陽性率）**: 「正規サイトを見せたとき、誤ってフィッシングと言ってしまう確率」
  - 100件の正規サイトを見せたら、0.84件を誤報する

### 重要な性質

**TPRとFPRは、入力の比率が変わっても変わらない。**

なぜなら:
- TPR は「フィッシングだけ」を見たときの正解率
- FPR は「正規だけ」を見たときの誤報率
- どちらも「相手のクラスが何件あるか」に影響されない

これが prior shift（事前確率のみ変化）の仮定。

---

## 2. 問題: 比率が変わると何が壊れるか

50:50 のとき:
- フィッシング 63,611件 → うち 532件が誤報に紛れ込む → Precision = 62,453 / (62,453 + 532) = 99.16%

100:1 のとき（正規が100倍）:
- フィッシング 63,611件、正規 6,361,100件
- TPR は変わらない → TP = 0.9818 × 63,611 = 62,453（同じ）
- FPR も変わらない → FP = 0.00836 × 6,361,100 = **53,200**（100倍！）
- Precision = 62,453 / (62,453 + 53,200) = **54.0%**

**正規サイトが増えると、FPの「数」が爆発する。これが base-rate fallacy。**

---

## 3. 数式の導出（ベイズの定理）

### ベイズの定理とは

「結果から原因を推定する」公式。

```
P(原因 | 結果) = P(結果 | 原因) × P(原因) / P(結果)
```

### Precision に適用する

Precision = 「フィッシングと予測したもの」のうち、「本当にフィッシング」の割合

```
Precision = P(本当にフィッシング | フィッシングと予測した)
```

ベイズの定理を使うと:

```
P(y=1 | ŷ=1) = P(ŷ=1 | y=1) × P(y=1) / P(ŷ=1)
```

ここで:
- P(ŷ=1 | y=1) = TPR（フィッシングを正しく検知する率）
- P(y=1) = p（フィッシングの事前確率 = フィッシングの比率）
- P(ŷ=1) = 「フィッシングと予測する全体の確率」

P(ŷ=1) を展開すると:

```
P(ŷ=1) = P(ŷ=1 | y=1) × P(y=1) + P(ŷ=1 | y=0) × P(y=0)
        = TPR × p + FPR × (1-p)
```

つまり「フィッシングと予測する」のは:
- 本物のフィッシングを正しく捕まえた分（TPR × p）と
- 正規サイトを間違えた分（FPR × (1-p)）の合計

### 最終形

```
PPV(p) = TPR × p / (TPR × p + FPR × (1-p))
```

これがメモの式(3)。

### 具体例で検算

p = 0.5（50:50）のとき:
```
PPV = 0.9818 × 0.5 / (0.9818 × 0.5 + 0.00836 × 0.5)
    = 0.4909 / (0.4909 + 0.00418)
    = 0.4909 / 0.4951
    = 0.9915 = 99.15% ✓
```

p = 1/101 ≈ 0.0099（100:1）のとき:
```
PPV = 0.9818 × 0.0099 / (0.9818 × 0.0099 + 0.00836 × 0.9901)
    = 0.00972 / (0.00972 + 0.00828)
    = 0.00972 / 0.01800
    = 0.540 = 54.0% ✓
```

---

## 4. 逆算式 — 「Precision 90% にするには比率いくつ以下？」

PPV(p) の式を p について解く:

```
PPV* = TPR × p / (TPR × p + FPR × (1-p))
```

両辺を展開:
```
PPV* × (TPR × p + FPR × (1-p)) = TPR × p
PPV* × TPR × p + PPV* × FPR - PPV* × FPR × p = TPR × p
PPV* × FPR = TPR × p - PPV* × TPR × p + PPV* × FPR × p
PPV* × FPR = p × (TPR - PPV* × TPR + PPV* × FPR)
PPV* × FPR = p × (TPR × (1 - PPV*) + PPV* × FPR)
```

したがって:
```
p ≥ PPV* × FPR / (TPR × (1 - PPV*) + PPV* × FPR)
```

これがメモの式(5)。

### 具体例

Precision ≥ 90% にしたい（PPV* = 0.90）:
```
p ≥ 0.90 × 0.00836 / (0.9818 × 0.10 + 0.90 × 0.00836)
  = 0.00752 / (0.09818 + 0.00752)
  = 0.00752 / 0.10571
  = 0.0712
```

p ≥ 0.0712 → フィッシングが全体の 7.12% 以上 → 比率で言うと 正規:フィッシング ≤ 13:1

**意味**: CTログの全証明書を入力にすると比率は100:1以上なので、
そのまま本システムに流すと Precision < 54%。
事前フィルタで候補を絞り、実効比率を 13:1 以下にすれば Precision ≥ 90% が達成できる。

---

## 5. F1の計算

F1 は Precision と Recall の調和平均:

```
F1 = 2 × Precision × Recall / (Precision + Recall)
```

Recall = TPR = 0.9818 は比率によらず一定なので、
Precision が下がれば F1 も下がる。

---

## 6. 教授への報告で押さえるべきポイント

1. **50:50 は統制条件としては正しい**。学習・評価の公平性のため
2. **現実の CTログは 100:1〜1000:1** なので、そのまま適用すると Precision が崩壊する（base-rate fallacy）
3. **TPR/FPR は比率に依存しない**（prior shift仮定）ので、ベイズ式で Precision を推定できる
4. **Precision ≥ 90% を維持するには、実効比率 ≤ 13:1 が必要**（逆算式より）
5. **対策**: 事前候補フィルタ（ブランド類似度、TLD絞り込み等）で比率を下げてから本システムに流す
6. **Caveat**: これは prior shift の仮定。CTログの正規ドメインの「特徴分布」がテストセットと異なれば、FPR自体が変わる（covariate shift）。その場合は実データでの追検証が必要

### 想定される教授からの質問と回答

**Q: prior shift の仮定は妥当か？**
A: Stage1 の XGBoost は個々のドメインの特徴量で判定するため、他のドメインの比率に影響されない。ただし、CTログの正規ドメインの分布がテストセットと異なる場合（covariate shift）、FPR が変わりうる。これは §5.2 の注記で明示し、今後の課題としている。

**Q: なぜ実データで再実験しないのか？**
A: CTログ規模の正規ドメインにラベル付けするコストが膨大。代わりにベイズ推定で理論値を示し、実環境データでの追検証を今後の課題とした。

**Q: 事前フィルタで 13:1 に絞れる根拠は？**
A: 本論文のスコープ外だが、ブランド名との編集距離フィルタ、free TLD への限定、DV証明書のみへの絞り込みなどが候補。具体的なフィルタ設計と実効比率の検証は今後の課題。
