# 研究日誌 2026-01-25

## 本日の作業

### パイプライン全体実行 (3 GPU並列)
- 1. run_full_pipeline.sh による全ステップ実行
- 2. Worker 0 vLLM停止バグ修正 (RecoveryManager)
- 3. parallel_config.yaml vLLM設定修正
- 4. GPU速度比に基づくドメイン分割 (speed_weight)

### Stage1 過学習検証
- 5. Stage1 XGBoost の FP=2, FN=8 は過学習か？
- 6. XGBoost単体の実用性検討

### Stage3 AI Agent 改善
- 9. FN削減改善実装 (危険TLD、ブランド検出強化)
- 10. 証明書特徴量のLLM解釈機能追加 (SAN数、CA、有効期間、ワイルドカード)

---

## 1. run_full_pipeline.sh による全ステップ実行

3 GPU (Worker 0,1,2) で全パイプラインを非対話実行:

```bash
./scripts/run_full_pipeline.sh -y --add-gpu 1,2
```

- Step 1-8 (データ準備 → 04-3 LLMツール): 正常完了
- Step 9 (evaluate_e2e_parallel.py): 初回は Worker 1,2 の vLLM 未起動で失敗、再実行で対処

---

## 2. Worker 0 vLLM停止バグ修正

### 問題
- Worker 0 完了後、`stop_on_complete` で vLLM を停止したが、RecoveryManager がヘルスチェック失敗を検知し、vLLM を再起動してしまう

### 修正
`scripts/parallel/orchestrator.py` の `_wait_for_workers` に `health_monitor.remove_port()` を追加:

```python
if wc and wc.stop_on_complete and self.vllm_cluster:
    # ヘルスモニターから除外（Recoveryによる誤再起動を防止）
    if self.health_monitor:
        self.health_monitor.remove_port(wc.port)
    msg = self.vllm_cluster.stop_by_port(wc.port)
```

---

## 3. parallel_config.yaml vLLM設定修正

`vllm.sh` と設定値を統一:

| 項目 | 修正前 | 修正後 |
|------|--------|--------|
| model | Qwen/Qwen3-4B | JunHowie/Qwen3-4B-Thinking-2507-GPTQ-Int8 |
| max_model_len | 8192 | 4096 |
| gpu_memory_utilization | 0.85 | 0.25 |

---

## 4. GPU速度比に基づくドメイン分割

### 実測速度

| Worker | GPU | 実測速度 | speed_weight |
|--------|-----|----------|-------------|
| 0 | RTX 5000 Ada | 9.0 dom/min | 1.59 |
| 1 | RTX 3080 | 10.0 dom/min | 1.77 |
| 2 | RTX 4000 Ada | 5.6 dom/min | 1.00 |

### 実装
- `config.py`: WorkerConfig に `speed_weight` フィールド追加
- `orchestrator.py`: `_split_domains()` を均等分割から重み比例分割に変更
- 全 Worker がほぼ同時に完了するよう最適化

---

## 5. Stage1 XGBoost の FP=2, FN=8 は過学習か？

### 結論: 過学習ではない

### 根拠

**データ分割構造** (`02_main.py` line 1713-1718):
- 全データ: 638,765 サンプル
- Train: 511,012 (80%) → XGBoost 学習用
- Test: 127,754 (20%) → Stage1 判定対象（学習に使用していない）

**保守的な閾値設定**:
```python
'xgb_risk_max_auto_benign': 0.001   # AUTO_BENIGN の FP 許容率 0.1%
'xgb_risk_max_auto_phish': 0.0002   # AUTO_PHISHING の FN 許容率 0.02%
```

**Stage1判定の分布** (test set 127,754件):

| 判定 | 件数 | 割合 | エラー |
|------|------|------|--------|
| AUTO_BENIGN | 6,166 | 4.8% | FN=8 |
| AUTO_PHISHING | 60,614 | 47.4% | FP=2 |
| handoff_to_agent | 60,974 | 47.7% | (Stage2/3へ) |

FP=2, FN=8 は「極めて高い確信度のサンプルだけを AUTO 判定した」結果であり、全体の52%しかカバーしていない。残り48%は判定を保留している。

---

## 6. XGBoost単体の実用性検討

### 疑問
「FP=2, FN=8 なら XGBoost だけで十分では？」

### 回答: 単体では実用不可

**理由1: 48%が未判定**
- handoff 60,974件 (phish=3,257, benign=57,717) に対して判定不能
- ML>0.5 で二値分類すると F1=66.55% しか出ない

**理由2: AUTO判定は「簡単な問題」だけ**
- AUTO_PHISHING: ランダム文字列 + LE証明書 + 危険TLD → ルールでも検出可能
- AUTO_BENIGN: EV/OV証明書 + 有名TLD → 明らかに正規

**理由3: 特徴量の限界**
- ドメイン構造 + 証明書情報のみ（42次元）
- ページ内容・ソーシャルエンジニアリング手法を分析不可
- 正規サブドメイン vs フィッシングの区別不可能（例: `appleid.apple.com` vs `apple-id-verify.com`）

**理由4: 証明書特徴量はゲーム可能**
- 攻撃者がLE以外のCA/長期証明書を使えば回避可能

### 結論
XGBoostの役割は**トリアージ（高速振り分け）**。簡単な52%を効率的に処理し、AI Agentのリソースを「本当に判断が難しい48%」に集中させる分業構造が本研究の核心。

---

## 7. 関連研究調査

査読付き論文を中心に、本研究に類似する過去研究を調査した。詳細は `docs/research/related_work.md` を参照。

### 最も近い先行研究

- **KnowPhish** (USENIX Security 2024): 20Kブランドの知識ベースでフィッシング検出を強化。Trancoドメインリストを使用。ただしロゴ画像ベースでクラウドAPI前提。
- **PhishDebate** (arXiv 2025): 4専門エージェント + Moderator + Judge のマルチエージェント構造。ただしGPT-4レベルの大型LLMを前提。
- **Small LLMs for Phishing** (arXiv 2025): Qwen-2.5-1.5B等の小型LLMでローカル推論。ファインチューニングで精度122%向上。

### 本研究の新規性

1. **3段カスケード (XGBoost → Gate → AI Agent)**: 既存研究は LLM を全件に適用するが、本研究は ML で48%に絞ってから LLM を投入
2. **4B量子化モデルでツール呼び出し型エージェント**: Debate型と異なり、構造化出力で分析ツールを順次実行
3. **証明書の二重活用**: ML特徴量 (Stage1) と LLM解釈 (Stage3) で同じ証明書データを異なる粒度で利用
4. **ドメイン名+証明書のみ、消費者GPU完結**: ページ内容取得不要、8-24GB GPU で推論可能

---

## 8. Stage3 中間性能分析 (32.8%時点)

### 処理進捗 (07:42時点)

| Worker | GPU | 完了 | 進捗 | 速度 | ETA |
|--------|-----|------|------|------|-----|
| 0 | RTX 5000 Ada | 1,831/5,715 | 32.0% | 8.5 dom/min | 15:19 |
| 1 | RTX 3080 | 2,070/6,361 | 32.5% | 9.6 dom/min | 15:09 |
| 2 | RTX 4000 Ada | 1,245/3,594 | 34.6% | 5.8 dom/min | 14:29 |

### Stage3 AI Agent vs ML閾値ベースライン (同一ドメイン集合 n=5,140)

| 指標 | ML閾値 (>0.5) | AI Agent | 差分 |
|------|--------------|---------|------|
| Precision | 0.847 | **0.889** | **+0.042** |
| FP (誤検知) | 92 | **61** | **-33.7%** |
| Recall | 0.566 | 0.541 | -0.025 |
| F1 | 0.678 | 0.673 | -0.006 |

### 考察

- F1 では AI Agent と ML 閾値がほぼ同等（中間時点）
- しかし **FP を33%削減** しており、Precision が有意に改善
- セキュリティシステムでは FP（正規サイト誤ブロック）が最も高コスト → Precision改善は実用上重要
- 前回全件評価では F1=72.5% (ML baseline 66.5%) であり、全件完了後に変化する可能性あり

### 論文での主張軸（暫定）

F1 改善だけに依存しない、多角的な主張構成:

1. **アーキテクチャの効率性**: XGBoost で52%を高速処理 → LLM コスト半減
2. **FP削減**: AI Agent は ML 閾値より FP を33%削減（実運用で最重要）
3. **解釈可能性**: 判定根拠の提示（ブランド偽装、証明書分析等）
4. **小型LLMの実用性**: 4B量子化モデルで消費者GPU (8-24GB) に収まる設計
5. **新規性**: 3段カスケード + ツール呼び出し型エージェント + 証明書二重活用

---

## 9. FN削減改善実装 (Stage3 AI Agent)

### 背景

中間評価 (n=8,826) で FN 739件を分析した結果、52.9%が既存ルールで検出可能であることが判明:

| カテゴリ | FN件数 | 割合 | 対策 |
|---------|--------|------|------|
| ランダムパターン検出可能 | 209 | 28.3% | short_domain_analysis 強化 |
| 危険TLD | 164 | 22.2% | contextual_risk_assessment 強化 |
| 短ドメイン (≤6文字) | 173 | 23.4% | 既存ルールで対応済み |
| ブランド検出済みだが見逃し | 26 | 3.5% | brand_impersonation_check 強化 |
| 明確なシグナルなし | 348 | 47.1% | 将来課題 |

### 実装内容

#### 9.1 危険TLD組み合わせスコアリング (`contextual_risk_assessment.py`)

```python
DANGEROUS_TLDS_CTX: frozenset = frozenset([
    # 超危険 (>50% フィッシング率)
    "top", "xyz", "icu", "buzz", "cfd", "cyou", "rest", "sbs",
    "tk", "ml", "ga", "cf", "gq", "pw",
    # 高危険 (>20% フィッシング率)
    "cn", "cc", "asia", "vip", "shop", "club", "one", "click", "link",
    "online", "site", "website", "lat", "ws", "wang", "bar", "mw", "live",
    # 中危険
    "info", "biz", "mobi", "work", "email", "date", "party", "review",
    "stream", "download", "men", "win", "loan", "science", "kim",
])
```

組み合わせルール:
- 危険TLD + random_pattern/high_entropy → +0.20
- 危険TLD + short/very_short → +0.15
- 危険TLD + brand_detected → +0.25 (最強)
- 上限0.50でクリップ、複数組み合わせは加算

#### 9.2 ブランド検出→phishing判定強化 (`brand_impersonation_check.py`)

```python
# CRITICAL_BRAND_KEYWORDS (110キーワード) に該当するブランドが検出された場合:
# - 危険TLD + critical_brand → 最低リスク 0.50
# - それ以外 + critical_brand → 最低リスク 0.40
```

#### 9.3 統合テスト結果

| テストケース | 検出されたissue | risk_score |
|------------|----------------|------------|
| xkpz2m.top (random+dangerousTLD) | short_random_combo | 0.60 |
| ab.xyz (very_short+dangerousTLD) | very_short_dangerous_combo | 0.60 |
| x7k.icu (combo) | dangerous_tld_combo (random+short) | 0.595 |
| ezpass-renew.top (critical_brand) | critical_brand_dangerous_tld | 0.50 |
| connexion-verification-compte.top | high_risk_words (multilingual) | 0.52 |

### 既に実装済みの改善 (2026-01-24)

1. **ランダム検出強化** (`short_domain_analysis.py`)
   - 子音クラスター検出 (`_count_consonant_clusters`)
   - レアバイグラム分析 (`_rare_bigram_ratio`)
   - 短いドメイン (≤8文字) のエントロピー閾値引き下げ (4.0→3.5)

2. **多言語キーワード** (`contextual_risk_assessment.py`)
   - MULTILINGUAL_RISK_WORDS (60+キーワード)
   - フランス語/ポルトガル語/スペイン語/ドイツ語/イタリア語対応

3. **CRITICAL_BRAND_KEYWORDS拡張** (`brand_impersonation_check.py`)
   - 110キーワード (ポルトガル/フランス/スペイン/北米/配送/暗号通貨/欧州銀行)

---

## 10. 証明書特徴量のLLM解釈機能追加

### 背景

SAN数分析（セクション14 of `stage3_certificate_analysis_report.md`）で発見した知見:
- SAN=2 は Benign indicator (61.5%がBenign、Phishing率11.3%)
- SAN=1 + 危険TLD は高リスク (79.6%がPhishing)
- SAN≥11 は予想外に高リスク (35-45%がPhishing)

これらをルールとして実装するとFPが407件増加（F1が0.665→0.619に悪化）。
代わりに、LLMに解釈情報を提供し、動的に判断させるアプローチを採用。

### 実装内容 (`certificate_analysis.py`)

4つの解釈関数を追加:

#### 10.1 SAN数の解釈 (`_interpret_san_count`)

```python
# SAN=1 + 危険TLD: 79.6%がPhishing → [SAN RISK]
# SAN=2: 61.5%がBenign、最も安全 → [SAN SAFE]
# SAN≥11: 予想外に35-45%がPhishing → elevated risk
```

#### 10.2 CA解釈 (`_interpret_ca`)

```python
# DigiCert/GlobalSign: 有料CA、信頼度高 → [CA TRUSTED]
# Let's Encrypt: 中立（正規57.9%、Phishing 92.4%で使用）
# ZeroSSL/cPanel: 無料、Phishingで多用 → [CA CAUTION]
```

#### 10.3 有効期間解釈 (`_interpret_validity`)

```python
# 90日: Let's Encrypt標準、判別困難
# 180-365日: やや信頼度高 → [VALIDITY SAFE]
# 365日超: 長期有効、Benign indicator
```

#### 10.4 ワイルドカード解釈 (`_interpret_wildcard`)

```python
# 安全TLD + wildcard: 正規55.1%使用、Phishing 1.5% → [WILDCARD SAFE]
# 危険TLD + wildcard: 逆にリスク → [WILDCARD RISK]
```

### 出力形式

`details` に解釈辞書を追加:
```python
details["san_interpretation"] = {
    "san_count": 2,
    "risk_level": "low",
    "explanation": "SAN=2: Standard configuration...",
    "is_benign_indicator": True,
    "is_risk_indicator": False
}
```

`reasoning` に重要な解釈を追加:
```
... || INTERPRETATIONS: [SAN SAFE] SAN=2: Standard configuration...
```

### 設計思想

- **ルールではなくLLMへの情報提供**: 硬直したルールはFPを増加させるが、LLMに解釈を提供することで文脈に応じた柔軟な判断が可能
- **研究知見の組み込み**: SAN数分析で得られた統計的知見をLLMが活用できる形式で提供
- **拡張性**: 新たな知見が得られれば解釈関数を追加するだけで対応可能

---

## 次回の作業予定

- Stage3 AI Agent 再評価（3GPU並列）→ Before/After 比較
- F1 72.5% → 78-81% の改善目標に向けた検証
- FP増加がないことを確認
