
---

## 背景

フィッシング検知の現実運用では、次の難しさがあります。

* 正常サイトが圧倒的に多く、誤検知を増やすと業務影響が大きい
* 一方で見逃し（フィッシングを見逃す）はセキュリティ事故に直結する
* 正解ラベルは運用時点では分からないことが多い
* さらに「本物の正規ドメイン配下の悪用」や「見た目が普通のドメイン」など、機械学習が苦手なケースが混じる

このため、単一モデルで全件を0/1決めると、誤検知を抑えるほど見逃しが残り、見逃しを抑えるほど誤検知が増える、というトレードオフが厳しくなります。

---

## 目的

あなたのシステムは、これを段階的に解く設計です。

* Stage1で全件を高速にスクリーニングし、明らかなものは自動判定する
* 明らかでないものはDEFERとして切り出す
* DEFERを次段で責任を持って裁くことで、見逃しを減らしつつ誤検知を抑える
* ただし運用では未処理をbenign確定にして通さない。未確定は未確定として責任ある扱いを定義する

研究としては、特に次が目的になります。

* 高確信AUTO領域の誤りを極小化しつつ
* DEFER領域の見逃しを後段で回収できる状態を作る
* その際の計算コスト（Stage3の負荷）を予算で制御できることを示す

---

## システム構成の要点

### Stage1（XGBoost）

* 目的は高速スクリーニング
* 高確信領域だけをAUTO（benign/phish）に確定
* 中間（グレー）はDEFERにして次へ

02系 ipynb では、Stage1の結果が stage1_decisions_latest.csv と route1_thresholds.json として出ます。

### Stage2（LRとゲート）

* Stage1=DEFER候補集合の中で優先度を付ける
* Stage3に回す件数をbudgetで制御する
* 未処理は未確定として残すべきで、benign確定にはしない

02系 ipynb では、Stage2の候補と決定が stage2_decisions_candidates_latest.csv と stage2_decisions_latest.csv に出ます。

### Stage3（AIエージェント）

* コストは高いが、追加の証拠や説明を使って精査する
* Stage1/Stage2で残る難例を裁く役割

今回はスコープ外（03系）なので変更しない前提です。

---

## いまやっている作業

現在の中心は「Stage2に残る誤り」を減らし、システムとして成立させることです。具体的には次の作業をしています。

1. 02系 ipynb の出力が想定通りかを成果物で確認

* Stage1のAUTO/DEFER件数
* Stage2の候補数、選抜数、誤り回収の規模

2. Stage2に残った誤り（FN/FP）の内訳を定量化

* DEFER内にどれだけ誤りが残るか
* それが「選抜ロジックの問題」か「モデルの限界」かを切り分ける

3. brand特徴が機能しているかを必ず検証

* DEFER候補集合でbrand_hitが全件0なら壊れている
* brand_hit=1の具体例を出し、辞書や照合方法の問題を特定する

4. 必要なら最小修正（02系のみ）で改善し、再実行・比較表で示す

* 出力互換性を壊さず、CHANGELOGを必ず残す
* 方式変更は勝手にしない。変更が必要なら先に提案し承認を取る

---

## これからの課題

課題は大きく3つに分かれます。

### 課題1 Stage2に残る誤りの扱いをシステム仕様として固定する

いくらStage2を改善しても、budget制約がある限り未処理は必ず残ります。
この未処理をbenign扱いで通すと、見逃しが事故になります。

したがって

* 未処理DEFERは隔離、警告、後追い解析、人手などに必ず回す
* どの段で最終責任を持つかを明確化する
  が必須です。

### 課題2 Stage2の改善余地を見極める

残っている誤りが

* 特徴量不足で改善できるもの
* 人間でもドメインだけでは判別困難なもの
* ラベル品質や時間ズレの疑いがあるもの
  のどれかを切り分ける必要があります。

この切り分けができると、研究としての説得力が上がります。

* 改善できるなら改善案と効果を実証
* 改善困難なら、なぜ困難かと調査方針を示す

### 課題3 Stage3のコスト制約下で回収が成立する設計にする

Stage3を無制限に回す設計は現実的ではないので

* Stage2で優先順位を付けて、限られた件数だけ回す
* それで見逃し回収が桁として成立する
* その時の誤検知増や未処理の扱いが定義されている
  ことを示す必要があります。

---

## まとめ

このシステムの狙いは、単一モデルでは解けない「誤検知と見逃しのトレードオフ」を、段階構造で現実的に制御することです。

いまの作業は、Stage1/Stage2（02系）の出力と誤り残りを定量化し、ブランド特徴などの基盤が壊れていないかを検証し、必要最小限の修正で「回収が成立する状態」に戻すことです。

これからの課題は、Stage2に残る誤りをどう扱うかの仕様化、改善可能性の切り分け、そしてStage3予算下で回収が成立する設計と実証です。


### 追記  
あと、データの0/1が本当なのかどうかもチェックしていく必要がある。検知不能なデータの中には誤りだったから、という理由もあるかもしれない。


### 追記に対するメッセージ

その通りです。いまの段階だと「Stage2に残るFN/FPが多い」こと自体は観測できていますが、そのうち一部はモデルの限界ではなく、ラベル0/1自体が誤っている、あるいは時間軸のズレで現時点では妥当でなくなっている可能性があります。ここを切り分けないと、改善余地の評価も誤ります。

以下、研究として筋が良く、かつ運用上も現実的な「ラベル監査の枠組み」を提案します。

---

## なぜラベル監査が必要か

02系の特徴量は主にドメインと証明書由来で、URLパスや当時のコンテンツ、当時の検知状況までは持っていません。すると、次の現象が起きやすいです。

* 実際は「特定のURLパスだけが悪性」なのに、ドメイン単位のラベルが1になっている
  例: 正規ドメイン配下に悪性ページが一時的に置かれた
* フィッシングとして収集されたが、検体が古く、現在は安全化済みで外部サービスにヒットしない
  例: すでに消えている、別用途に再利用された
* benign側も同様に、後で悪性化した、誤ってtrustedに入った等

この状態だと、Stage2で残った「難例」が本当に難例なのか、単にラベルが不安定なのかが分からなくなります。

---

## ラベル0/1の検証方針（現実的かつ再現可能）

### レベル1 自動照会で裏取り（低コスト、広く）

対象

* Stage2に残ったFNを優先（見逃し側が重大）
* 次に Stage2に残ったFP（誤検知側の説明用）

照会先候補（無料・低コストで実行可能な順）

* Google Transparency Report Safe Browsing（Webの照会画面）
* PhishTank（ドメインが載っているかの照会）
* urlscan.io（公開検索、ヒットがあれば証拠として強い）
* 可能なら VirusTotal（Web照会。大量自動は制限があるのでサンプル中心）

判定ルール（研究で説明できる形）

* 2種類以上の独立した外部ソースで「悪性」寄りの証拠が一致したら、ラベル1の妥当性が高い
* どのソースにも痕跡がなく、かつドメインが正規サイトとしての活動を示す場合は「ラベル疑義」候補にする
* 判定不能（情報なし）は「不明」として残す

成果物

* domainごとの照会結果テーブル（timestamp、ソース、結果、根拠URLやスクショの保存先）

重要
外部照会は時間依存です。必ず照会日時をログに残し、研究では「照会時点での状態」として扱う必要があります。

---

### レベル2 手動レビューの優先順位付け（少数に絞って深掘り）

全件は無理なので、優先順位を付けます。

優先度A（ラベル誤りの可能性が高い）

* 正規大手ドメイン配下に見えるもの
* sourceがtrusted側なのにラベル1、あるいはその逆など、ソースとラベルが矛盾しているもの
* 証明書の組織情報がしっかり入っているのにラベル1、かつ他ソースにも痕跡が薄いもの

優先度B（本当に難例かの確認に価値がある）

* ドメイン文字列も証明書も普通だがラベル1で、外部照会が不明なもの
  これは「特徴量不足の可能性」か「ラベル誤り」かを分けるために重要

成果物

* 優先度Aから上位N件を抽出し、調査票を作る（domain、source、ml_probability、p_error、証明書要約、外部照会結果欄）

---

## 02系でできることと、できないこと

02系だけでできる

* FN/FPのリストアップと優先順位付け
* 外部照会に回す対象抽出（上位100件など）
* 結果を取り込んで「ラベル疑義率」を推定し、実験結果の解釈に反映する

02系だけでは難しい

* 大量の外部照会の自動化（レート制限、APIキー）
* URLパス単位の検証やコンテンツ取得（安全な隔離環境が必要）
* 時系列での状態変化の追跡（継続観測が必要）

---

## これからの課題としての位置づけ

今後の分析は、次の3分類に落とすと整理しやすくなります。

1. 改善可能な検知漏れ
   特徴量や学習で拾える。Stage2 LR改善やbrand強化で減らせる。

2. 特徴量不足による限界
   ドメインと証明書だけでは難しい。Stage3や外部特徴が必要。

3. ラベル疑義
   モデルの限界ではなく、正解ラベルの品質・時間ズレが原因の可能性が高い。
   ここは「改善しても伸びない」領域なので、研究として明確に分けて説明する価値が高い。

---

## 次にこちら側でやるべき具体タスク案

あなたのデータ（Stage2に残ったFN/FP一覧CSV）を入力にして、こちらで

* FN/FPを分けた一覧CSVを作成
* 優先度A（ラベル疑義）候補を上位50〜100件抽出
* 外部照会用の入力リストを生成（1回で回せる形式）
* 照会結果を取り込むためのテンプレCSV（domain, source, check_time, service, verdict, evidence）を作成

まで一気に作れます。

外部照会の自動化については、APIキー無しで大量実行は難しいので、まずは

* 上位20〜50件を人手で照会し、ラベル疑義率の見積もりを出す
  が現実的です。

必要なら、あなたが一回で回せるように、上位N件を対象にした照会スクリプト案（Web照会の自動化は慎重に、アクセス間隔や回数制限を明記）も提示します。

